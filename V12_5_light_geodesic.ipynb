{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba92b65f",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "# Step 1: Introduction, Core Physics, and Project Goals\n",
    "\n",
    "This notebook is a self-contained tutorial that uses the `nrpy` library to construct a complete C-language project for integrating photon geodesics in curved spacetimes. The resulting C code is a flexible, high-performance ray-tracing engine capable of generating gravitationally lensed images of distant sources as seen by an observer near a black hole.\n",
    "\n",
    "The core of the project is the numerical solution of the geodesic equation, which describes the path of a free-falling particle (or photon) through curved spacetime. The geodesic equation, as detailed on [Wikipedia](https://en.wikipedia.org/wiki/Geodesic_equation), is a second-order ordinary differential equation (ODE) that relates a particle's acceleration to the spacetime curvature, represented by the Christoffel symbols ($\\Gamma^{\\alpha}_{\\mu\\nu}$):\n",
    "\n",
    "$$ \\frac{d^2x^{\\alpha}}{d\\lambda^2} = -\\Gamma^{\\alpha}_{\\mu\\nu} \\frac{dx^{\\mu}}{d\\lambda} \\frac{dx^{\\nu}}{d\\lambda} $$\n",
    "\n",
    "Here, $x^\\alpha = (t, x, y, z)$ are the spacetime coordinates, and $\\lambda$ is the affine parameter, which measures the proper distance along the path for a massive particle or a suitable path parameter for a photon.\n",
    "\n",
    "### The Reverse Ray-Tracing Transformation\n",
    "\n",
    "To render an image of what an observer sees, we must trace the photon's path from the observer's camera *backwards in time* to its source. While we could integrate the geodesic equation with a negative step `dλ < 0`, most ODE solvers are optimized for forward integration with a positive step. To accommodate this, we perform a change of variables on the affine parameter. We define a new parameter, $\\kappa$, that increases as the original parameter, $\\lambda$, decreases:\n",
    "\n",
    "$$ \\kappa = -\\lambda \\implies d\\kappa = -d\\lambda \\implies \\frac{d}{d\\lambda} = -\\frac{d}{d\\kappa} $$\n",
    "\n",
    "We now substitute this transformation directly into the second-order geodesic equation:\n",
    "\n",
    "$$ \\frac{d}{d\\lambda}\\left(\\frac{dx^{\\alpha}}{d\\lambda}\\right) = -\\Gamma^{\\alpha}_{\\mu\\nu} \\frac{dx^{\\mu}}{d\\lambda} \\frac{dx^{\\nu}}{d\\lambda} $$\n",
    "\n",
    "Applying the chain rule, $\\frac{d}{d\\lambda} = -\\frac{d}{d\\kappa}$:\n",
    "\n",
    "$$ \\left(-\\frac{d}{d\\kappa}\\right)\\left(-\\frac{dx^{\\alpha}}{d\\kappa}\\right) = -\\Gamma^{\\alpha}_{\\mu\\nu} \\left(-\\frac{dx^{\\mu}}{d\\kappa}\\right) \\left(-\\frac{dx^{\\nu}}{d\\kappa}\\right) $$\n",
    "\n",
    "The negatives on both sides cancel, yielding the reverse-time geodesic equation:\n",
    "\n",
    "$$ \\frac{d^2x^{\\alpha}}{d\\kappa^2} = -\\Gamma^{\\alpha}_{\\mu\\nu} \\frac{dx^{\\mu}}{d\\kappa} \\frac{dx^{\\nu}}{d\\kappa} $$\n",
    "\n",
    "This equation has the same form as the original, but describes the path integrated with respect to $\\kappa$. To solve it numerically, we now decompose this second-order ODE into a system of coupled first-order ODEs. We define the **reverse-time momentum**, $p^\\alpha$, as the 4-velocity with respect to our new parameter $\\kappa$:\n",
    "\n",
    "$$ p^{\\alpha} \\equiv \\frac{dx^{\\alpha}}{d\\kappa} $$\n",
    "\n",
    "This definition immediately gives us our first ODE. We find the second by substituting $p^\\alpha$ into the reverse-time geodesic equation:\n",
    "\n",
    "$$ \\frac{d}{d\\kappa}\\left(\\frac{dx^{\\alpha}}{d\\kappa}\\right) = -\\Gamma^{\\alpha}_{\\mu\\nu} \\left(\\frac{dx^{\\mu}}{d\\kappa}\\right) \\left(\\frac{dx^{\\nu}}{d\\kappa}\\right) \\implies \\frac{dp^{\\alpha}}{d\\kappa} = -\\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} $$\n",
    "\n",
    "This gives us the final set of ODEs that our C code will solve. We also add a third ODE to track the total proper distance traveled by the photon along its spatial path, using the spatial part of the metric $\\gamma_{ij}$:\n",
    "\n",
    "1.  **Position ODE**: $\\frac{dx^{\\alpha}}{d\\kappa} = p^{\\alpha}$\n",
    "2.  **Momentum ODE**: $\\frac{dp^{\\alpha}}{d\\kappa} = -\\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu}$\n",
    "3.  **Path Length ODE**: $\\frac{dL}{d\\kappa} = \\sqrt{\\gamma_{ij} \\frac{dx^i}{d\\kappa} \\frac{dx^j}{d\\kappa}} = \\sqrt{\\gamma_{ij}p^{i}p^{j}}$\n",
    "\n",
    "### Initial Conditions\n",
    "\n",
    "The initial value of the reverse-time momentum, $p^\\alpha_{\\text{initial}}$, determines the starting direction of the ray traced from the camera. It is physically equivalent to the *negative* of the final momentum of a photon that started at a distant source and ended its journey at the camera. If we denote the physical, forward-time 4-velocity as $k^\\alpha = dx^\\alpha/d\\lambda$, then:\n",
    "\n",
    "$$ p^\\alpha_{\\text{initial}} = \\left(\\frac{dx^\\alpha}{d\\kappa}\\right)_{\\text{initial}} = -\\left(\\frac{dx^\\alpha}{d\\lambda}\\right)_{\\text{final}} = -k^\\alpha_{\\text{final}} $$\n",
    "\n",
    "This relationship is key: setting the initial conditions for our reverse-time integration is equivalent to choosing the final momentum of a physically forward-propagating photon arriving at the camera.\n",
    "\n",
    "This notebook follows a modular, single-responsibility design pattern. It uses the `nrpy` library to first define the underlying physics symbolically, and then automatically generates a series of interoperable C functions, each with a specific job. This makes the final C project clear, efficient, and easily extensible.\n",
    "\n",
    "**Notebook Status:** <font color='green'><b>Validated</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bac0cb",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "This notebook is organized into a series of logical steps that build the complete C project from the ground up. Each step focuses on a specific aspect of the architecture, from pure mathematics to the final compiled executable.\n",
    "\n",
    "1.  [Step 1: Introduction, Core Physics, and Project Goals](#introduction)\n",
    "2.  [Step 2: Project Initialization and Parameter Definition](#initialize)\n",
    "3.  [Step 3: The Symbolic Core - Defining the Physics with `nrpy` and `sympy`](#symbolic_core)\n",
    "    *   [3.a: Symbolic Recipe for Metric Tensor Derivatives](#deriv_g4DD)\n",
    "    *   [3.b: Symbolic Recipe for Christoffel Symbols (Analytic Metrics)](#four_connections)\n",
    "    *   [3.c: Symbolic Recipe for the Geodesic Momentum ODE](#geodesic_mom_rhs)\n",
    "    *   [3.d: Symbolic Recipe for the Geodesic Position ODE](#geodesic_pos_rhs)\n",
    "    *   [3.e: Symbolic Recipe for the Path Length ODE](#proper_len_rhs)\n",
    "    *   [3.f: Symbolic Recipe for the Null Condition (Calculating p⁰)](#geodesic_mom0_calc)\n",
    "    *   [3.g: Symbolic Recipes for Conserved Quantities (E, L, Q)](#conserved_quantities)\n",
    "    *   [3.h: Symbolic Recipes for Numerical Metrics](#numerical_recipes)\n",
    "4.  [Step 4: Spacetime Definitions (Analytic Metrics)](#spacetime_definition)\n",
    "5.  [Step 5: Symbolic Workflow Execution](#symbolic_execution)\n",
    "6.  [Step 6: C Code Generation - Physics Engines and Workers](#generate_c_engines)\n",
    "    *   [6.a: C Workers for Analytic Metrics](#analytic_workers)\n",
    "    *   [6.b: C Engines and Workers for Numerical Metrics](#numerical_workers)\n",
    "    *   [6.c: Generic Physics and Integration Engines](#generic_engines)\n",
    "7.  [Step 7: C Code Generation - Orchestrators and Dispatchers](#generate_c_orchestrators)\n",
    "8.  [Step 8: Project Assembly and Compilation](#assemble_project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c0d30",
   "metadata": {},
   "source": [
    "<a id='initialize'></a>\n",
    "# Step 2: Project Initialization and Parameter Definition\n",
    "\n",
    "This cell sets up the foundational elements for our entire project. It performs three key tasks:\n",
    "\n",
    "1.  **Import Libraries**: We import necessary modules from standard Python libraries (`os`, `shutil`, `sympy`) and the core components of `nrpy`. The `nrpy` imports provide tools for C function registration, C code generation, parameter handling, and infrastructure management.\n",
    "\n",
    "2.  **Directory Management**: A clean output directory, `project/photon_geodesic_integrator/`, is created to store the generated C code, ensuring a fresh build every time the notebook is run.\n",
    "\n",
    "3.  **Physical and Runtime Parameter Definition**: We define the many parameters that control the simulation using `nrpy`'s parameter management system. This is the central mechanism for defining a runtime parameter that will be accessible in the generated C code. The `nrpy` build system uses this registry of parameters to automatically construct C data structures, a default parameter file, and a robust command-line parser.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.params.set_parval_from_str(par_name, value)`**:\n",
    "    *   **Source File**: `nrpy/params.py`\n",
    "    *   **Description**: Sets the value of a core `nrpy` parameter. Here, it is used to specify that we are using the `BHaH` (BlackHoles@Home) C code generation infrastructure, which governs how files are organized and how the `Makefile` is constructed.\n",
    "\n",
    "*   **`nrpy.params.register_CodeParameter(c_type, module, name, default_value, **kwargs)`**:\n",
    "    *   **Source File**: `nrpy/params.py`\n",
    "    *   **Description**: This is the primary function for registering a C-level parameter. It creates a parameter object that holds all its properties and stores it in a global registry.\n",
    "    *   **Key Inputs**:\n",
    "        *   `c_type`: The data type of the parameter in the C code (e.g., `\"REAL\"`, `\"int\"`).\n",
    "        *   `module`: The name of the Python module where the parameter is defined (usually `__name__`).\n",
    "        *   `name`: The C variable name for the parameter.\n",
    "        *   `default_value`: The default value for the parameter.\n",
    "    *   **Key Keyword Arguments (`kwargs`)**:\n",
    "        *   `commondata=True`: Specifies that the parameter is \"common\" to the entire simulation (e.g., black hole mass `M_scale`). It will be stored in the `commondata_struct` in the generated C code. If `False`, it's stored in the grid-specific `params_struct`.\n",
    "        *   `add_to_parfile=True`: Instructs the build system to add an entry for this parameter to a default parameter file, making it easy to configure at runtime.\n",
    "        *   `add_to_set_CodeParameters_h=True`: This is a crucial flag that enables the \"automatic unpacking\" mechanism. It tells `nrpy` to add an entry for the parameter to the `set_CodeParameters.h` convenience header. Any C function registered with `include_CodeParameters_h=True` will get a local `const REAL` variable with the same name as the parameter, making the C code clean and readable. This is handled by the `nrpy.infrastructures.BHaH.CodeParameters` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f07e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Registering CodeParameters for the Time Slot Manager...\n",
      "-> Registering CodeParameters for adaptive window grids...\n",
      "-> Registering CodeParameters for the disk bounding box...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sympy as sp\n",
    "\n",
    "# NRPy-related imports for C-code generation\n",
    "import nrpy.c_function as cfc\n",
    "import nrpy.c_codegen as ccg\n",
    "import nrpy.params as par\n",
    "import nrpy.indexedexp as ixp\n",
    "import nrpy.infrastructures.BHaH.BHaH_defines_h as Bdefines_h\n",
    "import nrpy.infrastructures.BHaH.Makefile_helpers as Makefile\n",
    "from nrpy.infrastructures.BHaH import cmdline_input_and_parfiles\n",
    "import nrpy.helpers.generic as gh\n",
    "import nrpy.infrastructures.BHaH.CodeParameters as CPs\n",
    "\n",
    "\n",
    "# Set project name and clean the output directory\n",
    "project_name = \"photon_geodesic_integrator\"\n",
    "project_dir = os.path.join(\"project\", project_name)\n",
    "shutil.rmtree(project_dir, ignore_errors=True)\n",
    "\n",
    "# Set NRPy parameters for the BHaH infrastructure\n",
    "par.set_parval_from_str(\"Infrastructure\", \"BHaH\")\n",
    "\n",
    "# --- Core Simulation & Physics Parameters ---\n",
    "# Register single integer and boolean parameters\n",
    "_ = par.register_CodeParameter(\"int\", __name__, \"metric_choice\", 0, add_to_parfile=True, commondata=True)\n",
    "use_numerical_pipeline = par.register_CodeParameter( \"bool\", __name__, \"use_numerical_pipeline\", False, add_to_parfile=True, commondata=True )\n",
    "_ = par.register_CodeParameters(\n",
    "    \"bool\", __name__,\n",
    "    [\"perform_conservation_check\", \"debug_mode\"],\n",
    "    False,  # Assign False to both\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "\n",
    "# Register physical parameters for the black hole.\n",
    "# Note: These need add_to_set_CodeParameters_h=True\n",
    "M_scale, a_spin = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"M_scale\", \"a_spin\"],\n",
    "    [1.0, 0.0],\n",
    "    add_to_parfile=True, commondata=True, add_to_set_CodeParameters_h=True\n",
    ")\n",
    "\n",
    "# --- Universal Camera System Parameters ---\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"camera_pos_x\", \"camera_pos_y\", \"camera_pos_z\"],\n",
    "    [0.0, 0.0, 51.0],\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"window_center_x\", \"window_center_y\", \"window_center_z\"],\n",
    "    [0.0, 0.0, 50.0],\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"window_up_vec_x\", \"window_up_vec_y\", \"window_up_vec_z\"],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "\n",
    "# --- Independent Source Plane Definition ---\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"source_plane_normal_x\", \"source_plane_normal_y\", \"source_plane_normal_z\"],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "# Use a single default value for all center coordinates\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"source_plane_center_x\", \"source_plane_center_y\", \"source_plane_center_z\"],\n",
    "    0.0,\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"source_up_vec_x\", \"source_up_vec_y\", \"source_up_vec_z\"],\n",
    "    [0.0, 1.0, 0.0],\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"source_r_min\", \"source_r_max\"],\n",
    "    [6.0, 25.0],\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "\n",
    "# --- General Ray-Tracing & Integration Parameters ---\n",
    "_ = par.register_CodeParameter(\"int\", __name__, \"scan_density\", 512, add_to_parfile=True, commondata=True)\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"flatness_threshold\", \"r_escape\", \"t_integration_max\", \"t_start\", \"mass_snapshot_every_t\", \"delta_r_max\"],\n",
    "    [1e-2, 1500.0, 10000.0, 2000.0, 10.0, 2.0],\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "p_t_max = par.CodeParameter(\n",
    "    \"REAL\", __name__, \"p_t_max\", 1000.0,\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "window_size = par.CodeParameter(\n",
    "    \"REAL\", __name__, \"window_size\", 1.5,\n",
    "    add_to_parfile=True, commondata=True, add_to_set_CodeParameters_h=True\n",
    ")\n",
    "\n",
    "# --- NEW: Time Slot Manager Parameters ---\n",
    "print(\"-> Registering CodeParameters for the Time Slot Manager...\")\n",
    "slot_manager_t_min = par.CodeParameter(\n",
    "    \"REAL\", __name__, \"slot_manager_t_min\", -100.0,\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "slot_manager_delta_t = par.CodeParameter(\n",
    "    \"REAL\", __name__, \"slot_manager_delta_t\", 0.1,\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "\n",
    "# --- Adaptive Window Grid Parameters ---\n",
    "print(\"-> Registering CodeParameters for adaptive window grids...\")\n",
    "_ = par.register_CodeParameters(\n",
    "    \"int\", __name__,\n",
    "    [\"window_grid_type\", \"log_polar_num_r\", \"log_polar_num_phi\"],\n",
    "    [0, 512, 1024],\n",
    "    commondata=True, add_to_parfile=True\n",
    ")\n",
    "_ = par.CodeParameter(\n",
    "    \"REAL\", __name__, \"log_polar_r_min\", 0.1,\n",
    "    commondata=True, add_to_parfile=True\n",
    ")\n",
    "\n",
    "# --- Bounding Box Parameters for the Accretion Disk ---\n",
    "print(\"-> Registering CodeParameters for the disk bounding box...\")\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"disk_bounds_x_min\", \"disk_bounds_x_max\", \"disk_bounds_y_min\", \"disk_bounds_y_max\", \"disk_bounds_z_min\", \"disk_bounds_z_max\"],\n",
    "    [-26.0, 26.0, -26.0, 26.0, -1.0, 1.0],\n",
    "    commondata=True, add_to_parfile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa84ac02",
   "metadata": {},
   "source": [
    "<a id='symbolic_core'></a>\n",
    "# Step 3: The Symbolic Core - Defining the Physics with `nrpy` and `sympy`\n",
    "\n",
    "This section is the mathematical heart of the project. Here, we define the pure physics of geodesic motion not as C code, but as symbolic \"recipes\" using Python's `sympy` library. Each Python function in this section takes symbolic `sympy` objects as input (like a metric tensor) and returns new symbolic `sympy` expressions as output (like the Christoffel symbols).\n",
    "\n",
    "This \"symbolic-first\" approach is a core principle of the `nrpy` framework. It offers several major advantages:\n",
    "1.  **Correctness**: By writing the physics in high-level symbolic math, we are much less likely to make subtle programming errors than if we were writing complex C code by hand. The computer handles the tedious algebra.\n",
    "2.  **Efficiency**: Complex calculations (like inverting a 4x4 matrix) are performed symbolically *once* when this notebook is run. The resulting simplified formula is then used to generate highly efficient C code.\n",
    "3.  **Modularity & Reusability**: We create generic recipes that are not tied to a specific spacetime. For example, the recipe for the geodesic equation RHS is valid for *any* metric. We can then plug different metric tensors into this single recipe to generate C code for different spacetimes.\n",
    "\n",
    "The functions in this section will produce global Python variables containing the final symbolic expressions. These variables will be used later in Step 6 to automatically generate the C code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23b659c",
   "metadata": {},
   "source": [
    "<a id='deriv_g4DD'></a>\n",
    "### 3.a: Symbolic Recipe for Metric Tensor Derivatives\n",
    "\n",
    "The first step in calculating the Christoffel symbols is to compute the partial derivatives of the metric tensor, $g_{\\mu\\nu}$. This function, `derivative_g4DD`, takes the symbolic 4x4 metric tensor `g4DD` and a list of the four coordinate symbols `xx` as input.\n",
    "\n",
    "The function iterates through all components to symbolically calculate the partial derivative of each metric component with respect to each coordinate. The resulting quantity, which we can denote using comma notation as $g_{\\mu\\nu,\\alpha}$, is defined as:\n",
    "\n",
    "$$ g_{\\mu\\nu,\\alpha} \\equiv \\frac{\\partial g_{\\mu\\nu}}{\\partial x^{\\alpha}} $$\n",
    "\n",
    "The nested `for` loops in the code directly correspond to the spacetime indices `μ, ν, α` in the physics equation. `sympy`'s built-in `sp.diff()` function is used to perform the symbolic differentiation, and the final result is returned as a rank-3 symbolic tensor.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.zerorank3(dimension)`**:\n",
    "    *   **Source File**: `nrpy/indexedexp.py`\n",
    "    *   **Description**: This function creates a symbolic rank-3 tensor (a Python list of lists of lists) of a specified dimension, with all elements initialized to the `sympy` integer 0. It is used here to create a container for the derivative results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0d80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_g4DD(g4DD, xx):\n",
    "    \"\"\"Computes the symbolic first derivatives of the metric tensor.\"\"\"\n",
    "    g4DD_dD = ixp.zerorank3(dimension=4)\n",
    "    for nu in range(4):\n",
    "        for mu in range(4):\n",
    "            for alpha in range(4):\n",
    "                g4DD_dD[nu][mu][alpha] = sp.diff(g4DD[nu][mu], xx[alpha])\n",
    "    return g4DD_dD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79893b7",
   "metadata": {},
   "source": [
    "<a id='four_connections'></a>\n",
    "### 3.b: Symbolic Recipe for Christoffel Symbols (Analytic Metrics)\n",
    "\n",
    "This function implements the core formula for the Christoffel symbols of the second kind, $\\Gamma^{\\delta}_{\\mu\\nu}$. It takes the symbolic metric tensor `g4DD` ($g_{\\mu\\nu}$) and its derivatives `g4DD_dD` ($g_{\\mu\\nu,\\alpha}$) as input. The calculation requires the inverse metric, $g^{\\mu\\nu}$, which is computed using another `nrpy` helper function.\n",
    "\n",
    "The function then applies the well-known formula for the Christoffel symbols. Using the comma notation for partial derivatives, the formula is:\n",
    "\n",
    "$$ \\Gamma^{\\delta}_{\\mu\\nu} = \\frac{1}{2} g^{\\delta\\alpha} \\left( g_{\\nu\\alpha,\\mu} + g_{\\mu\\alpha,\\nu} - g_{\\mu\\nu,\\alpha} \\right) $$\n",
    "\n",
    "The Python `for` loops iterate over the spacetime indices `δ, μ, ν, α` to construct each component of the Christoffel symbol tensor. The summation over the dummy index `α` is performed explicitly. After the summation is complete, the `sp.trigsimp()` function is used to simplify the resulting expression. This trigonometric simplification is highly effective and much faster than a general `sp.simplify()` for the Kerr-Schild metric, which contains trigonometric functions of the coordinates.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.symm_matrix_inverter4x4(g4DD)`**:\n",
    "    *   **Source File**: `nrpy/indexedexp.py`\n",
    "    *   **Description**: This function takes a symbolic 4x4 symmetric matrix and analytically computes its inverse. It is highly optimized for this specific task, returning both the inverse matrix ($g^{\\mu\\nu}$) and its determinant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "665bc0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_connections(g4DD, g4DD_dD):\n",
    "    \"\"\"\n",
    "    Computes and simplifies Christoffel symbols from the metric and its derivatives.\n",
    "    \n",
    "    This version uses sp.trigsimp() which is highly effective and much faster\n",
    "    than sp.simplify() for the Kerr-Schild metric.\n",
    "    \"\"\"\n",
    "    Gamma4UDD = ixp.zerorank3(dimension=4)\n",
    "    g4UU, _ = ixp.symm_matrix_inverter4x4(g4DD)\n",
    "    \n",
    "    for mu in range(4):\n",
    "        for nu in range(4):\n",
    "            for delta in range(4):\n",
    "                # Calculate the Christoffel symbol component using the standard formula\n",
    "                for alpha in range(4):\n",
    "                    Gamma4UDD[delta][mu][nu] += sp.Rational(1, 2) * g4UU[delta][alpha] * \\\n",
    "                        (g4DD_dD[nu][alpha][mu] + g4DD_dD[mu][alpha][nu] - g4DD_dD[mu][nu][alpha])\n",
    "                \n",
    "                # Use sp.trigsimp() to simplify the resulting expression.\n",
    "                # This is the key to speeding up the symbolic calculation.\n",
    "                Gamma4UDD[delta][mu][nu] = sp.trigsimp(Gamma4UDD[delta][mu][nu])\n",
    "\n",
    "    return Gamma4UDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59295c0b",
   "metadata": {},
   "source": [
    "<a id='geodesic_mom_rhs'></a>\n",
    "### 3.c: Symbolic Recipe for the Geodesic Momentum ODE\n",
    "\n",
    "This function defines the symbolic right-hand side (RHS) for the evolution of the **reverse-time momentum**, $p^{\\alpha}$. As established in the introduction, this is the second of our three first-order ODEs:\n",
    "$$ \\frac{dp^{\\alpha}}{d\\kappa} = -\\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} $$\n",
    "The function `geodesic_mom_rhs` takes the symbolic Christoffel symbols $\\Gamma^{\\alpha}_{\\mu\\nu}$ as its input. It then defines the symbolic momentum vector `pU` using `sympy`'s `sp.symbols()` function. A key `nrpy` technique is used here: the symbols are created with names that are already valid C array syntax (e.g., `\"y[4]\"`). This **\"direct naming\"** simplifies the final C code generation by eliminating the need for string substitutions.\n",
    "\n",
    "The core of this function constructs the symbolic expression for the RHS by performing the Einstein summation $-\\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu}$. A direct implementation would involve a double loop over both $\\mu$ and $\\nu$ from 0 to 3, resulting in $4 \\times 4 = 16$ terms for each component of $\\alpha$, which is computationally inefficient.\n",
    "\n",
    "However, we can significantly optimize this calculation by exploiting symmetry. The term $p^{\\mu} p^{\\nu}$ is symmetric with respect to the interchange of the indices $\\mu$ and $\\nu$. The Christoffel symbols $\\Gamma^{\\alpha}_{\\mu\\nu}$ are also symmetric in their lower two indices. Therefore, the full sum can be split into diagonal ($\\mu=\\nu$) and off-diagonal ($\\mu \\neq \\nu$) terms:\n",
    "$$ \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} =  \\Gamma^{\\alpha}_{\\mu\\mu} (p^{\\mu})^2 + \\sum_{\\mu \\neq \\nu} \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} $$\n",
    "The second sum over $\\mu \\neq \\nu$ contains pairs of identical terms (e.g., the $\\mu=1, \\nu=2$ term is the same as the $\\mu=2, \\nu=1$ term). We can combine all such pairs by summing over only one of the cases (e.g., $\\mu < \\nu$) and multiplying by two:\n",
    "$$ \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} =  \\Gamma^{\\alpha}_{\\mu\\mu} (p^{\\mu})^2 + 2 \\sum_{\\mu < \\nu} \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} $$\n",
    "The Python code implements this optimized version, ensuring that each component of the RHS is computed with the minimum number of floating point operations, leading to more efficient C code.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.zerorank1(dimension)`**:\n",
    "    *   **Source File**: `nrpy/indexedexp.py`\n",
    "    *   **Description**: Creates a symbolic rank-1 tensor (a Python list) of a specified dimension, with all elements initialized to the `sympy` integer 0. It is used here to create a container for the four components of the momentum RHS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867e4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geodesic_mom_rhs(Gamma4UDD):\n",
    "    \"\"\"\n",
    "    Symbolic RHS for momentum ODE: dp^a/dκ = -Γ^a_μν p^μ p^ν.\n",
    "    p is the reverse-momentum, y[4]...y[7].\n",
    "    \"\"\"\n",
    "    pt,pr,pth,pph = sp.symbols(\"y[4] y[5] y[6] y[7]\", Real=True)\n",
    "    pU = [pt,pr,pth,pph]\n",
    "    geodesic_rhs = ixp.zerorank1(dimension=4)\n",
    "    for alpha in range(4):\n",
    "        for mu in range(4):\n",
    "            geodesic_rhs[alpha] += Gamma4UDD[alpha][mu][mu] * pU[mu] * pU[mu]\n",
    "            for nu in range(mu + 1, 4):\n",
    "                geodesic_rhs[alpha] += 2 * Gamma4UDD[alpha][mu][nu] * pU[mu] * pU[nu]\n",
    "        geodesic_rhs[alpha] = -geodesic_rhs[alpha]\n",
    "    return geodesic_rhs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02fcc6",
   "metadata": {},
   "source": [
    "<a id='geodesic_pos_rhs'></a>\n",
    "### 3.d: Symbolic Recipe for the Geodesic Position ODE\n",
    "\n",
    "This function defines the symbolic right-hand side (RHS) for the evolution of the position coordinates, $x^{\\alpha}$. As derived in the introduction, this is the first of our three first-order ODEs:\n",
    "\n",
    "$$ \\frac{dx^{\\alpha}}{d\\kappa} = p^{\\alpha} $$\n",
    "\n",
    "The Python function `geodesic_pos_rhs` is straightforward. It defines the components of the reverse-time momentum vector, `pU`, using `sympy`'s `sp.symbols()` function with the \"direct naming\" convention (`y[4]`, `y[5]`, etc.). It then simply returns a list containing these momentum components. This list of four symbolic expressions will serve as the first four components of the complete 9-component RHS vector that our C code will solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc97c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geodesic_pos_rhs():\n",
    "    \"\"\"\n",
    "    Symbolic RHS for position ODE: dx^a/dκ = p^a.\n",
    "    p is the reverse-momentum, y[4]...y[7].\n",
    "    \"\"\"\n",
    "    pt,pr,pth,pph = sp.symbols(\"y[4] y[5] y[6] y[7]\", Real=True)\n",
    "    pU = [pt,pr,pth,pph]\n",
    "    return pU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976931d5",
   "metadata": {},
   "source": [
    "<a id='proper_len_rhs'></a>\n",
    "### 3.e: Symbolic Recipe for the Path Length ODE\n",
    "\n",
    "This function defines the symbolic right-hand side for the evolution of the proper length, $L$. This is the final component of our ODE system and allows us to track the total distance the photon has traveled along its spatial path. The proper length element $dL$ is defined by the spatial part of the metric, $\\gamma_{ij} = g_{ij}$ for $i,j \\in \\{1,2,3\\}$:\n",
    "\n",
    "$$ dL^2 = \\gamma_{ij} dx^{i} dx^{j} $$\n",
    "\n",
    "Dividing by $d\\kappa^2$ and taking the square root gives us the rate of change of proper length with respect to our integration parameter $\\kappa$:\n",
    "\n",
    "$$ \\frac{dL}{d\\kappa} = \\sqrt{\\gamma_{ij} \\frac{dx^{i}}{d\\kappa} \\frac{dx^{j}}{d\\kappa}} = \\sqrt{\\gamma_{ij} p^{i} p^{j}} $$\n",
    "\n",
    "The function `proper_lengh_rhs` symbolically implements the formula under the square root, $\\sqrt{\\gamma_{ij} p^{i} p^{j}}$. It uses `sympy` symbols for the spatial momentum components (`pU[1]`, `pU[2]`, `pU[3]`) and programmatically constructs the optimized sum $\\gamma_{ij} p^{i} p^{j}$ using the same symmetry trick as the momentum RHS to reduce the number of terms. Finally, it returns a single-element list containing the square root of this sum. This will be the 9th component (`rhs_out[8]`) of our ODE system.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.declarerank2(name, dimension, sym)`**:\n",
    "    *   **Source File**: `nrpy/indexedexp.py`\n",
    "    *   **Description**: This function creates an *abstract* symbolic rank-2 tensor. Instead of creating symbols like `g11`, `g12`, etc., it creates symbols whose names are literally `name[1][1]`, `name[1][2]`, etc. This is a powerful `nrpy` technique for creating generic symbolic \"recipes\" that are later filled in with runtime data from a C struct. Here, it creates a placeholder for the metric components, `metric->g`, which will be provided by a C struct at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f82ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proper_lengh_rhs():\n",
    "    p0,p1,p2,p3,L= sp.symbols(\"y[4] y[5] y[6] y[7] y[8]\",Real=True)\n",
    "    pU=[p0,p1,p2,p3] \n",
    "\n",
    "    g4DD=ixp.declarerank2(\"metric->g\",dimension=4, sym=\"sym01\")\n",
    "\n",
    "    sum = sp.simplify(0)\n",
    "    \n",
    "    for i in range(1,4):\n",
    "        sum += g4DD[i][i]*pU[i]*pU[i]\n",
    "\n",
    "        for j in range(i+1,4):\n",
    "            sum += 2*g4DD[i][j]*pU[i]*pU[j]\n",
    "\n",
    "    sp.simplify(sum)\n",
    "\n",
    "    return [sp.sqrt(sum)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896fc9e6",
   "metadata": {},
   "source": [
    "<a id='geodesic_mom0_calc'></a>\n",
    "### 3.f: Symbolic Recipe for the Null Condition (Calculating p⁰)\n",
    "\n",
    "To complete our initial data, we must enforce the **null geodesic condition**, which states that the squared 4-momentum of a photon is zero. This is because photons travel along null paths where the spacetime interval $ds^2$ is zero. This condition must be satisfied by the 4-momentum of any photon. Let's write this for the **forward-in-time** photon, with physical 4-momentum $q^\\alpha$:\n",
    "\n",
    "$$ g_{\\mu\\nu}q^\\mu q^\\nu = 0 $$\n",
    "\n",
    "Expanding this equation into its time and space components gives us the quadratic equation for the time-component of the physical momentum, $q^0$:\n",
    "\n",
    "$$ g_{00}(q^0)^2 + 2\\left( g_{0i}q^i\\right)q^0 + \\left( g_{ij}q^i q^j\\right) = 0 $$\n",
    "\n",
    "For our reverse ray-tracing, we use the **reverse-time momentum**, $p^\\alpha$, which is related to the physical momentum by $p^\\alpha = -q^\\alpha$. We can substitute this relationship directly into the equation above, replacing $q^0$ with $-p^0$ and $q^i$ with $-p^i$:\n",
    "\n",
    "$$ g_{00}(-p^0)^2 + 2g_{0i}(-p^i)(-p^0) + \\left(g_{ij}(-p^i)(-p^j)\\right) = 0 $$\n",
    "\n",
    "The negative signs in the squared terms and the cross-term cancel out: `(-p^0)^2 = (p^0)^2`, `(-p^i)(-p^j) = p^i p^j`, and `(-p^i)(-p^0) = p^i p^0`. This yields a quadratic equation for $p^0$ that has the exact same form as the one for $q^0$:\n",
    "\n",
    "$$ g_{00}(p^0)^2 + 2\\left( g_{0i}p^i\\right)p^0 + \\left(g_{ij}p^i p^j\\right) = 0 $$\n",
    "\n",
    "We now solve this equation for $p^0$. It is a standard quadratic equation of the form $ax^2 + bx + c = 0$, where $x = p^0$. The coefficients are:\n",
    "*   $a = g_{00}$\n",
    "*   $b = 2g_{0i}p^i$\n",
    "*   $c =  g_{ij}p^i p^j$\n",
    "\n",
    "The solution for $p^0$ is given by the [quadratic formula](https://en.wikipedia.org/wiki/Quadratic_formula):\n",
    "\n",
    "$$ p^0 = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} = \\frac{-2\\left(g_{0i}p^i\\right) \\pm \\sqrt{\\left(2 g_{0i}p^i\\right)^2 - 4g_{00}\\left(g_{ij}p^i p^j\\right)}}{2g_{00}} $$\n",
    "\n",
    "Simplifying by dividing the numerator and denominator by 2 gives:\n",
    "\n",
    "$$ p^0 = \\frac{-\\left( g_{0i}p^i\\right) \\pm \\sqrt{\\left( g_{0i}p^i\\right)^2 - g_{00}\\left( g_{ij}p^i p^j\\right)}}{g_{00}} $$\n",
    "\n",
    "The final step is to choose the physically correct root. For the reverse-traced photon, the parameter $\\kappa$ increases as coordinate time `t` decreases. Therefore, the derivative $p^0 = dt/d\\kappa$ must be **negative**. In a typical stationary spacetime outside a black hole, $g_{00}$ is negative. For the fraction to be negative, the numerator must be **positive**. The square root term is always positive and its magnitude is generally larger than the first term. To guarantee a positive numerator, we must choose the **plus sign (`+`)** in the `±`.\n",
    "\n",
    "This leads to the final, correct result implemented in the code:\n",
    "$$ p^0 = \\frac{-\\left( g_{0i}p^i\\right) + \\sqrt{\\left(g_{0i}p^i\\right)^2 - g_{00}\\left( g_{ij}p^i p^j\\right)}}{g_{00}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c2b0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mom_time_p0_reverse():\n",
    "    \"\"\"\n",
    "    Solves g_μν p^μ p^ν = 0 for our reverse-time momentum p^0.\n",
    "    \"\"\"\n",
    "    p0,p1,p2,p3 = sp.symbols(\"y[4] y[5] y[6] y[7]\", Real=True)\n",
    "    pU=[p0,p1,p2,p3]\n",
    "    g4DD = ixp.declarerank2(\"metric->g\", sym=\"sym01\", dimension=4)\n",
    "    sum_g0i_pi = sp.sympify(0)\n",
    "    for i in range(1,4):\n",
    "        sum_g0i_pi += g4DD[0][i]*pU[i]\n",
    "    sum_gij_pi_pj = sp.sympify(0)\n",
    "    for i in range(1,4):\n",
    "        sum_gij_pi_pj += g4DD[i][i]*pU[i]*pU[i]\n",
    "        for j in range(i+1,4):\n",
    "            sum_gij_pi_pj += 2*g4DD[i][j]*pU[i]*pU[j]\n",
    "    discriminant = sum_g0i_pi*sum_g0i_pi - g4DD[0][0]*sum_gij_pi_pj\n",
    "    answer = (-sum_g0i_pi + sp.sqrt(discriminant)) / g4DD[0][0]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea9bc84",
   "metadata": {},
   "source": [
    "<a id='conserved_quantities'></a>\n",
    "### 3.g: Symbolic Recipes for Conserved Quantities (E, L, Q)\n",
    "\n",
    "For geodesic motion in spacetimes with symmetries, certain physical quantities are conserved along the photon's path. These conserved quantities are invaluable for validating the numerical accuracy of our integrator. If the integrator is working correctly, these quantities should remain nearly constant throughout the entire evolution.\n",
    "\n",
    "The symmetries of a spacetime are described by **Killing vectors**. For the stationary and axisymmetric Kerr spacetime, there are two such vectors, which lead to two conserved quantities:\n",
    "\n",
    "1.  **Energy at Infinity (E):** The symmetry in time (stationarity) leads to the conservation of energy. It is defined as the projection of the 4-momentum onto the time-like Killing vector, which simplifies to:\n",
    "    $$ E = -p_t = -g_{t\\mu} p^\\mu $$\n",
    "    where $p_t$ is the covariant time-component of the 4-momentum.\n",
    "\n",
    "2.  **Angular Momentum Component Parallel to the Axis of Symmetry (L_z):** The symmetry in rotation about the z-axis (axisymmetry) leads to the conservation of the z-component of angular momentum. It is defined as:\n",
    "    $$ L_z = p_\\phi = g_{\\phi\\mu} p^\\mu $$\n",
    "    In Cartesian coordinates, this is equivalent to the standard definition:\n",
    "    $$ L_z = x p_y - y p_x $$\n",
    "    where $p_x$ and $p_y$ are the covariant spatial components of the 4-momentum.\n",
    "\n",
    "3.  **The Carter Constant (Q):** Remarkably, the Kerr spacetime possesses a hidden symmetry related to the separability of the Hamilton-Jacobi equation, which gives rise to a third conserved quantity known as the **Carter Constant, Q**. Its formula is more complex and is a combination of the other conserved quantities and the momentum components. For a photon (mass=0), it is given by:\n",
    "    $$ Q = p_\\theta^2 + \\cos^2\\theta \\left( \\frac{L_z^2}{\\sin^2\\theta} - a^2 E^2 \\right) $$\n",
    "    In the case of the Schwarzschild spacetime (where the spin $a=0$), the Carter constant simplifies to the squared total angular momentum: $Q = L_x^2 + L_y^2 + L_z^2 = L^2$.\n",
    "\n",
    "The following cells define the symbolic recipes for these three conserved quantities, which will be used to generate a C function for monitoring the numerical error of the integrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "373ef962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_energy():\n",
    "    \"\"\"\n",
    "    Computes the symbolic expression for conserved energy E = -p_t.\n",
    "    E = -g_{t,mu} p^mu\n",
    "    \"\"\"\n",
    "    # Define the 4-momentum components using the y[4]...y[7] convention\n",
    "    pt, px, py, pz = sp.symbols(\"y[4] y[5] y[6] y[7]\", real=True)\n",
    "    pU = [pt, px, py, pz]\n",
    "    \n",
    "    # Define an abstract metric tensor to be filled by a C struct at runtime\n",
    "    g4DD = ixp.declarerank2(\"metric->g\", sym=\"sym01\", dimension=4)\n",
    "    \n",
    "    # Calculate p_t = g_{t,mu} p^mu\n",
    "    p_t = sp.sympify(0)\n",
    "    for mu in range(4):\n",
    "        p_t += g4DD[0][mu] * pU[mu]\n",
    "        \n",
    "    return -p_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dd4d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_L_components_cart():\n",
    "    \"\"\"\n",
    "    Computes the symbolic expressions for the three components of angular momentum,\n",
    "    correctly accounting for the symmetry of the metric tensor.\n",
    "    \"\"\"\n",
    "    # Define coordinate and 4-momentum components\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    pt, px, py, pz = sp.symbols(\"y[4] y[5] y[6] y[7]\", real=True)\n",
    "    pU = [pt, px, py, pz]\n",
    "    \n",
    "    # Define an abstract metric tensor\n",
    "    g4DD = ixp.declarerank2(\"metric->g\", sym=\"sym01\", dimension=4)\n",
    "    \n",
    "    # --- THIS IS THE CORE FIX ---\n",
    "    # Calculate covariant momentum components p_k = g_{k,mu} p^mu,\n",
    "    # correctly exploiting the metric's symmetry g_mu,nu = g_nu,mu.\n",
    "    p_down = ixp.zerorank1(dimension=4)\n",
    "    for k in range(1, 4): # We only need p_x, p_y, p_z for L_i\n",
    "        # Sum over mu\n",
    "        for mu in range(4):\n",
    "            # Use g4DD[k][mu] if k <= mu, otherwise use g4DD[mu][k]\n",
    "            if k <= mu:\n",
    "                p_down[k] += g4DD[k][mu] * pU[mu]\n",
    "            else: # k > mu\n",
    "                p_down[k] += g4DD[mu][k] * pU[mu]\n",
    "            \n",
    "    p_x, p_y, p_z = p_down[1], p_down[2], p_down[3]\n",
    "\n",
    "    # Calculate angular momentum components \n",
    "    L_x = y*p_z - z*p_y\n",
    "    L_y = z*p_x - x*p_z\n",
    "    L_z = x*p_y - y*p_x\n",
    "    \n",
    "    return [L_x, L_y, L_z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1034fad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final symbolic recipes for conserved quantities defined (Carter Constant re-derived).\n"
     ]
    }
   ],
   "source": [
    "def symbolic_carter_constant_Q():\n",
    "    \"\"\"\n",
    "    Computes the symbolic expression for the Carter Constant Q using a\n",
    "    verified formula, robustly handling the axial singularity.\n",
    "    \"\"\"\n",
    "    # Define all necessary symbolic variables\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    pt, px, py, pz = sp.symbols(\"y[4] y[5] y[6] y[7]\", real=True)\n",
    "    pU = [pt, px, py, pz]\n",
    "    a = a_spin\n",
    "    g4DD = ixp.declarerank2(\"metric->g\", sym=\"sym01\", dimension=4)\n",
    "\n",
    "    # --- Step 1: Compute intermediate quantities E, Lz, and p_i ---\n",
    "    E = symbolic_energy()\n",
    "    _, _, Lz = symbolic_L_components_cart()\n",
    "    \n",
    "    p_down = ixp.zerorank1(dimension=4)\n",
    "    for k in range(1, 4):\n",
    "        for mu in range(4):\n",
    "            if k <= mu: p_down[k] += g4DD[k][mu] * pU[mu]\n",
    "            else: p_down[k] += g4DD[mu][k] * pU[mu]\n",
    "    p_x, p_y, p_z = p_down[1], p_down[2], p_down[3]\n",
    "\n",
    "    # --- Step 2: Compute geometric terms ---\n",
    "    r_sq = x**2 + y**2 + z**2\n",
    "    rho_sq = x**2 + y**2\n",
    "    \n",
    "    # --- Step 3: Compute p_theta^2 directly in Cartesian components ---\n",
    "    # This avoids square roots and potential complex number issues in sympy.\n",
    "    # p_theta^2 = r^2 * p_z^2 + cot^2(theta) * (x*p_x + y*p_y)^2 - 2*r*p_z*cot(theta)*(x*p_x+y*p_y)\n",
    "    # where cot(theta) = z / rho\n",
    "    \n",
    "    # This term is (x*p_x + y*p_y)\n",
    "    xpx_plus_ypy = x*p_x + y*p_y\n",
    "    \n",
    "    # This is p_theta^2, constructed to avoid dividing by rho before squaring.\n",
    "    # It is equivalent to (z*xpx_plus_ypy/rho - rho*p_z)^2\n",
    "    p_theta_sq = (z**2 * xpx_plus_ypy**2 / rho_sq) - (2 * z * p_z * xpx_plus_ypy) + (rho_sq * p_z**2)\n",
    "\n",
    "    # --- Step 4: Assemble the final formula for Q ---\n",
    "    # Q = p_theta^2 + cos^2(theta) * (-a^2*E^2 + L_z^2/sin^2(theta))\n",
    "    # where cos^2(theta) = z^2/r^2 and sin^2(theta) = rho^2/r^2\n",
    "    \n",
    "    # This is the second term in the Q formula\n",
    "    second_term = (z**2 / r_sq) * (-a**2 * E**2 + Lz**2 * (r_sq / rho_sq))\n",
    "    \n",
    "    Q_formula = p_theta_sq + second_term\n",
    "    \n",
    "    # --- Step 5: Handle the axial singularity ---\n",
    "    # For motion on the z-axis (rho_sq -> 0), Lz=0 and p_theta=0, so Q=0.\n",
    "    Q_final = sp.Piecewise(\n",
    "        (0, rho_sq < 1e-12),\n",
    "        (Q_formula, True)\n",
    "    )\n",
    "    \n",
    "    return Q_final\n",
    "\n",
    "print(\"Final symbolic recipes for conserved quantities defined (Carter Constant re-derived).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b39f1e",
   "metadata": {},
   "source": [
    "<a id='numerical_recipes'></a>\n",
    "### 3.h: Symbolic Recipes for Numerical Metrics\n",
    "\n",
    "While analytic metrics like Kerr-Schild are powerful, many modern simulations in astrophysics use numerical metrics, where the spacetime components are known only as numerical values on a discrete grid. To calculate Christoffel symbols for these spacetimes, we must perform all calculations numerically, including the derivatives.\n",
    "\n",
    "A naive approach would be to first interpolate the metric $g_{\\mu\\nu}$ to a point, then interpolate again at nearby points to perform a finite difference derivative. This is extremely inefficient, requiring many calls to the interpolation engine. A far superior method is the **\"analytic derivative of the interpolant.\"**\n",
    "\n",
    "The idea is as follows:\n",
    "1.  The interpolation formula (e.g., trilinear interpolation) is a simple polynomial.\n",
    "2.  We can take the analytical partial derivative of this polynomial formula itself. The result is a new formula for the derivative that is also a simple combination of the grid point values.\n",
    "3.  We can then implement both the interpolation formula and its derivative formula directly in C code. This allows us to compute both $g_{\\mu\\nu}$ and its derivatives $g_{\\mu\\nu,\\delta}$ in a single, efficient C function call.\n",
    "\n",
    "To generate the C code for this, we need a symbolic recipe for the Christoffel symbols that is built from abstract placeholders for the interpolated metric and its derivatives. The following function creates this recipe. It uses `sympy.Symbol` objects with descriptive names (e.g., `g4DD00`, `g4DDdD01_d2`) that will be matched to local C variables in the final C worker function. This avoids the \"expression swell\" that would occur if we tried to symbolically construct the entire interpolation and differentiation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93f070a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_numerical_christoffel_recipe():\n",
    "    \"\"\"\n",
    "    Generates the pure symbolic recipe for the Christoffel symbols assuming\n",
    "    that the metric g_μν and its derivatives g_μν,δ are provided as inputs.\n",
    "\n",
    "    This version manually constructs the derivative tensor with a naming\n",
    "    convention that matches the C code preamble (e.g., g4DDdD01_d2).\n",
    "    \"\"\"\n",
    "    # Step 1: Create symbolic placeholders for the 10 unique metric components.\n",
    "    g4DD = ixp.declarerank2(\"g4DD\", symmetry=\"sym01\", dimension=4)\n",
    "\n",
    "    # --- THIS IS THE CORRECTED LOGIC ---\n",
    "    # Step 2: Manually create symbolic placeholders for the 40 unique metric derivatives\n",
    "    # to enforce the g4DDdD{i}{j}_d{k} naming convention.\n",
    "    g4DDdD = ixp.zerorank3(dimension=4) # Initialize with zeros\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4): # Loop over unique metric components\n",
    "            for k in range(4): # Loop over derivative directions\n",
    "                # Create the symbol with the exact name we need\n",
    "                symbol_name = f\"g4DDdD{i}{j}_d{k}\"\n",
    "                g4DDdD[i][j][k] = sp.Symbol(symbol_name)\n",
    "                if i != j:\n",
    "                    # Enforce symmetry in the symbolic tensor\n",
    "                    g4DDdD[j][i][k] = g4DDdD[i][j][k]\n",
    "\n",
    "    # Step 3: Compute the symbolic inverse of the placeholder metric.\n",
    "    g4UU, _ = ixp.symm_matrix_inverter4x4(g4DD)\n",
    "\n",
    "    # Step 4: Initialize the output tensor for the Christoffel symbols.\n",
    "    Gamma4UDD_num_recipe = ixp.zerorank3(dimension=4)\n",
    "\n",
    "    # Step 5: Build the recipe for the 40 unique Christoffel symbols.\n",
    "    for alpha in range(4):\n",
    "        for mu in range(4):\n",
    "            for nu in range(mu, 4):\n",
    "                for delta in range(4):\n",
    "                    Gamma4UDD_num_recipe[alpha][mu][nu] += sp.Rational(1, 2) * g4UU[alpha][delta] * \\\n",
    "                        (g4DDdD[nu][delta][mu] + g4DDdD[mu][delta][nu] - g4DDdD[mu][nu][delta])\n",
    "\n",
    "    return Gamma4UDD_num_recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe10d0a",
   "metadata": {},
   "source": [
    "<a id='spacetime_definition'></a>\n",
    "# Step 4: Spacetime Definition in Kerr-Schild Coordinates\n",
    "\n",
    "This section defines the specific spacetime geometry in which the geodesics will be integrated. Instead of defining separate metrics for Schwarzschild (non-rotating) and Kerr (rotating) black holes, we use a single, powerful coordinate system: **Cartesian Kerr-Schild coordinates**. This system has a major advantage over more common coordinate systems like Boyer-Lindquist: it is regular everywhere, including at the event horizon. This means the metric components and their derivatives do not diverge, allowing the numerical integrator to trace a photon's path seamlessly across the horizon without encountering coordinate singularities.\n",
    "\n",
    "The Kerr-Schild metric $g_{\\mu\\nu}$ is constructed by adding a correction term to the flat Minkowski metric $\\eta_{\\mu\\nu}$:\n",
    "$$ g_{\\mu\\nu} = \\eta_{\\mu\\nu} + 2H l_\\mu l_\\nu $$\n",
    "where $\\eta_{\\mu\\nu}$ is the Minkowski metric `diag(-1, 1, 1, 1)`, $l_\\mu$ is a special null vector, and $H$ is a scalar function that depends on the black hole's mass $M$ and spin $a$.\n",
    "\n",
    "The function `define_kerr_metric_Cartesian_Kerr_Schild()` implements this formula symbolically. It defines the coordinates `(t, x, y, z)`, the mass `M`, and the spin `a` as `sympy` symbols. It then constructs the components of the null vector $l_\\mu$ and the scalar function $H$. Finally, it assembles the full metric tensor $g_{\\mu\\nu}$.\n",
    "\n",
    "A key feature of this formulation is that if the spin parameter `a` is set to zero, the metric automatically and exactly reduces to the Schwarzschild metric in Cartesian coordinates. This allows a single set of symbolic expressions and a single set of C functions to handle both spacetimes, with the specific behavior controlled by the runtime value of the `a_spin` parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6282a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_kerr_metric_Cartesian_Kerr_Schild():\n",
    "    \"\"\"\n",
    "    Defines the Kerr metric tensor in Cartesian Kerr-Schild coordinates.\n",
    "\n",
    "    This function is the new, unified source for both Kerr (a != 0) and\n",
    "    Schwarzschild (a = 0) spacetimes. The coordinates are (t, x, y, z).\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (g4DD, xx), where g4DD is the symbolic 4x4 metric tensor\n",
    "        and xx is the list of symbolic coordinate variables.\n",
    "    \"\"\"\n",
    "    # Define the symbolic coordinates using the 'y[i]' convention for the integrator\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    xx = [t, x, y, z]\n",
    "\n",
    "    # Access the symbolic versions of the mass and spin parameters\n",
    "    M = M_scale\n",
    "    a = a_spin\n",
    "\n",
    "    # Define intermediate quantities\n",
    "    r2 = x**2 + y**2 + z**2\n",
    "    r = sp.sqrt(r2)\n",
    "    \n",
    "    # Define the Kerr-Schild null vector l_μ\n",
    "    l_down = ixp.zerorank1(dimension=4)\n",
    "    l_down[0] = 1\n",
    "    l_down[1] = (r*x + a*y) / (r2 + a**2)\n",
    "    l_down[2] = (r*y - a*x) / (r2 + a**2)\n",
    "    l_down[3] = z/r\n",
    "\n",
    "    # Define the scalar function H\n",
    "    H = (M * r**3) / (r**4 + a**2 * z**2)\n",
    "\n",
    "    # The Kerr-Schild metric is g_μν = η_μν + 2H * l_μ * l_ν\n",
    "    # where η_μν is the Minkowski metric diag(-1, 1, 1, 1)\n",
    "    g4DD = ixp.zerorank2(dimension=4)\n",
    "    for mu in range(4):\n",
    "        for nu in range(4):\n",
    "            eta_mu_nu = 0\n",
    "            if mu == nu:\n",
    "                eta_mu_nu = 1\n",
    "            if mu == 0 and nu == 0:\n",
    "                eta_mu_nu = -1\n",
    "            \n",
    "            g4DD[mu][nu] = eta_mu_nu + 2 * H * l_down[mu] * l_down[nu]\n",
    "            \n",
    "    return g4DD, xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0f01f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_schwarzschild_metric_cartesian():\n",
    "    \"\"\"\n",
    "    Defines the Schwarzschild metric tensor directly in Cartesian coordinates.\n",
    "    \n",
    "    This version uses the standard textbook formula and ensures all components\n",
    "    are sympy objects to prevent C-generation errors.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (g4DD, xx), where g4DD is the symbolic 4x4 metric tensor\n",
    "        and xx is the list of symbolic coordinate variables.\n",
    "    \"\"\"\n",
    "    # Define Cartesian coordinates\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    xx = [t, x, y, z]\n",
    "\n",
    "    # Access the symbolic mass parameter\n",
    "    M = M_scale\n",
    "\n",
    "    # Define r in terms of Cartesian coordinates\n",
    "    r = sp.sqrt(x**2 + y**2 + z**2)\n",
    "\n",
    "    # Define the Cartesian Schwarzschild metric components directly\n",
    "    g4DD = ixp.zerorank2(dimension=4)\n",
    "    \n",
    "    # g_tt\n",
    "    g4DD[0][0] = -(1 - 2*M/r)\n",
    "    \n",
    "    # Spatial components g_ij = δ_ij + (2M/r) * (x_i * x_j / r^2)\n",
    "    x_i = [x, y, z]\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            # --- CORRECTED: Use sp.sympify() for the kronecker delta ---\n",
    "            delta_ij = sp.sympify(0)\n",
    "            if i == j:\n",
    "                delta_ij = sp.sympify(1)\n",
    "            \n",
    "            # The indices for g4DD are off by 1 from the spatial indices\n",
    "            g4DD[i+1][j+1] = delta_ij + (2*M/r) * (x_i[i] * x_i[j] / (r**2))\n",
    "\n",
    "    # --- CORRECTED: Ensure time-space components are sympy objects ---\n",
    "    g4DD[0][1] = g4DD[1][0] = sp.sympify(0)\n",
    "    g4DD[0][2] = g4DD[2][0] = sp.sympify(0)\n",
    "    g4DD[0][3] = g4DD[3][0] = sp.sympify(0)\n",
    "            \n",
    "    return g4DD, xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec78a4",
   "metadata": {},
   "source": [
    "<a id='symbolic_execution'></a>\n",
    "# Step 5: Symbolic Workflow Execution\n",
    "\n",
    "This cell acts as the central hub for the symbolic portion of our project. In the preceding cells, we *defined* a series of Python functions that act as mathematical blueprints. Here, we *execute* those functions in the correct sequence to generate all the final symbolic expressions that will serve as \"recipes\" for our C code generators.\n",
    "\n",
    "This \"symbolic-first\" approach is a core `nrpy` principle and offers significant advantages:\n",
    "1.  **Efficiency**: The complex symbolic calculations, such as inverting the metric tensor and deriving the Christoffel symbols, are performed **only once** when this notebook is run. The results are stored in global Python variables, preventing redundant and time-consuming recalculations. This is especially important for the Kerr metric, whose Christoffel symbols can take several minutes to compute.\n",
    "2.  **Modularity**: This workflow creates a clean separation between the *specific solution* for a metric (e.g., the explicit formulas for the Kerr-Schild Christoffels) and the *generic form* of the equations of motion (which are valid for any metric).\n",
    "\n",
    "This cell produces several key global variables containing symbolic expressions that will be used in the next step to generate the final C code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fbfe0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Computing Kerr-Schild metric and Christoffel symbols...\n",
      "    ... Done.\n",
      " -> Computing Standard Schwarzschild (Cartesian) metric and Christoffel symbols...\n",
      "    ... Done.\n",
      " -> Defined generic global symbolic variable for ODE RHS: all_rhs_expressions\n",
      " -> Generating symbolic recipes for conserved quantities...\n",
      "    ... Conservation recipes generated.\n",
      "Kerr expressions\n",
      "[-metric->g00*y[4] - metric->g01*y[5] - metric->g02*y[6] - metric->g03*y[7], y[2]*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7]) - y[3]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]), -y[1]*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7]) + y[3]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]), y[1]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]) - y[2]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]), Piecewise((0, y[1]**2 + y[2]**2 < 1.0e-12), (y[3]**2*(-a_spin**2*(-metric->g00*y[4] - metric->g01*y[5] - metric->g02*y[6] - metric->g03*y[7])**2 + (y[1]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]) - y[2]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]))**2*(y[1]**2 + y[2]**2 + y[3]**2)/(y[1]**2 + y[2]**2))/(y[1]**2 + y[2]**2 + y[3]**2) + y[3]**2*(y[1]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]) + y[2]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]))**2/(y[1]**2 + y[2]**2) - 2*y[3]*(y[1]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]) + y[2]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]))*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7]) + (y[1]**2 + y[2]**2)*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7])**2, True))]\n",
      "Schwarzs experessions\n",
      "[-metric->g00*y[4] - metric->g01*y[5] - metric->g02*y[6] - metric->g03*y[7], y[2]*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7]) - y[3]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]), -y[1]*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7]) + y[3]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]), y[1]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]) - y[2]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]), (y[1]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]) - y[2]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]))**2 + (-y[1]*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7]) + y[3]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]))**2 + (y[2]*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7]) - y[3]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]))**2]\n",
      "\n",
      "Symbolic setup complete. All expressions are now available globally.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define the Kerr-Schild metric and get its derivatives ---\n",
    "print(\" -> Computing Kerr-Schild metric and Christoffel symbols...\")\n",
    "g4DD_kerr, xx_kerr = define_kerr_metric_Cartesian_Kerr_Schild()\n",
    "g4DD_dD_kerr = derivative_g4DD(g4DD_kerr, xx_kerr)\n",
    "Gamma4UDD_kerr = four_connections(g4DD_kerr, g4DD_dD_kerr)\n",
    "print(\"    ... Done.\")\n",
    "\n",
    "# --- 2. Define the Standard Schwarzschild metric in Cartesian and get its derivatives ---\n",
    "print(\" -> Computing Standard Schwarzschild (Cartesian) metric and Christoffel symbols...\")\n",
    "g4DD_schw_cart, xx_schw_cart = define_schwarzschild_metric_cartesian()\n",
    "g4DD_dD_schw_cart = derivative_g4DD(g4DD_schw_cart, xx_schw_cart)\n",
    "Gamma4UDD_schw_cart = four_connections(g4DD_schw_cart, g4DD_dD_schw_cart)\n",
    "print(\"    ... Done.\")\n",
    "\n",
    "# --- 3. Generate the GENERIC symbolic RHS expressions for the geodesic equations ---\n",
    "# This part is unchanged, as the ODEs are generic.\n",
    "Gamma4UDD_placeholder = ixp.declarerank3(\"conn->Gamma4UDD\", dimension=4)\n",
    "rhs_pos = geodesic_pos_rhs() \n",
    "rhs_mom = geodesic_mom_rhs(Gamma4UDD_placeholder)\n",
    "rhs_length = proper_lengh_rhs()\n",
    "all_rhs_expressions = rhs_pos + rhs_mom + rhs_length\n",
    "print(\" -> Defined generic global symbolic variable for ODE RHS: all_rhs_expressions\")\n",
    "\n",
    "# --- 4. Generate symbolic recipes for conserved quantities ---\n",
    "# This is now simplified, as all calculations are Cartesian.\n",
    "print(\" -> Generating symbolic recipes for conserved quantities...\")\n",
    "\n",
    "\n",
    "E_expr = symbolic_energy()\n",
    "Lx_expr, Ly_expr, Lz_expr = symbolic_L_components_cart()\n",
    "Q_expr_kerr = symbolic_carter_constant_Q()\n",
    "Q_expr_schw = Lx_expr**2 + Ly_expr**2 + Lz_expr**2\n",
    "\n",
    "# We now have two lists of expressions, both using Cartesian formulas.\n",
    "list_of_expressions_kerr = [E_expr, Lx_expr, Ly_expr, Lz_expr, Q_expr_kerr]\n",
    "list_of_expressions_schw = [E_expr, Lx_expr, Ly_expr, Lz_expr, Q_expr_schw]\n",
    "print(\"    ... Conservation recipes generated.\")\n",
    "print(\"Kerr expressions\")\n",
    "print(list_of_expressions_kerr)\n",
    "print(\"Schwarzs experessions\")\n",
    "print(list_of_expressions_schw)\n",
    "print(\"\\nSymbolic setup complete. All expressions are now available globally.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032d263",
   "metadata": {},
   "source": [
    "<a id='generate_c_engines'></a>\n",
    "# Step 6: C Code Generation - Physics Engines and Workers\n",
    "\n",
    "This section marks our transition from pure symbolic mathematics to C code generation. The Python functions defined here are \"meta-functions\": their job is not to perform calculations themselves, but to **generate the C code** that will perform the calculations in the final compiled program.\n",
    "\n",
    "We distinguish between several types of generated functions:\n",
    "*   **Workers**: These are specialized functions that implement the physics for a *specific metric*. For example, `con_kerr_schild()` is a worker that only knows how to compute Christoffel symbols for the Kerr-Schild metric.\n",
    "*   **Engines**: These are generic functions that implement physics equations or numerical methods valid for *any metric*. For example, `calculate_ode_rhs()` is an engine that can compute the geodesic equations for any metric, as long as the Christoffel symbols are provided to it.\n",
    "*   **Helpers**: These are small, utility functions that perform common tasks, such as managing memory for a data structure.\n",
    "\n",
    "This modular design allows for maximum code reuse and extensibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd610ccf",
   "metadata": {},
   "source": [
    "<a id='analytic_workers'></a>\n",
    "### 6.a: C Workers for Analytic Metrics\n",
    "\n",
    "The Python functions in this subsection generate the C \"worker\" functions that are specialized for a particular analytic metric. Each function takes one of the symbolic metric recipes we generated in Step 5 (e.g., `Gamma4UDD_kerr`) and translates it into an optimized C function.\n",
    "\n",
    "The core of this process is the `nrpy.c_codegen.c_codegen` function, which converts the large `sympy` expressions into C code, automatically performing Common Subexpression Elimination (CSE) to significantly improve the performance of the final C code. The generated C code is then registered with `nrpy`'s in-memory C project manager, `nrpy.c_function.register_CFunction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c29ef433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g4DD_schwarzschild_cartesian():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Schwarzschild\n",
    "    metric components in standard Cartesian coordinates.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: g4DD_schwarzschild_cartesian()...\")\n",
    "    \n",
    "    # Use the globally defined g4DD_schw_cart from the symbolic execution step\n",
    "    list_of_g4DD_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_syms.append(g4DD_schw_cart[i][j])\n",
    "\n",
    "    list_of_g4DD_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_C_vars.append(f\"metric->g{i}{j}\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the 10 unique components of the Schwarzschild metric in Cartesian coords.\"\"\"\n",
    "    name = \"g4DD_schwarzschild_cartesian\"\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], metric_struct *restrict metric\"\n",
    "   \n",
    "    body = ccg.c_codegen(list_of_g4DD_syms, list_of_g4DD_C_vars, enable_cse=True)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... g4DD_schwarzschild_cartesian() registration complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78d52f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g4DD_kerr_schild():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Kerr-Schild\n",
    "    metric components in Cartesian coordinates. This is the new unified worker.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: g4DD_kerr_schild()...\")\n",
    "    \n",
    "    # We use the globally defined g4DD_kerr from the symbolic execution step\n",
    "    list_of_g4DD_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_syms.append(g4DD_kerr[i][j])\n",
    "\n",
    "    list_of_g4DD_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_C_vars.append(f\"metric->g{i}{j}\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the 10 unique components of the Kerr metric in Cartesian Kerr-Schild coords.\"\"\"\n",
    "    name = \"g4DD_kerr_schild\"\n",
    "    # The state vector y now contains (t, x, y, z)\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], metric_struct *restrict metric\"\n",
    "   \n",
    "    body = ccg.c_codegen(list_of_g4DD_syms, list_of_g4DD_C_vars, enable_cse=True)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... g4DD_kerr_schild() registration complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeb471c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_kerr_schild():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Kerr-Schild Christoffel symbols.\n",
    "    This is the new unified worker.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: con_kerr_schild()...\")\n",
    "    \n",
    "    # We use the globally defined Gamma4UDD_kerr from the symbolic execution step\n",
    "    list_of_Gamma_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_syms.append(Gamma4UDD_kerr[i][j][k])\n",
    "\n",
    "    conn_Gamma4UDD = ixp.declarerank3(\"conn->Gamma4UDD\", dimension=4)\n",
    "    list_of_Gamma_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_C_vars.append(str(conn_Gamma4UDD[i][j][k]))\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the 40 unique Christoffel symbols for the Kerr metric in Kerr-Schild coords.\"\"\"\n",
    "    name = \"con_kerr_schild\"\n",
    "    # The state vector y now contains (t, x, y, z)\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], connection_struct *restrict conn\"\n",
    "\n",
    "    body = ccg.c_codegen(list_of_Gamma_syms, list_of_Gamma_C_vars, enable_cse=True)\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... con_kerr_schild() registration complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d6072ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_schwarzschild_cartesian():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Schwarzschild Christoffel symbols\n",
    "    in standard Cartesian coordinates.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: con_schwarzschild_cartesian()...\")\n",
    "    \n",
    "    # Use the globally defined Gamma4UDD_schw_cart\n",
    "    list_of_Gamma_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_syms.append(Gamma4UDD_schw_cart[i][j][k])\n",
    "\n",
    "    conn_Gamma4UDD = ixp.declarerank3(\"conn->Gamma4UDD\", dimension=4)\n",
    "    list_of_Gamma_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_C_vars.append(str(conn_Gamma4UDD[i][j][k]))\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the unique Christoffel symbols for the Schwarzschild metric in Cartesian coords.\"\"\"\n",
    "    name = \"con_schwarzschild_cartesian\"\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], connection_struct *restrict conn\"\n",
    "\n",
    "    body = ccg.c_codegen(list_of_Gamma_syms, list_of_Gamma_C_vars, enable_cse=True)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... con_schwarzschild_cartesian() registration complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f49d2e",
   "metadata": {},
   "source": [
    "<a id='placeholder_interpolator'></a>\n",
    "### Placeholder Engine for External Interpolator\n",
    "\n",
    "This Python function generates the C function `placeholder_interpolation_engine()`. This is the cornerstone of our Phase 1 development strategy for integrating the professor's external interpolation library.\n",
    "\n",
    "This function serves as a **stand-in** or **mock** of the final, high-performance numerical interpolation engine. It has the **exact C API** that the final engine will have: it takes a batch of photon position `requests` and is expected to fill an `outputs` array with the corresponding Christoffel symbols.\n",
    "\n",
    "However, its internal logic does **not** perform interpolation. Instead, it loops through each request and calls our existing, trusted **analytic** C worker (`connections`) to compute the Christoffel symbols for that point.\n",
    "\n",
    "This powerful technique allows us to build and validate the entire complex \"Request-Compute-Distribute\" control flow of the numerical pipeline (`batch_integrator_numerical`) using a known-good source of Christoffel symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4eb03216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V12_5_light_geodesic.ipynb\n",
    "# This is the DEFINITIVE replacement for the placeholder_interpolator() cell.\n",
    "\n",
    "def placeholder_interpolator():\n",
    "    \"\"\"\n",
    "    Generates the high-fidelity C placeholder for the external interpolation engine.\n",
    "    \n",
    "    This version correctly bypasses the high-level dispatchers and calls the\n",
    "    low-level analytic WORKER functions directly, providing a true analytic\n",
    "    baseline for the numerical pipeline.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C placeholder engine: placeholder_interpolation_engine()...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"\n",
    " Placeholder for the external batch-processing interpolation engine.\n",
    " \n",
    " ========================================================================\n",
    " ================== THIS IS A VALIDATION PLACEHOLDER ==================\n",
    " This function will be replaced by the high-performance numerical engine\n",
    " provided by the professor.\n",
    " ========================================================================\n",
    " \n",
    " It mimics the required API but computes the metric and Christoffel symbols\n",
    " by calling the low-level ANALYTIC WORKER functions directly. This provides\n",
    " a ground-truth analytic result for validating the numerical control flow.\n",
    " \n",
    "\"\"\"\n",
    "    name = \"placeholder_interpolation_engine\"\n",
    "    params = \"\"\"int num_photons, \n",
    "                const photon_request_t requests[], \n",
    "                metric_struct metric_outputs[],\n",
    "                connection_struct conn_outputs[],\n",
    "                const commondata_struct *restrict commondata,\n",
    "                const params_struct *restrict params,\n",
    "                const metric_params *restrict metric\"\"\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "    // This function loops through each request and computes the metric and\n",
    "    // Christoffels individually by calling the high-level dispatchers.\n",
    "    #pragma omp parallel for\n",
    "    for (int i = 0; i < num_photons; ++i) {\n",
    "        // The analytic dispatcher functions expect a 9-element state vector.\n",
    "        // To call them safely, we create a temporary padded array on the stack.\n",
    "        // We only need to fill the first 4 position components from the request.\n",
    "        // The other 5 components (momentum, path length) are not used by these\n",
    "        // specific dispatcher functions.\n",
    "        double y_padded[9];\n",
    "        y_padded[0] = requests[i].pos[0]; // t\n",
    "        y_padded[1] = requests[i].pos[1]; // x\n",
    "        y_padded[2] = requests[i].pos[2]; // y\n",
    "        y_padded[3] = requests[i].pos[3]; // z\n",
    "\n",
    "        // Now, call the high-level DISPATCHERS with the correctly-sized array.\n",
    "        // These functions will internally use the 'metric->type' to call the\n",
    "        // correct low-level worker (e.g., g4DD_kerr_schild).\n",
    "        g4DD_metric(commondata, params, metric, y_padded, &metric_outputs[i]);\n",
    "        connections(commondata, params, metric, y_padded, &conn_outputs[i]);\n",
    "    }\n",
    "\"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body\n",
    "    )\n",
    "    print(f\"    ... Registered C placeholder engine: {name}() [High-Fidelity, Direct-Worker Call Version].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73a3bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algebraic_christoffel_worker():\n",
    "    \"\"\"\n",
    "    Generates the C worker that computes Christoffel symbols from pre-computed\n",
    "    metric and metric derivative values. This is a pure algebraic function.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C algebraic engine: calculate_christoffels_from_metric_and_derivs()...\")\n",
    "\n",
    "    # Step 1: Get the symbolic recipe.\n",
    "    Gamma4UDD_num_recipe = symbolic_numerical_christoffel_recipe()\n",
    "\n",
    "    # Step 2: Prepare lists for C code generation.\n",
    "    list_of_Gamma_C_vars = []\n",
    "    list_of_Gamma_syms = []\n",
    "    conn_Gamma4UDD = ixp.declarerank3(\"conn_out->Gamma4UDD\", dimension=4)\n",
    "    for alpha in range(4):\n",
    "        for mu in range(4):\n",
    "            for nu in range(mu, 4):\n",
    "                list_of_Gamma_C_vars.append(str(conn_Gamma4UDD[alpha][mu][nu]))\n",
    "                list_of_Gamma_syms.append(Gamma4UDD_num_recipe[alpha][mu][nu])\n",
    "\n",
    "    # Step 3: Generate the C preamble to unpack structs into local variables.\n",
    "    preamble = \"// Unpack input structs into local variables that match symbolic recipe.\\n\"\n",
    "    g_components = [f\"g{i}{j}\" for i in range(4) for j in range(i, 4)]\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            preamble += f\"    const double g4DD{i}{j} = g4DD_in->g{i}{j};\\n\"\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            for k in range(4):\n",
    "                preamble += f\"    const double g4DDdD{i}{j}_d{k} = g4DDdD_in->g{i}{j}d{k};\\n\"\n",
    "\n",
    "    # Step 4: Generate the computational kernel.\n",
    "    kernel_C_code = ccg.c_codegen(\n",
    "        list_of_Gamma_syms,\n",
    "        list_of_Gamma_C_vars,\n",
    "        enable_cse=True,\n",
    "        cse_varprefix=\"num_conn_intermed\"\n",
    "    )\n",
    "\n",
    "    # Step 5: Assemble and register the function.\n",
    "    body = preamble + kernel_C_code\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = \"Computes Christoffel symbols from pre-interpolated metric and derivative values.\"\n",
    "    name = \"calculate_christoffels_from_metric_and_derivs\"\n",
    "    params = \"\"\"const metric_struct *restrict g4DD_in,\n",
    "                const g4DD_deriv_struct *restrict g4DDdD_in,\n",
    "                connection_struct *restrict conn_out\"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body\n",
    "    )\n",
    "    print(f\"    ... Registered C algebraic engine: {name}().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce3df4",
   "metadata": {},
   "source": [
    "<a id='generic_engines'></a>\n",
    "### 6.c: Generic Physics and Integration Engines\n",
    "\n",
    "The Python functions in this subsection generate the generic C \"engines\" that are valid for *any* metric, whether analytic or numerical. They operate on abstract data structures (like `metric_struct` and `connection_struct`) and are completely decoupled from the specifics of how the values in those structs were computed.\n",
    "\n",
    "This is a key feature of the project's modular design. For example, the `calculate_ode_rhs()` engine doesn't care if the Christoffel symbols it receives were calculated from the analytic Kerr-Schild formula or the numerical interpolation pipeline; it just applies the geodesic equation to whatever values it is given. This allows for maximum code reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bece041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_p0_reverse():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the time component\n",
    "    of the reverse 4-momentum, p^0.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine function: calculate_p0_reverse()...\")\n",
    "    # The symbolic expression uses y[4] through y[7] for the 4-momentum\n",
    "    p0_expr = mom_time_p0_reverse()\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes reverse-time p^0 from the null condition g_munu p^mu p^nu = 0.\"\"\"\n",
    "    name = \"calculate_p0_reverse\"\n",
    "    c_type = \"double\"\n",
    "    # The function now takes the full 9-element state vector y.\n",
    "    params = \"const metric_struct *restrict metric, const double y[9]\"\n",
    "    \n",
    "\n",
    "            \n",
    "    # We generate the C code directly from the original expression.\n",
    "    # Since the C function takes the full y[9] vector, the array indices\n",
    "    # y[4], y[5], etc., in the generated code will be correct.\n",
    "    p0_C_code_lines = ccg.c_codegen(\n",
    "        p0_expr, 'double p0_val', enable_cse=True, include_braces=False\n",
    "    )\n",
    "    body = f\"{{\\n{p0_C_code_lines}\\nreturn p0_val;\\n}}\"\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, cfunc_type=c_type,\n",
    "        name=name, params=params, body=body\n",
    "    )\n",
    "    print(\"    ... calculate_p0_reverse() registration complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7fa79e",
   "metadata": {},
   "source": [
    "<a id='check_conservation'></a>\n",
    "### Generic Engine: `check_conservation()`\n",
    "\n",
    "This Python function generates the C engine `check_conservation()`. Its purpose is to calculate the conserved quantities (Energy `E`, the three components of angular momentum `L_i`, and the Carter Constant `Q`) for a given state vector `y`.\n",
    "\n",
    "This function is an excellent example of a **validation tool**. During a long integration, small numerical errors will inevitably accumulate. By calling this function periodically, we can monitor how well these physical quantities, which should be perfectly constant, are actually being conserved by our numerical solver. If they drift significantly, it indicates a problem with the integration accuracy (e.g., the step size is too large or the order of the integrator is too low).\n",
    "\n",
    "The C function is a dispatcher that operates on the *symbolic recipes* for the conserved quantities that we generated in Step 3.g. It takes the metric type as input and uses a `switch` statement to select the correct set of symbolic formulas (`list_of_expressions_kerr` or `list_of_expressions_schw`). It then calls `nrpy.c_codegen.c_codegen` to translate these high-level symbolic recipes into optimized C code on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e42b1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_conservation():\n",
    "    \"\"\"\n",
    "    Generates the C function `check_conservation`. This version is simplified\n",
    "    for a purely Cartesian pipeline.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine: check_conservation() [Cartesian Version]...\")\n",
    "\n",
    "    # Use the globally defined Cartesian recipes\n",
    "    output_vars_kerr = [\"*E\", \"*Lx\", \"*Ly\", \"*Lz\", \"*Q\"]\n",
    "    output_vars_schw = [\"*E\", \"*Lx\", \"*Ly\", \"*Lz\", \"*Q\"] # Q is L^2\n",
    "\n",
    "    body_C_code_kerr = ccg.c_codegen(list_of_expressions_kerr, output_vars_kerr, enable_cse=True, include_braces=False)\n",
    "    body_C_code_schw = ccg.c_codegen(list_of_expressions_schw, output_vars_schw, enable_cse=True, include_braces=False)\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Computes conserved quantities (E, L_i, Q/L^2) for a given state vector.\"\"\"\n",
    "    name = \"check_conservation\"\n",
    "    params = \"\"\"const commondata_struct *restrict commondata,\n",
    "        const params_struct *restrict params,\n",
    "        const metric_params *restrict metric_params_in,\n",
    "        const double y[9], \n",
    "        double *E, double *Lx, double *Ly, double *Lz, double *Q\"\"\"\n",
    "        \n",
    "    body = r\"\"\"\n",
    "    // Unpack parameters from commondata struct that are needed symbolically\n",
    "    const REAL a_spin = commondata->a_spin;\n",
    "\n",
    "    // Declare a POINTER to a metric_struct and allocate memory for it.\n",
    "    metric_struct* metric = (metric_struct*)malloc(sizeof(metric_struct));\n",
    "    \n",
    "    // Call the dispatcher to fill the allocated struct with metric components at the given state y.\n",
    "    g4DD_metric(commondata, params, metric_params_in, y, metric);\n",
    "\n",
    "    // --- MODIFIED: Simplified logic for Cartesian-only checks ---\n",
    "    if (metric_params_in->type == Kerr) {\n",
    "        \"\"\" + body_C_code_kerr + r\"\"\"\n",
    "    } else { // Both Schwarzschild types are now Cartesian\n",
    "        \"\"\" + body_C_code_schw + r\"\"\"\n",
    "    }\n",
    "    \n",
    "    free(metric);\n",
    "    \"\"\"\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, cfunc_type=\"void\",\n",
    "        name=name, params=params, body=body\n",
    "    )\n",
    "    print(f\"    ... {name}() registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c696c8",
   "metadata": {},
   "source": [
    "<a id='radiative_transfer_engine'></a>\n",
    "### Generic Engine: `radiative_transfer_engine()`\n",
    "\n",
    "This function generates the core C physics engine `calculate_radiative_transfer()`. This function implements the relativistic radiative transfer equation for an optically thin emitter, which connects the properties of the emitting gas to the light seen by a distant observer.\n",
    "\n",
    "It takes as input the photon's covariant 4-momentum ($p_\\mu$) at the point of emission, the fluid's covariant 4-velocity ($u_\\mu$) at that same point, and the fluid's intrinsic emissivity ($j_{int}$) and rest-frame emission wavelength ($\\lambda_{rest}$).\n",
    "\n",
    "The function then calculates the **redshift factor** (often denoted as `g` or `D`), which accounts for both gravitational redshift and the relativistic Doppler effect. This factor is the ratio of the energy of the photon as measured by the distant observer ($E_{obs}$) to the energy of the photon in the rest-frame of the emitting gas ($E_{emit}$):\n",
    "\n",
    "$$ g = \\frac{E_{obs}}{E_{emit}} = \\frac{(-p_\\mu u^\\mu)_{obs}}{(-p_\\mu u^\\mu)_{emit}} $$\n",
    "\n",
    "For a distant, stationary observer, their 4-velocity is simply $u^\\mu_{obs} = (1, 0, 0, 0)$, which simplifies the numerator to $E_{obs} = p_t$. The denominator is the full dot product of the photon's and the fluid's 4-momenta.\n",
    "\n",
    "Finally, it computes the observed physical quantities:\n",
    "*   **Observed Intensity:** For an optically thin source, the intensity scales as the cube of the redshift factor: $I_{obs} = j_{int} \\cdot g^3$.\n",
    "*   **Observed Wavelength:** The wavelength is directly shifted by the redshift factor: $\\lambda_{obs} = \\lambda_{rest} / g$.\n",
    "\n",
    "These final values are what are used to color the pixels in the final rendered image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a927da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radiative_transfer_engine():\n",
    "    \"\"\"\n",
    "    Generates the C engine for calculating the final observed intensity and\n",
    "    wavelength based on the interpolated disk state and photon momentum.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine for radiative transfer physics...\")\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\", \"<math.h>\"]\n",
    "    desc = r\"\"\"@brief Calculates the observed intensity and wavelength from the disk and photon state.\"\"\"\n",
    "    name = \"calculate_radiative_transfer\"\n",
    "    params = r\"\"\"\n",
    "    const double photon_p_mu[4], const double disk_u_mu[4],\n",
    "    const float disk_j_intrinsic, const double disk_lambda_rest,\n",
    "    double *stokes_I, double *lambda_observed\n",
    "    \"\"\"\n",
    "    body = r\"\"\"\n",
    "    // The observer is assumed to be at rest in the coordinate frame far away,\n",
    "    // so their 4-velocity is u_obs^mu = (1, 0, 0, 0).\n",
    "    // The metric is Minkowski far away, so u_obs_mu = (-1, 0, 0, 0).\n",
    "    // The photon momentum is p_mu.\n",
    "    // Therefore, (-p_mu u^mu)_obs = - (p_0 * -1) = p_0.\n",
    "    // NOTE: The photon momentum p_mu must be covariant (lower-indexed).\n",
    "    const double p_mu_u_mu_obs = photon_p_mu[0];\n",
    "\n",
    "    // Calculate (-p_mu u^mu)_disk\n",
    "    const double p_mu_u_mu_disk = - (photon_p_mu[0] * disk_u_mu[0] +\n",
    "                                     photon_p_mu[1] * disk_u_mu[1] +\n",
    "                                     photon_p_mu[2] * disk_u_mu[2] +\n",
    "                                     photon_p_mu[3] * disk_u_mu[3]);\n",
    "\n",
    "    // Doppler factor D = E_obs / E_disk = (-p_mu u^mu)_obs / (-p_mu u^mu)_disk\n",
    "    const double doppler_factor = p_mu_u_mu_obs / p_mu_u_mu_disk;\n",
    "\n",
    "    // Observed intensity I_obs = j_intrinsic * D^3\n",
    "    *stokes_I = disk_j_intrinsic * doppler_factor * doppler_factor * doppler_factor;\n",
    "\n",
    "    // Observed wavelength lambda_obs = lambda_rest / D\n",
    "    *lambda_observed = disk_lambda_rest / doppler_factor;\n",
    "\"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... Registered C engine: calculate_radiative_transfer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b67d389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ode_rhs():\n",
    "\n",
    "    rhs_output_vars = [f\"rhs_out[{i}]\" for i in range(9)]\n",
    "\n",
    "\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "\n",
    "    desc = r\"\"\"@brief Calculates the right-hand sides (RHS) of the 9 geodesic ODEs.\n",
    " \n",
    "    This function implements the generic geodesic equation using pre-computed\n",
    "    Christoffel symbols. It is a pure \"engine\" function that does not depend\n",
    "    on any specific metric's parameters (like M_scale), only on the geometric\n",
    "    values passed to it via the connection struct.\n",
    "\n",
    "    @param[in]  y         The 9-component state vector [t, r, th, ph, p^t, p^r, p^th, p^ph, L].\n",
    "    @param[in]  conn      A pointer to the connection_struct holding the pre-computed Christoffel symbols.\n",
    "    @param[out] rhs_out   A pointer to the 9-component output array where the RHS results are stored.\"\"\"\n",
    "            \n",
    "    name = \"calculate_ode_rhs\"\n",
    "    params = \"const double y[9], const metric_struct *restrict metric, const connection_struct *restrict conn, double rhs_out[9]\"\n",
    "\n",
    "    body=ccg.c_codegen(all_rhs_expressions,rhs_output_vars)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes= includes,\n",
    "        name=name,\n",
    "        desc=desc,\n",
    "        params=params,\n",
    "        body=body\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d87383",
   "metadata": {},
   "source": [
    "<a id='lagrange_interp_engine'></a>\n",
    "### 6.e: `find_event_time_and_state()` Interpolation Engine\n",
    "\n",
    "This Python function generates a crucial C **engine** called `find_event_time_and_state()`. Its purpose is to find the precise time and state vector of a \"plane-crossing\" event with high accuracy, using data from three consecutive steps of the ODE integrator. This is essential for accurately mapping where a ray hits the window and source planes.\n",
    "\n",
    "The function implements a robust interpolation scheme:\n",
    "1.  **Quadratic Root Finding:** It treats the event condition (e.g., the distance to a plane, `f(y) = n_i x^i - d = 0`) as a function of the affine parameter, `f(κ)`. Given three points `(κ_prev, f_prev)`, `(κ_curr, f_curr)`, and `(κ_next, f_next)` that are known to bracket a root (i.e., the function changes sign), it fits a quadratic polynomial to these points. It then uses a numerically stable formula (similar to Muller's method) to find the root `κ_event` of this polynomial. This gives a much more accurate time for the plane crossing than simply taking the time of the closest step.\n",
    "2.  **Lagrange Polynomial Interpolation:** Once the precise event time `κ_event` is known, the function uses second-order [Lagrange basis polynomials](https://en.wikipedia.org/wiki/Lagrange_polynomial) to interpolate each of the 9 components of the state vector `y` to that exact time.\n",
    "\n",
    "This two-step process provides a highly accurate snapshot of the photon's state `y_event` at the exact moment it crosses a plane of interest. The C function body is written manually as a string, as its logic is algorithmic rather than symbolic, and then registered with `nrpy`.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced. Used here to register the manually written C code for the interpolation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7b4572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagrange_interp_engine_generic():\n",
    "    \"\"\"\n",
    "    Generates the generic Lagrange interpolation engine.\n",
    "    \n",
    "    This definitive version is numerically robust. It checks for small denominators\n",
    "    and unstable conditions, falling back to stable linear interpolation to prevent\n",
    "    NaN results in edge cases.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine: find_event_time_and_state() [Robust Version]...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"<math.h>\"]\n",
    "    desc = r\"\"\"@brief Finds the root of a generic event using a robust, second-order interpolation.\"\"\"\n",
    "    \n",
    "    name = \"find_event_time_and_state\"\n",
    "    params = r\"\"\"const double y_prev[9], const double y_curr[9], const double y_next[9],\n",
    "                double lambda_prev, double lambda_curr, double lambda_next,\n",
    "                event_function_t event_func, void *event_params,\n",
    "                event_data_struct *restrict result\"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    double t0 = lambda_prev, t1 = lambda_curr, t2 = lambda_next;\n",
    "    double f0 = event_func(y_prev, event_params);\n",
    "    double f1 = event_func(y_curr, event_params);\n",
    "    double f2 = event_func(y_next, event_params);\n",
    "\n",
    "    // --- Linear interpolation as a fallback ---\n",
    "    // This is used if quadratic interpolation is unstable or fails.\n",
    "    // It finds the root between the two points where the sign change occurs.\n",
    "    double t_linear;\n",
    "    if (f0 * f1 < 0.0 && fabs(f1 - f0) > 1e-12) { // Sign change is between prev and curr\n",
    "        t_linear = (f1 * t0 - f0 * t1) / (f1 - f0);\n",
    "    } else if (f1 * f2 < 0.0 && fabs(f2 - f1) > 1e-12) { // Sign change is between curr and next\n",
    "        t_linear = (f2 * t1 - f1 * t2) / (f2 - f1);\n",
    "    } else {\n",
    "        // This can happen if f1 is exactly zero.\n",
    "        t_linear = t1;\n",
    "    }\n",
    "\n",
    "    // --- Quadratic interpolation (Muller's method variant) ---\n",
    "    double h0 = t1 - t0;\n",
    "    double h1 = t2 - t1;\n",
    "\n",
    "    // Check for degenerate intervals to prevent division by zero.\n",
    "    if (fabs(h0) < 1e-15 || fabs(h1) < 1e-15 || fabs(h0 + h1) < 1e-15) {\n",
    "        result->lambda_event = t_linear;\n",
    "    } else {\n",
    "        double delta0 = (f1 - f0) / h0;\n",
    "        double delta1 = (f2 - f1) / h1;\n",
    "        double a = (delta1 - delta0) / (h1 + h0);\n",
    "        double b = a * h1 + delta1;\n",
    "        double c = f2;\n",
    "        double discriminant = b*b - 4*a*c;\n",
    "\n",
    "        if (discriminant < 0.0 || fabs(a) < 1e-15) {\n",
    "            // Discriminant is negative or equation is effectively linear.\n",
    "            result->lambda_event = t_linear;\n",
    "        } else {\n",
    "            // Use the more stable form of the quadratic formula\n",
    "            double denom = (b >= 0.0) ? (b + sqrt(discriminant)) : (b - sqrt(discriminant));\n",
    "            if (fabs(denom) < 1e-15) {\n",
    "                result->lambda_event = t_linear;\n",
    "            } else {\n",
    "                double t_quad = t2 - (2.0 * c / denom);\n",
    "                // Only accept the quadratic result if it's within the bracketing interval.\n",
    "                if (t_quad > fmin(t0, t2) && t_quad < fmax(t0, t2)) {\n",
    "                    result->lambda_event = t_quad;\n",
    "                } else {\n",
    "                    result->lambda_event = t_linear;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // --- Perform final interpolation on the state vector using the found time ---\n",
    "    double t = result->lambda_event;\n",
    "    \n",
    "    // Check for degenerate intervals again before final interpolation\n",
    "    if (fabs(t0 - t1) < 1e-15 || fabs(t0 - t2) < 1e-15 || fabs(t1 - t2) < 1e-15) {\n",
    "        // Fallback to linear interpolation for the state vector as well\n",
    "        double frac = 0.5;\n",
    "        if (fabs(t2 - t1) > 1e-15) {\n",
    "            frac = (t - t1) / (t2 - t1);\n",
    "        }\n",
    "        for (int i = 0; i < 9; i++) {\n",
    "            result->y_event[i] = y_curr[i] + frac * (y_next[i] - y_curr[i]);\n",
    "        }\n",
    "    } else {\n",
    "        // Perform full quadratic interpolation\n",
    "        double L0 = ((t - t1) * (t - t2)) / ((t0 - t1) * (t0 - t2));\n",
    "        double L1 = ((t - t0) * (t - t2)) / ((t1 - t0) * (t1 - t2));\n",
    "        double L2 = ((t - t0) * (t - t1)) / ((t2 - t0) * (t2 - t1));\n",
    "        for (int i = 0; i < 9; i++) {\n",
    "            result->y_event[i] = y_prev[i] * L0 + y_curr[i] * L1 + y_next[i] * L2;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result->t_event = result->y_event[0];\n",
    "    result->found = true;\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... Registered C engine: find_event_time_and_state (Robust Version).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94fb7b8",
   "metadata": {},
   "source": [
    "<a id='generate_c_orchestrators'></a>\n",
    "# Step 7: C Code Generation - Orchestrators and Dispatchers\n",
    "\n",
    "With the low-level \"engine\" and \"worker\" functions defined in the previous step, we now generate the higher-level C functions that manage the simulation. These functions are responsible for dispatching to the correct worker based on runtime parameters and for orchestrating the overall program flow.\n",
    "\n",
    "*   **Dispatchers**: These are functions that contain a `switch` statement to select the correct \"worker\" function based on the chosen metric (e.g., `Schwarzschild` vs. `Kerr` vs. `Numerical`).\n",
    "*   **Orchestrators**: These are functions that execute a sequence of calls to other engines, workers, and dispatchers to perform a complex task, like setting up initial conditions or running the main integration loop.\n",
    "*   **Helpers**: These are small utility functions that manage resources, like loading data or sorting filenames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75843e1f",
   "metadata": {},
   "source": [
    "<a id='g4DD_metric_dispatcher'></a>\n",
    "### 7.a: `g4DD_metric()` Dispatcher\n",
    "\n",
    "This Python function generates the C function `g4DD_metric()`, which serves as a high-level **dispatcher** for the **analytic metrics**. Its role is to select and call the correct worker function to compute the components of the metric tensor, $g_{\\mu\\nu}$.\n",
    "\n",
    "The generated C code uses a `switch` statement that reads the `metric->type` member of the `metric_params` struct. It contains cases for the analytic spacetimes (`Kerr`, `Schwarzschild`, etc.) and calls the appropriate worker function (e.g., `g4DD_kerr_schild()`).\n",
    "\n",
    "This modular approach cleanly separates the control flow (deciding *which* analytic metric to use) from the physics implementation (the worker functions that know *how* to compute a specific metric). Note that this dispatcher is **not** used by the numerical metric pipeline, which has its own dedicated interpolation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65702cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g4DD_metric():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function g4DD_metric(), which serves as a\n",
    "    dispatcher to call the appropriate metric-specific worker function.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C dispatcher function: g4DD_metric()...\")\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Dispatcher to compute the 4-metric g_munu for the chosen metric.\"\"\"\n",
    "    name = \"g4DD_metric\"\n",
    "    # The signature is now coordinate-aware, but the y vector is always Cartesian here.\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const metric_params *restrict metric, const double y[9], metric_struct *restrict metric_out\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "    // The state vector y_pos contains only the position coordinates.\n",
    "    const double y_pos[4] = {y[0], y[1], y[2], y[3]};\n",
    "\n",
    "    // This switch statement chooses which \"worker\" function to call\n",
    "    // based on the metric type provided.\n",
    "    switch(metric->type) {\n",
    "        case Schwarzschild:\n",
    "        case Kerr:\n",
    "            // For Kerr or Schwarzschild in KS coords, call the unified Kerr-Schild C function.\n",
    "            g4DD_kerr_schild(commondata, params, y_pos, metric_out);\n",
    "            break;\n",
    "        // <-- MODIFIED: Call the new Cartesian worker\n",
    "        case Schwarzschild_Standard:\n",
    "            g4DD_schwarzschild_cartesian(commondata, params, y_pos, metric_out);\n",
    "            break;\n",
    "        case Numerical:\n",
    "            printf(\"Error: Numerical metric not supported yet.\\n\");\n",
    "            exit(1);\n",
    "            break;\n",
    "        default:\n",
    "            printf(\"Error: MetricType %d not supported in g4DD_metric() yet.\\n\", metric->type);\n",
    "            exit(1);\n",
    "            break;\n",
    "    }\n",
    "\"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... g4DD_metric() registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db30c0a",
   "metadata": {},
   "source": [
    "<a id='connections_dispatcher'></a>\n",
    "### 7.b: `connections()` Dispatcher\n",
    "\n",
    "This Python function generates the C function `connections()`, which acts as a second **dispatcher** for the **analytic metrics**. Its sole responsibility is to select and call the correct metric-specific worker function (like `con_kerr_schild()`) to compute the Christoffel symbols.\n",
    "\n",
    "Like the `g4DD_metric()` dispatcher, the generated C code uses a `switch` statement based on the `metric->type`. It dispatches the call to the appropriate specialized worker for the analytic spacetimes. This design is highly extensible: adding a new analytic metric simply requires writing a new worker function for its Christoffel symbols and adding a new `case` to this `switch` statement. This function is not used by the numerical metric pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b92b7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connections():\n",
    "    \"\"\"\n",
    "    Generates and registers the C dispatcher for Christoffel symbols.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C dispatcher: connections()...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"stdio.h\", \"stdlib.h\"]\n",
    "    desc = r\"\"\"@brief Dispatcher to compute Christoffel symbols for the chosen metric.\"\"\"\n",
    "    \n",
    "    name = \"connections\"\n",
    "    cfunc_type = \"void\" \n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const metric_params *restrict metric, const double y[9], connection_struct *restrict conn\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // The state vector y_pos contains only the position coordinates.\n",
    "    const double y_pos[4] = {y[0], y[1], y[2], y[3]};\n",
    "\n",
    "    // This switch statement chooses which \"worker\" function to call\n",
    "    // based on the metric type provided.\n",
    "    switch(metric->type) {\n",
    "        case Schwarzschild:\n",
    "        case Kerr:\n",
    "            con_kerr_schild(commondata, params, y_pos, conn);\n",
    "            break;\n",
    "        // <-- MODIFIED: Call the new Cartesian worker\n",
    "        case Schwarzschild_Standard:\n",
    "            con_schwarzschild_cartesian(commondata, params, y_pos, conn);\n",
    "            break;\n",
    "        case Numerical:\n",
    "            printf(\"Error: Numerical metric not supported yet.\\n\");\n",
    "            exit(1);\n",
    "            break;\n",
    "        default:\n",
    "            printf(\"Error: MetricType %d not supported yet.\\n\", metric->type);\n",
    "            exit(1);\n",
    "            break;\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, cfunc_type=cfunc_type,\n",
    "        name=name, params=params, body=body\n",
    "    )\n",
    "    print(\"    ... connections() registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ea28a",
   "metadata": {},
   "source": [
    "<a id='set_initial_conditions_cartesian'></a>\n",
    "### 7.c: `set_initial_conditions_cartesian()` Orchestrator\n",
    "\n",
    "This function generates the C **orchestrator** `set_initial_conditions_cartesian()`. This function is responsible for setting the complete initial state vector `y_out[9]` for a single light ray. It orchestrates a sequence of calculations to do this.\n",
    "\n",
    "The process for setting the initial state `y = (t, x, y, z, p^t, p^x, p^y, p^z, L)` is as follows:\n",
    "\n",
    "1.  **Set Initial Position**: The initial spatial coordinates `(x, y, z)` are set to the camera's location, `camera_pos`. The initial time `t` and path length `L` are set to `0.0`.\n",
    "2.  **Calculate Aiming Vector**: It computes the aiming vector `V`, which points from the camera to a specific target pixel on the window plane: `V = target_pos - camera_pos`.\n",
    "3.  **Set Initial Spatial Momentum**: As derived in the introduction, the initial reverse-time spatial momentum `(p^x, p^y, p^z)` must be parallel to the aiming vector `V`. It is therefore set to the normalized aiming vector: `p^i = V^i / |V|`.\n",
    "4.  **Calculate Initial Time Momentum**: With the spatial components of the momentum set, the final unknown is the time component, $p^t = p^0$. This requires a call to the physics engines:\n",
    "    *   First, it calls the `g4DD_metric()` dispatcher to compute the metric components $g_{\\mu\\nu}$ at the camera's location.\n",
    "    *   Then, it passes these metric components and the partially-filled state vector `y_out` to the `calculate_p0_reverse()` engine, which solves the null condition $g_{\\mu\\nu}p^\\mu p^\\nu=0$ for $p^0$.\n",
    "    *   The result is stored in `y_out[4]`, completing the initial state vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfd43b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_conditions_cartesian():\n",
    "    \"\"\"\n",
    "    Generates the C engine to set the initial state vector, now entirely in\n",
    "    Cartesian coordinates.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine: set_initial_conditions_cartesian()...\")\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Sets the full initial state for a ray in Cartesian coordinates.\"\"\"\n",
    "    \n",
    "    name = \"set_initial_conditions_cartesian\"\n",
    "    params = \"\"\"const commondata_struct *restrict commondata, const params_struct *restrict params,\n",
    "                const metric_params *restrict metric,\n",
    "                const double camera_pos[3], const double target_pos[3],\n",
    "                double y_out[9]\"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // --- Step 1: Set the initial position to the camera's location ---\n",
    "    y_out[0] = 0.0; // t\n",
    "    y_out[1] = camera_pos[0]; // x\n",
    "    y_out[2] = camera_pos[1]; // y\n",
    "    y_out[3] = camera_pos[2]; // z\n",
    "    y_out[8] = 0.0; // L (integrated path length)\n",
    "\n",
    "    // --- Step 2: Calculate the aiming vector V and set spatial momentum ---\n",
    "    const double V_x = target_pos[0] - camera_pos[0];\n",
    "    const double V_y = target_pos[1] - camera_pos[1];\n",
    "    const double V_z = target_pos[2] - camera_pos[2];\n",
    "    const double mag_V = sqrt(V_x*V_x + V_y*V_y + V_z*V_z);\n",
    "    \n",
    "    // The reverse-momentum p is parallel to the aiming vector V.\n",
    "    if (mag_V > 1e-12) {\n",
    "        y_out[5] = V_x / mag_V; // p^x\n",
    "        y_out[6] = V_y / mag_V; // p^y\n",
    "        y_out[7] = V_z / mag_V; // p^z\n",
    "    } else {\n",
    "        // Should not happen in production, but as a fallback, set a default momentum.\n",
    "        y_out[5] = 1.0; y_out[6] = 0.0; y_out[7] = 0.0;\n",
    "    }\n",
    "    \n",
    "    // --- Step 3: Calculate the time component p^t using the null condition ---\n",
    "    metric_struct g4DD;\n",
    "    // Note: The g4DD_metric function needs the first 4 elements of y_out (the coordinates).\n",
    "    g4DD_metric(commondata, params, metric, y_out, &g4DD);\n",
    "    \n",
    "    // The state vector y is (t,x,y,z, p^t,p^x,p^y,p^z, L).\n",
    "    y_out[4] = calculate_p0_reverse(&g4DD, y_out);\n",
    "    \"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a4a8ec",
   "metadata": {},
   "source": [
    "<a id='event_detection_manager'></a>\n",
    "### 7.d: `event_detection_manager()` Orchestrator\n",
    "\n",
    "This Python function generates the C orchestrator `event_detection_manager()`. This function is called at each step of the integration for photons that have not yet terminated. Its job is to check if the photon has crossed one of the predefined geometric surfaces: the camera's **window plane** or the fallback **source plane**.\n",
    "\n",
    "The logic is purely geometric. For each plane, it knows the photon's position at three consecutive substeps (`y_prev`, `y_curr`, `y_next`). It determines which side of the plane the photon is on at the start and end of the full step. If the photon has changed sides, a crossing has occurred.\n",
    "\n",
    "When a crossing is detected, this orchestrator calls the `find_event_time_and_state()` engine to perform a high-accuracy interpolation, finding the precise state of the photon at the exact moment of intersection. This event data is then stored for later processing by the finalizer. This function is a key part of the \"event cascade,\" being called only after the higher-priority disk intersection checks have been performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "397cd27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_detection_manager():\n",
    "    \"\"\"\n",
    "    Generates the C event detection manager.\n",
    "    \n",
    "    This final version is a pure, stateless plane-crossing detector. It takes\n",
    "    the previous state of the photon (which side of the plane it was on) and\n",
    "    updates the event_data_struct if a crossing has occurred.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C event detection manager (Stateless Plane Detector Version)...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"<math.h>\"]\n",
    "    \n",
    "\n",
    "    desc = r\"\"\"@brief Detects crossings of the window and source planes.\"\"\"\n",
    "    name = \"event_detection_manager\"\n",
    "    cfunc_type = \"void\"\n",
    "    params = r\"\"\"\n",
    "        const double y_prev[9], const double y_curr[9], const double y_next[9],\n",
    "        double lambda_prev, double lambda_curr, double lambda_next,\n",
    "        const commondata_struct *restrict commondata,\n",
    "        bool *on_positive_side_of_window_prev,\n",
    "        bool *on_positive_side_of_source_prev,\n",
    "        event_data_struct *restrict window_event,\n",
    "        event_data_struct *restrict source_plane_event\n",
    "        \"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // --- Window Plane Detection ---\n",
    "    // This logic is only performed if the caller has not already found the event.\n",
    "    if (!window_event->found) {\n",
    "        double window_plane_normal[3] = {commondata->window_center_x - commondata->camera_pos_x,\n",
    "                                         commondata->window_center_y - commondata->camera_pos_y,\n",
    "                                         commondata->window_center_z - commondata->camera_pos_z};\n",
    "        const double mag_w_norm = sqrt(SQR(window_plane_normal[0]) + SQR(window_plane_normal[1]) + SQR(window_plane_normal[2]));\n",
    "        if (mag_w_norm > 1e-12) {\n",
    "            const double inv_mag_w_norm = 1.0 / mag_w_norm;\n",
    "            for(int i=0;i<3;i++) window_plane_normal[i] *= inv_mag_w_norm;\n",
    "        }\n",
    "        const double window_plane_dist = commondata->window_center_x * window_plane_normal[0] +\n",
    "                                         commondata->window_center_y * window_plane_normal[1] +\n",
    "                                         commondata->window_center_z * window_plane_normal[2];\n",
    "\n",
    "        plane_event_params window_params = {{window_plane_normal[0], window_plane_normal[1], window_plane_normal[2]}, window_plane_dist};\n",
    "        bool on_positive_side_curr = (plane_event_func(y_next, &window_params) > 0);\n",
    "        if (on_positive_side_curr != *on_positive_side_of_window_prev) {\n",
    "            find_event_time_and_state(y_prev, y_curr, y_next, lambda_prev, lambda_curr, lambda_next,\n",
    "                                      plane_event_func, &window_params, window_event);\n",
    "        }\n",
    "        *on_positive_side_of_window_prev = on_positive_side_curr;\n",
    "    }\n",
    "\n",
    "    // --- Source Plane Detection ---\n",
    "    // This logic is only performed if the caller has not already found the event.\n",
    "    if (!source_plane_event->found) {\n",
    "        const double source_plane_normal[3] = {commondata->source_plane_normal_x,\n",
    "                                               commondata->source_plane_normal_y,\n",
    "                                               commondata->source_plane_normal_z};\n",
    "        const double source_plane_dist = commondata->source_plane_center_x * source_plane_normal[0] +\n",
    "                                         commondata->source_plane_center_y * source_plane_normal[1] +\n",
    "                                         commondata->source_plane_center_z * source_plane_normal[2];\n",
    "\n",
    "        plane_event_params source_params = {{source_plane_normal[0], source_plane_normal[1], source_plane_normal[2]}, source_plane_dist};\n",
    "        bool on_positive_side_curr = (plane_event_func(y_next, &source_params) > 0);\n",
    "        if (on_positive_side_curr != *on_positive_side_of_source_prev) {\n",
    "            find_event_time_and_state(y_prev, y_curr, y_next, lambda_prev, lambda_curr, lambda_next,\n",
    "                                      plane_event_func, &source_params, source_plane_event);\n",
    "        }\n",
    "        *on_positive_side_of_source_prev = on_positive_side_curr;\n",
    "    }\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, cfunc_type=cfunc_type, name=name, params=params, body=body)\n",
    "    print(\"    ... Registered event_detection_manager (Stateless Plane Detector Version).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed99f6d7",
   "metadata": {},
   "source": [
    "<a id='handle_source_plane_intersection_engine'></a>\n",
    "### 7.e: `handle_source_plane_intersection()` Engine\n",
    "\n",
    "This function generates the C engine that processes a fallback **source plane** intersection event. It is called by the main integration loop when the `event_detection_manager` reports that a photon has hit the source plane.\n",
    "\n",
    "Its responsibilities are:\n",
    "1.  **Coordinate Transformation**: It takes the 3D Cartesian intersection point `(x, y, z)` from the event data. It then projects this point onto the source plane's own local, 2D orthonormal basis to calculate the texture coordinates `(y_s, z_s)`.\n",
    "2.  **Bounds Checking**: It checks if the calculated planar radius `r_s = sqrt(y_s^2 + z_s^2)` is within the user-defined active region (`source_r_min`, `source_r_max`).\n",
    "3.  **Populate Blueprint**: If the hit is within the valid region, it populates the relevant fields in the `blueprint_data_t` struct and returns `true`. Otherwise, it returns `false`, and the photon continues its integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bbed74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_source_plane_intersection_engine():\n",
    "    \"\"\"\n",
    "    Generates a C engine that handles a source plane intersection.\n",
    "    This version is reverted to be compatible with the v11.7 termination_type_t enum.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine: handle_source_plane_intersection (v11.7 compatible)...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"<math.h>\", \"<stdbool.h>\"]\n",
    "    desc = r\"\"\"@brief Handles a source plane intersection by checking bounds and populating the blueprint.\"\"\"\n",
    "    name = \"handle_source_plane_intersection\"\n",
    "    cfunc_type = \"bool\"\n",
    "    params = r\"\"\"\n",
    "    const event_data_struct *restrict source_plane_event,\n",
    "    const commondata_struct *restrict commondata,\n",
    "    blueprint_data_t *restrict final_blueprint_data\n",
    "    \"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // --- Calculate the local (y_s, z_s) coordinates on the plane ---\n",
    "    const double intersection_pos[3] = {source_plane_event->y_event[1], source_plane_event->y_event[2], source_plane_event->y_event[3]};\n",
    "    const double source_plane_center[3] = {commondata->source_plane_center_x, commondata->source_plane_center_y, commondata->source_plane_center_z};\n",
    "    const double source_plane_normal[3] = {commondata->source_plane_normal_x, commondata->source_plane_normal_y, commondata->source_plane_normal_z};\n",
    "    const double source_up_vector[3] = {commondata->source_up_vec_x, commondata->source_up_vec_y, commondata->source_up_vec_z};\n",
    "\n",
    "    // Construct orthonormal basis vectors for the source plane\n",
    "    double s_z[3] = {source_plane_normal[0], source_plane_normal[1], source_plane_normal[2]};\n",
    "    double s_x[3] = {source_up_vector[1]*s_z[2] - source_up_vector[2]*s_z[1], \n",
    "                     source_up_vector[2]*s_z[0] - source_up_vector[0]*s_z[2], \n",
    "                     source_up_vector[0]*s_z[1] - source_up_vector[1]*s_z[0]};\n",
    "    double mag_s_x = sqrt(SQR(s_x[0]) + SQR(s_x[1]) + SQR(s_x[2]));\n",
    "    \n",
    "    if (mag_s_x < 1e-9) {\n",
    "        double alternative_up[3] = {1.0, 0.0, 0.0};\n",
    "        if (fabs(s_z[0]) > 0.999) {\n",
    "            alternative_up[0] = 0.0;\n",
    "            alternative_up[1] = 1.0;\n",
    "        }\n",
    "        s_x[0] = alternative_up[1]*s_z[2] - alternative_up[2]*s_z[1];\n",
    "        s_x[1] = alternative_up[2]*s_z[0] - alternative_up[0]*s_z[2];\n",
    "        s_x[2] = alternative_up[0]*s_z[1] - alternative_up[1]*s_z[0];\n",
    "        mag_s_x = sqrt(SQR(s_x[0]) + SQR(s_x[1]) + SQR(s_x[2]));\n",
    "    }\n",
    "    \n",
    "    for(int i=0; i<3; i++) s_x[i] /= mag_s_x;\n",
    "    \n",
    "    double s_y[3] = {s_z[1]*s_x[2] - s_z[2]*s_x[1], \n",
    "                     s_z[2]*s_x[0] - s_z[0]*s_x[2], \n",
    "                     s_z[0]*s_x[1] - s_z[1]*s_x[0]};\n",
    "\n",
    "    const double vec_s[3] = {intersection_pos[0] - source_plane_center[0], \n",
    "                             intersection_pos[1] - source_plane_center[1], \n",
    "                             intersection_pos[2] - source_plane_center[2]};\n",
    "    \n",
    "    const double y_s = vec_s[0]*s_x[0] + vec_s[1]*s_x[1] + vec_s[2]*s_x[2];\n",
    "    const double z_s = vec_s[0]*s_y[0] + vec_s[1]*s_y[1] + vec_s[2]*s_y[2];\n",
    "    \n",
    "    const double r_s_sq = SQR(y_s) + SQR(z_s);\n",
    "    \n",
    "    if (r_s_sq >= SQR(commondata->source_r_min) && r_s_sq <= SQR(commondata->source_r_max)) {\n",
    "        // This is a valid hit. Populate the blueprint and return true.\n",
    "        // *** REVERTED: Use the correct enum member from termination_type_t ***\n",
    "        final_blueprint_data->termination_type = TERMINATION_TYPE_SOURCE_PLANE;\n",
    "        final_blueprint_data->y_s = y_s;\n",
    "        final_blueprint_data->z_s = z_s;\n",
    "        final_blueprint_data->t_s = source_plane_event->t_event;\n",
    "        final_blueprint_data->L_s = source_plane_event->y_event[8];\n",
    "        return true;\n",
    "    }\n",
    "    \n",
    "    // The intersection was outside the valid radial bounds. Return false.\n",
    "    return false;\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, cfunc_type=cfunc_type, params=params, body=body)\n",
    "    print(f\"    ... Registered C engine: {name}().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e8cbb9",
   "metadata": {},
   "source": [
    "<a id='handle_disk_intersection_engine'></a>\n",
    "### 7.f: `handle_disk_intersection()` Engine\n",
    "\n",
    "This function generates the C engine that performs the final physics calculations for a photon that has terminated on the physical **accretion disk**. It is called by the main \"finalizer\" function (`calculate_and_fill_blueprint_data_universal`) after all integration is complete.\n",
    "\n",
    "This engine orchestrates the full radiative transfer calculation:\n",
    "1.  **Get Metric**: It calls the `g4DD_metric` dispatcher to get the metric tensor `g_{\\mu\\nu}` at the photon's final intersection point.\n",
    "2.  **Lower Indices**: It uses the metric to lower the indices of both the photon's 4-momentum (converting $p^\\mu$ to $p_\\mu$) and the disk particle's 4-velocity (converting $u^\\mu$ to $u_\\mu$). This is mathematically essential for the next step.\n",
    "3.  **Call Radiative Transfer Engine**: It passes the covariant vectors and the intrinsic properties of the disk particle (stored in the `nearest_neighbor` struct) to the `calculate_radiative_transfer()` engine.\n",
    "4.  **Populate Blueprint**: The `calculate_radiative_transfer` engine computes the final observed intensity and wavelength. This function then populates the `blueprint_data_t` struct with these physical results, as well as diagnostic information like the intersection time and path length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20b41edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_disk_intersection_engine():\n",
    "    \"\"\"\n",
    "    Generates the C engine for handling a disk intersection. This definitive\n",
    "    version (v6.0) is repurposed as a pure physics calculator, to be called\n",
    "    only during the finalization phase.\n",
    "    \"\"\"\n",
    "    print(\" -> Repurposing C engine: handle_disk_intersection (v6.0)...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"<math.h>\"]\n",
    "    desc = r\"\"\"@brief Performs the final radiative transfer calculation for a disk intersection.\n",
    "    @details This engine is called by the finalizer. It takes the photon's final\n",
    "             state and the stored nearest-neighbor data, computes the observed\n",
    "             intensity and wavelength, and populates the final blueprint record.\n",
    "    \"\"\"\n",
    "    name = \"handle_disk_intersection\"\n",
    "    \n",
    "    # *** CORRECTED: New signature for its new role as a finalizer helper. ***\n",
    "    params = r\"\"\"\n",
    "    const double final_y[9],\n",
    "    const MassiveParticle *restrict nearest_neighbor,\n",
    "    const commondata_struct *restrict commondata, const params_struct *restrict params,\n",
    "    const metric_params *restrict metric,\n",
    "    blueprint_data_t *restrict final_blueprint_data\n",
    "    \"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // This function now assumes the photon's status is already TERMINATED_DISK.\n",
    "    \n",
    "    // 1. Get metric at the photon's final position (the intersection point).\n",
    "    metric_struct g4DD;\n",
    "    g4DD_metric(commondata, params, metric, final_y, &g4DD);\n",
    "    \n",
    "    // 2. Lower the indices of the photon's 4-momentum and the neighbor's 4-velocity\n",
    "    //    using the metric at the intersection point.\n",
    "    const double g_munu[4][4] = {\n",
    "        {g4DD.g00, g4DD.g01, g4DD.g02, g4DD.g03},\n",
    "        {g4DD.g01, g4DD.g11, g4DD.g12, g4DD.g13},\n",
    "        {g4DD.g02, g4DD.g12, g4DD.g22, g4DD.g23},\n",
    "        {g4DD.g03, g4DD.g13, g4DD.g23, g4DD.g33}\n",
    "    };\n",
    "    \n",
    "    double photon_p_mu[4] = {0,0,0,0};\n",
    "    double disk_u_mu[4] = {0,0,0,0};\n",
    "    for(int mu=0; mu<4; mu++) {\n",
    "        for(int nu=0; nu<4; nu++) {\n",
    "            photon_p_mu[mu] += g_munu[mu][nu] * final_y[nu+4];\n",
    "            disk_u_mu[mu] += g_munu[mu][nu] * nearest_neighbor->u[nu];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // 3. Call the core radiative transfer physics engine.\n",
    "    double temp_stokes_I;\n",
    "    double temp_lambda_observed;\n",
    "    calculate_radiative_transfer(photon_p_mu, disk_u_mu, \n",
    "                                 nearest_neighbor->j_intrinsic, nearest_neighbor->lambda_rest,\n",
    "                                 &temp_stokes_I, &temp_lambda_observed);\n",
    "    \n",
    "    // 4. Populate the final blueprint with the results.\n",
    "    final_blueprint_data->stokes_I = temp_stokes_I;\n",
    "    final_blueprint_data->lambda_observed = temp_lambda_observed;\n",
    "    \n",
    "    // 5. Populate diagnostic information from the intersection.\n",
    "    final_blueprint_data->y_s = nearest_neighbor->pos[0]; // x-pos of neighbor\n",
    "    final_blueprint_data->z_s = nearest_neighbor->pos[1]; // y-pos of neighbor\n",
    "    final_blueprint_data->t_s = final_y[0]; // time of intersection\n",
    "    final_blueprint_data->L_s = final_y[8]; // path length at intersection\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)\n",
    "    print(f\"    ... Registered C engine: {name}() (Repurposed as Finalizer Helper).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0327045",
   "metadata": {},
   "source": [
    "<a id='data_processing'></a>\n",
    "### 7.g: `calculate_and_fill_blueprint_data_universal()` \n",
    "\n",
    "This Python function generates the C \"finalizer\" engine `calculate_and_fill_blueprint_data_universal()`. Its sole purpose is to process the raw data from a single completed ray trace and compute the final quantities that are saved to the `blueprint.bin` file. It is called once for each photon after its integration is finished.\n",
    "\n",
    "This function acts as a high-level dispatcher based on the photon's final `status`:\n",
    "*   If the photon hit the **window plane**, it projects the 3D intersection point to 2D window coordinates `(y_w, z_w)`.\n",
    "*   If the photon hit the **source plane**, it calls the `handle_source_plane_intersection()` engine.\n",
    "*   If the photon hit the **accretion disk**, it calls the `handle_disk_intersection()` engine to perform the full radiative transfer calculation.\n",
    "*   If the photon hit the **celestial sphere**, it converts the final Cartesian position to spherical polar angles `(θ, φ)`.\n",
    "*   If the photon **failed**, it does nothing further.\n",
    "\n",
    "Finally, it returns the fully populated `blueprint_data_t` struct to be written to the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faf83411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_fill_blueprint_data_universal():\n",
    "    \"\"\"\n",
    "    Generates the C finalization engine, now updated to handle disk intersections\n",
    "    by calling the radiative transfer physics engines.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C finalization engine: calculate_and_fill_blueprint_data_universal (with disk physics)...\")\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Processes a photon's final state to compute all blueprint quantities.\"\"\"\n",
    "    name = \"calculate_and_fill_blueprint_data_universal\"\n",
    "    cfunc_type = \"blueprint_data_t\"\n",
    "    \n",
    "    params = \"\"\"const commondata_struct *restrict commondata, const params_struct *restrict params,\n",
    "                const metric_params *restrict metric,\n",
    "                const PhotonState *restrict photon,\n",
    "                const double window_center[3], const double n_x[3], const double n_y[3]\"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // Initialize all fields to zero.\n",
    "    blueprint_data_t result = {0};\n",
    "    // The C enum 'termination_type_t' is compatible with the integer field in the blueprint.\n",
    "    result.termination_type = photon->status;\n",
    "\n",
    "    // Always populate window data if a crossing was found.\n",
    "    if (photon->window_event_data.found) {\n",
    "        const double *y_event = photon->window_event_data.y_event;\n",
    "        const double pos_w_cart[3] = {y_event[1], y_event[2], y_event[3]};\n",
    "        const double vec_w[3] = {pos_w_cart[0] - window_center[0], pos_w_cart[1] - window_center[1], pos_w_cart[2] - window_center[2]};\n",
    "        result.y_w = vec_w[0]*n_x[0] + vec_w[1]*n_x[1] + vec_w[2]*n_x[2];\n",
    "        result.z_w = vec_w[0]*n_y[0] + vec_w[1]*n_y[1] + vec_w[2]*n_y[2];\n",
    "        result.L_w = y_event[8];\n",
    "        result.t_w = photon->window_event_data.t_event;\n",
    "    }\n",
    "\n",
    "    // Populate remaining fields based on the specific termination type.\n",
    "    if (photon->status == TERMINATION_TYPE_SOURCE_PLANE) {\n",
    "        // Use a temporary blueprint struct to satisfy the handle_source_plane_intersection signature.\n",
    "        // This function validates the hit and calculates geometric properties.\n",
    "        blueprint_data_t temp_blueprint;\n",
    "        if (handle_source_plane_intersection(&photon->source_event_data, commondata, &temp_blueprint)) {\n",
    "            result.y_s = temp_blueprint.y_s;\n",
    "            result.z_s = temp_blueprint.z_s;\n",
    "            result.L_s = temp_blueprint.L_s;\n",
    "            result.t_s = temp_blueprint.t_s;\n",
    "        }\n",
    "    } else if (photon->status == TERMINATION_TYPE_DISK) {\n",
    "        // *** NEW LOGIC FOR DISK HITS ***\n",
    "        // Call the dedicated physics engine for disk hits. This function will perform\n",
    "        // the index lowering and radiative transfer calculations.\n",
    "        handle_disk_intersection(\n",
    "            photon->y,                      // Photon's final state vector\n",
    "            &photon->nearest_neighbor,      // The stored particle data from the k-d tree hit\n",
    "            commondata, params, metric,\n",
    "            &result                         // The blueprint to be filled with I_obs, lambda_obs, etc.\n",
    "        );\n",
    "    } else if (photon->status == TERMINATION_TYPE_CELESTIAL_SPHERE) {\n",
    "        const double *final_y = photon->y;\n",
    "        const double x = final_y[1];\n",
    "        const double y = final_y[2];\n",
    "        const double z = final_y[3];\n",
    "        const double r = sqrt(SQR(x) + SQR(y) + SQR(z));\n",
    "        if (r > 1e-9) {\n",
    "            result.final_theta = acos(z / r);\n",
    "            result.final_phi = atan2(y, x);\n",
    "        }\n",
    "    }\n",
    "    // For TERMINATION_TYPE_FAILURE, no other fields need to be set.\n",
    "    \n",
    "    return result;\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, cfunc_type=cfunc_type, name=name, params=params, body=body, include_CodeParameters_h=True)\n",
    "    print(f\"    ... Registered C finalizer: {name}() (with disk physics).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d04bbb6",
   "metadata": {},
   "source": [
    "<a id='gsl_helpers'></a>\n",
    "### 7.h: GSL State Management Helpers\n",
    "\n",
    "The GNU Scientific Library (GSL) ODE integrator is a powerful tool, but it requires careful memory management. To avoid repeatedly allocating and freeing memory for every single time step (which would be extremely slow), we allocate a persistent \"state\" for each photon at the beginning of the simulation. This state includes the GSL stepper, control function, and evolution objects.\n",
    "\n",
    "The Python function in the next cell generates two small C helper functions to manage this process:\n",
    "*   **`gsl_photon_init(PhotonState *photon)`**: This function is called once per photon at the start of the simulation. It allocates the necessary GSL objects and attaches their pointers to the photon's `PhotonState` struct.\n",
    "*   **`gsl_photon_free(PhotonState *photon)`**: This function is called once per photon at the end of the simulation. It safely frees all the memory allocated by the `init` function, preventing memory leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aff0a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsl_photon_helpers():\n",
    "    \"\"\"\n",
    "    Generates and registers the C helper functions for initializing and\n",
    "    freeing the persistent GSL state associated with each photon.\n",
    "    \n",
    "    UPDATED to use a custom GSL control function that bases the adaptive\n",
    "    step-size control ONLY on the 4-momentum components, ignoring position.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating GSL state helper functions (Momentum-Only Control)...\")\n",
    "\n",
    "    # Helper 1: gsl_photon_init\n",
    "    includes_init = [\"BHaH_defines.h\"]\n",
    "    desc_init = r\"\"\"@brief Initializes the persistent GSL state for a single photon.\n",
    "    @details Allocates memory for the GSL stepper, a custom control function,\n",
    "             and the evolution function. The control function is configured to\n",
    "             base its error checking and step-size adaptation only on the\n",
    "             4-momentum components of the state vector, ignoring the positions.\n",
    "    \"\"\"\n",
    "    name_init = \"gsl_photon_init\"\n",
    "    params_init = \"PhotonState *photon\"\n",
    "    body_init = r\"\"\"\n",
    "    // Allocate the stepper, using the Runge-Kutta-Fehlberg 4(5) method.\n",
    "    photon->step = gsl_odeiv2_step_alloc(gsl_odeiv2_step_rkf45, 9);\n",
    "    \n",
    "    // --- CUSTOM STEP-SIZE CONTROL ---\n",
    "    // The GSL error control mechanism is based on the error D_i in each component y_i:\n",
    "    // D_i = eps_abs + eps_rel * (a_y |y_i| + a_dydt h |f_i|)\n",
    "    // The step is accepted if the norm of D_i/scale_abs_i is < 1.\n",
    "    // By setting scale_abs_i = 0 for the position components (i=0,1,2,3),\n",
    "    // we effectively remove them from the error control, basing the step-size\n",
    "    // adaptation solely on the 4-momentum components (i=4,5,6,7).\n",
    "    // The path length component (i=8) is also excluded.\n",
    "    const double scale_abs[9] = {\n",
    "        0.0, 0.0, 0.0, 0.0, // Ignore t, x, y, z\n",
    "        1.0, 1.0, 1.0, 1.0, // Use p^t, p^x, p^y, p^z for error control\n",
    "        0.0                 // Ignore L\n",
    "    };\n",
    "    // The a_y and a_dydt factors are set to 0 and 1 respectively, so the error\n",
    "    // is based only on the change in momentum (f_i), not its absolute value (y_i).\n",
    "    photon->control = gsl_odeiv2_control_scaled_new(1e-8, 1e-8, 0.0, 1.0, scale_abs, 9);\n",
    "    \n",
    "    // Allocate the evolution function.\n",
    "    photon->evolve = gsl_odeiv2_evolve_alloc(9);\n",
    "    \n",
    "    if (!photon->step || !photon->control || !photon->evolve) {\n",
    "        fprintf(stderr, \"Error: Failed to allocate GSL state for a photon.\\n\");\n",
    "        exit(1);\n",
    "    }\n",
    "\"\"\"\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes_init, desc=desc_init,\n",
    "        name=name_init, params=params_init, body=body_init\n",
    "    )\n",
    "    print(f\"    ... Registered C helper: {name_init}().\")\n",
    "\n",
    "    # Helper 2: gsl_photon_free (This function does not need to be changed)\n",
    "    includes_free = [\"BHaH_defines.h\"]\n",
    "    desc_free = r\"\"\"@brief Frees the memory associated with a single photon's GSL state.\"\"\"\n",
    "    name_free = \"gsl_photon_free\"\n",
    "    params_free = \"PhotonState *photon\"\n",
    "    body_free = r\"\"\"\n",
    "    if (photon->evolve) { gsl_odeiv2_evolve_free(photon->evolve); }\n",
    "    if (photon->control) { gsl_odeiv2_control_free(photon->control); }\n",
    "    if (photon->step) { gsl_odeiv2_step_free(photon->step); }\n",
    "\"\"\"\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes_free, desc=desc_free,\n",
    "        name=name_free, params=params_free, body=body_free\n",
    "    )\n",
    "    print(f\"    ... Registered C helper: {name_free}().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed0136e",
   "metadata": {},
   "source": [
    "<a id='gsl_wrapper'></a>\n",
    "### 7.i: The GSL Wrapper and Stepper Functions\n",
    "\n",
    "The GNU Scientific Library (GSL) requires that the user provide a function that calculates the right-hand side of the ODE system, and this function must have a specific C signature. The `ode_gsl_wrapper` C function serves as this critical **adapter** or **bridge** between the generic GSL interface and our specialized project code.\n",
    "\n",
    "The Python function in the next cell generates two C functions:\n",
    "1.  **`ode_gsl_wrapper()`**: This is the core adapter. At every GSL substep, it is called. Its job is to:\n",
    "    *   Unpack the `gsl_params` struct to get access to all necessary data (like the metric choice and the numerical metric cache).\n",
    "    *   Act as the top-level dispatcher between the **analytic** and **numerical** metric pipelines.\n",
    "    *   If the metric is analytic, it calls our `g4DD_metric` and `connections` dispatchers.\n",
    "    *   If the metric is numerical, it calls our all-in-one `interpolate_metric_and_derivatives` engine and the algebraic `calculate_christoffels_from_metric_and_derivs` worker.\n",
    "    *   Finally, it passes the computed metric and Christoffel symbols to the generic `calculate_ode_rhs` engine.\n",
    "\n",
    "2.  **`calculate_and_apply_single_step()`**: This is a small helper function that encapsulates the call to the main GSL evolution function, `gsl_odeiv2_evolve_apply`. This keeps the main integration loop in `batch_integrator` cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3313c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V12_5_light_geodesic.ipynb\n",
    "# This cell REPLACES the existing granular_gsl_engines() (Cell 3313c851).\n",
    "\n",
    "def analytic_gsl_engines():\n",
    "    \"\"\"\n",
    "    Generates the C engines for the ANALYTIC GSL pipeline.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating GSL control engines for ANALYTIC pipeline...\")\n",
    "\n",
    "    # --- Engine 1: calculate_and_apply_single_step (This can be moved to a shared helper) ---\n",
    "    # For now, we keep it here. It's used by both pipelines.\n",
    "    cfc.register_CFunction(\n",
    "        includes=[\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"],\n",
    "        desc=\"Applies a single adaptive step of the GSL integrator.\",\n",
    "        name=\"calculate_and_apply_single_step\",\n",
    "        cfunc_type=\"int\",\n",
    "        params=\"PhotonState *photon, gsl_odeiv2_system *sys\",\n",
    "        body=r\"\"\"\n",
    "    int status = gsl_odeiv2_evolve_apply(\n",
    "        photon->evolve, photon->control, photon->step, sys,\n",
    "        &photon->lambda, 1e10, &photon->d_lambda, photon->y\n",
    "    );\n",
    "    return status;\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    # --- Engine 2: ode_gsl_wrapper_analytic ---\n",
    "    includes_wrapper = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc_wrapper = r\"\"\"@brief GSL wrapper for the ANALYTIC geodesic ODEs.\"\"\"\n",
    "    name_wrapper = \"ode_gsl_wrapper_analytic\"\n",
    "    cfunc_type_wrapper = \"int\"\n",
    "    params_wrapper = \"double lambda, const double y[9], double f[9], void *params\"\n",
    "    body_wrapper = r\"\"\"\n",
    "    (void)lambda; // Suppress unused parameter warning for lambda.\n",
    "\n",
    "    gsl_params_analytic_t *gsl_parameters = (gsl_params_analytic_t *)params;\n",
    "\n",
    "    metric_struct g4DD_analytic;\n",
    "    connection_struct conn_analytic;\n",
    "    \n",
    "    g4DD_metric(gsl_parameters->commondata, gsl_parameters->params, gsl_parameters->metric, y, &g4DD_analytic);\n",
    "    connections(gsl_parameters->commondata, gsl_parameters->params, gsl_parameters->metric, y, &conn_analytic);\n",
    "    \n",
    "    calculate_ode_rhs(y, &g4DD_analytic, &conn_analytic, f);\n",
    "\n",
    "    return GSL_SUCCESS;\n",
    "\"\"\"\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes_wrapper, desc=desc_wrapper, cfunc_type=cfunc_type_wrapper,\n",
    "        name=name_wrapper, params=params_wrapper, body=body_wrapper\n",
    "    )\n",
    "    print(f\"    ... Registered C engines: calculate_and_apply_single_step() and {name_wrapper}().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b28dc31",
   "metadata": {},
   "source": [
    "# Numerical gsl wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60339fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gsl_wrapper():\n",
    "    \"\"\"\n",
    "    Generates the simplified C function `ode_gsl_wrapper_numerical`.\n",
    "    \n",
    "    UPDATED to accept and pass a pre-computed metric struct, fixing the\n",
    "    dummy variable bug and making it fully functional.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C GSL wrapper for numerical pipeline: ode_gsl_wrapper_numerical()...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief GSL wrapper for the numerical geodesic ODEs.\n",
    "This function's only job is to unpack the gsl_params_numerical_t struct,\n",
    "which contains pointers to the pre-computed metric and Christoffel symbols\n",
    "for the current step, and pass them to the generic RHS engine.\n",
    "\"\"\"\n",
    "    name = \"ode_gsl_wrapper_numerical\"\n",
    "    cfunc_type = \"int\"\n",
    "    params = \"double lambda, const double y[9], double f[9], void *params\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "    (void)lambda;\n",
    "    \n",
    "    // Unpack the carrier struct to get the pre-computed data.\n",
    "    gsl_params_numerical_t *gsl_params = (gsl_params_numerical_t *)params;\n",
    "    const metric_struct *metric = gsl_params->metric;\n",
    "    const connection_struct *conn = gsl_params->christoffels;\n",
    "\n",
    "\n",
    "    // Call the generic engine to compute the RHS of the ODEs with the correct data.\n",
    "    calculate_ode_rhs(y, metric, conn, f);\n",
    "    \n",
    "    return GSL_SUCCESS;\n",
    "\"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, cfunc_type=cfunc_type,\n",
    "        name=name, params=params, body=body\n",
    "    )\n",
    "    print(f\"    ... Registered C GSL wrapper: {name}().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3592b87",
   "metadata": {},
   "source": [
    "<a id='filename_sorter'></a>\n",
    "### 7.j: K-d Tree and Numerical Metric Helper Functions\n",
    "\n",
    "The following cells generate a series of C helper functions that are essential for managing the external data required by the simulation, such as the k-d tree snapshots and the numerical metric slices. These functions handle tasks like file I/O, sorting, and memory management.\n",
    "\n",
    "This first function, `filename_sorter`, generates a C comparison function `compare_filenames`. This small utility is required by the standard C library's `qsort` function. Its only job is to compare two snapshot filenames (e.g., `mass_blueprint_t_0100.kdtree.bin` and `mass_blueprint_t_0110.kdtree.bin`) based on their numerical timestamp, ensuring that when we load all the snapshot files, they are in the correct chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf6b3c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_sorter():\n",
    "    \"\"\"\n",
    "    Generates a C helper function to be used by qsort for sorting snapshot filenames.\n",
    "    \"\"\"\n",
    "    print(\" -> Registering C helper: filename_sorter()...\")\n",
    "    includes = [\"stdio.h\", \"<stdlib.h>\"]\n",
    "    desc = \"Comparison function for qsort to sort filenames numerically.\"\n",
    "    name = \"compare_filenames\"\n",
    "    cfunc_type = \"int\"\n",
    "    params = \"const void *a, const void *b\"\n",
    "    body = r\"\"\"\n",
    "    const char *str_a = *(const char **)a;\n",
    "    const char *str_b = *(const char **)b;\n",
    "    int num_a, num_b;\n",
    "    sscanf(str_a, \"mass_blueprint_t_%d.kdtree.bin\", &num_a);\n",
    "    sscanf(str_b, \"mass_blueprint_t_%d.kdtree.bin\", &num_b);\n",
    "    return (num_a > num_b) - (num_a < num_b);\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, cfunc_type=cfunc_type, params=params, body=body)\n",
    "    print(f\"    ... Registered C helper: {name}().\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da49cd9a",
   "metadata": {},
   "source": [
    "<a id='kdtree_loader'></a>\n",
    "### 7.k: K-d Tree Snapshot Loader and Unloader\n",
    "\n",
    "This Python function generates two low-level C worker functions for managing the memory of a single k-d tree snapshot file.\n",
    "\n",
    "*   **`load_kdtree_snapshot()`**: This function is responsible for loading a single `.kdtree.bin` file into memory. To achieve maximum performance and minimize RAM usage, it uses the `mmap` (memory-map) system call. Instead of reading the entire (potentially very large) file into the heap, `mmap` tells the operating system's virtual memory manager to map the file directly into the program's address space. The data is then loaded from disk on-demand by the OS as it is accessed.\n",
    "*   **`unload_kdtree_snapshot()`**: This function calls `munmap` to release the memory mapping created by the loader, ensuring there are no resource leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8f09e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdtree_loader_and_unloader():\n",
    "    \"\"\"\n",
    "    Generates C functions for memory-mapping a .kdtree.bin file into memory\n",
    "    and for unmapping it.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C functions for k-d tree memory mapping...\")\n",
    "\n",
    "    # Function to load a snapshot\n",
    "    load_includes = [\"BHaH_defines.h\", \"<stdio.h>\", \"<stdlib.h>\", \"<sys/mman.h>\", \"<sys/stat.h>\", \"<fcntl.h>\", \"<unistd.h>\"]\n",
    "    load_desc = r\"\"\"@brief Loads a .kdtree.bin snapshot file into memory using mmap.\"\"\"\n",
    "    load_name = \"load_kdtree_snapshot\"\n",
    "    load_params = \"const char *filename, CustomKDTree *tree\"\n",
    "    load_body = r\"\"\"\n",
    "    int fd = open(filename, O_RDONLY);\n",
    "    if (fd == -1) {\n",
    "        perror(\"Error opening k-d tree file\");\n",
    "        return -1; // Failure\n",
    "    }\n",
    "\n",
    "    struct stat sb;\n",
    "    if (fstat(fd, &sb) == -1) {\n",
    "        perror(\"Error getting file size\");\n",
    "        close(fd);\n",
    "        return -1;\n",
    "    }\n",
    "    tree->file_size = sb.st_size;\n",
    "\n",
    "    void *mapped_mem = mmap(NULL, tree->file_size, PROT_READ, MAP_PRIVATE, fd, 0);\n",
    "    if (mapped_mem == MAP_FAILED) {\n",
    "        perror(\"Error memory-mapping the file\");\n",
    "        close(fd);\n",
    "        return -1;\n",
    "    }\n",
    "    close(fd); // File descriptor no longer needed after mmap\n",
    "\n",
    "    tree->original_mmap_ptr = mapped_mem;\n",
    "    char *current_ptr = (char *)mapped_mem;\n",
    "\n",
    "    // Read header\n",
    "    tree->num_particles = *(uint64_t *)current_ptr;\n",
    "    current_ptr += sizeof(uint64_t);\n",
    "    tree->dimensions = *(uint64_t *)current_ptr;\n",
    "    current_ptr += sizeof(uint64_t);\n",
    "\n",
    "    // Set pointers to payloads\n",
    "    tree->node_metadata = (int32_t *)current_ptr;\n",
    "    current_ptr += sizeof(int32_t) * tree->num_particles;\n",
    "    tree->particle_data = (MassiveParticle *)current_ptr;\n",
    "\n",
    "    return 0; // Success\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=load_includes, desc=load_desc, name=load_name, params=load_params, body=load_body, cfunc_type=\"int\")\n",
    "\n",
    "    # Function to unload a snapshot\n",
    "    unload_includes = [\"BHaH_defines.h\", \"<sys/mman.h>\"]\n",
    "    unload_desc = r\"\"\"@brief Unloads a memory-mapped k-d tree snapshot.\"\"\"\n",
    "    unload_name = \"unload_kdtree_snapshot\"\n",
    "    unload_params = \"CustomKDTree *tree\"\n",
    "    unload_body = r\"\"\"\n",
    "    if (tree->original_mmap_ptr != NULL) {\n",
    "        munmap(tree->original_mmap_ptr, tree->file_size);\n",
    "        tree->original_mmap_ptr = NULL;\n",
    "    }\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=unload_includes, desc=unload_desc, name=unload_name, params=unload_params, body=unload_body)\n",
    "    \n",
    "    print(\"    ... Registered C functions: load_kdtree_snapshot, unload_kdtree_snapshot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab4090",
   "metadata": {},
   "source": [
    "<a id='kdtree_orchestrator'></a>\n",
    "### 7.l: K-d Tree Loader Orchestrator\n",
    "\n",
    "This Python function generates the C orchestrator `load_all_kdtree_snapshots()`. This function is called once by `main()` at the beginning of the simulation. It is responsible for finding, sorting, and loading all available k-d tree snapshot files.\n",
    "\n",
    "Its logic is as follows:\n",
    "1.  **Scan Directory**: It scans the `../processed_snapshots/` directory to find all files ending in `.kdtree.bin`. It first does a pass to count the number of files to allocate the correct amount of memory.\n",
    "2.  **Sort Filenames**: It stores the filenames in an array and calls the standard C library's `qsort` function, passing it our custom `compare_filenames` helper. This ensures the snapshots are sorted chronologically.\n",
    "3.  **Load Snapshots**: It iterates through the sorted list of filenames, calling the `load_kdtree_snapshot()` worker for each one. This populates the array of `CustomKDTree` structs.\n",
    "4.  **Calculate Timestamps**: It parses the timestamp from each filename and, using the `mass_snapshot_every_t` parameter, calculates the physical coordinate time for each snapshot, storing it in an array.\n",
    "5.  **Return Data**: It returns the total number of snapshots loaded and the pointers to the arrays containing the loaded tree data and the timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fd39296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdtree_loader_orchestrator():\n",
    "    \"\"\"\n",
    "    Generates and registers the C orchestrator function for finding, sorting,\n",
    "    and loading all k-d tree snapshot files from a directory into memory.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C k-d tree loader: load_all_kdtree_snapshots()...\")\n",
    "\n",
    "    # Add <dirent.h> for directory reading and <string.h> for strstr\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"stdio.h\", \"stdlib.h\", \"<dirent.h>\", \"<string.h>\"]\n",
    "    desc = r\"\"\"@brief Finds, sorts, and loads all .kdtree.bin files from the snapshot directory.\n",
    "    @details This function encapsulates the logic for memory-mapping the k-d tree\n",
    "             data needed for disk intersection checks.\n",
    "    @param[in]  commondata        Pointer to the commondata struct with runtime parameters.\n",
    "    @param[out] kdtree_snapshots  Pointer to be allocated and filled with snapshot data.\n",
    "    @param[out] snapshot_times    Pointer to be allocated and filled with snapshot times.\n",
    "    @return The total number of snapshots successfully loaded.\n",
    "    \"\"\"\n",
    "    name = \"load_all_kdtree_snapshots\"\n",
    "    cfunc_type = \"int\"\n",
    "    params = r\"\"\"\n",
    "    const commondata_struct *restrict commondata,\n",
    "    CustomKDTree **kdtree_snapshots,\n",
    "    double **snapshot_times\n",
    "    \"\"\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "    const char* snapshot_dir_path = \"../processed_snapshots\"; // Assumes a relative path\n",
    "    printf(\"Loading k-d tree snapshots from '%s'...\\n\", snapshot_dir_path);\n",
    "    DIR *dir;\n",
    "    struct dirent *ent;\n",
    "    int num_snapshots = 0;\n",
    "    if ((dir = opendir(snapshot_dir_path)) != NULL) {\n",
    "        while ((ent = readdir(dir)) != NULL) {\n",
    "            if (strstr(ent->d_name, \".kdtree.bin\") != NULL) {\n",
    "                num_snapshots++;\n",
    "            }\n",
    "        }\n",
    "        closedir(dir);\n",
    "    } else {\n",
    "        perror(\"Could not open snapshot directory\");\n",
    "        exit(1);\n",
    "    }\n",
    "\n",
    "    if (num_snapshots == 0) {\n",
    "        fprintf(stderr, \"Warning: No .kdtree.bin snapshot files found in '%s'. Disk intersection will be disabled.\\n\", snapshot_dir_path);\n",
    "        *kdtree_snapshots = NULL;\n",
    "        *snapshot_times = NULL;\n",
    "        return 0;\n",
    "    }\n",
    "\n",
    "    char **filenames = (char **)malloc(sizeof(char *) * num_snapshots);\n",
    "    if (filenames == NULL) { exit(1); }\n",
    "    dir = opendir(snapshot_dir_path);\n",
    "    int count = 0;\n",
    "    while ((ent = readdir(dir)) != NULL) {\n",
    "        if (strstr(ent->d_name, \".kdtree.bin\") != NULL) {\n",
    "            filenames[count] = strdup(ent->d_name);\n",
    "            count++;\n",
    "        }\n",
    "    }\n",
    "    closedir(dir);\n",
    "    qsort(filenames, num_snapshots, sizeof(char *), compare_filenames);\n",
    "\n",
    "    *kdtree_snapshots = (CustomKDTree *)malloc(sizeof(CustomKDTree) * num_snapshots);\n",
    "    *snapshot_times = (double *)malloc(sizeof(double) * num_snapshots);\n",
    "    if (*kdtree_snapshots == NULL || *snapshot_times == NULL) { exit(1); }\n",
    "\n",
    "    for (int i = 0; i < num_snapshots; ++i) {\n",
    "        char filepath[512];\n",
    "        snprintf(filepath, sizeof(filepath), \"%s/%s\", snapshot_dir_path, filenames[i]);\n",
    "        if (load_kdtree_snapshot(filepath, &(*kdtree_snapshots)[i]) != 0) {\n",
    "            fprintf(stderr, \"Error: Failed to load snapshot %s\\n\", filepath);\n",
    "            exit(1);\n",
    "        }\n",
    "        int snapshot_index;\n",
    "        sscanf(filenames[i], \"mass_blueprint_t_%d.kdtree.bin\", &snapshot_index);\n",
    "        (*snapshot_times)[i] = (double)snapshot_index * commondata->mass_snapshot_every_t;\n",
    "        free(filenames[i]);\n",
    "    }\n",
    "    free(filenames);\n",
    "    printf(\"Successfully loaded and sorted %d snapshots.\\n\", num_snapshots);\n",
    "    \n",
    "    return num_snapshots;\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, cfunc_type=cfunc_type,\n",
    "        name=name, params=params, body=body\n",
    "    )\n",
    "    print(f\"    ... Registered C orchestrator: {name}().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f243ad70",
   "metadata": {},
   "source": [
    "<a id='kdtree_search_engine'></a>\n",
    "### 7.m: K-d Tree Nearest Neighbor Search Engine\n",
    "\n",
    "This function generates the high-performance C engine for performing the k-Nearest Neighbor (k-NN) search. The core of the engine is the `search_recursive` C function.\n",
    "\n",
    "A naive implementation of a tree search can be slow due to **memory latency**. When the algorithm needs to access a child node, the data for that node might be in slow main memory (RAM) instead of the fast CPU cache, causing the CPU to stall.\n",
    "\n",
    "To solve this, the generated C code uses a low-level compiler intrinsic called `__builtin_prefetch`. This instruction acts as a hint to the CPU, telling it to start loading the data for both the \"good\" and \"bad\" child nodes into the cache *before* they are actually needed. While the CPU is busy processing the current node, the memory controller works in the background to fetch the next required data. This technique of **hiding memory latency** is crucial for achieving high performance in pointer-heavy algorithms like a tree search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f34cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdtree_search_engine():\n",
    "    \"\"\"\n",
    "    Generates the C functions that perform the recursive k-Nearest Neighbor search\n",
    "    on a loaded k-d tree.\n",
    "    \n",
    "    VERSION 2: PERFORMANCE OPTIMIZED.\n",
    "    This version adds __builtin_prefetch compiler intrinsics to the recursive\n",
    "    search function. This is a low-level hint to the CPU to begin fetching data\n",
    "    for child nodes from main memory into the cache before it is explicitly needed.\n",
    "    This technique aims to hide memory latency and reduce CPU stalls caused by\n",
    "    cache misses, which were identified as the primary performance bottleneck.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine for k-d tree nearest neighbor search [PERFORMANCE OPTIMIZED]...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"<math.h>\", \"<stdio.h>\"]\n",
    "    \n",
    "    prefunc = r\"\"\"\n",
    "// Helper to initialize the WinnersCircle struct\n",
    "static void wc_init(WinnersCircle *wc, int n_wanted) {\n",
    "    wc->n_wanted = n_wanted;\n",
    "    wc->count = 0;\n",
    "    for (int i = 0; i < n_wanted; ++i) {\n",
    "        wc->indices[i] = -1;\n",
    "        wc->sq_distances[i] = 1e300; // Initialize with a very large number\n",
    "    }\n",
    "}\n",
    "\n",
    "// Helper to add a candidate to the WinnersCircle, maintaining sorted order\n",
    "static void wc_add(WinnersCircle *wc, int index, double sq_dist) {\n",
    "    if (wc->count < wc->n_wanted) {\n",
    "        wc->indices[wc->count] = index;\n",
    "        wc->sq_distances[wc->count] = sq_dist;\n",
    "        wc->count++;\n",
    "    } else if (sq_dist < wc->sq_distances[wc->n_wanted - 1]) {\n",
    "        wc->indices[wc->n_wanted - 1] = index;\n",
    "        wc->sq_distances[wc->n_wanted - 1] = sq_dist;\n",
    "    } else {\n",
    "        return; // Not a winner\n",
    "    }\n",
    "\n",
    "    for (int i = wc->count - 1; i > 0; --i) {\n",
    "        if (wc->sq_distances[i] < wc->sq_distances[i - 1]) {\n",
    "            double temp_d = wc->sq_distances[i];\n",
    "            int temp_i = wc->indices[i];\n",
    "            wc->sq_distances[i] = wc->sq_distances[i - 1];\n",
    "            wc->indices[i] = wc->indices[i - 1];\n",
    "            wc->sq_distances[i - 1] = temp_d;\n",
    "            wc->indices[i - 1] = temp_i;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// The recursive search function\n",
    "static void search_recursive(const CustomKDTree *tree, const double query_pos[3], int current_idx, WinnersCircle *wc) {\n",
    "    if (current_idx < 0 || current_idx >= (int)tree->num_particles) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    const MassiveParticle *pivot = &tree->particle_data[current_idx];\n",
    "    const int split_axis = tree->node_metadata[current_idx];\n",
    "\n",
    "    const double dx = query_pos[0] - pivot->pos[0];\n",
    "    const double dy = query_pos[1] - pivot->pos[1];\n",
    "    const double dz = query_pos[2] - pivot->pos[2];\n",
    "    const double dist_sq = dx*dx + dy*dy + dz*dz;\n",
    "    wc_add(wc, current_idx, dist_sq);\n",
    "\n",
    "    if (split_axis == -1) { // Leaf node\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    const double axis_dist = query_pos[split_axis] - pivot->pos[split_axis];\n",
    "    const int good_side_idx = (axis_dist < 0) ? (2 * current_idx + 1) : (2 * current_idx + 2);\n",
    "    const int bad_side_idx = (axis_dist < 0) ? (2 * current_idx + 2) : (2 * current_idx + 1);\n",
    "\n",
    "    // *** PERFORMANCE OPTIMIZATION ***\n",
    "    // Issue prefetch instructions for the data of the child nodes. This hints to the\n",
    "    // CPU to start loading this memory into the cache while we process the current node.\n",
    "    // The '0' indicates a read operation.\n",
    "    // The '1' indicates low temporal locality (we likely won't need this exact data again soon).\n",
    "    if (good_side_idx < (int)tree->num_particles) {\n",
    "        __builtin_prefetch(&tree->particle_data[good_side_idx], 0, 1);\n",
    "    }\n",
    "    if (bad_side_idx < (int)tree->num_particles) {\n",
    "        __builtin_prefetch(&tree->particle_data[bad_side_idx], 0, 1);\n",
    "    }\n",
    "    // *** END OF OPTIMIZATION ***\n",
    "\n",
    "    search_recursive(tree, query_pos, good_side_idx, wc);\n",
    "\n",
    "    const double search_radius_sq = wc->sq_distances[wc->n_wanted - 1];\n",
    "    if (axis_dist * axis_dist < search_radius_sq) {\n",
    "        search_recursive(tree, query_pos, bad_side_idx, wc);\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "    desc = r\"\"\"@brief Finds the N nearest neighbors to a query point in a k-d tree.\"\"\"\n",
    "    name = \"find_n_nearest_neighbors\"\n",
    "    params = \"const CustomKDTree *tree, const double query_pos[3], int n_neighbors, MassiveParticle *neighbor_results\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "    if (n_neighbors > MAX_NEIGHBORS) {\n",
    "        fprintf(stderr, \"Error: Requested more neighbors than MAX_NEIGHBORS.\\n\");\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    WinnersCircle wc;\n",
    "    wc_init(&wc, n_neighbors);\n",
    "\n",
    "    // Start the recursive search from the root (index 0)\n",
    "    search_recursive(tree, query_pos, 0, &wc);\n",
    "\n",
    "    // Copy the results into the output array\n",
    "    for (int i = 0; i < wc.count; ++i) {\n",
    "        neighbor_results[i] = tree->particle_data[wc.indices[i]];\n",
    "    }\n",
    "\"\"\"\n",
    "    cfc.register_CFunction(includes=includes, prefunc=prefunc, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... Registered C engine: find_n_nearest_neighbors [PERFORMANCE OPTIMIZED].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69029a7a",
   "metadata": {},
   "source": [
    "<a id='integration_loop'></a>\n",
    "### 7.p: The Main Integration Loop Orchestrator\n",
    "\n",
    "This function generates the `batch_integrator`, which is the C orchestrator for the entire simulation. It implements the **\"Iterative Time Slotting\"** algorithm, which is a highly efficient method for integrating a large number of photons in parallel.\n",
    "\n",
    "The core idea is to group photons into \"time slots\" based on their current coordinate time. The algorithm then processes these slots in a chronological, backward-in-time sweep. For each slot, it:\n",
    "1.  \n",
    "2.  Processes all photons in the current slot in parallel bundles.\n",
    "3.  For each photon, it takes one adaptive time step using the GSL solver.\n",
    "4.  It then performs the full **event cascade**: checking for hard failures, then physical disk intersections (via the bounding box and k-d tree), and finally fallback geometric plane intersections.\n",
    "5.  If a photon is not terminated, it is placed into its new, earlier time slot to be processed in a future epoch.\n",
    "\n",
    "This architecture ensures that all photons being processed at any given moment are clustered in time, which maximizes data reuse for both the k-d tree snapshots and the numerical metric slices, dramatically reducing I/O and redundant computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7467afb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_integrator_orchestrator():\n",
    "    \"\"\"\n",
    "    Generates the main C orchestrator, now fully integrated with k-d tree\n",
    "    logic for physical disk intersection checks.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating top-level C orchestrator: batch_integrator() (with k-d tree logic)...\")\n",
    "\n",
    "\n",
    "    prefunc = r\"\"\"\n",
    "// --- Time Slot Manager Implementation ---\n",
    "typedef struct {\n",
    "    long int *photons;\n",
    "    long int count;\n",
    "    long int capacity;\n",
    "} PhotonList;\n",
    "typedef struct {\n",
    "    double t_min, t_max, delta_t_slot;\n",
    "    int num_slots;\n",
    "    PhotonList *slots;\n",
    "} TimeSlotManager;\n",
    "static void slot_manager_init(TimeSlotManager *tsm, double t_min, double t_max, double delta_t_slot) {\n",
    "    tsm->t_min = t_min;\n",
    "    tsm->t_max = t_max;\n",
    "    tsm->delta_t_slot = delta_t_slot;\n",
    "    tsm->num_slots = (int)ceil((t_max - t_min) / delta_t_slot);\n",
    "    if (tsm->num_slots <= 0) { fprintf(stderr, \"Error: Invalid TimeSlotManager dimensions.\\n\"); exit(1); }\n",
    "    tsm->slots = (PhotonList *)malloc(sizeof(PhotonList) * tsm->num_slots);\n",
    "    if (tsm->slots == NULL) { fprintf(stderr, \"Error: Failed to allocate memory for time slots.\\n\"); exit(1); }\n",
    "    for (int i = 0; i < tsm->num_slots; i++) {\n",
    "        tsm->slots[i].photons = (long int *)malloc(sizeof(long int) * 16);\n",
    "        if (tsm->slots[i].photons == NULL) { fprintf(stderr, \"Error: Failed to allocate memory for a slot's photon list.\\n\"); exit(1); }\n",
    "        tsm->slots[i].count = 0;\n",
    "        tsm->slots[i].capacity = 16;\n",
    "    }\n",
    "}\n",
    "static void slot_manager_free(TimeSlotManager *tsm) {\n",
    "    for (int i = 0; i < tsm->num_slots; i++) { free(tsm->slots[i].photons); }\n",
    "    free(tsm->slots);\n",
    "}\n",
    "static inline int slot_get_index(const TimeSlotManager *tsm, double t) {\n",
    "    if (t < tsm->t_min || t >= tsm->t_max) return -1;\n",
    "    return (int)floor((t - tsm->t_min) / tsm->delta_t_slot);\n",
    "}\n",
    "static void slot_add_photon(PhotonList *slot, long int photon_idx) {\n",
    "    if (slot->count >= slot->capacity) {\n",
    "        slot->capacity *= 2;\n",
    "        slot->photons = (long int *)realloc(slot->photons, sizeof(long int) * slot->capacity);\n",
    "        if (slot->photons == NULL) { fprintf(stderr, \"Error: Failed to reallocate memory for a slot's photon list.\\n\"); exit(1); }\n",
    "    }\n",
    "    slot->photons[slot->count++] = photon_idx;\n",
    "}\n",
    "static void slot_remove_chunk(PhotonList *slot, long int *chunk_buffer, long int chunk_size) {\n",
    "    for (long int i = 0; i < chunk_size; ++i) {\n",
    "        chunk_buffer[i] = slot->photons[i];\n",
    "    }\n",
    "    for (long int i = 0; i < slot->count - chunk_size; ++i) {\n",
    "        slot->photons[i] = slot->photons[i + chunk_size];\n",
    "    }\n",
    "    slot->count -= chunk_size;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"omp.h\", \"<stdbool.h>\"]\n",
    "    desc = r\"\"\"@brief Main orchestrator for \"Iterative Time Slotting\" photon integration with disk intersection.\"\"\"\n",
    "    name = \"batch_integrator\"\n",
    "    # UPDATED C function signature to accept k-d tree data\n",
    "    params = r\"\"\"\n",
    "    const commondata_struct *restrict commondata,\n",
    "    const params_struct *restrict params,\n",
    "    const metric_params *restrict metric,\n",
    "    long int num_rays,\n",
    "    int num_snapshots,\n",
    "    const CustomKDTree *kdtree_snapshots,\n",
    "    const double *snapshot_times,\n",
    "    blueprint_data_t *results_buffer\n",
    "    \"\"\"\n",
    "    body = r\"\"\"\n",
    "\n",
    "\n",
    "    // === INITIALIZATION ===\n",
    "    printf(\"Initializing %ld photon states for batch integration...\\n\", num_rays);\n",
    "    PhotonState *all_photons = (PhotonState *)malloc(sizeof(PhotonState) * num_rays);\n",
    "    if (all_photons == NULL) { fprintf(stderr, \"Error: Failed to allocate memory for photon states.\\n\"); exit(1); }\n",
    "    long int active_photons = num_rays;\n",
    "\n",
    "    TimeSlotManager tsm;\n",
    "    slot_manager_init(&tsm, commondata->slot_manager_t_min, commondata->t_start + 1.0, commondata->slot_manager_delta_t);\n",
    "\n",
    "    const double camera_pos[3] = {commondata->camera_pos_x, commondata->camera_pos_y, commondata->camera_pos_z};\n",
    "    const double window_center[3] = {commondata->window_center_x, commondata->window_center_y, commondata->window_center_z};\n",
    "    double n_z[3] = {window_center[0] - camera_pos[0], window_center[1] - camera_pos[1], window_center[2] - camera_pos[2]};\n",
    "    double mag_n_z = sqrt(SQR(n_z[0]) + SQR(n_z[1]) + SQR(n_z[2]));\n",
    "    for(int i=0; i<3; i++) n_z[i] /= mag_n_z;\n",
    "    const double guide_up[3] = {commondata->window_up_vec_x, commondata->window_up_vec_y, commondata->window_up_vec_z};\n",
    "    double n_x[3] = {n_z[1]*guide_up[2] - n_z[2]*guide_up[1], n_z[2]*guide_up[0] - n_z[0]*guide_up[2], n_z[0]*guide_up[1] - n_z[1]*guide_up[0]};\n",
    "    double mag_n_x = sqrt(SQR(n_x[0]) + SQR(n_x[1]) + SQR(n_x[2]));\n",
    "    if (mag_n_x < 1e-9) {\n",
    "        double alternative_up[3] = {0.0, 1.0, 0.0};\n",
    "        if (fabs(n_z[1]) > 0.999) { alternative_up[1] = 0.0; alternative_up[2] = 1.0; }\n",
    "        n_x[0] = alternative_up[1]*n_z[2] - alternative_up[2]*n_z[1];\n",
    "        n_x[1] = alternative_up[2]*n_z[0] - alternative_up[0]*n_z[2];\n",
    "        n_x[2] = alternative_up[0]*n_z[1] - alternative_up[1]*n_z[0];\n",
    "        mag_n_x = sqrt(SQR(n_x[0]) + SQR(n_x[1]) + SQR(n_x[2]));\n",
    "    }\n",
    "    for(int i=0; i<3; i++) n_x[i] /= mag_n_x;\n",
    "    double n_y[3] = {n_z[1]*n_x[2] - n_z[2]*n_x[1], n_z[2]*n_x[0] - n_z[0]*n_x[2], n_z[0]*n_x[1] - n_z[1]*n_x[0]};\n",
    "\n",
    "    #pragma omp parallel for\n",
    "    for (long int i = 0; i < num_rays; i++) {\n",
    "        const int j = i / commondata->scan_density;\n",
    "        const int k = i % commondata->scan_density;\n",
    "        const double x_pix = -commondata->window_size/2.0 + (k + 0.5) * (commondata->window_size / commondata->scan_density);\n",
    "        const double y_pix = -commondata->window_size/2.0 + (j + 0.5) * (commondata->window_size / commondata->scan_density);\n",
    "        double target_pos[3] = {window_center[0] + x_pix*n_x[0] + y_pix*n_y[0],\n",
    "                                 window_center[1] + x_pix*n_x[1] + y_pix*n_y[1],\n",
    "                                 window_center[2] + x_pix*n_x[2] + y_pix*n_y[2]};\n",
    "        set_initial_conditions_cartesian(commondata, params, metric, camera_pos, target_pos, all_photons[i].y);\n",
    "        all_photons[i].y[0] += commondata->t_start;\n",
    "        all_photons[i].lambda = 0.0;\n",
    "        all_photons[i].d_lambda = 1.0;\n",
    "        all_photons[i].status = ACTIVE;\n",
    "        for(int ii=0; ii<9; ++ii) { all_photons[i].y_p[ii] = all_photons[i].y[ii]; all_photons[i].y_p_p[ii] = all_photons[i].y[ii]; }\n",
    "        all_photons[i].lambda_p = all_photons[i].lambda; all_photons[i].lambda_p_p = all_photons[i].lambda;\n",
    "        plane_event_params window_params = {{n_z[0], n_z[1], n_z[2]}, n_z[0]*window_center[0] + n_z[1]*window_center[1] + n_z[2]*window_center[2]};\n",
    "        all_photons[i].on_positive_side_of_window_prev = (plane_event_func(all_photons[i].y, &window_params) > 0);\n",
    "        plane_event_params source_params = {{commondata->source_plane_normal_x, commondata->source_plane_normal_y, commondata->source_plane_normal_z},\n",
    "                                            commondata->source_plane_center_x*commondata->source_plane_normal_x + commondata->source_plane_center_y*commondata->source_plane_normal_y + commondata->source_plane_center_z*commondata->source_plane_normal_z};\n",
    "        all_photons[i].on_positive_side_of_source_prev = (plane_event_func(all_photons[i].y, &source_params) > 0);\n",
    "        all_photons[i].source_event_data.found = false;\n",
    "        all_photons[i].window_event_data.found = false;\n",
    "        gsl_photon_init(&all_photons[i]);\n",
    "    }\n",
    "\n",
    "\n",
    "    int initial_slot_idx = slot_get_index(&tsm, commondata->t_start);\n",
    "    if(initial_slot_idx != -1) {\n",
    "        for(long int i=0; i<num_rays; ++i) { slot_add_photon(&tsm.slots[initial_slot_idx], i); }\n",
    "    } else {\n",
    "        fprintf(stderr, \"Error: Initial t_start is outside the defined time slot manager domain.\\n\");\n",
    "        exit(1);\n",
    "    }\n",
    "\n",
    "    printf(\"Starting batch integration loop (Iterative Time Slotting)...\\n\");\n",
    "    \n",
    "    gsl_params_analytic_t gsl_parameters = {commondata, params, metric};\n",
    "    gsl_odeiv2_system sys = {ode_gsl_wrapper_analytic, NULL, 9, &gsl_parameters};\n",
    "    \n",
    "    long int *bundle_photons = (long int *)malloc(sizeof(long int) * BUNDLE_CAPACITY);\n",
    "    if (bundle_photons == NULL) { exit(1); }\n",
    "\n",
    "    double start_time = omp_get_wtime();\n",
    "    long int initial_active_photons = active_photons;\n",
    "\n",
    "    // === MAIN EPOCH LOOP ===\n",
    "    for (int i = initial_slot_idx; i >= 0 && active_photons > 0; i--) {\n",
    "        int current_slot_idx = i;\n",
    "        if (tsm.slots[current_slot_idx].count == 0) continue;\n",
    "        \n",
    "        while (tsm.slots[current_slot_idx].count > 0 && active_photons > 0) {\n",
    "            long int bundle_size = MIN(tsm.slots[current_slot_idx].count, BUNDLE_CAPACITY);\n",
    "            slot_remove_chunk(&tsm.slots[current_slot_idx], bundle_photons, bundle_size);\n",
    "\n",
    "            #pragma omp parallel for\n",
    "            for (long int j = 0; j < bundle_size; j++) {\n",
    "                long int photon_idx = bundle_photons[j];\n",
    "                if (all_photons[photon_idx].status != ACTIVE) continue;\n",
    "\n",
    "                for(int ii=0; ii<9; ++ii) { all_photons[photon_idx].y_p_p[ii] = all_photons[photon_idx].y_p[ii]; all_photons[photon_idx].y_p[ii] = all_photons[photon_idx].y[ii]; }\n",
    "                all_photons[photon_idx].lambda_p_p = all_photons[photon_idx].lambda_p; all_photons[photon_idx].lambda_p = all_photons[photon_idx].lambda;\n",
    "                \n",
    "                int status = calculate_and_apply_single_step(&all_photons[photon_idx], &sys);\n",
    "\n",
    "                const double p_t = all_photons[photon_idx].y[4];\n",
    "                const double r_sq = SQR(all_photons[photon_idx].y[1]) + SQR(all_photons[photon_idx].y[2]) + SQR(all_photons[photon_idx].y[3]);\n",
    "\n",
    "                 if (status != GSL_SUCCESS) {\n",
    "                    all_photons[photon_idx].status = FAILURE_GSL_ERROR;\n",
    "                } else if (fabs(p_t) > commondata->p_t_max) {\n",
    "                    all_photons[photon_idx].status = FAILURE_PT_TOO_BIG;\n",
    "                } else if (fabs(all_photons[photon_idx].y[0]) > commondata->t_integration_max) {\n",
    "                    all_photons[photon_idx].status = FAILURE_T_MAX_EXCEEDED;\n",
    "                } else if (r_sq > SQR(commondata->r_escape)) {\n",
    "                    all_photons[photon_idx].status = TERMINATION_TYPE_CELESTIAL_SPHERE;\n",
    "                } else {\n",
    "                    // *** NEW K-D TREE LOGIC INSERTED HERE ***\n",
    "                    const double x = all_photons[photon_idx].y[1];\n",
    "                    const double y = all_photons[photon_idx].y[2];\n",
    "                    const double z = all_photons[photon_idx].y[3];\n",
    "                    if (num_snapshots > 0 &&\n",
    "                        x >= commondata->disk_bounds_x_min && x <= commondata->disk_bounds_x_max &&\n",
    "                        y >= commondata->disk_bounds_y_min && y <= commondata->disk_bounds_y_max &&\n",
    "                        z >= commondata->disk_bounds_z_min && z <= commondata->disk_bounds_z_max) {\n",
    "                        \n",
    "                        // Find nearest snapshot in time\n",
    "                        double min_dt = 1e100;\n",
    "                        int best_snapshot_idx = -1;\n",
    "                        for(int snap_i=0; snap_i<num_snapshots; ++snap_i) {\n",
    "                            double dt = fabs(all_photons[photon_idx].y[0] - snapshot_times[snap_i]);\n",
    "                            if (dt < min_dt) {\n",
    "                                min_dt = dt;\n",
    "                                best_snapshot_idx = snap_i;\n",
    "                            }\n",
    "                        }\n",
    "                        \n",
    "                        if (min_dt < 0.5 * commondata->mass_snapshot_every_t) {\n",
    "                            // K-d tree proximity search\n",
    "                            MassiveParticle neighbor;\n",
    "                            find_n_nearest_neighbors(&kdtree_snapshots[best_snapshot_idx], &all_photons[photon_idx].y[1], 1, &neighbor);\n",
    "                            \n",
    "                            const double dist_sq = SQR(x - neighbor.pos[0]) + SQR(y - neighbor.pos[1]) + SQR(z - neighbor.pos[2]);\n",
    "                            if (dist_sq < SQR(commondata->delta_r_max)) {\n",
    "                                all_photons[photon_idx].status = TERMINATION_TYPE_DISK;\n",
    "                                all_photons[photon_idx].nearest_neighbor = neighbor;\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    if (all_photons[photon_idx].status == ACTIVE) {\n",
    "                        event_detection_manager(all_photons[photon_idx].y_p_p, all_photons[photon_idx].y_p, all_photons[photon_idx].y,\n",
    "                                                all_photons[photon_idx].lambda_p_p, all_photons[photon_idx].lambda_p, all_photons[photon_idx].lambda,\n",
    "                                                commondata, &all_photons[photon_idx].on_positive_side_of_window_prev, &all_photons[photon_idx].on_positive_side_of_source_prev,\n",
    "                                                &all_photons[photon_idx].window_event_data, &all_photons[photon_idx].source_event_data);\n",
    "                        \n",
    "                        if (all_photons[photon_idx].source_event_data.found) {\n",
    "                            blueprint_data_t temp_blueprint;\n",
    "                            if (handle_source_plane_intersection(&all_photons[photon_idx].source_event_data, commondata, &temp_blueprint)) {\n",
    "                                all_photons[photon_idx].status = TERMINATION_TYPE_SOURCE_PLANE;\n",
    "                            } else {\n",
    "                                all_photons[photon_idx].source_event_data.found = false;\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                if (all_photons[photon_idx].status != ACTIVE) {\n",
    "                    #pragma omp atomic\n",
    "                    active_photons--;\n",
    "                }\n",
    "            } // End of omp for loop\n",
    "\n",
    "            for (long int j = 0; j < bundle_size; j++) {\n",
    "                long int photon_idx = bundle_photons[j];\n",
    "                if (all_photons[photon_idx].status == ACTIVE) {\n",
    "                    int new_slot_idx = slot_get_index(&tsm, all_photons[photon_idx].y[0]);\n",
    "                    if (new_slot_idx != -1) {\n",
    "                        slot_add_photon(&tsm.slots[new_slot_idx], photon_idx);\n",
    "                    } else {\n",
    "                        all_photons[photon_idx].status = FAILURE_SLOT_MANAGER_ERROR;\n",
    "                        active_photons--;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        } // End inner while loop\n",
    "        \n",
    "        #pragma omp master\n",
    "        {\n",
    "            double current_time = omp_get_wtime();\n",
    "            double elapsed_time = current_time - start_time;\n",
    "            long int photons_terminated = initial_active_photons - active_photons;\n",
    "            double rays_per_sec = (elapsed_time > 1e-9) ? (double)photons_terminated / elapsed_time : 0.0;\n",
    "            double percent_done = (double)photons_terminated / initial_active_photons * 100.0;\n",
    "            \n",
    "            printf(\"\\rEpoch (Slot %d), Active Photons: %ld (%.1f%% done, %.1f rays/sec) \", i, active_photons, percent_done, rays_per_sec);\n",
    "            fflush(stdout);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    printf(\"\\nBatch integration finished.\\n\");\n",
    "    free(bundle_photons);\n",
    "\n",
    "    // === FINALIZATION ===\n",
    "    printf(\"Processing final states and populating blueprint buffer...\\n\");\n",
    "    #pragma omp parallel for\n",
    "    for (long int i = 0; i < num_rays; i++) {\n",
    "        results_buffer[i] = calculate_and_fill_blueprint_data_universal(\n",
    "            commondata, params, metric, &all_photons[i],\n",
    "            window_center, n_x, n_y\n",
    "        );\n",
    "    }\n",
    "    printf(\"Cleaning up GSL states...\\n\");\n",
    "    #pragma omp parallel for\n",
    "    for (long int i = 0; i < num_rays; i++) {\n",
    "        gsl_photon_free(&all_photons[i]);\n",
    "    }\n",
    "\n",
    "    slot_manager_free(&tsm);\n",
    "    free(all_photons);\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, prefunc=prefunc, desc=desc, name=name, params=params, body=body)\n",
    "    print(f\"    ... Registered C orchestrator: {name}() (with k-d tree logic).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05c12d3",
   "metadata": {},
   "source": [
    "# Numerical batch integrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40bb2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_batch_integrator():\n",
    "    \"\"\"\n",
    "    Generates the main C orchestrator for the numerical pipeline,\n",
    "    implementing the \"Request-Compute-Distribute\" model.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C orchestrator for numerical pipeline: batch_integrator_numerical()...\")\n",
    "\n",
    "    # The prefunc for the Time Slot Manager is identical and can be reused.\n",
    "    prefunc = r\"\"\"\n",
    "typedef struct { long int *photons; long int count; long int capacity; } PhotonList;\n",
    "typedef struct { double t_min, t_max, delta_t_slot; int num_slots; PhotonList *slots; } TimeSlotManager;\n",
    "static void slot_manager_init(TimeSlotManager *tsm, double t_min, double t_max, double delta_t_slot) {\n",
    "    tsm->t_min = t_min; tsm->t_max = t_max; tsm->delta_t_slot = delta_t_slot;\n",
    "    tsm->num_slots = (int)ceil((t_max - t_min) / delta_t_slot);\n",
    "    if (tsm->num_slots <= 0) { exit(1); }\n",
    "    tsm->slots = (PhotonList *)malloc(sizeof(PhotonList) * tsm->num_slots);\n",
    "    if (tsm->slots == NULL) { exit(1); }\n",
    "    for (int i = 0; i < tsm->num_slots; i++) {\n",
    "        tsm->slots[i].photons = (long int *)malloc(sizeof(long int) * 16);\n",
    "        if (tsm->slots[i].photons == NULL) { exit(1); }\n",
    "        tsm->slots[i].count = 0; tsm->slots[i].capacity = 16;\n",
    "    }\n",
    "}\n",
    "static void slot_manager_free(TimeSlotManager *tsm) {\n",
    "    for (int i = 0; i < tsm->num_slots; i++) { free(tsm->slots[i].photons); }\n",
    "    free(tsm->slots);\n",
    "}\n",
    "static inline int slot_get_index(const TimeSlotManager *tsm, double t) {\n",
    "    if (t < tsm->t_min || t >= tsm->t_max) return -1;\n",
    "    return (int)floor((t - tsm->t_min) / tsm->delta_t_slot);\n",
    "}\n",
    "static void slot_add_photon(PhotonList *slot, long int photon_idx) {\n",
    "    if (slot->count >= slot->capacity) {\n",
    "        slot->capacity *= 2;\n",
    "        slot->photons = (long int *)realloc(slot->photons, sizeof(long int) * slot->capacity);\n",
    "        if (slot->photons == NULL) { exit(1); }\n",
    "    }\n",
    "    slot->photons[slot->count++] = photon_idx;\n",
    "}\n",
    "static void slot_remove_chunk(PhotonList *slot, long int *chunk_buffer, long int chunk_size) {\n",
    "    for (long int i = 0; i < chunk_size; ++i) { chunk_buffer[i] = slot->photons[i]; }\n",
    "    for (long int i = 0; i < slot->count - chunk_size; ++i) { slot->photons[i] = slot->photons[i + chunk_size]; }\n",
    "    slot->count -= chunk_size;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"omp.h\", \"<stdbool.h>\"]\n",
    "    desc = \"Main orchestrator for the numerical pipeline, using the Request-Compute-Distribute model.\"\n",
    "    name = \"batch_integrator_numerical\"\n",
    "    params = r\"\"\"\n",
    "    const commondata_struct *restrict commondata,\n",
    "    const params_struct *restrict params,\n",
    "    const metric_params *restrict metric,\n",
    "    long int num_rays,\n",
    "    int num_snapshots,\n",
    "    const CustomKDTree *kdtree_snapshots,\n",
    "    const double *snapshot_times,\n",
    "    blueprint_data_t *results_buffer\n",
    "    \"\"\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "    // === INITIALIZATION (Same as analytic integrator) ===\n",
    "    printf(\"Initializing %ld photon states for BATCHED NUMERICAL integration...\\n\", num_rays);\n",
    "    PhotonState *all_photons = (PhotonState *)malloc(sizeof(PhotonState) * num_rays);\n",
    "    if (all_photons == NULL) { exit(1); }\n",
    "    long int active_photons = num_rays;\n",
    "    TimeSlotManager tsm;\n",
    "    slot_manager_init(&tsm, commondata->slot_manager_t_min, commondata->t_start + 1.0, commondata->slot_manager_delta_t);\n",
    "    \n",
    "    const double camera_pos[3] = {commondata->camera_pos_x, commondata->camera_pos_y, commondata->camera_pos_z};\n",
    "    const double window_center[3] = {commondata->window_center_x, commondata->window_center_y, commondata->window_center_z};\n",
    "    double n_z[3] = {window_center[0] - camera_pos[0], window_center[1] - camera_pos[1], window_center[2] - camera_pos[2]};\n",
    "    double mag_n_z = sqrt(SQR(n_z[0]) + SQR(n_z[1]) + SQR(n_z[2]));\n",
    "    for(int i=0; i<3; i++) n_z[i] /= mag_n_z;\n",
    "    const double guide_up[3] = {commondata->window_up_vec_x, commondata->window_up_vec_y, commondata->window_up_vec_z};\n",
    "    double n_x[3] = {n_z[1]*guide_up[2] - n_z[2]*guide_up[1], n_z[2]*guide_up[0] - n_z[0]*guide_up[2], n_z[0]*guide_up[1] - n_z[1]*guide_up[0]};\n",
    "    double mag_n_x = sqrt(SQR(n_x[0]) + SQR(n_x[1]) + SQR(n_x[2]));\n",
    "    if (mag_n_x < 1e-9) {\n",
    "        double alternative_up[3] = {0.0, 1.0, 0.0};\n",
    "        if (fabs(n_z[1]) > 0.999) { alternative_up[1] = 0.0; alternative_up[2] = 1.0; }\n",
    "        n_x[0] = alternative_up[1]*n_z[2] - alternative_up[2]*n_z[1];\n",
    "        n_x[1] = alternative_up[2]*n_z[0] - alternative_up[0]*n_z[2];\n",
    "        n_x[2] = alternative_up[0]*n_z[1] - alternative_up[1]*n_z[0];\n",
    "        mag_n_x = sqrt(SQR(n_x[0]) + SQR(n_x[1]) + SQR(n_x[2]));\n",
    "    }\n",
    "    for(int i=0; i<3; i++) n_x[i] /= mag_n_x;\n",
    "    double n_y[3] = {n_z[1]*n_x[2] - n_z[2]*n_x[1], n_z[2]*n_x[0] - n_z[0]*n_x[2], n_z[0]*n_x[1] - n_z[1]*n_x[0]};\n",
    "\n",
    "    #pragma omp parallel for\n",
    "    for (long int i = 0; i < num_rays; i++) {\n",
    "        const int j = i / commondata->scan_density;\n",
    "        const int k = i % commondata->scan_density;\n",
    "        const double x_pix = -commondata->window_size/2.0 + (k + 0.5) * (commondata->window_size / commondata->scan_density);\n",
    "        const double y_pix = -commondata->window_size/2.0 + (j + 0.5) * (commondata->window_size / commondata->scan_density);\n",
    "        double target_pos[3] = {window_center[0] + x_pix*n_x[0] + y_pix*n_y[0],\n",
    "                                 window_center[1] + x_pix*n_x[1] + y_pix*n_y[1],\n",
    "                                 window_center[2] + x_pix*n_x[2] + y_pix*n_y[2]};\n",
    "        set_initial_conditions_cartesian(commondata, params, metric, camera_pos, target_pos, all_photons[i].y);\n",
    "        all_photons[i].y[0] += commondata->t_start;\n",
    "        all_photons[i].lambda = 0.0;\n",
    "        all_photons[i].d_lambda = 1.0;\n",
    "        all_photons[i].status = ACTIVE;\n",
    "        for(int ii=0; ii<9; ++ii) { all_photons[i].y_p[ii] = all_photons[i].y[ii]; all_photons[i].y_p_p[ii] = all_photons[i].y[ii]; }\n",
    "        all_photons[i].lambda_p = all_photons[i].lambda; all_photons[i].lambda_p_p = all_photons[i].lambda;\n",
    "        plane_event_params window_params = {{n_z[0], n_z[1], n_z[2]}, n_z[0]*window_center[0] + n_z[1]*window_center[1] + n_z[2]*window_center[2]};\n",
    "        all_photons[i].on_positive_side_of_window_prev = (plane_event_func(all_photons[i].y, &window_params) > 0);\n",
    "        plane_event_params source_params = {{commondata->source_plane_normal_x, commondata->source_plane_normal_y, commondata->source_plane_normal_z},\n",
    "                                            commondata->source_plane_center_x*commondata->source_plane_normal_x + commondata->source_plane_center_y*commondata->source_plane_normal_y + commondata->source_plane_center_z*commondata->source_plane_normal_z};\n",
    "        all_photons[i].on_positive_side_of_source_prev = (plane_event_func(all_photons[i].y, &source_params) > 0);\n",
    "        all_photons[i].source_event_data.found = false;\n",
    "        all_photons[i].window_event_data.found = false;\n",
    "        gsl_photon_init(&all_photons[i]);\n",
    "    }\n",
    "\n",
    "    \n",
    "    int initial_slot_idx = slot_get_index(&tsm, commondata->t_start);\n",
    "    if(initial_slot_idx != -1) { for(long int i=0; i<num_rays; ++i) { slot_add_photon(&tsm.slots[initial_slot_idx], i); } }\n",
    "    else { fprintf(stderr, \"Error: Initial t_start is outside the defined time slot manager domain.\\n\"); exit(1); }\n",
    "\n",
    "    // === BATCH PROCESSING SETUP ===\n",
    "    photon_request_t *requests = (photon_request_t *)malloc(sizeof(photon_request_t) * BUNDLE_CAPACITY);\n",
    "    metric_struct *metric_results = (metric_struct *)malloc(sizeof(metric_struct) * BUNDLE_CAPACITY);\n",
    "    connection_struct *christoffel_results = (connection_struct *)malloc(sizeof(connection_struct) * BUNDLE_CAPACITY);\n",
    "    long int *bundle_photons = (long int *)malloc(sizeof(long int) * BUNDLE_CAPACITY);\n",
    "    if (!requests || !metric_results || !christoffel_results || !bundle_photons) { exit(1); }\n",
    "\n",
    "    double start_time = omp_get_wtime();\n",
    "    long int initial_active_photons = active_photons;\n",
    "\n",
    "    // === MAIN EPOCH LOOP ===\n",
    "    for (int i = initial_slot_idx; i >= 0 && active_photons > 0; i--) {\n",
    "        int current_slot_idx = i;\n",
    "        if (tsm.slots[current_slot_idx].count == 0) continue;\n",
    "        \n",
    "        \n",
    "        while (tsm.slots[current_slot_idx].count > 0 && active_photons > 0) {\n",
    "            long int bundle_size = MIN(tsm.slots[current_slot_idx].count, BUNDLE_CAPACITY);\n",
    "            slot_remove_chunk(&tsm.slots[current_slot_idx], bundle_photons, bundle_size);\n",
    "\n",
    "            // --- STEP 1: GATHER (REQUEST) ---\n",
    "            for (long int j = 0; j < bundle_size; j++) {\n",
    "                long int photon_idx = bundle_photons[j];\n",
    "                requests[j].photon_id = photon_idx;\n",
    "                for(int k=0; k<4; k++) requests[j].pos[k] = all_photons[photon_idx].y[k];\n",
    "            }\n",
    "\n",
    "            // --- STEP 2: COMPUTE (BATCH CALL) ---\n",
    "            placeholder_interpolation_engine(bundle_size, requests, metric_results, christoffel_results, commondata, params, metric);\n",
    "\n",
    "            // --- STEP 3: DISTRIBUTE & EVOLVE ---\n",
    "            #pragma omp parallel for\n",
    "            for (long int j = 0; j < bundle_size; j++) {\n",
    "                long int photon_idx = bundle_photons[j];\n",
    "                if (all_photons[photon_idx].status != ACTIVE) continue;\n",
    "\n",
    "                gsl_params_numerical_t gsl_params_num = {photon_idx, &metric_results[j], &christoffel_results[j]}; \n",
    "                gsl_odeiv2_system sys_num = {ode_gsl_wrapper_numerical, NULL, 9, &gsl_params_num};\n",
    "\n",
    "                for(int ii=0; ii<9; ++ii) { all_photons[photon_idx].y_p_p[ii] = all_photons[photon_idx].y_p[ii]; all_photons[photon_idx].y_p[ii] = all_photons[photon_idx].y[ii]; }\n",
    "                all_photons[photon_idx].lambda_p_p = all_photons[photon_idx].lambda_p; all_photons[photon_idx].lambda_p = all_photons[photon_idx].lambda;\n",
    "                int status = calculate_and_apply_single_step(&all_photons[photon_idx], &sys_num);\n",
    "\n",
    "                // --- Event Cascade (identical to other integrator) ---\n",
    "                const double p_t = all_photons[photon_idx].y[4];\n",
    "                const double r_sq = SQR(all_photons[photon_idx].y[1]) + SQR(all_photons[photon_idx].y[2]) + SQR(all_photons[photon_idx].y[3]);\n",
    "                 if (status != GSL_SUCCESS) {\n",
    "                    all_photons[photon_idx].status = FAILURE_GSL_ERROR;\n",
    "                } else if (fabs(p_t) > commondata->p_t_max) {\n",
    "                    all_photons[photon_idx].status = FAILURE_PT_TOO_BIG;\n",
    "                } else if (fabs(all_photons[photon_idx].y[0]) > commondata->t_integration_max) {\n",
    "                    all_photons[photon_idx].status = FAILURE_T_MAX_EXCEEDED;\n",
    "                } else if (r_sq > SQR(commondata->r_escape)) {\n",
    "                    all_photons[photon_idx].status = TERMINATION_TYPE_CELESTIAL_SPHERE;\n",
    "                } else {\n",
    "                    const double x = all_photons[photon_idx].y[1];\n",
    "                    const double y = all_photons[photon_idx].y[2];\n",
    "                    const double z = all_photons[photon_idx].y[3];\n",
    "                    if (num_snapshots > 0 &&\n",
    "                        x >= commondata->disk_bounds_x_min && x <= commondata->disk_bounds_x_max &&\n",
    "                        y >= commondata->disk_bounds_y_min && y <= commondata->disk_bounds_y_max &&\n",
    "                        z >= commondata->disk_bounds_z_min && z <= commondata->disk_bounds_z_max) {\n",
    "                        double min_dt = 1e100;\n",
    "                        int best_snapshot_idx = -1;\n",
    "                        for(int snap_i=0; snap_i<num_snapshots; ++snap_i) {\n",
    "                            double dt = fabs(all_photons[photon_idx].y[0] - snapshot_times[snap_i]);\n",
    "                            if (dt < min_dt) { min_dt = dt; best_snapshot_idx = snap_i; }\n",
    "                        }\n",
    "                        if (min_dt < 0.5 * commondata->mass_snapshot_every_t) {\n",
    "                            // K-d tree proximity search\n",
    "                            MassiveParticle neighbor;\n",
    "                            find_n_nearest_neighbors(&kdtree_snapshots[best_snapshot_idx], &all_photons[photon_idx].y[1], 1, &neighbor);\n",
    "                            \n",
    "                            const double dist_sq = SQR(x - neighbor.pos[0]) + SQR(y - neighbor.pos[1]) + SQR(z - neighbor.pos[2]);\n",
    "                            if (dist_sq < SQR(commondata->delta_r_max)) {\n",
    "                                all_photons[photon_idx].status = TERMINATION_TYPE_DISK;\n",
    "                                all_photons[photon_idx].nearest_neighbor = neighbor;\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                    if (all_photons[photon_idx].status == ACTIVE) {\n",
    "                        event_detection_manager(all_photons[photon_idx].y_p_p, all_photons[photon_idx].y_p, all_photons[photon_idx].y,\n",
    "                                                all_photons[photon_idx].lambda_p_p, all_photons[photon_idx].lambda_p, all_photons[photon_idx].lambda,\n",
    "                                                commondata, &all_photons[photon_idx].on_positive_side_of_window_prev, &all_photons[photon_idx].on_positive_side_of_source_prev,\n",
    "                                                &all_photons[photon_idx].window_event_data, &all_photons[photon_idx].source_event_data);\n",
    "                        if (all_photons[photon_idx].source_event_data.found) {\n",
    "                            blueprint_data_t temp_blueprint;\n",
    "                            if (handle_source_plane_intersection(&all_photons[photon_idx].source_event_data, commondata, &temp_blueprint)) {\n",
    "                                all_photons[photon_idx].status = TERMINATION_TYPE_SOURCE_PLANE;\n",
    "                            } else {\n",
    "                                all_photons[photon_idx].source_event_data.found = false;\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                if (all_photons[photon_idx].status != ACTIVE) {\n",
    "                    #pragma omp atomic\n",
    "                    active_photons--;\n",
    "                }\n",
    "            }\n",
    "\n",
    "            for (long int j = 0; j < bundle_size; j++) {\n",
    "                long int photon_idx = bundle_photons[j];\n",
    "                if (all_photons[photon_idx].status == ACTIVE) {\n",
    "                    int new_slot_idx = slot_get_index(&tsm, all_photons[photon_idx].y[0]);\n",
    "                    if (new_slot_idx != -1) {\n",
    "                        slot_add_photon(&tsm.slots[new_slot_idx], photon_idx);\n",
    "                    } else {\n",
    "                        all_photons[photon_idx].status = FAILURE_SLOT_MANAGER_ERROR;\n",
    "                        active_photons--;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        #pragma omp master\n",
    "        {\n",
    "            double current_time = omp_get_wtime();\n",
    "            double elapsed_time = current_time - start_time;\n",
    "            long int photons_terminated = initial_active_photons - active_photons;\n",
    "            double rays_per_sec = (elapsed_time > 1e-9) ? (double)photons_terminated / elapsed_time : 0.0;\n",
    "            double percent_done = (double)photons_terminated / initial_active_photons * 100.0;\n",
    "            printf(\"\\rEpoch (Slot %d), Active Photons: %ld (%.1f%% done, %.1f rays/sec) \", i, active_photons, percent_done, rays_per_sec);\n",
    "            fflush(stdout);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    printf(\"\\nBatch integration finished.\\n\");\n",
    "    free(requests);\n",
    "    free(metric_results);\n",
    "    free(christoffel_results);\n",
    "    free(bundle_photons);\n",
    "\n",
    "    printf(\"Processing final states and populating blueprint buffer...\\n\");\n",
    "    #pragma omp parallel for\n",
    "    for (long int i = 0; i < num_rays; i++) {\n",
    "        results_buffer[i] = calculate_and_fill_blueprint_data_universal(\n",
    "            commondata, params, metric, &all_photons[i],\n",
    "            window_center, n_x, n_y\n",
    "        );\n",
    "    }\n",
    "    printf(\"Cleaning up GSL states...\\n\");\n",
    "    #pragma omp parallel for\n",
    "    for (long int i = 0; i < num_rays; i++) {\n",
    "        gsl_photon_free(&all_photons[i]);\n",
    "    }\n",
    "\n",
    "    slot_manager_free(&tsm);\n",
    "    free(all_photons);\n",
    "\"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(includes=includes, prefunc=prefunc, desc=desc, name=name, params=params, body=body)\n",
    "    print(f\"    ... Registered C orchestrator: {name}().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c4eaf0",
   "metadata": {},
   "source": [
    "<a id='main_entry_point'></a>\n",
    "### 7.q: The `main()` C Function Entry Point\n",
    "\n",
    "This function registers the C `main()` function, which serves as the entry point for the entire executable program. In our final architecture, `main()` is a pure **orchestrator**; it contains no physics logic itself. Instead, it calls other functions to manage the entire lifecycle of the simulation.\n",
    "\n",
    "The `main` function performs the following sequence of operations:\n",
    "1.  **Initialize Parameters**: It first calls `commondata_struct_set_to_default()` to set compiled-in defaults, then calls `cmdline_input_and_parfile_parser()` to override them with user-provided values.\n",
    "2.  **Load Global Data**: It calls `load_all_kdtree_snapshots()` to load the entire accretion disk model into memory. If the user has selected a numerical metric, it also calls `initialize_metric_cache()` to load the initial set of metric data files.\n",
    "3.  **Print Banner**: It prints a summary of the simulation parameters to the console.\n",
    "4.  **Execute Integration**: It calls the main `batch_integrator()` orchestrator to run the full simulation.\n",
    "5.  **Save Results**: After the integrator finishes, it saves the final `results_buffer` to the `light_blueprint.bin` file.\n",
    "6.  **Cleanup**: It calls the appropriate helper functions (`unload_kdtree_snapshot`, `free_metric_cache`, etc.) to safely free all allocated memory before exiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4661b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V12_6_light_geodesic.ipynb\n",
    "# This function REPLACES the existing main() (Cell 4661b574).\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Re-registers the main() C function to act as the master dispatcher.\n",
    "    \n",
    "    This definitive version uses the 'use_numerical_pipeline' boolean to select\n",
    "    the correct pipeline and makes the correct 8-argument calls to both\n",
    "    integration orchestrators.\n",
    "    \"\"\"\n",
    "    print(\" -> Updating main() to dispatch with 'use_numerical_pipeline' boolean...\")\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"stdio.h\", \"stdlib.h\"]\n",
    "    desc = r\"\"\"@brief Main entry point for the geodesic integrator.\n",
    "    \n",
    "    Acts as the master dispatcher, selecting the appropriate integration\n",
    "    pipeline (analytic vs. numerical) based on the 'use_numerical_pipeline'\n",
    "    parameter. It manages the lifecycle of all major data structures.\n",
    "\"\"\"\n",
    "    cfunc_type = \"int\"\n",
    "    name = \"main\"\n",
    "    params = \"int argc, const char *argv[]\"\n",
    "    \n",
    "    # --- THIS IS THE CORRECTED C BODY ---\n",
    "    body = r\"\"\"\n",
    "    // --- Step 1: Initialize Core Data Structures ---\n",
    "    commondata_struct commondata;\n",
    "    params_struct params = {0}; // Initialize to zero; unused in this project but required by signatures.\n",
    "    metric_params metric;\n",
    "\n",
    "    // --- Step 2: Set Default Parameters and Parse User Input ---\n",
    "    commondata_struct_set_to_default(&commondata);\n",
    "    cmdline_input_and_parfile_parser(&commondata, argc, argv);\n",
    "\n",
    "    // --- Step 3: Set Metric Type Enum Based on User Choice ---\n",
    "    // This is used by the analytic workers, even when called from the numerical pipeline's placeholder.\n",
    "    if (commondata.metric_choice == 0) {\n",
    "        metric.type = (commondata.a_spin == 0.0) ? Schwarzschild : Kerr;\n",
    "    } else if (commondata.metric_choice == 1) {\n",
    "        metric.type = Schwarzschild_Standard;\n",
    "    } else {\n",
    "        // For Phase 1, metric_choice=2 is invalid as it's controlled by the boolean.\n",
    "        fprintf(stderr, \"Error: Invalid metric_choice = %d for this validation build.\\n\", commondata.metric_choice);\n",
    "        fprintf(stderr, \"       Please use 0 (Kerr-Schild) or 1 (Standard Schwarzschild).\\n\");\n",
    "        exit(1);\n",
    "    }\n",
    "    \n",
    "    // --- Step 4: Load k-d tree snapshot files (used by both pipelines) ---\n",
    "    CustomKDTree *kdtree_snapshots = NULL;\n",
    "    double *snapshot_times = NULL;\n",
    "    int num_snapshots = 0;\n",
    "    num_snapshots = load_all_kdtree_snapshots(&commondata, &kdtree_snapshots, &snapshot_times);\n",
    "\n",
    "    // --- Step 5: Print Simulation Banner ---\n",
    "    printf(\"=============================================\\n\");\n",
    "    printf(\"  Photon Geodesic Integrator (Batch Mode)  \\n\");\n",
    "    printf(\"=============================================\\n\");\n",
    "    if (commondata.use_numerical_pipeline) {\n",
    "        printf(\"PIPELINE: NUMERICAL (Validation Mode)\\n\");\n",
    "    } else {\n",
    "        printf(\"PIPELINE: ANALYTIC\\n\");\n",
    "    }\n",
    "    printf(\"Metric: %s (a=%.3f)\\n\", (metric.type == Kerr) ? \"Kerr-Schild\" : \"Schwarzschild-Standard\", commondata.a_spin);\n",
    "    printf(\"Scan Resolution: %d x %d\\n\", commondata.scan_density, commondata.scan_density);\n",
    "    if (num_snapshots > 0) {\n",
    "        printf(\"Accretion Disk: ENABLED (%d snapshots loaded)\\n\", num_snapshots);\n",
    "    } else {\n",
    "        printf(\"Accretion Disk: DISABLED (no snapshots found)\\n\");\n",
    "    }\n",
    "\n",
    "    // --- Step 6: Main Logic Dispatcher ---\n",
    "    if (commondata.debug_mode) {\n",
    "        printf(\"\\n>>> RUNNING IN SINGLE-RAY DEBUG MODE <<<\\n\");\n",
    "        printf(\"Debug mode is not supported in this batching main() function.\\n\");\n",
    "    } else {\n",
    "        long int num_rays = (long int)commondata.scan_density * commondata.scan_density;\n",
    "        blueprint_data_t *results_buffer = (blueprint_data_t *)malloc(sizeof(blueprint_data_t) * num_rays);\n",
    "        if (results_buffer == NULL) { exit(1); }\n",
    "\n",
    "        if (commondata.use_numerical_pipeline) {\n",
    "            // --- Call the NUMERICAL pipeline orchestrator with the CORRECT 8 arguments ---\n",
    "            batch_integrator_numerical(&commondata, &params, &metric, num_rays, \n",
    "                                     num_snapshots, kdtree_snapshots, snapshot_times, \n",
    "                                     results_buffer);\n",
    "        } else {\n",
    "            // --- Call the ANALYTIC pipeline orchestrator with the CORRECT 8 arguments ---\n",
    "            batch_integrator(&commondata, &params, &metric, num_rays, \n",
    "                             num_snapshots, kdtree_snapshots, snapshot_times, \n",
    "                             results_buffer);\n",
    "        }\n",
    "\n",
    "        printf(\"Scan finished. Writing %ld ray results to light_blueprint.bin...\\n\", num_rays);\n",
    "        FILE *fp_blueprint = fopen(\"light_blueprint.bin\", \"wb\");\n",
    "        if (fp_blueprint == NULL) { perror(\"Error opening blueprint file\"); exit(1); }\n",
    "        fwrite(results_buffer, sizeof(blueprint_data_t), num_rays, fp_blueprint);\n",
    "        fclose(fp_blueprint);\n",
    "        free(results_buffer);\n",
    "    }\n",
    "\n",
    "    // --- Step 7: Cleanup ---\n",
    "    printf(\"Unloading k-d tree snapshots...\\n\");\n",
    "    if (kdtree_snapshots != NULL) {\n",
    "        for (int i = 0; i < num_snapshots; ++i) {\n",
    "            unload_kdtree_snapshot(&kdtree_snapshots[i]);\n",
    "        }\n",
    "        free(kdtree_snapshots);\n",
    "    }\n",
    "    if (snapshot_times != NULL) { free(snapshot_times); }\n",
    "\n",
    "    printf(\"\\nRun complete.\\n\");\n",
    "    return 0;\n",
    "\"\"\"\n",
    "    # Use pop() to ensure we are replacing any old version of this function\n",
    "    cfc.CFunction_dict.pop(name, None)\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, cfunc_type=cfunc_type, name=name, params=params, body=body)\n",
    "    print(\"    ... main() has been updated to dispatch using 'use_numerical_pipeline'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec8cb55",
   "metadata": {},
   "source": [
    "<a id='assemble_project'></a>\n",
    "# Step 8: Project Assembly and Compilation\n",
    "\n",
    "This is the final phase of the notebook for C code generation. It brings all the previously defined pieces together to construct the complete, compilable C project. The Python functions in this section do not generate any new physics code; instead, they manage the `nrpy` build system itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350d54d8",
   "metadata": {},
   "source": [
    "<a id='register_structs'></a>\n",
    "### 8.a: Registering Core C Data Structures\n",
    "\n",
    "This function, `register_core_data_structures`, is one of the most critical in the entire notebook. Its job is to generate the C `typedef`s for all the custom data structures (`struct`s and `enum`s) used by the project.\n",
    "\n",
    "This definitive version has been updated to support the **dual-pipeline architecture**. It now defines the new `photon_request_t` struct for the numerical pipeline's batch processing, as well as a new, leaner `gsl_params_numerical_t` carrier struct. It reuses the existing `connection_struct` for the output of the interpolation engine, avoiding code duplication.\n",
    "\n",
    "It consolidates all type definitions into a single, large C code string. This is crucial because the C compiler requires that a type be defined before it can be used as a member in another struct. By defining everything in one place, we have full control over the declaration order, ensuring that dependencies are met (e.g., `MassiveParticle` is defined before it is used in `PhotonState`). The entire string of C code is then registered with the `BHaH` infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92dadff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V12_5_light_geodesic.ipynb\n",
    "# This cell REPLACES the existing register_core_data_structures() (Cell 92dadff3).\n",
    "\n",
    "def register_core_data_structures():\n",
    "    \"\"\"\n",
    "    Generates and registers all core C data structures. This definitive version\n",
    "    implements the full dual-pipeline architecture with all necessary structs\n",
    "    in the correct C declaration order.\n",
    "    \"\"\"\n",
    "    print(\" -> Registering all core C data structures (Definitive Dual-Pipeline Version)...\")\n",
    "\n",
    "    metric_components = [f\"g{i}{j}\" for i in range(4) for j in range(i, 4)]\n",
    "    metric_struct_str = \"typedef struct { double \" + \", \".join(metric_components) + \"; } metric_struct;\"\n",
    "\n",
    "    connection_components = [f\"Gamma4UDD{i}{j}{k}\" for i in range(4) for j in range(4) for k in range(j, 4)]\n",
    "    connections_struct_str = \"typedef struct { double \" + \", \".join(connection_components) + \"; } connection_struct;\"\n",
    "\n",
    "    deriv_components = [f\"g{i}{j}d{k}\" for i in range(4) for j in range(i, 4) for k in range(4)]\n",
    "    deriv_struct_str = \"typedef struct { double \" + \", \".join(deriv_components) + \"; } g4DD_deriv_struct;\"\n",
    "\n",
    "    consolidated_structs_c_code = rf\"\"\"\n",
    "// =============================================================================\n",
    "// Core Metric and GSL Parameter Structs\n",
    "// =============================================================================\n",
    "#include <gsl/gsl_errno.h>\n",
    "#include <gsl/gsl_odeiv2.h>\n",
    "\n",
    "{metric_struct_str}\n",
    "{connections_struct_str}\n",
    "{deriv_struct_str}\n",
    "\n",
    "typedef enum {{ Schwarzschild, Kerr, Numerical, Schwarzschild_Standard }} Metric_t;\n",
    "typedef struct {{ Metric_t type; }} metric_params;\n",
    "\n",
    "// GSL carrier struct for the ANALYTIC pipeline\n",
    "typedef struct {{ \n",
    "    const commondata_struct *commondata; \n",
    "    const params_struct *params; \n",
    "    const metric_params *metric;\n",
    "}} gsl_params_analytic_t;\n",
    "\n",
    "// GSL carrier struct for the NUMERICAL pipeline.\n",
    "typedef struct {{\n",
    "    long int photon_id; // <<< ADD THIS FOR DEBUGGING\n",
    "    const metric_struct *metric;\n",
    "    const connection_struct *christoffels;\n",
    "}} gsl_params_numerical_t;\n",
    "\n",
    "// =============================================================================\n",
    "// Event Detection and Plane Crossing Helpers\n",
    "// =============================================================================\n",
    "// Struct to hold parameters for a plane-crossing event\n",
    "typedef struct {{\n",
    "    double n[3]; // Plane normal vector\n",
    "    double d;    // Plane distance from origin\n",
    "}} plane_event_params;\n",
    "\n",
    "// Event function pointer type\n",
    "typedef double (*event_function_t)(const double y[9], void *event_params);\n",
    "\n",
    "// Event function for a generic plane crossing.\n",
    "static inline double plane_event_func(const double y[9], void *event_params) {{\n",
    "    plane_event_params *params = (plane_event_params *)event_params;\n",
    "    return y[1]*params->n[0] + y[2]*params->n[1] + y[3]*params->n[2] - params->d;\n",
    "}}\n",
    "\n",
    "// =============================================================================\n",
    "// K-d Tree and Particle Data Structures\n",
    "// =============================================================================\n",
    "typedef struct {{\n",
    "    int id; double pos[3]; double u[4]; double lambda_rest; float j_intrinsic;\n",
    "}} __attribute__((packed)) MassiveParticle;\n",
    "typedef struct {{\n",
    "    int32_t* node_metadata; MassiveParticle* particle_data; uint64_t num_particles;\n",
    "    uint64_t dimensions; void* original_mmap_ptr; size_t file_size;\n",
    "}} CustomKDTree;\n",
    "#define MAX_NEIGHBORS 10\n",
    "typedef struct {{\n",
    "    int indices[MAX_NEIGHBORS]; double sq_distances[MAX_NEIGHBORS]; int count; int n_wanted;\n",
    "}} WinnersCircle;\n",
    "\n",
    "\n",
    "// =============================================================================\n",
    "// Batch Integration and Output Structs\n",
    "// =============================================================================\n",
    "typedef struct {{\n",
    "    int photon_id;\n",
    "    double pos[4];\n",
    "}} photon_request_t;\n",
    "typedef struct {{\n",
    "    bool found; double lambda_event, t_event; double y_event[9];\n",
    "}} event_data_struct;\n",
    "    typedef enum {{\n",
    "        // Success States\n",
    "        TERMINATION_TYPE_DISK,\n",
    "        TERMINATION_TYPE_SOURCE_PLANE,\n",
    "        TERMINATION_TYPE_CELESTIAL_SPHERE,\n",
    "        // Active State\n",
    "        ACTIVE,\n",
    "        // Failure States (for debugging)\n",
    "        FAILURE_GSL_ERROR,\n",
    "        FAILURE_PT_TOO_BIG,\n",
    "        FAILURE_T_MAX_EXCEEDED,\n",
    "        FAILURE_SLOT_MANAGER_ERROR,\n",
    "        FAILURE_GENERIC // Fallback\n",
    "    }} termination_type_t;\n",
    "typedef struct {{\n",
    "    termination_type_t termination_type; double y_w, z_w; double stokes_I, lambda_observed;\n",
    "    double y_s, z_s; double final_theta, final_phi; double L_w, t_w, L_s, t_s;\n",
    "}} __attribute__((packed)) blueprint_data_t;\n",
    "#define CACHE_LINE_SIZE 64\n",
    "#define BUNDLE_CAPACITY 16384\n",
    "typedef struct {{\n",
    "    double y[9], lambda, d_lambda; termination_type_t status; double y_p_p[9], y_p[9];\n",
    "    double lambda_p_p, lambda_p; bool on_positive_side_of_window_prev, on_positive_side_of_source_prev;\n",
    "    event_data_struct source_event_data, window_event_data; MassiveParticle nearest_neighbor;\n",
    "    gsl_odeiv2_step *step; gsl_odeiv2_control *control; gsl_odeiv2_evolve *evolve;\n",
    "    char _padding[CACHE_LINE_SIZE - (sizeof(double)*31 + sizeof(termination_type_t) + sizeof(bool)*2 + sizeof(event_data_struct)*2 + sizeof(MassiveParticle) + sizeof(void*)*3) % CACHE_LINE_SIZE];\n",
    "}} __attribute__((aligned(CACHE_LINE_SIZE))) PhotonState;\n",
    "\"\"\"\n",
    "    Bdefines_h.register_BHaH_defines(\"after_general\", consolidated_structs_c_code)\n",
    "    print(\"    ... Registered all core data structures (Definitive Dual-Pipeline Version).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9583e0f3",
   "metadata": {},
   "source": [
    "<a id='final_build'></a>\n",
    "### 8.b: Final Build Command\n",
    "\n",
    "This is the main execution block of the notebook. It brings all the previously defined Python functions together and calls them in a precise sequence to generate every file needed for the final, compilable C project.\n",
    "\n",
    "The sequence of operations is critical, as later steps depend on the files and registrations created by earlier ones:\n",
    "\n",
    "1.  **Register All Components**: It calls all the C-generating Python functions that we have defined throughout the notebook. This populates `nrpy`'s internal library (`cfc.CFunction_dict`) with the complete definitions for all our custom C functions. At this stage, no files have been written yet; everything exists only in memory.\n",
    "\n",
    "2.  **Generate Parameter Handling Files**: It calls the necessary functions from the BHaH infrastructure to set up the parameter system:\n",
    "    *   `CPs.write_CodeParameters_h_files()`: Generates `set_CodeParameters.h` and its variants.\n",
    "    *   `CPs.register_CFunctions_params_commondata_struct_set_to_default()`: Registers the C functions that initialize the parameter structs with their compiled-in default values.\n",
    "    *   `cmdline_input_and_parfiles.generate_default_parfile()`: Creates the `project_name.par` file.\n",
    "    *   `cmdline_input_and_parfiles.register_CFunction_cmdline_input_and_parfile_parser()`: Registers the C function that reads the `.par` file and command-line arguments at runtime.\n",
    "\n",
    "3.  **Generate `BHaH_defines.h`**: It calls `Bdefines_h.output_BHaH_defines_h()`. This function scans `nrpy`'s internal library for all registered data structures and writes them into the master C header file, `BHaH_defines.h`.\n",
    "\n",
    "4.  **Copy Helper Files**: It calls `gh.copy_files()` to copy any necessary dependency files from the `nrpy` library installation into our project directory.\n",
    "\n",
    "5.  **Generate C Source, Prototypes, and Makefile**: It calls the final, most important build function, `Makefile.output_CFunctions_function_prototypes_and_construct_Makefile()`. This powerful function performs three tasks at once:\n",
    "    *   It iterates through every C function registered with `nrpy` and writes each one into its own `.c` file.\n",
    "    *   It generates `BHaH_function_prototypes.h`, a header file containing the declarations (prototypes) for all the generated `.c` files.\n",
    "    *   It constructs the `Makefile`, which contains the compilation and linking instructions needed to build the final executable program, including linking against GSL and OpenMP.\n",
    "\n",
    "After this cell is run, a complete, self-contained, and ready-to-compile C project will exist in the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc39adb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assembling and building C project with DUAL PIPELINE support...\n",
      " -> Registering C data structures and functions...\n",
      " -> Registering all core C data structures (Definitive Dual-Pipeline Version)...\n",
      "    ... Registered all core data structures (Definitive Dual-Pipeline Version).\n",
      " -> Generating C functions for k-d tree memory mapping...\n",
      "    ... Registered C functions: load_kdtree_snapshot, unload_kdtree_snapshot.\n",
      " -> Registering C helper: filename_sorter()...\n",
      "    ... Registered C helper: compare_filenames().\n",
      " -> Generating C k-d tree loader: load_all_kdtree_snapshots()...\n",
      "    ... Registered C orchestrator: load_all_kdtree_snapshots().\n",
      " -> Generating C engine for k-d tree nearest neighbor search [PERFORMANCE OPTIMIZED]...\n",
      "    ... Registered C engine: find_n_nearest_neighbors [PERFORMANCE OPTIMIZED].\n",
      " -> Generating C placeholder engine: placeholder_interpolation_engine()...\n",
      "    ... Registered C placeholder engine: placeholder_interpolation_engine() [High-Fidelity, Direct-Worker Call Version].\n",
      " -> Generating C algebraic engine: calculate_christoffels_from_metric_and_derivs()...\n",
      "    ... Registered C algebraic engine: calculate_christoffels_from_metric_and_derivs().\n",
      " -> Generating GSL state helper functions (Momentum-Only Control)...\n",
      "    ... Registered C helper: gsl_photon_init().\n",
      "    ... Registered C helper: gsl_photon_free().\n",
      " -> Generating GSL control engines for ANALYTIC pipeline...\n",
      "    ... Registered C engines: calculate_and_apply_single_step() and ode_gsl_wrapper_analytic().\n",
      " -> Generating C GSL wrapper for numerical pipeline: ode_gsl_wrapper_numerical()...\n",
      "    ... Registered C GSL wrapper: ode_gsl_wrapper_numerical().\n",
      " -> Generating C worker function: g4DD_kerr_schild()...\n",
      "    ... g4DD_kerr_schild() registration complete.\n",
      " -> Generating C worker function: con_kerr_schild()...\n",
      "    ... con_kerr_schild() registration complete.\n",
      " -> Generating C worker function: g4DD_schwarzschild_cartesian()...\n",
      "    ... g4DD_schwarzschild_cartesian() registration complete.\n",
      " -> Generating C worker function: con_schwarzschild_cartesian()...\n",
      "    ... con_schwarzschild_cartesian() registration complete.\n",
      " -> Generating C dispatcher function: g4DD_metric()...\n",
      "    ... g4DD_metric() registration complete.\n",
      " -> Generating C dispatcher: connections()...\n",
      "    ... connections() registration complete.\n",
      " -> Generating C engine function: calculate_p0_reverse()...\n",
      "    ... calculate_p0_reverse() registration complete.\n",
      " -> Generating C engine: set_initial_conditions_cartesian()...\n",
      " -> Generating C engine: check_conservation() [Cartesian Version]...\n",
      "    ... check_conservation() registration complete.\n",
      " -> Generating C engine: find_event_time_and_state() [Robust Version]...\n",
      "    ... Registered C engine: find_event_time_and_state (Robust Version).\n",
      " -> Generating C event detection manager (Stateless Plane Detector Version)...\n",
      "    ... Registered event_detection_manager (Stateless Plane Detector Version).\n",
      " -> Generating C engine for radiative transfer physics...\n",
      "    ... Registered C engine: calculate_radiative_transfer.\n",
      " -> Repurposing C engine: handle_disk_intersection (v6.0)...\n",
      "    ... Registered C engine: handle_disk_intersection() (Repurposed as Finalizer Helper).\n",
      " -> Generating C engine: handle_source_plane_intersection (v11.7 compatible)...\n",
      "    ... Registered C engine: handle_source_plane_intersection().\n",
      " -> Generating C finalization engine: calculate_and_fill_blueprint_data_universal (with disk physics)...\n",
      "    ... Registered C finalizer: calculate_and_fill_blueprint_data_universal() (with disk physics).\n",
      " -> Generating top-level C orchestrator: batch_integrator() (with k-d tree logic)...\n",
      "    ... Registered C orchestrator: batch_integrator() (with k-d tree logic).\n",
      " -> Generating C orchestrator for numerical pipeline: batch_integrator_numerical()...\n",
      "    ... Registered C orchestrator: batch_integrator_numerical().\n",
      " -> Updating main() to dispatch with 'use_numerical_pipeline' boolean...\n",
      "    ... main() has been updated to dispatch using 'use_numerical_pipeline'.\n",
      " -> Generating BHaH infrastructure files...\n",
      "\n",
      "Generating BHaH master header file...\n",
      "Outputting non-core modules key = after_general to BHaH_defines.h\n",
      "Copying required helper files...\n",
      "Generating C source files, prototypes, and Makefile...\n",
      "\n",
      "Finished! A C project has been generated in project/photon_geodesic_integrator/\n",
      "To build, navigate to this directory in your terminal and type 'make'.\n",
      "To run, type './photon_geodesic_integrator'.\n"
     ]
    }
   ],
   "source": [
    "# In file: V12_3_light_geodesic.ipynb\n",
    "# This is the final build cell for the project, with all numerical metric\n",
    "# functionality included.\n",
    "\n",
    "import os\n",
    "import nrpy.helpers.generic as gh\n",
    "\n",
    "print(\"\\nAssembling and building C project with DUAL PIPELINE support...\")\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "# --- Step 1: Register all C-generating functions in the correct dependency order ---\n",
    "print(\" -> Registering C data structures and functions...\")\n",
    "\n",
    "# 1a. Register ALL data structures in a single, consolidated call.\n",
    "# This MUST be first, as all other functions depend on these type definitions.\n",
    "register_core_data_structures()\n",
    "\n",
    "# 1b. Register all k-d tree related C functions.\n",
    "# These are self-contained and can be registered early.\n",
    "kdtree_loader_and_unloader()\n",
    "filename_sorter()\n",
    "kdtree_loader_orchestrator()\n",
    "kdtree_search_engine()\n",
    "\n",
    "# 1c. Register all numerical metric C engines and helpers.\n",
    "# These are also largely self-contained but are logically grouped.\n",
    "# Note: The placeholder interpolator is part of this logical group.\n",
    "placeholder_interpolator()\n",
    "algebraic_christoffel_worker()\n",
    "# 1d. Register all remaining C functions for physics and integration.\n",
    "# These are the core components used by one or both pipelines.\n",
    "\n",
    "# GSL Helpers (must be registered before integrators that use them)\n",
    "gsl_photon_helpers()\n",
    "analytic_gsl_engines()      # Registers calculate_and_apply_single_step & ode_gsl_wrapper_analytic\n",
    "numerical_gsl_wrapper()     # Registers ode_gsl_wrapper_numerical\n",
    "\n",
    "# Analytic physics workers (must be registered before dispatchers that call them)\n",
    "g4DD_kerr_schild()\n",
    "con_kerr_schild()\n",
    "g4DD_schwarzschild_cartesian()\n",
    "con_schwarzschild_cartesian()\n",
    "\n",
    "# Dispatchers (must be registered before engines that call them)\n",
    "g4DD_metric()\n",
    "connections()\n",
    "\n",
    "# Core physics engines (must be registered before orchestrators that call them)\n",
    "calculate_ode_rhs()\n",
    "calculate_p0_reverse()\n",
    "set_initial_conditions_cartesian()\n",
    "check_conservation()\n",
    "lagrange_interp_engine_generic()\n",
    "event_detection_manager()\n",
    "radiative_transfer_engine()\n",
    "handle_disk_intersection_engine()\n",
    "handle_source_plane_intersection_engine()\n",
    "calculate_and_fill_blueprint_data_universal()\n",
    "\n",
    "# Top-level Orchestrators (must be registered before main())\n",
    "batch_integrator_orchestrator()  # The original analytic pipeline orchestrator\n",
    "numerical_batch_integrator()     # The new numerical pipeline orchestrator\n",
    "\n",
    "# Final entry point / master dispatcher\n",
    "main()\n",
    "\n",
    "# --- Step 2: Call BHaH infrastructure functions to generate the build system ---\n",
    "print(\" -> Generating BHaH infrastructure files...\")\n",
    "CPs.write_CodeParameters_h_files(project_dir=project_dir)\n",
    "CPs.register_CFunctions_params_commondata_struct_set_to_default()\n",
    "cmdline_input_and_parfiles.generate_default_parfile(project_dir=project_dir, project_name=project_name)\n",
    "\n",
    "# Define the complete list of parameters for the command-line parser.\n",
    "cmdline_inputs_list = [\n",
    "    'M_scale', 'a_spin', 'metric_choice','use_numerical_pipeline', \n",
    "    'camera_pos_x', 'camera_pos_y', 'camera_pos_z',\n",
    "    'window_center_x', 'window_center_y', 'window_center_z',\n",
    "    'window_up_vec_x', 'window_up_vec_y', 'window_up_vec_z',\n",
    "    'source_plane_normal_x', 'source_plane_normal_y', 'source_plane_normal_z',\n",
    "    'source_plane_center_x', 'source_plane_center_y', 'source_plane_center_z',\n",
    "    'source_up_vec_x', 'source_up_vec_y', 'source_up_vec_z',\n",
    "    'source_r_min', 'source_r_max',\n",
    "    'scan_density', 'window_size',\n",
    "    'r_escape', 't_integration_max', 't_start', 'p_t_max',\n",
    "    'debug_mode', 'perform_conservation_check',\n",
    "    'slot_manager_t_min', 'slot_manager_delta_t',\n",
    "    'mass_snapshot_every_t', 'delta_r_max',\n",
    "    'disk_bounds_x_min', 'disk_bounds_x_max',\n",
    "    'disk_bounds_y_min', 'disk_bounds_y_max',\n",
    "    'disk_bounds_z_min', 'disk_bounds_z_max'\n",
    "]\n",
    "\n",
    "cmdline_input_and_parfiles.register_CFunction_cmdline_input_and_parfile_parser(\n",
    "    project_name=project_name,\n",
    "    cmdline_inputs=cmdline_inputs_list\n",
    ")\n",
    "\n",
    "# --- Step 3: Generate headers, helpers, and the final Makefile ---\n",
    "print(\"\\nGenerating BHaH master header file...\")\n",
    "Bdefines_h.output_BHaH_defines_h(project_dir=project_dir)\n",
    "\n",
    "print(\"Copying required helper files...\")\n",
    "gh.copy_files(\n",
    "    package=\"nrpy.helpers\",\n",
    "    filenames_list=[\"simd_intrinsics.h\"],\n",
    "    project_dir=project_dir,\n",
    "    subdirectory=\"simd\",\n",
    ")\n",
    "\n",
    "print(\"Generating C source files, prototypes, and Makefile...\")\n",
    "addl_CFLAGS = [\"-Wall -Wextra -g $(shell gsl-config --cflags) -fopenmp\"]\n",
    "addl_libraries = [\"$(shell gsl-config --libs) -fopenmp\"]\n",
    "\n",
    "Makefile.output_CFunctions_function_prototypes_and_construct_Makefile(\n",
    "    project_dir=project_dir,\n",
    "    project_name=project_name,\n",
    "    exec_or_library_name=project_name,\n",
    "    addl_CFLAGS=addl_CFLAGS,\n",
    "    addl_libraries=addl_libraries,\n",
    ")\n",
    "\n",
    "print(f\"\\nFinished! A C project has been generated in {project_dir}/\")\n",
    "print(f\"To build, navigate to this directory in your terminal and type 'make'.\")\n",
    "print(f\"To run, type './{project_name}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Jupyter notebook)",
   "language": "python",
   "name": "docs-project-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
