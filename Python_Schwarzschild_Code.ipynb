{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dff361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_trajectory\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import time # Optional: for timing checks if needed\n",
    "\n",
    "# Compute_trajectory calculates the trajectory based on the initial polar coordinates and psi/b values\n",
    "# t_end is the max lambda values to integrate to, r_max is the max radius before integration stops\n",
    "# x_stop: If provided (number), integration stops if x decreases below this value.\n",
    "# x_targets: A list/array of x-values. Record y-values when the trajectory crosses each x-value moving from x > x_target to x < x_target.\n",
    "#            Uses interpolation for higher accuracy at the crossing point.\n",
    "# num_interp_points: The number of points to use for the final interpolated output trajectory.\n",
    "# Compute_trajectory returns:\n",
    "#   x, y, r, phi, K (trajectory arrays, interpolated to num_interp_points)\n",
    "#   crossings_y_at_x_targets (list of lists for y-values at x_targets, calculated accurately at event times)\n",
    "def compute_trajectory(r_0, phi_0, M, psi, r_max, x_stop=None, x_targets=None, t_end=10**6, num_interp_points=1000):\n",
    "    # --- Basic Setup ---\n",
    "    b = np.cos(psi) * r_0 / np.sqrt(1 - 2 * M / r_0)\n",
    "    sign = [1]\n",
    "    if psi % (2 * np.pi) > np.pi:\n",
    "        sign[0] *= -1\n",
    "\n",
    "    # --- ODE Definition ---\n",
    "    def ODE_Solver(K, u):\n",
    "        global k\n",
    "        r, phi = u\n",
    "        if r <= 2 * M:\n",
    "            return [0.0, 0.0]\n",
    "        metric_term = (1 - 2 * M / r)\n",
    "        term_b_r_sq = (b / r) ** 2\n",
    "        fr = 1 - metric_term * term_b_r_sq\n",
    "        # Use abs() to prevent sqrt domain error just before event triggers\n",
    "        # Event handling should manage the sign change correctly\n",
    "        drdK = sign[0] * np.sqrt(abs(fr))\n",
    "        dphidK = b / r**2\n",
    "        return [drdK, dphidK]\n",
    "\n",
    "    # --- Standard Terminal Event Definitions ---\n",
    "    # (Event definitions remain the same as the previous version)\n",
    "    def event_fr_zero(K, u): # Index 0\n",
    "        r, phi = u\n",
    "        if r <= (2 * M + 1e-12): return 0.0\n",
    "        metric_term = (1 - 2 * M / r)\n",
    "        term_b_r_sq = (b / r) ** 2\n",
    "        return 1 - metric_term * term_b_r_sq\n",
    "    event_fr_zero.terminal = True\n",
    "    event_fr_zero.direction = 0\n",
    "\n",
    "    def event_r_leq_2M(K, u): # Index 1\n",
    "        r, phi = u\n",
    "        return r - (2 * M + 1e-12)\n",
    "    event_r_leq_2M.terminal = True\n",
    "    event_r_leq_2M.direction = -1\n",
    "\n",
    "    def event_r_max(K, u): # Index 2\n",
    "        r, phi = u\n",
    "        return r - r_max\n",
    "    event_r_max.terminal = True\n",
    "    event_r_max.direction = 1\n",
    "\n",
    "    # --- Initialize Event List & Indices ---\n",
    "    active_events = [event_fr_zero, event_r_leq_2M, event_r_max]\n",
    "    event_x_stop_index = -1\n",
    "    x_target_event_indices = []\n",
    "\n",
    "    # --- Optional Terminal Event: x_stop ---\n",
    "    event_x_stop_active = isinstance(x_stop, (int, float))\n",
    "    if event_x_stop_active:\n",
    "        def event_x_stop_func(K, u):\n",
    "            r, phi = u\n",
    "            if r < 1e-10: return 1.0\n",
    "            x = r * np.cos(phi)\n",
    "            return x - x_stop\n",
    "        event_x_stop_func.terminal = True\n",
    "        event_x_stop_func.direction = -1\n",
    "        event_x_stop_index = len(active_events)\n",
    "        active_events.append(event_x_stop_func)\n",
    "\n",
    "    # --- Optional Non-Terminal Events: x_targets ---\n",
    "    num_x_targets = 0\n",
    "    event_x_targets_active = False\n",
    "    x_targets_list = []\n",
    "    if x_targets is not None:\n",
    "        try:\n",
    "            _ = iter(x_targets)\n",
    "            x_targets_list = list(x_targets)\n",
    "            num_x_targets = len(x_targets_list)\n",
    "            if num_x_targets > 0: event_x_targets_active = True\n",
    "        except TypeError:\n",
    "            print(\"Warning: x_targets provided but not iterable. Ignoring.\")\n",
    "            num_x_targets = 0\n",
    "\n",
    "    if event_x_targets_active:\n",
    "        base_idx = len(active_events)\n",
    "        for i, xt in enumerate(x_targets_list):\n",
    "            def make_event_func(target_x):\n",
    "                def event_x_target_dynamic(K, u):\n",
    "                    r, phi = u\n",
    "                    if r < 1e-10: return 1.0\n",
    "                    x = r * np.cos(phi)\n",
    "                    return x - target_x\n",
    "                event_x_target_dynamic.terminal = False\n",
    "                event_x_target_dynamic.direction = -1\n",
    "                return event_x_target_dynamic\n",
    "            event_func = make_event_func(xt)\n",
    "            active_events.append(event_func)\n",
    "            x_target_event_indices.append(base_idx + i)\n",
    "\n",
    "    # --- Initialization for Integration Loop ---\n",
    "    # Store dense solutions for each segment\n",
    "    segments_data = [] # List to store {'t_start':..., 't_end':..., 'interpolator':...}\n",
    "    crossings_y_at_x_targets = [[] for _ in range(num_x_targets)]\n",
    "    current_t, current_y = 0.0, [r_0, phi_0]\n",
    "    final_K = 0.0 # Track the maximum K reached\n",
    "\n",
    "    # --- Integration Loop ---\n",
    "    while current_t < t_end:\n",
    "        sol = solve_ivp(\n",
    "            ODE_Solver,\n",
    "            (current_t, t_end),\n",
    "            current_y,\n",
    "            events=active_events,\n",
    "            dense_output=True, # <<< MUST BE TRUE FOR INTERPOLATION\n",
    "            rtol=1e-10, atol=1e-10,\n",
    "        )\n",
    "\n",
    "        # Store the dense output function and its time range for this segment\n",
    "        if sol.t.size > 1: # Need at least two points for interpolation interval\n",
    "             segments_data.append({\n",
    "                 't_start': sol.t[0],\n",
    "                 't_end': sol.t[-1],\n",
    "                 'interpolator': sol.sol # Store the callable interpolator\n",
    "             })\n",
    "             final_K = sol.t[-1] # Update the final time reached\n",
    "        elif sol.t.size == 1: # Handle case where solver stops immediately (e.g., event at t=0)\n",
    "             # Only one point, can't really interpolate, but record the endpoint\n",
    "             final_K = sol.t[0]\n",
    "             # Maybe add this point explicitly later if needed?\n",
    "\n",
    "\n",
    "        # --- Process NON-TERMINAL x_target events using INTERPOLATION ---\n",
    "        # (This logic remains the same, using sol.sol for accuracy *at the event*)\n",
    "        if event_x_targets_active and sol.sol:\n",
    "            for i, event_idx in enumerate(x_target_event_indices):\n",
    "                if event_idx < len(sol.t_events) and sol.t_events[event_idx].size > 0:\n",
    "                    target_list_index = i\n",
    "                    for t_event in sol.t_events[event_idx]:\n",
    "                        try:\n",
    "                            interpolated_u = sol.sol(t_event)\n",
    "                            r_event, phi_event = interpolated_u\n",
    "                            if r_event < 2 * M or r_event < 1e-10: continue\n",
    "                            y_event = r_event * np.sin(phi_event)\n",
    "                            crossings_y_at_x_targets[target_list_index].append(y_event)\n",
    "                        except ValueError:\n",
    "                            # Handle cases where t_event might be slightly outside sol.t range due to numerics\n",
    "                            print(f\"Warning: Could not interpolate at x_target event K={t_event}. Skipping point.\")\n",
    "\n",
    "\n",
    "        # --- Handle ALL TERMINAL events ---\n",
    "        # (This logic remains largely the same, determining the break/continue condition)\n",
    "        terminal_event_occurred = False\n",
    "        event_time = t_end\n",
    "        event_state = sol.y[:,-1] if sol.t.size > 0 else current_y\n",
    "\n",
    "        min_terminal_event_time = t_end\n",
    "        triggering_event_index = -1\n",
    "        triggering_event_subindex = -1\n",
    "\n",
    "        terminal_indices = [0, 1, 2]\n",
    "        if event_x_stop_active: terminal_indices.append(event_x_stop_index)\n",
    "\n",
    "        for term_idx in terminal_indices:\n",
    "             if term_idx < len(sol.t_events) and sol.t_events[term_idx].size > 0:\n",
    "                 first_event_time = sol.t_events[term_idx][0]\n",
    "                 if first_event_time <= min_terminal_event_time:\n",
    "                    if abs(first_event_time - min_terminal_event_time) < 1e-12:\n",
    "                         # Prioritize critical events if times are near-identical\n",
    "                         if term_idx == 0: # fr=0\n",
    "                            min_terminal_event_time = first_event_time\n",
    "                            triggering_event_index = term_idx\n",
    "                            triggering_event_subindex = 0\n",
    "                         elif term_idx == 1 and triggering_event_index != 0: # r=2M\n",
    "                            min_terminal_event_time = first_event_time\n",
    "                            triggering_event_index = term_idx\n",
    "                            triggering_event_subindex = 0\n",
    "                    else:\n",
    "                        min_terminal_event_time = first_event_time\n",
    "                        triggering_event_index = term_idx\n",
    "                        triggering_event_subindex = 0\n",
    "\n",
    "\n",
    "        if triggering_event_index != -1:\n",
    "            terminal_event_occurred = True\n",
    "            event_time = min_terminal_event_time\n",
    "            try:\n",
    "                # Use dense output to get state at the precise event time\n",
    "                event_state = sol.sol(event_time)\n",
    "            except ValueError:\n",
    "                 # Fallback if interpolation fails (e.g., event exactly at segment boundary)\n",
    "                 print(f\"Warning: Interpolation failed for terminal event {triggering_event_index} at K={event_time}. Using endpoint.\")\n",
    "                 if triggering_event_subindex != -1 and triggering_event_subindex < len(sol.y_events[triggering_event_index]):\n",
    "                     event_state = sol.y_events[triggering_event_index][triggering_event_subindex].copy()\n",
    "                 elif sol.t.size > 0: # Fallback to last point of trajectory segment\n",
    "                     event_state = sol.y[:,-1].copy()\n",
    "                 else: # Fallback to current_y if segment was empty\n",
    "                     event_state = current_y.copy()\n",
    "\n",
    "\n",
    "            if triggering_event_index == 0: # fr=0: Reverse sign and continue\n",
    "                sign[0] *= -1\n",
    "                current_t = event_time\n",
    "                current_y = event_state.copy()\n",
    "\n",
    "                # Nudge slightly to avoid immediate re-triggering/numerical issues\n",
    "                nudge_r_amount = 1e-7 * sign[0]\n",
    "                current_y[0] = current_y[0] + nudge_r_amount\n",
    "                current_t += 1e-7 # Also nudge time slightly\n",
    "\n",
    "                # Check if nudge immediately caused termination\n",
    "                if current_y[0] <= 2 * M or current_y[0] >= r_max: break\n",
    "                if event_x_stop_active and (current_y[0] * np.cos(current_y[1]) <= x_stop): break\n",
    "\n",
    "                continue # Continue to next integration segment\n",
    "\n",
    "            else: # Any other terminal event: Stop integration\n",
    "                # Update final_K to the exact event time\n",
    "                final_K = event_time\n",
    "                break # Exit while loop\n",
    "\n",
    "        # Handle solver status if no specific terminal event caused termination\n",
    "        if not terminal_event_occurred:\n",
    "            if sol.status == 1: # Reached t_end\n",
    "                final_K = t_end\n",
    "                break\n",
    "            elif sol.status < 0:\n",
    "                print(f\"Warning: Solver failed with status {sol.status} at K={current_t}, state={current_y}\")\n",
    "                final_K = sol.t[-1] if sol.t.size > 0 else current_t\n",
    "                break\n",
    "            elif sol.status == 0 and sol.t[-1] >= t_end: # Normal completion at t_end\n",
    "                 final_K = sol.t[-1]\n",
    "                 break\n",
    "\n",
    "\n",
    "    # --- Post-Integration Interpolation ---\n",
    "    if not segments_data and final_K == 0.0: # Handle immediate stop or no integration\n",
    "        # print(\"Warning: No integration segments generated.\")\n",
    "        # Return initial conditions as a single point trajectory\n",
    "        K_out = np.array([0.0])\n",
    "        r_out = np.array([r_0])\n",
    "        phi_out = np.array([phi_0 % (2 * np.pi)])\n",
    "        x_out = r_out * np.cos(phi_out)\n",
    "        y_out = r_out * np.sin(phi_out)\n",
    "        return x_out, y_out, r_out, phi_out, K_out, crossings_y_at_x_targets\n",
    "\n",
    "    # Create the unified time grid for interpolation\n",
    "    # Ensure K starts at 0 and ends at final_K\n",
    "    K_interp = np.linspace(0, final_K, num_interp_points)\n",
    "\n",
    "    # Initialize output arrays\n",
    "    r_interp = np.zeros_like(K_interp)\n",
    "    phi_interp = np.zeros_like(K_interp)\n",
    "\n",
    "    # Perform interpolation across all segments\n",
    "    current_segment_idx = 0\n",
    "    for i, k_val in enumerate(K_interp):\n",
    "        # Find the correct segment for this k_val\n",
    "        # Start search from the last used segment index for efficiency\n",
    "        found_segment = False\n",
    "        for seg_idx in range(current_segment_idx, len(segments_data)):\n",
    "            segment = segments_data[seg_idx]\n",
    "            # Check if k_val is within the segment's time range (inclusive)\n",
    "            # Add small tolerance for floating point comparisons\n",
    "            if segment['t_start'] - 1e-12 <= k_val <= segment['t_end'] + 1e-12:\n",
    "                try:\n",
    "                    r_interp[i], phi_interp[i] = segment['interpolator'](k_val)\n",
    "                    current_segment_idx = seg_idx # Update hint for next search\n",
    "                    found_segment = True\n",
    "                    break # Move to the next k_val\n",
    "                except ValueError:\n",
    "                     # This might happen if k_val is *extremely* close to boundary\n",
    "                     # Try using the endpoint value as a fallback\n",
    "                     if abs(k_val - segment['t_start']) < 1e-10:\n",
    "                         r_interp[i], phi_interp[i] = segment['interpolator'](segment['t_start'])\n",
    "                         current_segment_idx = seg_idx\n",
    "                         found_segment = True\n",
    "                         break\n",
    "                     elif abs(k_val - segment['t_end']) < 1e-10:\n",
    "                          r_interp[i], phi_interp[i] = segment['interpolator'](segment['t_end'])\n",
    "                          current_segment_idx = seg_idx\n",
    "                          found_segment = True\n",
    "                          break\n",
    "                     else:\n",
    "                         print(f\"Warning: Interpolation failed for K={k_val} within segment {seg_idx}. Setting to NaN.\")\n",
    "                         r_interp[i], phi_interp[i] = np.nan, np.nan\n",
    "                         found_segment = True # Mark as found to avoid fallback message\n",
    "                         break\n",
    "\n",
    "\n",
    "        if not found_segment:\n",
    "             # This case should ideally not happen if segments cover 0 to final_K\n",
    "             # It might occur if the very first point (k_val=0) wasn't captured in a segment\n",
    "             if i == 0 and k_val == 0.0:\n",
    "                 r_interp[i], phi_interp[i] = r_0, phi_0 # Use initial condition\n",
    "             else:\n",
    "                 print(f\"Warning: Could not find segment for K={k_val}. Setting state to NaN.\")\n",
    "                 r_interp[i], phi_interp[i] = np.nan, np.nan\n",
    "\n",
    "\n",
    "    # Final post-processing\n",
    "    phi_interp = phi_interp % (2 * np.pi) # Ensure phi is in [0, 2*pi)\n",
    "    x_interp = r_interp * np.cos(phi_interp)\n",
    "    y_interp = r_interp * np.sin(phi_interp)\n",
    "\n",
    "    # Remove NaN values if any occurred, although they indicate a problem\n",
    "    nan_mask = np.isnan(r_interp) | np.isnan(phi_interp)\n",
    "    if np.any(nan_mask):\n",
    "        print(f\"Warning: Removing {np.sum(nan_mask)} NaN values from interpolated output.\")\n",
    "        K_out = K_interp[~nan_mask]\n",
    "        x_out = x_interp[~nan_mask]\n",
    "        y_out = y_interp[~nan_mask]\n",
    "        r_out = r_interp[~nan_mask]\n",
    "        phi_out = phi_interp[~nan_mask]\n",
    "    else:\n",
    "        K_out, x_out, y_out, r_out, phi_out = K_interp, x_interp, y_interp, r_interp, phi_interp\n",
    "\n",
    "\n",
    "    return x_out, y_out, r_out, phi_out, K_out, crossings_y_at_x_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89036b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A slimed down verison of the one above, only difference if this trajectory function only returns the crossings\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "# import time # Optional: for timing checks if needed\n",
    "\n",
    "# Optimized version based on compute_trajectory_1 logic,\n",
    "# focused solely on returning accurate y-crossings at x_targets.\n",
    "def compute_trajectory_crossings_only(r_0, phi_0, M, psi, r_max, x_stop=None, x_targets=None, t_end=10**6):\n",
    "    \"\"\"\n",
    "    Calculates trajectory intersections with x_targets accurately using interpolation.\n",
    "\n",
    "    Based on the robust logic of compute_trajectory_1, but optimized to return\n",
    "    *only* the crossings_y_at_x_targets list for improved speed when the full\n",
    "    trajectory is not needed.\n",
    "\n",
    "    Args:\n",
    "        r_0, phi_0: Initial polar coordinates.\n",
    "        M: Mass parameter.\n",
    "        psi: Initial angle related to impact parameter.\n",
    "        r_max: Maximum radius before integration stops.\n",
    "        x_stop: If provided (number), integration stops if x decreases below this value.\n",
    "        x_targets: A list/array of x-values. Records y-values when the trajectory\n",
    "                   crosses each x-value (x decreasing). Uses interpolation for accuracy.\n",
    "        t_end: Maximum integration parameter (lambda/K) value.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of lists. Each inner list corresponds to an x_target and\n",
    "              contains the y-values recorded at each crossing of that target.\n",
    "              Example: [[y_cross1_xtarget1, y_cross2_xtarget1], [y_cross1_xtarget2], ...]\n",
    "              Returns empty lists ([[], [], ...]) if x_targets is None or empty,\n",
    "              or if the trajectory cannot be computed (e.g., r_0 <= 2M).\n",
    "    \"\"\"\n",
    "    # --- Basic Setup ---\n",
    "    # Handle cases where x_targets is None or empty early\n",
    "    num_x_targets_initial = 0\n",
    "    x_targets_list_initial = []\n",
    "    if x_targets is not None:\n",
    "         try:\n",
    "             x_targets_list_initial = list(x_targets) # Check iterability early\n",
    "             num_x_targets_initial = len(x_targets_list_initial)\n",
    "         except TypeError:\n",
    "             print(\"Warning: x_targets provided but not iterable. Will return empty lists.\")\n",
    "             x_targets = None # Treat as None if not iterable\n",
    "\n",
    "    # Ensure r_0 is far enough for b calculation and initial state is physical\n",
    "    if r_0 <= 2 * M: return [[] for _ in range(num_x_targets_initial)]\n",
    "    metric_term_r0 = (1 - 2 * M / r_0)\n",
    "    if metric_term_r0 <= 0: return [[] for _ in range(num_x_targets_initial)]\n",
    "    b = np.cos(psi) * r_0 / np.sqrt(metric_term_r0)\n",
    "    sign = [1]\n",
    "    if psi % (2 * np.pi) > np.pi: sign[0] *= -1\n",
    "\n",
    "    # --- ODE Definition (Identical to compute_trajectory_1, no global k) ---\n",
    "    def ODE_Solver(K, u):\n",
    "        r, phi = u\n",
    "        if r <= 2 * M: return [0.0, 0.0]\n",
    "        metric_term = (1 - 2 * M / r)\n",
    "        term_b_r_sq = (b / r) ** 2\n",
    "        fr = 1 - metric_term * term_b_r_sq\n",
    "        drdK = sign[0] * np.sqrt(abs(fr)) # Use abs() for robustness near event\n",
    "        if r < 1e-15: dphidK = 0.0 # Avoid division by zero\n",
    "        else: dphidK = b / r**2\n",
    "        return [drdK, dphidK]\n",
    "\n",
    "    # --- Standard Terminal Event Definitions (Identical to compute_trajectory_1) ---\n",
    "    def event_fr_zero(K, u): # Index 0\n",
    "        r, phi = u\n",
    "        if r <= (2 * M + 1e-12): return 0.0 # Match compute_trajectory_1\n",
    "        metric_term = (1 - 2 * M / r)\n",
    "        term_b_r_sq = (b / r) ** 2\n",
    "        return 1 - metric_term * term_b_r_sq\n",
    "    event_fr_zero.terminal = True\n",
    "    event_fr_zero.direction = 0\n",
    "\n",
    "    def event_r_leq_2M(K, u): # Index 1\n",
    "        r, phi = u\n",
    "        return r - (2 * M + 1e-12)\n",
    "    event_r_leq_2M.terminal = True\n",
    "    event_r_leq_2M.direction = -1\n",
    "\n",
    "    def event_r_max(K, u): # Index 2\n",
    "        r, phi = u\n",
    "        return r - r_max\n",
    "    event_r_max.terminal = True\n",
    "    event_r_max.direction = 1\n",
    "\n",
    "    # --- Initialize Event List & Indices (Identical to compute_trajectory_1) ---\n",
    "    active_events = [event_fr_zero, event_r_leq_2M, event_r_max]\n",
    "    event_x_stop_index = -1\n",
    "    x_target_event_indices = []\n",
    "    event_x_stop_active = isinstance(x_stop, (int, float))\n",
    "    if event_x_stop_active:\n",
    "        def event_x_stop_func(K, u):\n",
    "            r, phi = u; x = r * np.cos(phi)\n",
    "            if r < 1e-10: return 1.0\n",
    "            return x - x_stop\n",
    "        event_x_stop_func.terminal = True; event_x_stop_func.direction = -1\n",
    "        event_x_stop_index = len(active_events); active_events.append(event_x_stop_func)\n",
    "\n",
    "    num_x_targets = 0; event_x_targets_active = False; x_targets_list = []\n",
    "    if x_targets is not None and num_x_targets_initial > 0:\n",
    "        x_targets_list = x_targets_list_initial\n",
    "        num_x_targets = num_x_targets_initial; event_x_targets_active = True\n",
    "    if event_x_targets_active:\n",
    "        base_idx = len(active_events)\n",
    "        for i, xt in enumerate(x_targets_list):\n",
    "            def make_event_func(target_x):\n",
    "                def event_x_target_dynamic(K, u):\n",
    "                    r, phi = u; x = r * np.cos(phi)\n",
    "                    if r < 1e-10: return 1.0\n",
    "                    return x - target_x\n",
    "                event_x_target_dynamic.terminal = False; event_x_target_dynamic.direction = -1\n",
    "                return event_x_target_dynamic\n",
    "            event_func = make_event_func(xt)\n",
    "            active_events.append(event_func); x_target_event_indices.append(base_idx + i)\n",
    "\n",
    "    # --- Initialization for Integration Loop ---\n",
    "    # Only need to store the crossings, not segment data or final_K\n",
    "    crossings_y_at_x_targets = [[] for _ in range(num_x_targets)]\n",
    "    current_t, current_y = 0.0, [r_0, phi_0]\n",
    "\n",
    "    # --- Integration Loop (Logic identical to compute_trajectory_1) ---\n",
    "    while current_t < t_end:\n",
    "        sol = solve_ivp(\n",
    "            ODE_Solver,\n",
    "            (current_t, t_end),\n",
    "            current_y,\n",
    "            events=active_events,\n",
    "            dense_output=True, # KEEP True for accurate event interpolation\n",
    "            rtol=1e-8, atol=1e-10,\n",
    "        )\n",
    "\n",
    "        # --- Process NON-TERMINAL x_target events using INTERPOLATION ---\n",
    "        # (Keep identical to compute_trajectory_1 for accuracy)\n",
    "        if event_x_targets_active and sol.sol is not None:\n",
    "            for i, event_idx in enumerate(x_target_event_indices):\n",
    "                if event_idx < len(sol.t_events) and sol.t_events[event_idx].size > 0:\n",
    "                    target_list_index = i\n",
    "                    for t_event in sol.t_events[event_idx]:\n",
    "                        # Check bounds for robustness\n",
    "                        if not (sol.t[0] <= t_event <= sol.t[-1]): continue\n",
    "                        try:\n",
    "                            interpolated_u = sol.sol(t_event); r_event, phi_event = interpolated_u\n",
    "                            if r_event < 2 * M or r_event < 1e-10: continue\n",
    "                            y_event = r_event * np.sin(phi_event)\n",
    "                            crossings_y_at_x_targets[target_list_index].append(y_event)\n",
    "                        except ValueError:\n",
    "                            print(f\"Warning: Could not interpolate state at x_target event K={t_event}. Skipping.\")\n",
    "\n",
    "\n",
    "        # --- Handle ALL TERMINAL events (Identical logic to compute_trajectory_1) ---\n",
    "        terminal_event_occurred = False\n",
    "        event_time = t_end # Default if no event before t_end\n",
    "        event_state = sol.y[:,-1] if sol.t.size > 0 else current_y # Default state\n",
    "\n",
    "        min_terminal_event_time = t_end\n",
    "        triggering_event_index = -1\n",
    "        triggering_event_subindex = -1 # Keep for potential fallback logic matching _1\n",
    "\n",
    "        terminal_indices = [0, 1, 2]\n",
    "        if event_x_stop_active: terminal_indices.append(event_x_stop_index)\n",
    "\n",
    "        # Find the earliest terminal event (Identical logic to _1)\n",
    "        for term_idx in terminal_indices:\n",
    "             if term_idx < len(sol.t_events) and sol.t_events[term_idx].size > 0:\n",
    "                 first_event_time = sol.t_events[term_idx][0]\n",
    "                 if first_event_time < min_terminal_event_time - 1e-12: # Use tolerance\n",
    "                     min_terminal_event_time = first_event_time\n",
    "                     triggering_event_index = term_idx\n",
    "                     triggering_event_subindex = 0 # Index within the specific event's list\n",
    "                 elif abs(first_event_time - min_terminal_event_time) < 1e-12:\n",
    "                     # Prioritize critical events (Identical logic to _1)\n",
    "                     if term_idx == 0 and triggering_event_index not in [0]: # fr=0 highest priority if same time\n",
    "                         min_terminal_event_time = first_event_time\n",
    "                         triggering_event_index = term_idx\n",
    "                         triggering_event_subindex = 0\n",
    "                     elif term_idx == 1 and triggering_event_index not in [0, 1]: # r=2M next\n",
    "                         min_terminal_event_time = first_event_time\n",
    "                         triggering_event_index = term_idx\n",
    "                         triggering_event_subindex = 0\n",
    "                     # else: keep the already found event if it was 0 or 1\n",
    "\n",
    "        # Process the first terminal event that occurred (Identical logic to _1)\n",
    "        # Check if an event was found *before* the end of the integration interval sol.t[-1]\n",
    "        if triggering_event_index != -1 and min_terminal_event_time <= sol.t[-1] + 1e-12 : # Check includes endpoint\n",
    "            terminal_event_occurred = True\n",
    "            event_time = min_terminal_event_time\n",
    "            try:\n",
    "                # Use dense output for accuracy (Identical logic to _1)\n",
    "                t_interp = np.clip(event_time, sol.t[0], sol.t[-1]) # Ensure time is within bounds\n",
    "                event_state = sol.sol(t_interp)\n",
    "            except ValueError:\n",
    "                 # Fallback logic (Identical logic to _1)\n",
    "                 print(f\"Warning: Interpolation failed for terminal event {triggering_event_index} at K={event_time}. Using endpoint/event state.\")\n",
    "                 # Try using y_events if available and index is valid\n",
    "                 if triggering_event_subindex != -1 and \\\n",
    "                    triggering_event_index < len(sol.y_events) and \\\n",
    "                    triggering_event_subindex < len(sol.y_events[triggering_event_index]):\n",
    "                     event_state = sol.y_events[triggering_event_index][triggering_event_subindex].copy()\n",
    "                 elif sol.t.size > 0: # Fallback to last point\n",
    "                     event_state = sol.y[:,-1].copy()\n",
    "                 else: # Fallback to current_y if segment was empty\n",
    "                     event_state = current_y.copy()\n",
    "\n",
    "\n",
    "            if triggering_event_index == 0: # fr=0: Reverse sign and continue (Identical logic to _1)\n",
    "                sign[0] *= -1\n",
    "                current_t = event_time\n",
    "                current_y = event_state.copy()\n",
    "                # Nudge slightly (Identical logic to _1)\n",
    "                nudge_r_amount = 1e-7 * sign[0]\n",
    "                current_y[0] = current_y[0] + nudge_r_amount\n",
    "                current_t += 1e-7 # Also nudge time slightly\n",
    "                # Check if nudge immediately caused termination (Identical logic to _1)\n",
    "                if current_y[0] <= 2 * M or current_y[0] >= r_max: break\n",
    "                if event_x_stop_active and (current_y[0] * np.cos(current_y[1]) <= x_stop): break\n",
    "                continue # Continue to next integration segment\n",
    "\n",
    "            else: # Any other terminal event: Stop integration\n",
    "                break # Exit while loop\n",
    "\n",
    "        # --- Handle solver status if no specific terminal event caused termination ---\n",
    "        # (Identical logic to compute_trajectory_1, just no final_K update)\n",
    "        if not terminal_event_occurred:\n",
    "            if sol.status == 1: # Reached t_end for this segment\n",
    "                 # Check if it's the overall t_end\n",
    "                 if sol.t[-1] >= t_end - 1e-12: break # Reached overall t_end\n",
    "                 else: # Should not happen if interval is (current_t, t_end)\n",
    "                      current_t = sol.t[-1]; current_y = sol.y[:, -1].copy()\n",
    "            elif sol.status < 0:\n",
    "                print(f\"Warning: Solver failed with status {sol.status} at K={current_t}, state={current_y}\")\n",
    "                break\n",
    "            elif sol.status == 0: # Step completed successfully\n",
    "                 if sol.t[-1] >= t_end - 1e-12: break # Reached overall t_end exactly\n",
    "                 else: # Step finished before t_end, no event? Update and continue.\n",
    "                      current_t = sol.t[-1]; current_y = sol.y[:, -1].copy()\n",
    "\n",
    "\n",
    "    # --- Return ONLY the accumulated y-values at x-target crossings ---\n",
    "    # No final interpolation needed.\n",
    "    return crossings_y_at_x_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc44618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image_Map Cartesian\n",
    "#Takes in the starting position (y,z) and returns where the photon hits the window and hits the target image in xy_{phi_{prime}}\n",
    "def Image_map(Y,Z,x_0,x_1,x_2,a):\n",
    "    a_prime=(x_2-x_0)/(x_2-x_1)*a\n",
    "    r_max=np.sqrt(2*a_prime**2+x_0**2)\n",
    "    psi=-np.arccos(np.sqrt(Y**2+Z**2)/np.sqrt((x_2-x_1)**2+Y**2+Z**2))\n",
    "    #_, _, _, _, _,y_list = compute_trajectory_interpolated(r_0=x_2,phi_0=0, M=1,psi=psi,r_max=r_max,x_targets=[x_0,x_1],x_stop=x_0-1)\n",
    "    y_list = compute_trajectory_crossings_only(r_0=x_2,phi_0=0, M=1,psi=psi,r_max=r_max,x_targets=[x_0,x_1],x_stop=x_0-1)\n",
    "    y_image=y_list[0]\n",
    "    y_window=y_list[1]\n",
    "    if len(y_image) == 0 or len(y_window) == 0:\n",
    "        return \"Miss\"\n",
    "    return y_window[0],y_image[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597dc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image_Map_Radial\n",
    "#Takes in the starting position (y,z) and returns where the photon hits the window and hits the target image in xy_{phi_{prime}}\n",
    "# coordinates described in Lab noteboook \n",
    "def Image_map_radial(r,x_0,x_1,x_2,a):\n",
    "    a_prime=(x_2-x_0)/(x_2-x_1)*a\n",
    "    r_max=np.sqrt(2*a_prime**2+x_0**2)\n",
    "    psi=-np.arccos(np.sqrt(r**2)/np.sqrt((x_2-x_1)**2+r**2))\n",
    "    y_list = compute_trajectory_crossings_only(r_0=x_2,phi_0=0, M=1,psi=psi,r_max=r_max,x_targets=[x_0,x_1],x_stop=x_0-1)\n",
    "    y_image=y_list[0]\n",
    "    y_window=y_list[1]\n",
    "    if len(y_image) == 0 or len(y_window) == 0:\n",
    "        return \"Miss\"\n",
    "    return y_window[0],y_image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93d3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results_cartesian\n",
    "import numpy as np\n",
    "import time\n",
    "import os # Added for path operations\n",
    "\n",
    "# NOTE: This function assumes that a function named 'Image_map_radial'\n",
    "#       is defined or imported in the scope where Results_Light_Ring is called.\n",
    "\n",
    "def Results_Cartesian(x_0,x_1,x_2,a,n, chunk_size=1e7): # Added chunk_size parameter\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    results_chunk=[] # Renamed from results\n",
    "    saved_files = []\n",
    "    chunk_index = 0\n",
    "\n",
    "    print(\"Starting Results_Light_Ring generation...\")\n",
    "\n",
    "    # --- Define base filename ---\n",
    "    x0_str = str(x_0).replace('.','p').replace('-','neg')\n",
    "    x1_str = str(x_1).replace('.','p').replace('-','neg')\n",
    "    x2_str = str(x_2).replace('.','p').replace('-','neg')\n",
    "    base_save_path = f'Results_Light_Ring_Cartesian_{x0_str}_{x1_str}_{x2_str}_{n}'\n",
    "    output_directory = \".\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # --- Helper function to save chunk ---\n",
    "    def save_chunk(current_chunk_list, current_chunk_index):\n",
    "        if not current_chunk_list: return None\n",
    "        chunk_save_path = os.path.join(output_directory, f\"{base_save_path}_chunk_{current_chunk_index:03d}.npy\")\n",
    "        print(f\"\\nSaving chunk {current_chunk_index} ({len(current_chunk_list)} results) to {chunk_save_path}...\")\n",
    "        try:\n",
    "            np.save(chunk_save_path, np.array(current_chunk_list, dtype=np.float64))\n",
    "            print(f\"Chunk {current_chunk_index} saved.\")\n",
    "            return chunk_save_path\n",
    "        except Exception as e:\n",
    "            print(f\"\\nERROR saving chunk {current_chunk_index} to {chunk_save_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # --- Main Loops ---\n",
    "    try:\n",
    "        for i in range(n+1):\n",
    "            y=a*i/n\n",
    "\n",
    "            for j in range(i+1):\n",
    "                z=a*j/n\n",
    "\n",
    "                if j % 10**4==0:\n",
    "                    print(y,\"y\",z,\" z \")\n",
    "\n",
    "                phi_prime=np.arctan2(z,y)\n",
    "\n",
    "                output=Image_map(Y=y,Z=z,x_0=x_0,x_1=x_1,x_2=x_2,a=a)\n",
    "                if output=='Miss':\n",
    "                    continue\n",
    "                else:\n",
    "                    y_window, y_image = output\n",
    "                if y == z or z==0:\n",
    "                    phi_values = [phi_prime, phi_prime + np.pi/2, phi_prime + np.pi, phi_prime + 3/2 * np.pi]\n",
    "                else:\n",
    "                    phi_values = [\n",
    "                        phi_prime, phi_prime + np.pi/2, phi_prime + np.pi, phi_prime + 3/2 * np.pi,\n",
    "                        np.pi/2 - phi_prime, np.pi - phi_prime, 3*np.pi/2 - phi_prime, 2*np.pi - phi_prime]\n",
    "                for phi_prime in phi_values:\n",
    "                    results_chunk.append((\n",
    "                        y_window * np.cos(phi_prime), y_window * np.sin(phi_prime),\n",
    "                        y_image * np.cos(phi_prime), y_image * np.sin(phi_prime)))\n",
    "\n",
    "                # --- Check chunk size and save if needed ---\n",
    "                if len(results_chunk) >= chunk_size:\n",
    "                    saved_path = save_chunk(results_chunk, chunk_index)\n",
    "                    if saved_path:\n",
    "                        saved_files.append(saved_path)\n",
    "                    else:\n",
    "                        # Handle save error - e.g., stop the process\n",
    "                        raise IOError(f\"Failed to save chunk {chunk_index}\")\n",
    "                    results_chunk = [] # Reset chunk\n",
    "                    chunk_index += 1\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "         print(\"\\n--- Process Interrupted ---\")\n",
    "    except Exception as e:\n",
    "         print(f\"\\n--- Error during processing: {e} ---\")\n",
    "         import traceback\n",
    "         traceback.print_exc()\n",
    "    finally:\n",
    "        # --- Save the final (potentially incomplete) chunk ---\n",
    "        print(\"\\nAttempting to save final chunk...\")\n",
    "        final_saved_path = save_chunk(results_chunk, chunk_index)\n",
    "        if final_saved_path:\n",
    "            saved_files.append(final_saved_path)\n",
    "\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "\n",
    "        total_results_saved = sum(len(np.load(f)) for f in saved_files if os.path.exists(f))\n",
    "\n",
    "        print(f\"\\nFinished generation attempt.\")\n",
    "        print(f\"Total results saved: {total_results_saved}\")\n",
    "        print(f\"Number of chunk files created: {len(saved_files)}\")\n",
    "        print(f\"Total execution time: {duration:.2f} seconds\")\n",
    "\n",
    "        # Original code returned the array, now return filenames\n",
    "        return saved_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c6734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results_Radial\n",
    "import numpy as np\n",
    "import time\n",
    "import os # Added for path operations\n",
    "\n",
    "# NOTE: This function assumes that a function named 'Image_map_radial'\n",
    "#       is defined or imported in the scope where Results_Light_Ring is called.\n",
    "\n",
    "def Results_Radial(x_0,x_1,x_2,R_max,n, chunk_size=1e7): # Added chunk_size parameter\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    a=1*(x_2-x_1)\n",
    "    results_chunk=[] # Renamed from results\n",
    "    saved_files = []\n",
    "    chunk_index = 0\n",
    "\n",
    "    print(\"Starting Results_Light_Ring generation...\")\n",
    "\n",
    "    # --- Define base filename ---\n",
    "    x0_str = str(x_0).replace('.','p').replace('-','neg')\n",
    "    x1_str = str(x_1).replace('.','p').replace('-','neg')\n",
    "    x2_str = str(x_2).replace('.','p').replace('-','neg')\n",
    "    base_save_path = f'Results_rainbow_thesis_{x0_str}_{x1_str}_{x2_str}_{n}'\n",
    "    output_directory = \".\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # --- Helper function to save chunk ---\n",
    "    def save_chunk(current_chunk_list, current_chunk_index):\n",
    "        if not current_chunk_list: return None\n",
    "        chunk_save_path = os.path.join(output_directory, f\"{base_save_path}_chunk_{current_chunk_index:03d}.npy\")\n",
    "        print(f\"\\nSaving chunk {current_chunk_index} ({len(current_chunk_list)} results) to {chunk_save_path}...\")\n",
    "        try:\n",
    "            np.save(chunk_save_path, np.array(current_chunk_list, dtype=np.float64))\n",
    "            print(f\"Chunk {current_chunk_index} saved.\")\n",
    "            return chunk_save_path\n",
    "        except Exception as e:\n",
    "            print(f\"\\nERROR saving chunk {current_chunk_index} to {chunk_save_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # --- Main Loops ---\n",
    "    try:\n",
    "        for i in range(n+1):\n",
    "            r=R_max*i/n\n",
    "\n",
    "            k=max(int(5*10**4*r),int(1))\n",
    "\n",
    "            # Only call Image_map_radial once if k > 0\n",
    "            output = Image_map_radial(r,x_0,x_1,x_2,a)\n",
    "            valid_output = (output != \"Miss\")\n",
    "            if valid_output:\n",
    "                 y_window, y_image = output\n",
    "\n",
    "            for j in range(k+1):\n",
    "                # Calculate phi_prime inside loop as before\n",
    "                phi_prime=j/k*2*np.pi\n",
    "\n",
    "                if j % 10**4==0:\n",
    "                    print(r,\"r\",phi_prime,\" phi_prime  \")\n",
    "\n",
    "                if valid_output:\n",
    "                    cos_phi = np.cos(phi_prime)\n",
    "                    sin_phi = np.sin(phi_prime)\n",
    "                    results_chunk.append((y_window * cos_phi, y_window * sin_phi,y_image * cos_phi, y_image * sin_phi))\n",
    "                # NOTE: Original inner loop logic had `continue` for `output == \"Miss\"`.\n",
    "                #       So, we only append if it's NOT a miss, matching original behaviour.\n",
    "\n",
    "                # --- Check chunk size and save if needed ---\n",
    "                if len(results_chunk) >= chunk_size:\n",
    "                    saved_path = save_chunk(results_chunk, chunk_index)\n",
    "                    if saved_path:\n",
    "                        saved_files.append(saved_path)\n",
    "                    else:\n",
    "                        # Handle save error - e.g., stop the process\n",
    "                        raise IOError(f\"Failed to save chunk {chunk_index}\")\n",
    "                    results_chunk = [] # Reset chunk\n",
    "                    chunk_index += 1\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "         print(\"\\n--- Process Interrupted ---\")\n",
    "    except Exception as e:\n",
    "         print(f\"\\n--- Error during processing: {e} ---\")\n",
    "         import traceback\n",
    "         traceback.print_exc()\n",
    "    finally:\n",
    "        # --- Save the final (potentially incomplete) chunk ---\n",
    "        print(\"\\nAttempting to save final chunk...\")\n",
    "        final_saved_path = save_chunk(results_chunk, chunk_index)\n",
    "        if final_saved_path:\n",
    "            saved_files.append(final_saved_path)\n",
    "\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "\n",
    "        total_results_saved = sum(len(np.load(f)) for f in saved_files if os.path.exists(f))\n",
    "\n",
    "        print(f\"\\nFinished generation attempt.\")\n",
    "        print(f\"Total results saved: {total_results_saved}\")\n",
    "        print(f\"Number of chunk files created: {len(saved_files)}\")\n",
    "        print(f\"Total execution time: {duration:.2f} seconds\")\n",
    "\n",
    "        # Original code returned the array, now return filenames\n",
    "        return saved_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a97bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results_Light_Ring\n",
    "import numpy as np\n",
    "import time\n",
    "import os # Added for path operations\n",
    "\n",
    "# NOTE: This function assumes that a function named 'Image_map_radial'\n",
    "#       is defined or imported in the scope where Results_Light_Ring is called.\n",
    "\n",
    "def Results_Radial_Light_Ring(x_0,x_1,x_2,n, chunk_size=1e7): # Added chunk_size parameter\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    a=1*(x_2-x_1)\n",
    "    results_chunk=[] # Renamed from results\n",
    "    saved_files = []\n",
    "    chunk_index = 0\n",
    "    misses=[]\n",
    "    hits=[]\n",
    "\n",
    "    print(\"Starting Results_Light_Ring generation...\")\n",
    "\n",
    "    # --- Define base filename ---\n",
    "    x0_str = str(x_0).replace('.','p').replace('-','neg')\n",
    "    x1_str = str(x_1).replace('.','p').replace('-','neg')\n",
    "    x2_str = str(x_2).replace('.','p').replace('-','neg')\n",
    "    base_save_path = f'Light_Ring_Segement_0th_large_{x0_str}_{x1_str}_{x2_str}_{n}'\n",
    "    output_directory = \".\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # --- Helper function to save chunk ---\n",
    "    def save_chunk(current_chunk_list, current_chunk_index):\n",
    "        if not current_chunk_list: return None\n",
    "        chunk_save_path = os.path.join(output_directory, f\"{base_save_path}_chunk_{current_chunk_index:03d}.npy\")\n",
    "        print(f\"\\nSaving chunk {current_chunk_index} ({len(current_chunk_list)} results) to {chunk_save_path}...\")\n",
    "        try:\n",
    "            np.save(chunk_save_path, np.array(current_chunk_list, dtype=np.float64))\n",
    "            print(f\"Chunk {current_chunk_index} saved.\")\n",
    "            return chunk_save_path\n",
    "        except Exception as e:\n",
    "            print(f\"\\nERROR saving chunk {current_chunk_index} to {chunk_save_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # --- Main Loops ---\n",
    "    try:\n",
    "        for i in range(n+1):\n",
    "\n",
    "            r=0.2543706590950274+i/n*.0008610946154524735\n",
    "            k=int(6*10**4*r)\n",
    "            #k=0\n",
    "            #print(k,\"   k \")\n",
    "\n",
    "            # Only call Image_map_radial once if k > 0\n",
    "            output = Image_map_radial(r,x_0,x_1,x_2,a)\n",
    "            valid_output = (output != \"Miss\")\n",
    "            if valid_output:\n",
    "                 y_window, y_image = output\n",
    "                 #hits.append(r)\n",
    "            #else:\n",
    "                #misses.append(r)\n",
    "\n",
    "            for j in range(k+1):\n",
    "                # Calculate phi_prime inside loop as before\n",
    "                phi_prime=3/2*np.pi+j/k*np.pi/180/10\n",
    "\n",
    "                if j % 10**4==0:\n",
    "                    print(r,\"r\",phi_prime,\" phi_prime  \")\n",
    "\n",
    "                if valid_output:\n",
    "                    cos_phi = np.cos(phi_prime)\n",
    "                    sin_phi = np.sin(phi_prime)\n",
    "                    results_chunk.append((y_window * cos_phi, y_window * sin_phi,y_image * cos_phi, y_image * sin_phi))\n",
    "                # NOTE: Original inner loop logic had `continue` for `output == \"Miss\"`.\n",
    "                #       So, we only append if it's NOT a miss, matching original behaviour.\n",
    "\n",
    "                # --- Check chunk size and save if needed ---\n",
    "                if len(results_chunk) >= chunk_size:\n",
    "                    saved_path = save_chunk(results_chunk, chunk_index)\n",
    "                    if saved_path:\n",
    "                        saved_files.append(saved_path)\n",
    "                    else:\n",
    "                        # Handle save error - e.g., stop the process\n",
    "                        raise IOError(f\"Failed to save chunk {chunk_index}\")\n",
    "                    results_chunk = [] # Reset chunk\n",
    "                    chunk_index += 1\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "         print(\"\\n--- Process Interrupted ---\")\n",
    "    except Exception as e:\n",
    "         print(f\"\\n--- Error during processing: {e} ---\")\n",
    "         import traceback\n",
    "         traceback.print_exc()\n",
    "    finally:\n",
    "        # --- Save the final (potentially incomplete) chunk ---\n",
    "        print(\"\\nAttempting to save final chunk...\")\n",
    "        final_saved_path = save_chunk(results_chunk, chunk_index)\n",
    "        if final_saved_path:\n",
    "            saved_files.append(final_saved_path)\n",
    "\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "\n",
    "        total_results_saved = sum(len(np.load(f)) for f in saved_files if os.path.exists(f))\n",
    "\n",
    "        print(f\"\\nFinished generation attempt.\")\n",
    "        print(f\"Total results saved: {total_results_saved}\")\n",
    "        print(f\"Number of chunk files created: {len(saved_files)}\")\n",
    "        print(f\"Total execution time: {duration:.2f} seconds\")\n",
    "\n",
    "        # Original code returned the array, now return filenames\n",
    "        return saved_files,misses,hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57610b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map_photons (Takes in multiple files, can zoom in on a region [a,b]x[c,d] in the window, will do normal region if [a,b]x[c,d] isn't specified)\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import traceback\n",
    "import math # Import math for ceiling function\n",
    "\n",
    "# Helper function _save_image (keep unchanged from original)\n",
    "def _save_image(image_array, save_path):\n",
    "    \"\"\"Helper function to save a NumPy array as an RGB image using PIL.\"\"\"\n",
    "    try:\n",
    "        parent_dir = os.path.dirname(save_path)\n",
    "        if parent_dir and not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir, exist_ok=True)\n",
    "        if image_array.dtype != np.uint8:\n",
    "             if image_array.dtype in [np.float32, np.float64]:\n",
    "                 # Ensure conversion handles potential NaN/Inf before clipping/casting\n",
    "                 image_array = np.nan_to_num(image_array, nan=0.0, posinf=255.0, neginf=0.0)\n",
    "                 image_array = np.clip(image_array, 0, 255).astype(np.uint8)\n",
    "             else:\n",
    "                 try:\n",
    "                     # Attempt direct cast for integer types after checking range maybe?\n",
    "                     # For now, assume potential issues and convert carefully\n",
    "                     if np.issubdtype(image_array.dtype, np.integer):\n",
    "                         min_val, max_val = np.min(image_array), np.max(image_array)\n",
    "                         if min_val < 0 or max_val > 255:\n",
    "                              print(f\"Warning: Integer data out of uint8 range [{min_val}, {max_val}]. Clipping.\")\n",
    "                              image_array = np.clip(image_array, 0, 255).astype(np.uint8)\n",
    "                         else:\n",
    "                              image_array = image_array.astype(np.uint8)\n",
    "                     else: # For other types, attempt standard conversion\n",
    "                          image_array = image_array.astype(np.uint8)\n",
    "                 except (ValueError, OverflowError, TypeError) as e:\n",
    "                      print(f\"Warning: Could not convert final image dtype {image_array.dtype} to uint8. Error: {e}\");\n",
    "                      return False\n",
    "        if image_array.ndim != 3 or image_array.shape[0] == 0 or image_array.shape[1] == 0 or image_array.shape[2] != 3:\n",
    "             print(f\"Error: Final image is not valid RGB (shape: {image_array.shape}). Cannot save.\");\n",
    "             return False\n",
    "\n",
    "        # Double-check for NaN/Inf again after potential type conversions\n",
    "        if np.any(np.isnan(image_array)) or np.any(np.isinf(image_array)):\n",
    "             print(f\"Error: Final image array contains NaN or Inf values after conversion attempts. Cannot save.\")\n",
    "             return False\n",
    "\n",
    "        pil_image = Image.fromarray(image_array, mode='RGB')\n",
    "        pil_image.save(save_path)\n",
    "        print(f\"Successfully saved image to {save_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving image to {save_path}: {e}\");\n",
    "        traceback.print_exc(limit=2);\n",
    "        return False\n",
    "\n",
    "\n",
    "def map_photons(\n",
    "    image_source,\n",
    "    photon_chunk_files,\n",
    "    save_path,\n",
    "    dest_logical_bounds=None,      # Format: [y_min(horiz), y_max(horiz), z_min(vert), z_max(vert)]\n",
    "    pixels_per_logical_unit=None, # Resolution scale parameter\n",
    "    output_shape=None,           # Optional, only used if dest_logical_bounds is None\n",
    "    default_color=(0, 0, 0),\n",
    "    epsilon=1e-9,\n",
    "    flip_z_axis_render=True # New parameter to control Z-axis rendering direction\n",
    "):\n",
    "    \"\"\"\n",
    "    Maps photons. Uses max extent for source bounds.\n",
    "    VERSION 3: Adds flip_z_axis_render to control Z-axis mapping for \"bottom-up\" view.\n",
    "\n",
    "    Two main modes:\n",
    "    1. Manual Bounds + Scale: Provide 'dest_logical_bounds' and 'pixels_per_logical_unit'.\n",
    "       The output width and height are calculated automatically based on the logical range\n",
    "       and the specified scale, preserving the logical aspect ratio (no stretch/compression).\n",
    "       'output_shape' must be None.\n",
    "    2. Auto Bounds + Manual Shape: Provide 'output_shape' (height, width).\n",
    "       'dest_logical_bounds' and 'pixels_per_logical_unit' must be None. Bounds are calculated\n",
    "       automatically from max photon extent and output_shape aspect ratio.\n",
    "\n",
    "    **Axis Convention Change:** Destination coordinate y maps to the HORIZONTAL axis (width),\n",
    "    and z maps to the VERTICAL axis (height).\n",
    "    **Photon Chunk Convention:** Assumes y0,y1 are HORIZONTAL; z0,z1 are VERTICAL in chunk files.\n",
    "\n",
    "    Args:\n",
    "        image_source (str | np.ndarray): Path to image or NumPy array (H,W[,C]).\n",
    "        photon_chunk_files (list[str]): REQUIRED. List of file paths to .npy chunks.\n",
    "        save_path (str): REQUIRED. Path where the output image will be saved.\n",
    "        dest_logical_bounds (list|tuple, optional): Defines the destination mapping window\n",
    "            in *logical* coordinates [y_min(horiz), y_max(horiz), z_min(vert), z_max(vert)].\n",
    "            If set, 'pixels_per_logical_unit' MUST also be set. Defaults to None.\n",
    "            The z_min(vert) and z_max(vert) define the logical range.\n",
    "        pixels_per_logical_unit (float | int, optional): Resolution scale (pixels per 1 unit\n",
    "            of logical distance). REQUIRED if 'dest_logical_bounds' is set. Ignored otherwise.\n",
    "        output_shape (tuple, optional): Output (height, width) in pixels.\n",
    "            REQUIRED if 'dest_logical_bounds' is None. Ignored otherwise.\n",
    "        default_color (int | tuple, optional): Background RGB color. Defaults to (0, 0, 0).\n",
    "        epsilon (float, optional): Small value for division-by-zero checks.\n",
    "        flip_z_axis_render (bool, optional): If True, renders the Z-axis such that\n",
    "            dest_map_bound_min_z maps to the bottom of the image (pixel row mapped_h-1)\n",
    "            and dest_map_bound_max_z maps to the top (pixel row 0). This gives a\n",
    "            \"bottom-up\" view if z_min is logically \"lower\". Defaults to True for your case.\n",
    "            If False, behaves as original (min_z to top, max_z to bottom).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the image was processed and saved successfully, False otherwise.\n",
    "    \"\"\"\n",
    "    start_time_total = time.time()\n",
    "    mapped_image = None\n",
    "    mapped_h, mapped_w = 1, 1 # Will be overwritten\n",
    "    using_manual_dest_bounds = False # Flag to track mode\n",
    "\n",
    "    # --- DEBUG COUNTERS ---\n",
    "    total_photons_loaded_from_chunks = 0\n",
    "    photons_lost_nan = 0\n",
    "    photons_lost_source_bounds = 0\n",
    "    photons_lost_dest_logical_filter = 0\n",
    "    photons_lost_dest_pixel_map = 0\n",
    "    photons_lost_invalid_source_idx = 0\n",
    "    photons_accumulated = 0\n",
    "    # --- END DEBUG COUNTERS ---\n",
    "\n",
    "    # --- 0. Validate save_path & chunk list ---\n",
    "    if not save_path or not isinstance(save_path, str): raise ValueError(\"A valid string save_path is required.\")\n",
    "    if not isinstance(photon_chunk_files, list) or not all(isinstance(f, str) for f in photon_chunk_files):\n",
    "        raise TypeError(\"photon_chunk_files must be a list of file path strings.\")\n",
    "\n",
    "    # --- Determine Mode and Validate Inputs / Set Output Shape ---\n",
    "    dest_map_bound_min_y, dest_map_bound_max_y = 0, 0 # y now maps to horizontal\n",
    "    dest_map_bound_min_z, dest_map_bound_max_z = 0, 0 # z now maps to vertical\n",
    "\n",
    "    if dest_logical_bounds is not None:\n",
    "        # --- Mode 1: Manual Bounds + Scale ---\n",
    "        using_manual_dest_bounds = True\n",
    "        print(\"Using MANUAL destination bounds + SCALE mode.\")\n",
    "        if flip_z_axis_render:\n",
    "            print(\"  Z-axis rendering: FLIPPED (min_z to image bottom, max_z to image top).\")\n",
    "        else:\n",
    "            print(\"  Z-axis rendering: NORMAL (min_z to image top, max_z to image bottom).\")\n",
    "\n",
    "\n",
    "        # Check required inputs for this mode\n",
    "        if pixels_per_logical_unit is None:\n",
    "            raise ValueError(\"Must provide 'pixels_per_logical_unit' when 'dest_logical_bounds' is set.\")\n",
    "        # Check for conflicting inputs\n",
    "        if output_shape is not None:\n",
    "            print(\"    Warning: 'output_shape' parameter provided but ignored because 'dest_logical_bounds' is set.\")\n",
    "\n",
    "        # Validate dest_logical_bounds\n",
    "        if not isinstance(dest_logical_bounds, (list, tuple)) or len(dest_logical_bounds) != 4:\n",
    "            raise ValueError(\"dest_logical_bounds must be a list or tuple of four numbers: [y_min(horiz), y_max(horiz), z_min(vert), z_max(vert)]\")\n",
    "        try:\n",
    "            a, b, c, d = [float(x) for x in dest_logical_bounds]\n",
    "            if a > b or c > d: # c is min_z, d is max_z\n",
    "                raise ValueError(\"Destination logical bounds must have min <= max for both y ([a,b], horizontal) and z ([c,d], vertical).\")\n",
    "            dest_map_bound_min_y = a\n",
    "            dest_map_bound_max_y = b\n",
    "            dest_map_bound_min_z = c # This is the logical minimum Z for the range\n",
    "            dest_map_bound_max_z = d # This is the logical maximum Z for the range\n",
    "            print(f\"  Logical Bounds: y(horiz)=[{a:.3f}, {b:.3f}], z(vert)=[{c:.3f}, {d:.3f}]\")\n",
    "        except (ValueError, TypeError) as e:\n",
    "             raise ValueError(f\"Invalid dest_logical_bounds format or values: {e}\")\n",
    "\n",
    "        # Validate pixels_per_logical_unit\n",
    "        try:\n",
    "            scale = float(pixels_per_logical_unit)\n",
    "            if scale <= 0:\n",
    "                raise ValueError(\"pixels_per_logical_unit must be a positive number.\")\n",
    "            print(f\"  Scale: {scale:.3f} pixels per logical unit\")\n",
    "        except (ValueError, TypeError):\n",
    "            raise ValueError(\"pixels_per_logical_unit must be a positive number.\")\n",
    "\n",
    "        # Calculate output dimensions based on logical range and scale\n",
    "        logical_width = dest_map_bound_max_y - dest_map_bound_min_y\n",
    "        logical_height = dest_map_bound_max_z - dest_map_bound_min_z # This is the extent of the Z range\n",
    "\n",
    "        # Use ceiling to ensure the pixel grid covers the entire logical range\n",
    "        # Ensure minimum dimension is 1 pixel\n",
    "        mapped_w = max(1, int(math.ceil(logical_width * scale)))\n",
    "        mapped_h = max(1, int(math.ceil(logical_height * scale)))\n",
    "\n",
    "        print(f\"--> Calculated Output Shape (Preserving Aspect Ratio): (Height={mapped_h}, Width={mapped_w})\")\n",
    "\n",
    "    else:\n",
    "        # --- Mode 2: Auto Bounds + Manual Shape ---\n",
    "        print(\"Using AUTO destination bounds + SHAPE mode.\")\n",
    "        if flip_z_axis_render:\n",
    "            print(\"  Z-axis rendering: FLIPPED (min_z to image bottom, max_z to image top).\")\n",
    "        else:\n",
    "            print(\"  Z-axis rendering: NORMAL (min_z to image top, max_z to image bottom).\")\n",
    "\n",
    "\n",
    "        # Check required input for this mode\n",
    "        if output_shape is None:\n",
    "             raise ValueError(\"Must provide 'output_shape' when 'dest_logical_bounds' is not set.\")\n",
    "        # Check for conflicting inputs\n",
    "        if pixels_per_logical_unit is not None:\n",
    "             print(\"    Warning: 'pixels_per_logical_unit' parameter provided but ignored because 'dest_logical_bounds' is not set.\")\n",
    "\n",
    "        # Validate output_shape\n",
    "        if not isinstance(output_shape, tuple) or len(output_shape) != 2:\n",
    "            raise ValueError(\"output_shape must be a tuple of (height, width).\")\n",
    "        try:\n",
    "            mapped_h, mapped_w = int(output_shape[0]), int(output_shape[1])\n",
    "            if mapped_h <= 0 or mapped_w <= 0:\n",
    "                raise ValueError(\"output_shape dimensions must be positive integers.\")\n",
    "        except (ValueError, TypeError):\n",
    "            raise ValueError(\"output_shape dimensions must be positive integers.\")\n",
    "        print(f\"  Using provided Output Shape: (Height={mapped_h}, Width={mapped_w})\")\n",
    "\n",
    "\n",
    "    # --- Handle Empty Chunk List (Uses calculated/provided mapped_h/w) ---\n",
    "    if not photon_chunk_files:\n",
    "        print(\"Warning: photon_chunk_files list is empty. Nothing to process.\")\n",
    "        try:\n",
    "            if isinstance(default_color, (int,float,np.number)): default_color_rgb = (default_color,)*3\n",
    "            elif isinstance(default_color, (tuple, list)) and len(default_color) == 3: default_color_rgb = tuple(default_color)\n",
    "            else: default_color_rgb = (0, 0, 0); print(\"Warning: Invalid default_color. Using (0,0,0).\")\n",
    "            default_color_rgb = tuple(np.clip(int(c), 0, 255) for c in default_color_rgb) # Ensure default_color_rgb is defined\n",
    "            mapped_image = np.full((mapped_h, mapped_w, 3), default_color_rgb, dtype=np.uint8)\n",
    "            return _save_image(mapped_image, save_path)\n",
    "        except Exception as e: print(f\"Error setting up background image dimensions: {e}\"); return False\n",
    "\n",
    "\n",
    "    # --- Continue Processing ---\n",
    "    try:\n",
    "        # --- 1. Calculate Output Aspect Ratio ---\n",
    "        output_pixel_aspect = mapped_w / mapped_h if mapped_h > 0 else 1.0\n",
    "\n",
    "        # --- 2. Load Source Image ---\n",
    "        if isinstance(image_source, str):\n",
    "            try:\n",
    "                with Image.open(image_source) as img:\n",
    "                    img_mode = img.mode;\n",
    "                    if img.mode != 'RGB': img = img.convert('RGB')\n",
    "                    original_image = np.array(img)\n",
    "            except FileNotFoundError: raise FileNotFoundError(f\"Source image file not found: {image_source}\")\n",
    "            except UnidentifiedImageError: raise RuntimeError(f\"Could not identify or open image file: {image_source}\")\n",
    "            except Exception as e: raise RuntimeError(f\"Error loading image file {image_source}: {e}\")\n",
    "        elif isinstance(image_source, np.ndarray):\n",
    "            original_image = image_source.copy()\n",
    "        else:\n",
    "            raise TypeError(\"image_source must be a file path (string) or a NumPy array.\")\n",
    "\n",
    "        # --- Force RGB, Get Source Dimensions, Aspect ---\n",
    "        if original_image.ndim == 2: original_image_rgb = np.stack([original_image] * 3, axis=-1)\n",
    "        elif original_image.ndim == 3 and original_image.shape[2] == 1: original_image_rgb = np.repeat(original_image, 3, axis=-1)\n",
    "        elif original_image.ndim == 3 and original_image.shape[2] == 3: original_image_rgb = original_image\n",
    "        elif original_image.ndim == 3 and original_image.shape[2] == 4: original_image_rgb = original_image[:, :, :3] # Drop alpha\n",
    "        else: raise ValueError(f\"Unsupported source image format (shape: {original_image.shape})\")\n",
    "\n",
    "        orig_h, orig_w, _ = original_image_rgb.shape\n",
    "        if orig_h == 0 or orig_w == 0: raise ValueError(\"Source image dimensions cannot be zero.\")\n",
    "        source_pixel_aspect = orig_w / orig_h\n",
    "\n",
    "        # --- Rescale Logic ---\n",
    "        final_image_for_sampling = original_image_rgb\n",
    "        try:\n",
    "            source_max_val = np.max(final_image_for_sampling); source_min_val = np.min(final_image_for_sampling)\n",
    "            needs_rescaling = False; rescale_threshold = 32 # Rescale if max value is low (e.g., < 32 for uint8)\n",
    "            if final_image_for_sampling.dtype == np.uint8 and source_max_val > source_min_val and source_max_val < rescale_threshold: needs_rescaling = True\n",
    "\n",
    "            if needs_rescaling:\n",
    "                 print(\"    Rescaling low-contrast source image to full range [0, 255].\")\n",
    "                 if source_max_val > source_min_val:\n",
    "                     scaled_image_float = ((final_image_for_sampling.astype(np.float64) - source_min_val) / (source_max_val - source_min_val) * 255.0)\n",
    "                 else: # Handle flat image case\n",
    "                     scaled_image_float = np.full_like(final_image_for_sampling, 128.0)\n",
    "                 final_image_for_sampling = np.clip(scaled_image_float, 0, 255).astype(np.uint8)\n",
    "            elif final_image_for_sampling.dtype != np.uint8: # Ensure uint8 otherwise\n",
    "                 print(f\"    Converting source image from {final_image_for_sampling.dtype} to uint8, clipping to [0, 255].\")\n",
    "                 final_image_for_sampling = np.clip(final_image_for_sampling, 0, 255).astype(np.uint8)\n",
    "        except Exception as scale_e: print(f\"  Warning: Could not perform source image range check/rescaling: {scale_e}.\")\n",
    "\n",
    "        original_image_rgb = final_image_for_sampling # Use potentially rescaled image\n",
    "\n",
    "        print(f\"Source image loaded: shape={original_image_rgb.shape}, aspect={source_pixel_aspect:.3f}\")\n",
    "        print(f\"Output shape set to: {(mapped_h, mapped_w)}, aspect={output_pixel_aspect:.3f}\")\n",
    "\n",
    "\n",
    "        # --- 4. Prepare Default Color ---\n",
    "        if isinstance(default_color, (int, float, np.number)): default_color_rgb = (default_color,) * 3\n",
    "        elif isinstance(default_color, (tuple, list)) and len(default_color) == 3: default_color_rgb = tuple(default_color)\n",
    "        else: default_color_rgb = (0, 0, 0); print(\"Warning: Invalid default_color. Using (0,0,0).\")\n",
    "        try:\n",
    "            default_color_rgb = tuple(np.clip(int(c), 0, 255) for c in default_color_rgb)\n",
    "        except (ValueError, TypeError):\n",
    "            default_color_rgb = (0, 0, 0); print(\"Warning: Could not parse default_color. Using (0,0,0).\")\n",
    "\n",
    "\n",
    "        # --- 5. Initialize Accumulation Buffers (Uses determined mapped_h/w) ---\n",
    "        print(\"Initializing accumulation buffers...\")\n",
    "        sum_array = np.zeros((mapped_h, mapped_w, 3), dtype=np.float64)\n",
    "        count_array = np.zeros((mapped_h, mapped_w), dtype=np.int64)\n",
    "        mapped_image = np.full((mapped_h, mapped_w, 3), default_color_rgb, dtype=np.uint8)\n",
    "\n",
    "        # --- Determine Source & Auto Destination Bounds (Scan needed for source + auto dest) ---\n",
    "        print(\"Scanning chunks to determine coordinate bounds...\")\n",
    "        global_max_abs_y0=epsilon; global_max_abs_z0=epsilon # Needed only for Auto mode\n",
    "        global_max_abs_y1=epsilon; global_max_abs_z1=epsilon # Needed for Source bounds\n",
    "        scan_start_time = time.time()\n",
    "        photons_found_in_scan = False\n",
    "        for chunk_idx, chunk_file in enumerate(photon_chunk_files):\n",
    "             try:\n",
    "                photon_list_chunk = np.load(chunk_file)\n",
    "                if photon_list_chunk.ndim != 2 or photon_list_chunk.shape[1] != 4 or photon_list_chunk.shape[0] == 0: continue\n",
    "                y0c, z0c, y1c, z1c = photon_list_chunk[:,0], photon_list_chunk[:,1], photon_list_chunk[:,2], photon_list_chunk[:,3]\n",
    "                nan_mask_chunk = np.isnan(y0c)|np.isnan(z0c)|np.isnan(y1c)|np.isnan(z1c)\n",
    "                valid_indices = ~nan_mask_chunk\n",
    "                if not np.any(valid_indices): continue\n",
    "                photons_found_in_scan = True\n",
    "                if not using_manual_dest_bounds:\n",
    "                    global_max_abs_y0=max(global_max_abs_y0, np.max(np.abs(y0c[valid_indices])))\n",
    "                    global_max_abs_z0=max(global_max_abs_z0, np.max(np.abs(z0c[valid_indices])))\n",
    "                global_max_abs_y1=max(global_max_abs_y1, np.max(np.abs(y1c[valid_indices])))\n",
    "                global_max_abs_z1=max(global_max_abs_z1, np.max(np.abs(z1c[valid_indices])))\n",
    "                del photon_list_chunk\n",
    "             except FileNotFoundError: print(f\"\\nWarn: File not found during scan: {chunk_file}. Skip.\"); continue\n",
    "             except Exception as e: print(f\"\\nWarn: Error scanning {chunk_file} for bounds: {e}\")\n",
    "        print(f\"\\nBounds scan complete. Time: {time.time() - scan_start_time:.2f}s\")\n",
    "\n",
    "        if not photons_found_in_scan:\n",
    "             print(\"\\nError: No valid (non-NaN) photons found in any chunk during scan. Cannot proceed.\")\n",
    "             return _save_image(mapped_image, save_path)\n",
    "\n",
    "\n",
    "        # --- Calculate SOURCE Mapping Bounds ---\n",
    "        source_bound_y = max(global_max_abs_y1, epsilon); source_bound_z = max(global_max_abs_z1, epsilon)\n",
    "        if source_pixel_aspect >= 1.0:\n",
    "             temp_source_map_bound_y = source_bound_y\n",
    "             temp_source_map_bound_z = max(source_bound_z, source_bound_y / source_pixel_aspect)\n",
    "        else:\n",
    "             temp_source_map_bound_z = source_bound_z\n",
    "             temp_source_map_bound_y = max(source_bound_y, source_bound_z * source_pixel_aspect)\n",
    "        source_map_bound_y = temp_source_map_bound_y\n",
    "        source_map_bound_z = temp_source_map_bound_z\n",
    "        source_denom_y = max(2.0 * source_map_bound_y, epsilon); source_denom_z = max(2.0 * source_map_bound_z, epsilon)\n",
    "        print(f\"Source mapping bounds (Aspect Corrected): y1(horiz):[+/-{source_map_bound_y:.3f}], z1(vert):[+/-{source_map_bound_z:.3f}]\")\n",
    "\n",
    "\n",
    "        # --- Calculate DESTINATION Mapping Denominators ---\n",
    "        dest_denom_y, dest_denom_z = epsilon, epsilon\n",
    "\n",
    "        if using_manual_dest_bounds:\n",
    "            # Mode 1: dest_map_bound_min_z and dest_map_bound_max_z already set from input\n",
    "            dest_range_y = dest_map_bound_max_y - dest_map_bound_min_y\n",
    "            dest_range_z = dest_map_bound_max_z - dest_map_bound_min_z # This is (logical_max_z - logical_min_z)\n",
    "            dest_denom_y = max(dest_range_y, epsilon)\n",
    "            dest_denom_z = max(dest_range_z, epsilon) # Denominator for Z mapping\n",
    "        else: # Mode 2 (Auto Bounds)\n",
    "            logical_dest_bound_y = max(global_max_abs_y0, epsilon)\n",
    "            logical_dest_bound_z = max(global_max_abs_z0, epsilon)\n",
    "            print(f\"Auto-calculating destination bounds from max extent: y0(horiz)=+/-{logical_dest_bound_y:.3f}, z0(vert)=+/-{logical_dest_bound_z:.3f}\")\n",
    "            temp_dest_map_bound_y, temp_dest_map_bound_z = 0, 0\n",
    "            if output_pixel_aspect >= 1.0:\n",
    "                 temp_dest_map_bound_y = logical_dest_bound_y\n",
    "                 temp_dest_map_bound_z = max(logical_dest_bound_z, logical_dest_bound_y / output_pixel_aspect)\n",
    "            else:\n",
    "                 temp_dest_map_bound_z = logical_dest_bound_z\n",
    "                 temp_dest_map_bound_y = max(logical_dest_bound_y, logical_dest_bound_z * output_pixel_aspect)\n",
    "            dest_map_bound_min_y = -temp_dest_map_bound_y\n",
    "            dest_map_bound_max_y = temp_dest_map_bound_y\n",
    "            dest_map_bound_min_z = -temp_dest_map_bound_z # This is logical_min_z for auto mode\n",
    "            dest_map_bound_max_z = temp_dest_map_bound_z # This is logical_max_z for auto mode\n",
    "            dest_denom_y = max(2.0 * temp_dest_map_bound_y, epsilon)\n",
    "            dest_denom_z = max(2.0 * temp_dest_map_bound_z, epsilon) # Denominator for Z mapping\n",
    "            print(f\"Destination mapping bounds (Auto, Aspect Corrected): y(horiz)=[{dest_map_bound_min_y:.3f},{dest_map_bound_max_y:.3f}], z(vert)=[{dest_map_bound_min_z:.3f},{dest_map_bound_max_z:.3f}]\")\n",
    "\n",
    "        print(f\"Final Mapping Denominators: src_y1(horiz)={source_denom_y:.3f}, src_z1(vert)={source_denom_z:.3f}, dst_y0(horiz)={dest_denom_y:.3f}, dst_z0(vert)={dest_denom_z:.3f}\")\n",
    "\n",
    "\n",
    "        # --- Loop Through Chunks for Processing ---\n",
    "        print(\"\\nProcessing photon data chunk by chunk...\")\n",
    "        start_proc_time = time.time()\n",
    "        for chunk_idx, chunk_file in enumerate(photon_chunk_files):\n",
    "            if (chunk_idx + 1) % 10 == 0 or chunk_idx == 0 or chunk_idx == len(photon_chunk_files) - 1:\n",
    "                 print(f\"\\rProcessing chunk {chunk_idx + 1}/{len(photon_chunk_files)}: {os.path.basename(chunk_file)}...\", end=\"\")\n",
    "            try:\n",
    "                photon_list = np.load(chunk_file)\n",
    "                count_loaded_chunk = 0\n",
    "                if photon_list.ndim == 2 and photon_list.shape[1] == 4 and photon_list.shape[0] > 0:\n",
    "                    count_loaded_chunk = photon_list.shape[0]\n",
    "                    total_photons_loaded_from_chunks += count_loaded_chunk\n",
    "                else:\n",
    "                    print(f\"\\nWarn: Invalid shape in chunk {chunk_file}: {photon_list.shape}. Skipping.\")\n",
    "                    del photon_list; continue\n",
    "                y0_f, z0_f, y1_f, z1_f = photon_list[:, 0], photon_list[:, 1], photon_list[:, 2], photon_list[:, 3]\n",
    "                nan_mask = np.isnan(y0_f) | np.isnan(z0_f) | np.isnan(y1_f) | np.isnan(z1_f)\n",
    "                valid_indices_nan = np.where(~nan_mask)[0]\n",
    "                count_after_nan = len(valid_indices_nan)\n",
    "                photons_lost_nan += (count_loaded_chunk - count_after_nan)\n",
    "                if count_after_nan == 0: del photon_list; continue\n",
    "                source_bounds_ok = (np.abs(y1_f[valid_indices_nan]) <= source_map_bound_y + epsilon) & \\\n",
    "                                   (np.abs(z1_f[valid_indices_nan]) <= source_map_bound_z + epsilon)\n",
    "                valid_indices_src_bounds = valid_indices_nan[source_bounds_ok]\n",
    "                count_after_src_bounds = len(valid_indices_src_bounds)\n",
    "                photons_lost_source_bounds += (count_after_nan - count_after_src_bounds)\n",
    "                if count_after_src_bounds == 0: del photon_list; continue\n",
    "                y0_f_filt = y0_f[valid_indices_src_bounds]; z0_f_filt = z0_f[valid_indices_src_bounds]\n",
    "                dest_logical_ok = (y0_f_filt >= dest_map_bound_min_y - epsilon) & (y0_f_filt <= dest_map_bound_max_y + epsilon) & \\\n",
    "                                  (z0_f_filt >= dest_map_bound_min_z - epsilon) & (z0_f_filt <= dest_map_bound_max_z + epsilon)\n",
    "                valid_indices_dest_logical = valid_indices_src_bounds[dest_logical_ok]\n",
    "                count_after_dest_logical = len(valid_indices_dest_logical)\n",
    "                photons_lost_dest_logical_filter += (count_after_src_bounds - count_after_dest_logical)\n",
    "                if count_after_dest_logical == 0: del photon_list; continue\n",
    "                y0_f_pv = y0_f[valid_indices_dest_logical]; z0_f_pv = z0_f[valid_indices_dest_logical]\n",
    "                y1_f_pv = y1_f[valid_indices_dest_logical]; z1_f_pv = z1_f[valid_indices_dest_logical]\n",
    "\n",
    "                row_indices_f = ((z1_f_pv + source_map_bound_z) / source_denom_z) * (orig_h - 1)\n",
    "                col_indices_f = ((y1_f_pv + source_map_bound_y) / source_denom_y) * (orig_w - 1)\n",
    "                y1_physical = np.round(row_indices_f).astype(int)\n",
    "                z1_physical = np.round(col_indices_f).astype(int)\n",
    "                y1_physical = np.clip(y1_physical, 0, orig_h - 1)\n",
    "                z1_physical = np.clip(z1_physical, 0, orig_w - 1)\n",
    "\n",
    "                # --- MODIFIED Z-AXIS MAPPING ---\n",
    "                if using_manual_dest_bounds: # Mode 1\n",
    "                    y0_idx_f = ((y0_f_pv - dest_map_bound_min_y) / dest_denom_y) * (mapped_w - 1)\n",
    "                    if flip_z_axis_render:\n",
    "                        # Maps min_z to bottom row, max_z to top row\n",
    "                        z0_idx_f = ((dest_map_bound_max_z - z0_f_pv) / dest_denom_z) * (mapped_h - 1)\n",
    "                    else: # Original mapping\n",
    "                        z0_idx_f = ((z0_f_pv - dest_map_bound_min_z) / dest_denom_z) * (mapped_h - 1)\n",
    "                else: # Mode 2 (Auto Bounds)\n",
    "                    # dest_map_bound_min_z is -auto_bound_z, dest_map_bound_max_z is +auto_bound_z\n",
    "                    # dest_denom_z is 2 * auto_bound_z\n",
    "                    auto_bound_y = dest_map_bound_max_y\n",
    "                    auto_bound_z_positive_extent = dest_map_bound_max_z # This is the positive extent for auto mode\n",
    "\n",
    "                    y0_idx_f = ((y0_f_pv + auto_bound_y) / dest_denom_y) * (mapped_w - 1)\n",
    "                    if flip_z_axis_render:\n",
    "                        # Maps -auto_bound_z (logical bottom) to bottom row, +auto_bound_z (logical top) to top row\n",
    "                        z0_idx_f = ((auto_bound_z_positive_extent - z0_f_pv) / dest_denom_z) * (mapped_h - 1)\n",
    "                    else: # Original mapping\n",
    "                        z0_idx_f = ((z0_f_pv + auto_bound_z_positive_extent) / dest_denom_z) * (mapped_h - 1)\n",
    "                # --- END MODIFIED Z-AXIS MAPPING ---\n",
    "\n",
    "                y0_idx_clipped = np.round(y0_idx_f).astype(int)\n",
    "                z0_idx_clipped = np.round(z0_idx_f).astype(int)\n",
    "                y0_idx_clipped = np.clip(y0_idx_clipped, 0, mapped_w - 1)\n",
    "                z0_idx_clipped = np.clip(z0_idx_clipped, 0, mapped_h - 1)\n",
    "                pixel_map_ok_mask = (y0_idx_f >= -epsilon) & (y0_idx_f < mapped_w + epsilon) & \\\n",
    "                                    (z0_idx_f >= -epsilon) & (z0_idx_f < mapped_h + epsilon)\n",
    "                count_after_pixel_map = np.sum(pixel_map_ok_mask)\n",
    "                photons_lost_dest_pixel_map += (count_after_dest_logical - count_after_pixel_map)\n",
    "                if count_after_pixel_map == 0: del photon_list; continue\n",
    "                y0_idx_final = y0_idx_clipped[pixel_map_ok_mask]\n",
    "                z0_idx_final = z0_idx_clipped[pixel_map_ok_mask]\n",
    "                y1_physical_final = y1_physical[pixel_map_ok_mask]\n",
    "                z1_physical_final = z1_physical[pixel_map_ok_mask]\n",
    "                invalid_src_idx_mask = (y1_physical_final >= orig_h) | (z1_physical_final >= orig_w) | \\\n",
    "                                       (y1_physical_final < 0) | (z1_physical_final < 0)\n",
    "                num_invalid_src_idx = np.sum(invalid_src_idx_mask)\n",
    "                photons_lost_invalid_source_idx += num_invalid_src_idx\n",
    "                if num_invalid_src_idx > 0 :\n",
    "                     valid_accumulation_mask = ~invalid_src_idx_mask\n",
    "                     if not np.any(valid_accumulation_mask):\n",
    "                         del photon_list; continue\n",
    "                     y0_idx_final = y0_idx_final[valid_accumulation_mask]\n",
    "                     z0_idx_final = z0_idx_final[valid_accumulation_mask]\n",
    "                     y1_physical_final = y1_physical_final[valid_accumulation_mask]\n",
    "                     z1_physical_final = z1_physical_final[valid_accumulation_mask]\n",
    "                count_accumulated_chunk = len(y0_idx_final)\n",
    "                photons_accumulated += count_accumulated_chunk\n",
    "                if count_accumulated_chunk > 0:\n",
    "                    source_colors = original_image_rgb[y1_physical_final, z1_physical_final].astype(np.float64)\n",
    "                    np.add.at(sum_array, (z0_idx_final, y0_idx_final), source_colors)\n",
    "                    np.add.at(count_array, (z0_idx_final, y0_idx_final), 1)\n",
    "                del photon_list, y0_f, z0_f, y1_f, z1_f, valid_indices_nan, valid_indices_src_bounds, valid_indices_dest_logical\n",
    "                del y0_idx_final, z0_idx_final, y1_physical_final, z1_physical_final\n",
    "                if count_accumulated_chunk > 0: del source_colors\n",
    "            except FileNotFoundError: print(f\"\\nWarn: Chunk file not found during processing: {chunk_file}. Skip.\"); continue\n",
    "            except Exception as e: print(f\"\\nWarn: Error processing chunk {chunk_file}: {e}. Skip.\"); traceback.print_exc(limit=1, file=sys.stdout); continue\n",
    "        print(f\"\\nFinished processing all chunks. Time: {time.time() - start_proc_time:.2f}s\")\n",
    "        print(\"\\n--- Photon Loss Debug Summary ---\")\n",
    "        print(f\"Destination Mode: {'MANUAL Bounds + Scale' if using_manual_dest_bounds else 'AUTO Bounds + Shape'}\")\n",
    "        print(f\"  Z-axis Render Flip: {flip_z_axis_render}\")\n",
    "        print(f\"Total photons loaded from chunks: {total_photons_loaded_from_chunks}\")\n",
    "        print(f\"  Lost due to NaN values:         {photons_lost_nan}\")\n",
    "        count_rem_1 = total_photons_loaded_from_chunks - photons_lost_nan\n",
    "        print(f\"  Remaining after NaN filter:     {count_rem_1}\")\n",
    "        print(f\"  Lost due to source bounds filter [y1(horiz):+/-{source_map_bound_y:.3f}, z1(vert):+/-{source_map_bound_z:.3f}]: {photons_lost_source_bounds}\")\n",
    "        count_rem_2 = count_rem_1 - photons_lost_source_bounds\n",
    "        print(f\"  Remaining after source bounds:  {count_rem_2}\")\n",
    "        print(f\"  Lost due to DEST LOGICAL filter [y0(horiz)=[{dest_map_bound_min_y:.3f},{dest_map_bound_max_y:.3f}], z0(vert)=[{dest_map_bound_min_z:.3f},{dest_map_bound_max_z:.3f}]]: {photons_lost_dest_logical_filter}\")\n",
    "        count_rem_3 = count_rem_2 - photons_lost_dest_logical_filter\n",
    "        print(f\"  Remaining after dest logical:   {count_rem_3}\")\n",
    "        print(f\"  Lost due to dest pixel map/clip (outside vert=[{0}-{mapped_h-1}], horiz=[{0}-{mapped_w-1}]): {photons_lost_dest_pixel_map}\")\n",
    "        count_rem_4 = count_rem_3 - photons_lost_dest_pixel_map\n",
    "        print(f\"  Remaining after dest pixel map: {count_rem_4}\")\n",
    "        print(f\"  Lost due to invalid source idx (post-map/clip check): {photons_lost_invalid_source_idx}\")\n",
    "        print(f\"Total photons accumulated (pre-add.at): {photons_accumulated}\")\n",
    "        print(f\"Calculated total loss:            {total_photons_loaded_from_chunks - photons_accumulated}\")\n",
    "        calc_total = photons_lost_nan + photons_lost_source_bounds + photons_lost_dest_logical_filter + photons_lost_dest_pixel_map + photons_lost_invalid_source_idx + photons_accumulated\n",
    "        if abs(calc_total - total_photons_loaded_from_chunks) > 0:\n",
    "             print(f\"!!! WARNING: Photon count sanity check failed! Calculated Total ({calc_total}) != Loaded ({total_photons_loaded_from_chunks}). Diff: {total_photons_loaded_from_chunks - calc_total}\")\n",
    "        print(\"----------------------------------\")\n",
    "        print(\"Calculating averages and finalizing image...\")\n",
    "        hit_mask = count_array > 0\n",
    "        num_hit_pixels = np.sum(hit_mask)\n",
    "        if num_hit_pixels > 0:\n",
    "            print(f\"  Averaging colors for {num_hit_pixels} hit pixels.\")\n",
    "            valid_counts = count_array[hit_mask]\n",
    "            average_colors_float = sum_array[hit_mask] / valid_counts[..., np.newaxis]\n",
    "            mapped_image[hit_mask] = np.clip(average_colors_float, 0, 255).astype(np.uint8)\n",
    "        else:\n",
    "            print(\"  No pixels were hit by valid photons.\")\n",
    "        end_time_total = time.time()\n",
    "        print(f\"Processing finished. Total time: {end_time_total - start_time_total:.2f} seconds.\")\n",
    "        return _save_image(mapped_image, save_path)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- An critical error occurred during mapping setup or processing ---\"); traceback.print_exc()\n",
    "        if 'mapped_h' in locals() and 'mapped_w' in locals() and save_path:\n",
    "             try:\n",
    "                 if 'default_color_rgb' not in locals(): default_color_rgb = (0,0,0)\n",
    "                 if 'mapped_image' not in locals() or mapped_image is None:\n",
    "                     print(\"Initializing empty background for error image.\")\n",
    "                     mapped_image = np.full((mapped_h, mapped_w, 3), default_color_rgb, dtype=np.uint8)\n",
    "                 elif mapped_image.shape != (mapped_h, mapped_w, 3):\n",
    "                      print(f\"Warning: Mapped image shape {mapped_image.shape} doesn't match expected {(mapped_h, mapped_w, 3)}. Creating empty background.\")\n",
    "                      mapped_image = np.full((mapped_h, mapped_w, 3), default_color_rgb, dtype=np.uint8)\n",
    "                 print(\"Attempting to save background/partial image due to critical error.\")\n",
    "                 _save_image(mapped_image, save_path + \"_CRITICAL_ERROR.png\")\n",
    "             except Exception as save_err:\n",
    "                 print(f\"Failed to save error image: {save_err}\")\n",
    "        return False"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
