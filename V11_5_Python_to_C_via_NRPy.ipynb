{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba92b65f",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "# Step 1: Introduction and Core Physics\n",
    "\n",
    "This notebook is a self-contained tutorial that uses the `nrpy` library to construct a complete C-language project for integrating photon geodesics in curved spacetimes. The resulting C code is a flexible, high-performance ray-tracing engine capable of generating gravitationally lensed images of distant sources as seen by an observer near a black hole.\n",
    "\n",
    "The core of the project is the numerical solution of the geodesic equation, which describes the path of a free-falling particle (or photon) through curved spacetime. The geodesic equation, as detailed on [Wikipedia](https://en.wikipedia.org/wiki/Geodesic_equation), is a second-order ordinary differential equation (ODE) that relates a particle's acceleration to the spacetime curvature, represented by the Christoffel symbols ($\\Gamma^{\\alpha}_{\\mu\\nu}$):\n",
    "\n",
    "$$ \\frac{d^2x^{\\alpha}}{d\\lambda^2} = -\\Gamma^{\\alpha}_{\\mu\\nu} \\frac{dx^{\\mu}}{d\\lambda} \\frac{dx^{\\nu}}{d\\lambda} $$\n",
    "\n",
    "Here, $x^\\alpha = (t, x, y, z)$ are the spacetime coordinates, and $\\lambda$ is the affine parameter, which measures the proper distance along the path for a massive particle or a suitable path parameter for a photon.\n",
    "\n",
    "### The Reverse Ray-Tracing Transformation\n",
    "\n",
    "To render an image of what an observer sees, we must trace the photon's path from the observer's camera *backwards in time* to its source. While we could integrate the geodesic equation with a negative step `dλ < 0`, most ODE solvers are optimized for forward integration with a positive step. To accommodate this, we perform a change of variables on the affine parameter. We define a new parameter, $\\kappa$, that increases as the original parameter, $\\lambda$, decreases:\n",
    "\n",
    "$$ \\kappa = -\\lambda \\implies d\\kappa = -d\\lambda \\implies \\frac{d}{d\\lambda} = -\\frac{d}{d\\kappa} $$\n",
    "\n",
    "We now substitute this transformation directly into the second-order geodesic equation:\n",
    "\n",
    "$$ \\frac{d}{d\\lambda}\\left(\\frac{dx^{\\alpha}}{d\\lambda}\\right) = -\\Gamma^{\\alpha}_{\\mu\\nu} \\frac{dx^{\\mu}}{d\\lambda} \\frac{dx^{\\nu}}{d\\lambda} $$\n",
    "\n",
    "Applying the chain rule, $\\frac{d}{d\\lambda} = -\\frac{d}{d\\kappa}$:\n",
    "\n",
    "$$ \\left(-\\frac{d}{d\\kappa}\\right)\\left(-\\frac{dx^{\\alpha}}{d\\kappa}\\right) = -\\Gamma^{\\alpha}_{\\mu\\nu} \\left(-\\frac{dx^{\\mu}}{d\\kappa}\\right) \\left(-\\frac{dx^{\\nu}}{d\\kappa}\\right) $$\n",
    "\n",
    "The negatives on both sides cancel, yielding the reverse-time geodesic equation:\n",
    "\n",
    "$$ \\frac{d^2x^{\\alpha}}{d\\kappa^2} = -\\Gamma^{\\alpha}_{\\mu\\nu} \\frac{dx^{\\mu}}{d\\kappa} \\frac{dx^{\\nu}}{d\\kappa} $$\n",
    "\n",
    "This equation has the same form as the original, but describes the path integrated with respect to $\\kappa$. To solve it numerically, we now decompose this second-order ODE into a system of coupled first-order ODEs. We define the **reverse-time momentum**, $p^\\alpha$, as the 4-velocity with respect to our new parameter $\\kappa$:\n",
    "\n",
    "$$ p^{\\alpha} \\equiv \\frac{dx^{\\alpha}}{d\\kappa} $$\n",
    "\n",
    "This definition immediately gives us our first ODE. We find the second by substituting $p^\\alpha$ into the reverse-time geodesic equation:\n",
    "\n",
    "$$ \\frac{d}{d\\kappa}\\left(\\frac{dx^{\\alpha}}{d\\kappa}\\right) = -\\Gamma^{\\alpha}_{\\mu\\nu} \\left(\\frac{dx^{\\mu}}{d\\kappa}\\right) \\left(\\frac{dx^{\\nu}}{d\\kappa}\\right) \\implies \\frac{dp^{\\alpha}}{d\\kappa} = -\\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} $$\n",
    "\n",
    "This gives us the final set of ODEs that our C code will solve. We also add a third ODE to track the total proper distance traveled by the photon along its spatial path, using the spatial part of the metric $\\gamma_{ij}$:\n",
    "\n",
    "1.  **Position ODE**: $\\frac{dx^{\\alpha}}{d\\kappa} = p^{\\alpha}$\n",
    "2.  **Momentum ODE**: $\\frac{dp^{\\alpha}}{d\\kappa} = -\\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu}$\n",
    "3.  **Path Length ODE**: $\\frac{dL}{d\\kappa} = \\sqrt{\\gamma_{ij} \\frac{dx^i}{d\\kappa} \\frac{dx^j}{d\\kappa}} = \\sqrt{\\gamma_{ij}p^{i}p^{j}}$\n",
    "\n",
    "### Initial Conditions\n",
    "\n",
    "The initial value of the reverse-time momentum, $p^\\alpha_{\\text{initial}}$, determines the starting direction of the ray traced from the camera. It is physically equivalent to the *negative* of the final momentum of a photon that started at a distant source and ended its journey at the camera. If we denote the physical, forward-time 4-velocity as $k^\\alpha = dx^\\alpha/d\\lambda$, then:\n",
    "\n",
    "$$ p^\\alpha_{\\text{initial}} = \\left(\\frac{dx^\\alpha}{d\\kappa}\\right)_{\\text{initial}} = -\\left(\\frac{dx^\\alpha}{d\\lambda}\\right)_{\\text{final}} = -k^\\alpha_{\\text{final}} $$\n",
    "\n",
    "This relationship is key: setting the initial conditions for our reverse-time integration is equivalent to choosing the final momentum of a physically forward-propagating photon arriving at the camera.\n",
    "\n",
    "This notebook follows a modular, single-responsibility design pattern. It uses the `nrpy` library to first define the underlying physics symbolically, and then automatically generates a series of interoperable C functions, each with a specific job. This makes the final C project clear, efficient, and easily extensible.\n",
    "\n",
    "**Notebook Status:** <font color='green'><b>Validated</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bac0cb",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "This notebook is organized into a series of logical steps, with each core Python function encapsulated in its own cell. This modular design enhances readability and maintainability.\n",
    "\n",
    "1.  [Step 1: Introduction and Core Physics](#introduction)\n",
    "    *   The Geodesic Equation\n",
    "    *   The Reverse Ray-Tracing Transformation\n",
    "    *   Initial Conditions\n",
    "2.  [Step 2: Project Initialization](#initialize)\n",
    "    *   Importing Libraries\n",
    "    *   Directory Management\n",
    "    *   Defining Physical and Runtime Parameters\n",
    "3.  [Step 3: The Symbolic Core - Foundational Math](#symbolic_core)\n",
    "    *   [3.a: Metric Tensor Derivatives](#deriv_g4DD)\n",
    "    *   [3.b: Christoffel Symbol Calculation](#four_connections)\n",
    "    *   [3.c: Geodesic Momentum RHS](#geodesic_mom_rhs)\n",
    "    *   [3.d: Geodesic Position RHS](#geodesic_pos_rhs)\n",
    "    *   [3.e: Proper Length ODE RHS](#proper_len_rhs)\n",
    "    *   [3.f: Symbolic Calculation of p⁰](#geodesic_mom0_calc)\n",
    "4.  [Step 4: Spacetime Definition in Kerr-Schild Coordinates](#spacetime_definition)\n",
    "    *   The Kerr-Schild Metric\n",
    "5.  [Step 5: Symbolic Workflow Execution](#symbolic_execution)\n",
    "    *   Applying Blueprints to the Metric\n",
    "6.  [Step 6: C Code Generation - Physics \"Engines\" and \"Workers\"](#generate_c_engines)\n",
    "    *   [6.a: `g4DD_kerr_schild()` Worker](#g4DD_kerr_schild_engine)\n",
    "    *   [6.b: `con_kerr_schild()` Worker](#con_kerr_schild_engine)\n",
    "    *   [6.c: `calculate_p0_reverse()` Engine](#calculate_p0_engine)\n",
    "    *   [6.d: `calculate_ode_rhs()` Engine](#calculate_ode_rhs_engine)\n",
    "    *   [6.e: `find_event_time_and_state()` Interpolation Engine](#lagrange_interp_engine)\n",
    "7.  [Step 7: C Code Generation - Orchestrators and Dispatchers](#generate_c_orchestrators)\n",
    "    *   [7.a: `g4DD_metric()` Dispatcher](#g4DD_metric_dispatcher)\n",
    "    *   [7.b: `connections()` Dispatcher](#connections_dispatcher)\n",
    "    *   [7.c: `set_initial_conditions_cartesian()` Orchestrator](#set_initial_conditions_cartesian)\n",
    "    *   [7.d: The GSL Wrapper Function](#gsl_wrapper)\n",
    "    *   [7.e: The Main Integration Loop](#integration_loop)\n",
    "    *   [7.f: Data Processing and Saving](#data_processing)\n",
    "    *   [7.g: The `main()` C Function Entry Point](#main_entry_point)\n",
    "8.  [Step 8: Project Assembly and Compilation](#assemble_project)\n",
    "    *   [8.a: Custom Data Structures](#register_structs)\n",
    "    *   [8.b: Final Build Command](#final_build)\n",
    "9.  [Step 9: Visualization and Analysis](#plotting)\n",
    "    *   [9.a: 3D Scene Geometry Visualizer](#plot_3d_scene)\n",
    "    *   [9.b: Blueprint File Statistical Analysis](#plot_stats)\n",
    "    *   [9.c: Unlensed Source Disk Visualizer](#plot_unlensed)\n",
    "    *   [9.d: Final Lensed Image Renderer](#plot_lensed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c0d30",
   "metadata": {},
   "source": [
    "<a id='initialize'></a>\n",
    "# Step 2: Project Initialization\n",
    "\n",
    "This cell sets up the foundational elements for our entire project. It performs three key tasks:\n",
    "\n",
    "1.  **Import Libraries**: We import necessary modules from standard Python libraries (`os`, `shutil`, `sympy`) and the core components of `nrpy`. The `nrpy` imports provide tools for C function registration, C code generation, parameter handling, and infrastructure management.\n",
    "\n",
    "2.  **Directory Management**: A clean output directory, `project/photon_geodesic_integrator/`, is created to store the generated C code, ensuring a fresh build every time the notebook is run.\n",
    "\n",
    "3.  **Physical and Runtime Parameter Definition**: We define the many parameters that control the simulation using `nrpy.params.CodeParameter`. This is the central object for defining a runtime parameter that will be accessible in the generated C code. It registers each parameter's name, C type, default value, and properties in a global dictionary, which `nrpy`'s build system then uses to construct the C interface.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.params.set_parval_from_str(par_name, value)`**:\n",
    "    *   **Source File**: `nrpy/params.py`\n",
    "    *   **Description**: Sets the value of a core `nrpy` parameter. Here, it is used to specify that we are using the `BHaH` (BlackHoles@Home) C code generation infrastructure.\n",
    "\n",
    "*   **`nrpy.params.CodeParameter(c_type, module, name, default_value, **kwargs)`**:\n",
    "    *   **Source File**: `nrpy/params.py`\n",
    "    *   **Description**: This is the primary function for registering a C-level parameter. It creates a parameter object that holds all its properties.\n",
    "    *   **Key Inputs**:\n",
    "        *   `c_type`: The data type of the parameter in the C code (e.g., `\"REAL\"`, `\"int\"`).\n",
    "        *   `module`: The name of the Python module where the parameter is defined (usually `__name__`).\n",
    "        *   `name`: The C variable name for the parameter.\n",
    "        *   `default_value`: The default value for the parameter.\n",
    "    *   **Key Keyword Arguments (`kwargs`)**:\n",
    "        *   `commondata=True`: Specifies that the parameter is \"common\" to the entire simulation (e.g., black hole mass `M_scale`). It will be stored in the `commondata_struct` in the generated C code. If `False`, it's stored in the grid-specific `params_struct`.\n",
    "        *   `add_to_parfile=True`: Instructs the build system to add an entry for this parameter to a default parameter file, making it easy to configure at runtime.\n",
    "        *   `add_to_set_CodeParameters_h=True`: This is a crucial flag that enables the \"automatic unpacking\" mechanism, also known as the \"Triple-Lock\" system. It tells `nrpy` to add an entry for the parameter to the `set_CodeParameters.h` convenience header. Any C function registered with `include_CodeParameters_h=True` will get a local `const REAL` variable with the same name as the parameter, making the C code clean and readable. This is handled by the `nrpy.infrastructures.BHaH.CodeParameters` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f07e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Registering CodeParameter for the disk proximity check...\n",
      "-> Registering CodeParameters for the disk bounding box...\n"
     ]
    }
   ],
   "source": [
    "# Cell ID: 33f07e1c (Replacement)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sympy as sp\n",
    "\n",
    "# NRPy-related imports for C-code generation\n",
    "import nrpy.c_function as cfc\n",
    "import nrpy.c_codegen as ccg\n",
    "import nrpy.params as par\n",
    "import nrpy.indexedexp as ixp\n",
    "import nrpy.infrastructures.BHaH.BHaH_defines_h as Bdefines_h\n",
    "import nrpy.infrastructures.BHaH.Makefile_helpers as Makefile\n",
    "from nrpy.infrastructures.BHaH import cmdline_input_and_parfiles\n",
    "import nrpy.helpers.generic as gh\n",
    "import nrpy.infrastructures.BHaH.CodeParameters as CPs\n",
    "\n",
    "\n",
    "# Set project name and clean the output directory\n",
    "project_name = \"photon_geodesic_integrator\"\n",
    "project_dir = os.path.join(\"project\", project_name)\n",
    "shutil.rmtree(project_dir, ignore_errors=True)\n",
    "\n",
    "# Set NRPy parameters for the BHaH infrastructure\n",
    "par.set_parval_from_str(\"Infrastructure\", \"BHaH\")\n",
    "\n",
    "\n",
    "metric_choice = par.CodeParameter(\n",
    "    \"int\", __name__, \"metric_choice\", 0,\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "\n",
    "# --- Universal Camera System Parameters ---\n",
    "camera_pos_x = par.CodeParameter(\"REAL\", __name__, \"camera_pos_x\", 0.0, add_to_parfile=True, commondata=True)\n",
    "camera_pos_y = par.CodeParameter(\"REAL\", __name__, \"camera_pos_y\", 0.0,  add_to_parfile=True, commondata=True)\n",
    "camera_pos_z = par.CodeParameter(\"REAL\", __name__, \"camera_pos_z\", 51.0,  add_to_parfile=True, commondata=True)\n",
    "\n",
    "window_center_x = par.CodeParameter(\"REAL\", __name__, \"window_center_x\", 0.0, add_to_parfile=True, commondata=True)\n",
    "window_center_y = par.CodeParameter(\"REAL\", __name__, \"window_center_y\", 0.0,  add_to_parfile=True, commondata=True)\n",
    "window_center_z = par.CodeParameter(\"REAL\", __name__, \"window_center_z\", 50.0,  add_to_parfile=True, commondata=True)\n",
    "\n",
    "\n",
    "window_up_vec_x = par.CodeParameter(\"REAL\", __name__, \"window_up_vec_x\", 0.0, add_to_parfile=True, commondata=True)\n",
    "window_up_vec_y = par.CodeParameter(\"REAL\", __name__, \"window_up_vec_y\", 1.0, add_to_parfile=True, commondata=True)\n",
    "window_up_vec_z = par.CodeParameter(\"REAL\", __name__, \"window_up_vec_z\", 0.0, add_to_parfile=True, commondata=True)\n",
    "\n",
    "# --- Independent Source Plane Definition ---\n",
    "source_plane_normal_x = par.CodeParameter(\"REAL\", __name__, \"source_plane_normal_x\", 0.0, add_to_parfile=True, commondata=True)\n",
    "source_plane_normal_y = par.CodeParameter(\"REAL\", __name__, \"source_plane_normal_y\", 0.0, add_to_parfile=True, commondata=True)\n",
    "source_plane_normal_z = par.CodeParameter(\"REAL\", __name__, \"source_plane_normal_z\", 1.0, add_to_parfile=True, commondata=True)\n",
    "\n",
    "source_plane_center_x = par.CodeParameter(\"REAL\", __name__, \"source_plane_center_x\", 0.0, add_to_parfile=True, commondata=True)\n",
    "source_plane_center_y = par.CodeParameter(\"REAL\", __name__, \"source_plane_center_y\", 0.0, add_to_parfile=True, commondata=True)\n",
    "source_plane_center_z = par.CodeParameter(\"REAL\", __name__, \"source_plane_center_z\", 0.0, add_to_parfile=True, commondata=True)\n",
    "\n",
    "\n",
    "source_up_vec_x = par.CodeParameter(\"REAL\", __name__, \"source_up_vec_x\", 0.0, add_to_parfile=True, commondata=True)\n",
    "source_up_vec_y = par.CodeParameter(\"REAL\", __name__, \"source_up_vec_y\", 1.0, add_to_parfile=True, commondata=True)\n",
    "source_up_vec_z = par.CodeParameter(\"REAL\", __name__, \"source_up_vec_z\", 0.0, add_to_parfile=True, commondata=True) \n",
    "\n",
    "source_r_min = par.CodeParameter(\"REAL\", __name__, \"source_r_min\", 6.0, add_to_parfile=True, commondata=True)\n",
    "source_r_max = par.CodeParameter(\"REAL\", __name__, \"source_r_max\", 25.0, add_to_parfile=True, commondata=True)\n",
    "\n",
    "# --- General Ray-Tracing Parameters ---\n",
    "scan_density = par.CodeParameter(\"int\", __name__, \"scan_density\", 512, add_to_parfile=True, commondata=True)\n",
    "flatness_threshold = par.CodeParameter(\"REAL\", __name__, \"flatness_threshold\", 1e-2, add_to_parfile=True, commondata=True)\n",
    "r_escape = par.CodeParameter(\"REAL\", __name__, \"r_escape\", 1500.0, add_to_parfile=True, commondata=True)\n",
    "\n",
    "\n",
    "\n",
    "window_size = par.CodeParameter(\n",
    "    \"REAL\", __name__, \"window_size\", 1.5, \n",
    "    add_to_parfile=True, commondata=True, add_to_set_CodeParameters_h=True\n",
    ")\n",
    "\n",
    "# --- Physical Parameters ---\n",
    "M_scale = par.CodeParameter(\n",
    "    \"REAL\", __name__, \"M_scale\", 1.0,\n",
    "    add_to_parfile=True, commondata=True, add_to_set_CodeParameters_h=True\n",
    ")\n",
    "a_spin = par.CodeParameter(\n",
    "    \"REAL\", __name__, \"a_spin\", 0.0,\n",
    "    add_to_parfile=True, commondata=True, add_to_set_CodeParameters_h=True\n",
    ")\n",
    "\n",
    "# --- Debugging Parameters ---\n",
    "perform_conservation_check = par.CodeParameter(\n",
    "    \"bool\", __name__, \"perform_conservation_check\", False,\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "\n",
    "debug_mode = par.CodeParameter(\"bool\", __name__, \"debug_mode\", False, add_to_parfile=True, commondata=True)\n",
    "\n",
    "mass_snapshot_every_t = par.CodeParameter(\"REAL\", __name__, \"mass_snapshot_every_t\", 10.0, commondata=True, add_to_parfile=True)\n",
    "\n",
    "# --- NEW: Proximity Detection Parameter for Radiative Transfer ---\n",
    "print(\"-> Registering CodeParameter for the disk proximity check...\")\n",
    "delta_r_max = par.CodeParameter(\"REAL\", __name__, \"delta_r_max\", 2.0, commondata=True, add_to_parfile=True)\n",
    "\n",
    "# --- Bounding Box Parameters for the Accretion Disk ---\n",
    "print(\"-> Registering CodeParameters for the disk bounding box...\")\n",
    "disk_bounds_x_min = par.CodeParameter(\"REAL\", __name__, \"disk_bounds_x_min\", -26.0, commondata=True, add_to_parfile=True)\n",
    "disk_bounds_x_max = par.CodeParameter(\"REAL\", __name__, \"disk_bounds_x_max\", 26.0,  commondata=True, add_to_parfile=True)\n",
    "disk_bounds_y_min = par.CodeParameter(\"REAL\", __name__, \"disk_bounds_y_min\", -26.0, commondata=True, add_to_parfile=True)\n",
    "disk_bounds_y_max = par.CodeParameter(\"REAL\", __name__, \"disk_bounds_y_max\", 26.0,  commondata=True, add_to_parfile=True)\n",
    "disk_bounds_z_min = par.CodeParameter(\"REAL\", __name__, \"disk_bounds_z_min\", -1.0,  commondata=True, add_to_parfile=True)\n",
    "disk_bounds_z_max = par.CodeParameter(\"REAL\", __name__, \"disk_bounds_z_max\", 1.0,   commondata=True, add_to_parfile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa84ac02",
   "metadata": {},
   "source": [
    "<a id='symbolic_core'></a>\n",
    "# Step 3: The Symbolic Core - Foundational Math\n",
    "\n",
    "This section defines the pure mathematical logic of our problem using Python's `sympy` library. Each function in this section is a \"blueprint\" for a physical calculation. These functions take symbolic `sympy` objects as input and return new symbolic expressions as output. They have no knowledge of C code; they are concerned only with mathematics and will be called later to generate the \"recipes\" for our C code engines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23b659c",
   "metadata": {},
   "source": [
    "<a id='deriv_g4DD'></a>\n",
    "### 3.a: Metric Tensor Derivatives\n",
    "\n",
    "The first step in calculating the Christoffel symbols is to compute the partial derivatives of the metric tensor, $g_{\\mu\\nu}$. This function, `derivative_g4DD`, takes the symbolic 4x4 metric tensor `g4DD` and a list of the four coordinate symbols `xx` as input.\n",
    "\n",
    "The function iterates through all components to symbolically calculate the partial derivative of each metric component with respect to each coordinate. The resulting quantity, which we can denote using comma notation as $g_{\\mu\\nu,\\alpha}$, is defined as:\n",
    "\n",
    "$$ g_{\\mu\\nu,\\alpha} \\equiv \\frac{\\partial g_{\\mu\\nu}}{\\partial x^{\\alpha}} $$\n",
    "\n",
    "The nested `for` loops in the code directly correspond to the spacetime indices `μ, ν, α` in the physics equation. `sympy`'s built-in `sp.diff()` function is used to perform the symbolic differentiation, and the final result is returned as a rank-3 symbolic tensor.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.zerorank3(dimension)`**:\n",
    "    *   **Source File**: `nrpy/indexedexp.py`\n",
    "    *   **Description**: This function creates a symbolic rank-3 tensor (a Python list of lists of lists) of a specified dimension, with all elements initialized to the `sympy` integer 0. It is used here to create a container for the derivative results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0d80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_g4DD(g4DD, xx):\n",
    "    \"\"\"Computes the symbolic first derivatives of the metric tensor.\"\"\"\n",
    "    g4DD_dD = ixp.zerorank3(dimension=4)\n",
    "    for nu in range(4):\n",
    "        for mu in range(4):\n",
    "            for alpha in range(4):\n",
    "                g4DD_dD[nu][mu][alpha] = sp.diff(g4DD[nu][mu], xx[alpha])\n",
    "    return g4DD_dD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79893b7",
   "metadata": {},
   "source": [
    "<a id='four_connections'></a>\n",
    "### 3.b: Christoffel Symbol Calculation\n",
    "\n",
    "This function implements the core formula for the Christoffel symbols of the second kind, $\\Gamma^{\\delta}_{\\mu\\nu}$. It takes the symbolic metric tensor `g4DD` ($g_{\\mu\\nu}$) and its derivatives `g4DD_dD` ($g_{\\mu\\nu,\\alpha}$) as input. The calculation requires the inverse metric, $g^{\\mu\\nu}$, which is computed using another `nrpy` helper function.\n",
    "\n",
    "The function then applies the well-known formula for the Christoffel symbols. Using the comma notation for partial derivatives, the formula is:\n",
    "\n",
    "$$ \\Gamma^{\\delta}_{\\mu\\nu} = \\frac{1}{2} g^{\\delta\\alpha} \\left( g_{\\nu\\alpha,\\mu} + g_{\\mu\\alpha,\\nu} - g_{\\mu\\nu,\\alpha} \\right) $$\n",
    "\n",
    "The Python `for` loops iterate over the spacetime indices `δ, μ, ν, α` to construct each component of the Christoffel symbol tensor. After the summation is complete, the `sp.trigsimp()` function is used to simplify the resulting expression. This trigonometric simplification is highly effective and much faster than a general `sp.simplify()` for the Kerr-Schild metric, which contains trigonometric functions of the coordinates.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.zerorank3(dimension)`**: Previously introduced. Used to initialize the Christoffel symbol tensor.\n",
    "*   **`nrpy.indexedexp.symm_matrix_inverter4x4(g4DD)`**:\n",
    "    *   **Source File**: `nrpy/indexedexp.py`\n",
    "    *   **Description**: This function takes a symbolic 4x4 symmetric matrix and analytically computes its inverse. It is highly optimized for this specific task, returning both the inverse matrix ($g^{\\mu\\nu}$) and its determinant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "665bc0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_connections(g4DD, g4DD_dD):\n",
    "    \"\"\"\n",
    "    Computes and simplifies Christoffel symbols from the metric and its derivatives.\n",
    "    \n",
    "    This version uses sp.trigsimp() which is highly effective and much faster\n",
    "    than sp.simplify() for the Kerr-Schild metric.\n",
    "    \"\"\"\n",
    "    Gamma4UDD = ixp.zerorank3(dimension=4)\n",
    "    g4UU, _ = ixp.symm_matrix_inverter4x4(g4DD)\n",
    "    \n",
    "    for mu in range(4):\n",
    "        for nu in range(4):\n",
    "            for delta in range(4):\n",
    "                # Calculate the Christoffel symbol component using the standard formula\n",
    "                for alpha in range(4):\n",
    "                    Gamma4UDD[delta][mu][nu] += sp.Rational(1, 2) * g4UU[delta][alpha] * \\\n",
    "                        (g4DD_dD[nu][alpha][mu] + g4DD_dD[mu][alpha][nu] - g4DD_dD[mu][nu][alpha])\n",
    "                \n",
    "                # Use sp.trigsimp() to simplify the resulting expression.\n",
    "                # This is the key to speeding up the symbolic calculation.\n",
    "                Gamma4UDD[delta][mu][nu] = sp.trigsimp(Gamma4UDD[delta][mu][nu])\n",
    "\n",
    "    return Gamma4UDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59295c0b",
   "metadata": {},
   "source": [
    "<a id='geodesic_mom_rhs'></a>\n",
    "### 3.c: Geodesic Momentum RHS\n",
    "\n",
    "This function defines the symbolic right-hand side (RHS) for the evolution of the **reverse-time momentum**, $p^{\\alpha}$. As established in the introduction, this is the second of our three first-order ODEs:\n",
    "$$ \\frac{dp^{\\alpha}}{d\\kappa} = -\\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} $$\n",
    "The function `geodesic_mom_rhs` takes the symbolic Christoffel symbols $\\Gamma^{\\alpha}_{\\mu\\nu}$ as its input. It then defines the symbolic momentum vector `pU` using `sympy`'s `sp.symbols()` function. A key `nrpy` technique is used here: the symbols are created with names that are already valid C array syntax (e.g., `\"y[4]\"`). This \"direct naming\" simplifies the final C code generation by eliminating the need for string substitutions.\n",
    "\n",
    "The core of this function constructs the symbolic expression for the RHS by performing the Einstein summation $-\\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu}$. A direct implementation would involve a double loop over both $\\mu$ and $\\nu$ from 0 to 3, resulting in $4 \\times 4 = 16$ terms for each component of $\\alpha$, which is computationally inefficient.\n",
    "\n",
    "However, we can significantly optimize this calculation by exploiting symmetry. The term $p^{\\mu} p^{\\nu}$ is symmetric with respect to the interchange of the indices $\\mu$ and $\\nu$. The Christoffel symbols $\\Gamma^{\\alpha}_{\\mu\\nu}$ are also symmetric in their lower two indices. Therefore, the full sum can be split into diagonal ($\\mu=\\nu$) and off-diagonal ($\\mu \\neq \\nu$) terms:\n",
    "$$ \\sum_{\\mu,\\nu} \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} = \\sum_{\\mu=0}^{3} \\Gamma^{\\alpha}_{\\mu\\mu} (p^{\\mu})^2 + \\sum_{\\mu \\neq \\nu} \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} $$\n",
    "The second sum over $\\mu \\neq \\nu$ contains pairs of identical terms (e.g., the $\\mu=1, \\nu=2$ term is the same as the $\\mu=2, \\nu=1$ term). We can combine all such pairs by summing over only one of the cases (e.g., $\\mu < \\nu$) and multiplying by two:\n",
    "$$ \\sum_{\\mu,\\nu} \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} = \\sum_{\\mu=0}^{3} \\Gamma^{\\alpha}_{\\mu\\mu} (p^{\\mu})^2 + 2 \\sum_{\\mu < \\nu} \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} $$\n",
    "The Python code implements this optimized version, ensuring that each component of the RHS is computed with the minimum number of floating point operations, leading to more efficient C code.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.zerorank1(dimension)`**:\n",
    "    *   **Source File**: `nrpy/indexedexp.py`\n",
    "    *   **Description**: Creates a symbolic rank-1 tensor (a Python list) of a specified dimension, with all elements initialized to the `sympy` integer 0. It is used here to create a container for the four components of the momentum RHS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867e4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geodesic_mom_rhs(Gamma4UDD):\n",
    "    \"\"\"\n",
    "    Symbolic RHS for momentum ODE: dp^a/dκ = -Γ^a_μν p^μ p^ν.\n",
    "    p is the reverse-momentum, y[4]...y[7].\n",
    "    \"\"\"\n",
    "    pt,pr,pth,pph = sp.symbols(\"y[4] y[5] y[6] y[7]\", Real=True)\n",
    "    pU = [pt,pr,pth,pph]\n",
    "    geodesic_rhs = ixp.zerorank1(dimension=4)\n",
    "    for alpha in range(4):\n",
    "        for mu in range(4):\n",
    "            geodesic_rhs[alpha] += Gamma4UDD[alpha][mu][mu] * pU[mu] * pU[mu]\n",
    "            for nu in range(mu + 1, 4):\n",
    "                geodesic_rhs[alpha] += 2 * Gamma4UDD[alpha][mu][nu] * pU[mu] * pU[nu]\n",
    "        geodesic_rhs[alpha] = -geodesic_rhs[alpha]\n",
    "    return geodesic_rhs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02fcc6",
   "metadata": {},
   "source": [
    "<a id='geodesic_pos_rhs'></a>\n",
    "### 3.d: Geodesic Position RHS\n",
    "\n",
    "This function defines the symbolic right-hand side (RHS) for the evolution of the position coordinates, $x^{\\alpha}$. As derived in the introduction, this is the first of our three first-order ODEs:\n",
    "\n",
    "$$ \\frac{dx^{\\alpha}}{d\\kappa} = p^{\\alpha} $$\n",
    "\n",
    "The Python function `geodesic_pos_rhs` is straightforward. It defines the components of the reverse-time momentum vector, `pU`, using `sympy`'s `sp.symbols()` function with the \"direct naming\" convention (`y[4]`, `y[5]`, etc.). It then simply returns a list containing these momentum components. This list of four symbolic expressions will serve as the first four components of the complete 9-component RHS vector that our C code will solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc97c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geodesic_pos_rhs():\n",
    "    \"\"\"\n",
    "    Symbolic RHS for position ODE: dx^a/dκ = p^a.\n",
    "    p is the reverse-momentum, y[4]...y[7].\n",
    "    \"\"\"\n",
    "    pt,pr,pth,pph = sp.symbols(\"y[4] y[5] y[6] y[7]\", Real=True)\n",
    "    pU = [pt,pr,pth,pph]\n",
    "    return pU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976931d5",
   "metadata": {},
   "source": [
    "<a id='proper_len_rhs'></a>\n",
    "### 3.e: Proper Length ODE RHS\n",
    "\n",
    "This function defines the symbolic right-hand side for the evolution of the proper length, $L$. This is the final component of our ODE system and allows us to track the total distance the photon has traveled along its spatial path. The proper length element $dL$ is defined by the spatial part of the metric, $\\gamma_{ij} = g_{ij}$ for $i,j \\in \\{1,2,3\\}$:\n",
    "\n",
    "$$ dL^2 = \\gamma_{ij} dx^{i} dx^{j} $$\n",
    "\n",
    "Dividing by $d\\kappa^2$ and taking the square root gives us the rate of change of proper length with respect to our integration parameter $\\kappa$:\n",
    "\n",
    "$$ \\frac{dL}{d\\kappa} = \\sqrt{\\gamma_{ij} \\frac{dx^{i}}{d\\kappa} \\frac{dx^{j}}{d\\kappa}} = \\sqrt{\\gamma_{ij} p^{i} p^{j}} $$\n",
    "\n",
    "The function `proper_lengh_rhs` symbolically implements the formula under the square root, $\\sqrt{\\gamma_{ij} p^{i} p^{j}}$. It uses `sympy` symbols for the spatial momentum components (`pU[1]`, `pU[2]`, `pU[3]`) and programmatically constructs the optimized sum $\\gamma_{ij} p^{i} p^{j}$ using the same symmetry trick as the momentum RHS to reduce the number of terms. Finally, it returns a single-element list containing the square root of this sum. This will be the 9th component (`rhs_out[8]`) of our ODE system.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.declarerank2(name, dimension, sym)`**:\n",
    "    *   **Source File**: `nrpy/indexedexp.py`\n",
    "    *   **Description**: This function creates an *abstract* symbolic rank-2 tensor. Instead of creating symbols like `g11`, `g12`, etc., it creates symbols whose names are literally `name[1][1]`, `name[1][2]`, etc. This is a powerful technique for creating generic symbolic \"recipes\" that are later filled in with runtime data from a C struct. Here, it creates a placeholder for the metric components, `metric->g`, which will be provided by a C struct at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f82ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proper_lengh_rhs():\n",
    "    p0,p1,p2,p3,L= sp.symbols(\"y[4] y[5] y[6] y[7] y[8]\",Real=True)\n",
    "    pU=[p0,p1,p2,p3] \n",
    "\n",
    "    g4DD=ixp.declarerank2(\"metric->g\",dimension=4, sym=\"sym01\")\n",
    "\n",
    "    sum = sp.simplify(0)\n",
    "    \n",
    "    for i in range(1,4):\n",
    "        sum += g4DD[i][i]*pU[i]*pU[i]\n",
    "\n",
    "        for j in range(i+1,4):\n",
    "            sum += 2*g4DD[i][j]*pU[i]*pU[j]\n",
    "\n",
    "    sp.simplify(sum)\n",
    "\n",
    "    return [sp.sqrt(sum)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896fc9e6",
   "metadata": {},
   "source": [
    "<a id='geodesic_mom0_calc'></a>\n",
    "### 3.f: Symbolic Calculation of p⁰\n",
    "\n",
    "To complete our initial data, we must enforce the **null geodesic condition**, which states that the squared 4-momentum of a photon is zero. This is because photons travel along null paths where the spacetime interval $ds^2$ is zero. This condition must be satisfied by the 4-momentum of any photon. Let's write this for the **forward-in-time** photon, with physical 4-momentum $q^\\alpha$:\n",
    "\n",
    "$$ g_{\\mu\\nu}q^\\mu q^\\nu = 0 $$\n",
    "\n",
    "Expanding this equation into its time and space components gives us the quadratic equation for the time-component of the physical momentum, $q^0$:\n",
    "\n",
    "$$ g_{00}(q^0)^2 + 2\\left(\\sum_{i=1}^3 g_{0i}q^i\\right)q^0 + \\left(\\sum_{i,j=1}^3 g_{ij}q^i q^j\\right) = 0 $$\n",
    "\n",
    "For our reverse ray-tracing, we use the **reverse-time momentum**, $p^\\alpha$, which is related to the physical momentum by $p^\\alpha = -q^\\alpha$. We can substitute this relationship directly into the equation above, replacing $q^0$ with $-p^0$ and $q^i$ with $-p^i$:\n",
    "\n",
    "$$ g_{00}(-p^0)^2 + 2\\left(\\sum_{i=1}^3 g_{0i}(-p^i)\\right)(-p^0) + \\left(\\sum_{i,j=1}^3 g_{ij}(-p^i)(-p^j)\\right) = 0 $$\n",
    "\n",
    "The negative signs in the squared terms and the cross-term cancel out: `(-p^0)^2 = (p^0)^2`, `(-p^i)(-p^j) = p^i p^j`, and `(-p^i)(-p^0) = p^i p^0`. This yields a quadratic equation for $p^0$ that has the exact same form as the one for $q^0$:\n",
    "\n",
    "$$ g_{00}(p^0)^2 + 2\\left(\\sum_{i=1}^3 g_{0i}p^i\\right)p^0 + \\left(\\sum_{i,j=1}^3 g_{ij}p^i p^j\\right) = 0 $$\n",
    "\n",
    "We now solve this equation for $p^0$. It is a standard quadratic equation of the form $ax^2 + bx + c = 0$, where $x = p^0$. The coefficients are:\n",
    "*   $a = g_{00}$\n",
    "*   $b = 2 \\sum_{i=1}^3 g_{0i}p^i$\n",
    "*   $c = \\sum_{i,j=1}^3 g_{ij}p^i p^j$\n",
    "\n",
    "The solution for $p^0$ is given by the [quadratic formula](https://en.wikipedia.org/wiki/Quadratic_formula):\n",
    "\n",
    "$$ p^0 = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} = \\frac{-2\\left(\\sum g_{0i}p^i\\right) \\pm \\sqrt{\\left(2\\sum g_{0i}p^i\\right)^2 - 4g_{00}\\left(\\sum g_{ij}p^i p^j\\right)}}{2g_{00}} $$\n",
    "\n",
    "Simplifying by dividing the numerator and denominator by 2 gives:\n",
    "\n",
    "$$ p^0 = \\frac{-\\left(\\sum g_{0i}p^i\\right) \\pm \\sqrt{\\left(\\sum g_{0i}p^i\\right)^2 - g_{00}\\left(\\sum g_{ij}p^i p^j\\right)}}{g_{00}} $$\n",
    "\n",
    "The final step is to choose the physically correct root. For the reverse-traced photon, the parameter $\\kappa$ increases as coordinate time `t` decreases. Therefore, the derivative $p^0 = dt/d\\kappa$ must be **negative**. In a typical stationary spacetime outside a black hole, $g_{00}$ is negative. For the fraction to be negative, the numerator must be **positive**. The square root term is always positive and its magnitude is generally larger than the first term. To guarantee a positive numerator, we must choose the **plus sign (`+`)** in the `±`.\n",
    "\n",
    "This leads to the final, correct result implemented in the code:\n",
    "$$ p^0 = \\frac{-\\left(\\sum g_{0i}p^i\\right) + \\sqrt{\\left(\\sum g_{0i}p^i\\right)^2 - g_{00}\\left(\\sum g_{ij}p^i p^j\\right)}}{g_{00}} $$\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.declarerank2(name, dimension, sym)`**: Previously introduced. Used here to create an abstract symbolic tensor for the metric components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c2b0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mom_time_p0_reverse():\n",
    "    \"\"\"\n",
    "    Solves g_μν p^μ p^ν = 0 for our reverse-time momentum p^0.\n",
    "    \"\"\"\n",
    "    p0,p1,p2,p3 = sp.symbols(\"y[4] y[5] y[6] y[7]\", Real=True)\n",
    "    pU=[p0,p1,p2,p3]\n",
    "    g4DD = ixp.declarerank2(\"g\", sym=\"sym01\", dimension=4)\n",
    "    sum_g0i_pi = sp.sympify(0)\n",
    "    for i in range(1,4):\n",
    "        sum_g0i_pi += g4DD[0][i]*pU[i]\n",
    "    sum_gij_pi_pj = sp.sympify(0)\n",
    "    for i in range(1,4):\n",
    "        sum_gij_pi_pj += g4DD[i][i]*pU[i]*pU[i]\n",
    "        for j in range(i+1,4):\n",
    "            sum_gij_pi_pj += 2*g4DD[i][j]*pU[i]*pU[j]\n",
    "    discriminant = sum_g0i_pi*sum_g0i_pi - g4DD[0][0]*sum_gij_pi_pj\n",
    "    answer = (-sum_g0i_pi + sp.sqrt(discriminant)) / g4DD[0][0]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea9bc84",
   "metadata": {},
   "source": [
    "# Markdown for conserved Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "373ef962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_energy():\n",
    "    \"\"\"\n",
    "    Computes the symbolic expression for conserved energy E = -p_t.\n",
    "    E = -g_{t,mu} p^mu\n",
    "    \"\"\"\n",
    "    # Define the 4-momentum components using the y[4]...y[7] convention\n",
    "    pt, px, py, pz = sp.symbols(\"y[4] y[5] y[6] y[7]\", real=True)\n",
    "    pU = [pt, px, py, pz]\n",
    "    \n",
    "    # Define an abstract metric tensor to be filled by a C struct at runtime\n",
    "    g4DD = ixp.declarerank2(\"metric->g\", sym=\"sym01\", dimension=4)\n",
    "    \n",
    "    # Calculate p_t = g_{t,mu} p^mu\n",
    "    p_t = sp.sympify(0)\n",
    "    for mu in range(4):\n",
    "        p_t += g4DD[0][mu] * pU[mu]\n",
    "        \n",
    "    return -p_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52801f14",
   "metadata": {},
   "source": [
    "# Markdown for conserved L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dd4d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_L_components_cart():\n",
    "    \"\"\"\n",
    "    Computes the symbolic expressions for the three components of angular momentum,\n",
    "    correctly accounting for the symmetry of the metric tensor.\n",
    "    \"\"\"\n",
    "    # Define coordinate and 4-momentum components\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    pt, px, py, pz = sp.symbols(\"y[4] y[5] y[6] y[7]\", real=True)\n",
    "    pU = [pt, px, py, pz]\n",
    "    \n",
    "    # Define an abstract metric tensor\n",
    "    g4DD = ixp.declarerank2(\"metric->g\", sym=\"sym01\", dimension=4)\n",
    "    \n",
    "    # --- THIS IS THE CORE FIX ---\n",
    "    # Calculate covariant momentum components p_k = g_{k,mu} p^mu,\n",
    "    # correctly exploiting the metric's symmetry g_mu,nu = g_nu,mu.\n",
    "    p_down = ixp.zerorank1(dimension=4)\n",
    "    for k in range(1, 4): # We only need p_x, p_y, p_z for L_i\n",
    "        # Sum over mu\n",
    "        for mu in range(4):\n",
    "            # Use g4DD[k][mu] if k <= mu, otherwise use g4DD[mu][k]\n",
    "            if k <= mu:\n",
    "                p_down[k] += g4DD[k][mu] * pU[mu]\n",
    "            else: # k > mu\n",
    "                p_down[k] += g4DD[mu][k] * pU[mu]\n",
    "            \n",
    "    p_x, p_y, p_z = p_down[1], p_down[2], p_down[3]\n",
    "\n",
    "    # Calculate angular momentum components \n",
    "    L_x = y*p_z - z*p_y\n",
    "    L_y = z*p_x - x*p_z\n",
    "    L_z = x*p_y - y*p_x\n",
    "    \n",
    "    return [L_x, L_y, L_z]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b68249",
   "metadata": {},
   "source": [
    "# Markdown for Carter Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1034fad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final symbolic recipes for conserved quantities defined (Carter Constant re-derived).\n"
     ]
    }
   ],
   "source": [
    "# In file: V10_Python_to_C_via_NRPy.ipynb\n",
    "# In the \"Symbolic Recipes\" cell (Final, Corrected symbolic_carter_constant_Q_final)\n",
    "\n",
    "# symbolic_energy() and symbolic_L_components_cart() remain correct.\n",
    "\n",
    "def symbolic_carter_constant_Q():\n",
    "    \"\"\"\n",
    "    Computes the symbolic expression for the Carter Constant Q using a\n",
    "    verified formula, robustly handling the axial singularity.\n",
    "    \"\"\"\n",
    "    # Define all necessary symbolic variables\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    pt, px, py, pz = sp.symbols(\"y[4] y[5] y[6] y[7]\", real=True)\n",
    "    pU = [pt, px, py, pz]\n",
    "    a = sp.Symbol(\"a_spin\", real=True)\n",
    "    g4DD = ixp.declarerank2(\"metric->g\", sym=\"sym01\", dimension=4)\n",
    "\n",
    "    # --- Step 1: Compute intermediate quantities E, Lz, and p_i ---\n",
    "    E = symbolic_energy()\n",
    "    _, _, Lz = symbolic_L_components_cart()\n",
    "    \n",
    "    p_down = ixp.zerorank1(dimension=4)\n",
    "    for k in range(1, 4):\n",
    "        for mu in range(4):\n",
    "            if k <= mu: p_down[k] += g4DD[k][mu] * pU[mu]\n",
    "            else: p_down[k] += g4DD[mu][k] * pU[mu]\n",
    "    p_x, p_y, p_z = p_down[1], p_down[2], p_down[3]\n",
    "\n",
    "    # --- Step 2: Compute geometric terms ---\n",
    "    r_sq = x**2 + y**2 + z**2\n",
    "    rho_sq = x**2 + y**2\n",
    "    \n",
    "    # --- Step 3: Compute p_theta^2 directly in Cartesian components ---\n",
    "    # This avoids square roots and potential complex number issues in sympy.\n",
    "    # p_theta^2 = r^2 * p_z^2 + cot^2(theta) * (x*p_x + y*p_y)^2 - 2*r*p_z*cot(theta)*(x*p_x+y*p_y)\n",
    "    # where cot(theta) = z / rho\n",
    "    \n",
    "    # This term is (x*p_x + y*p_y)\n",
    "    xpx_plus_ypy = x*p_x + y*p_y\n",
    "    \n",
    "    # This is p_theta^2, constructed to avoid dividing by rho before squaring.\n",
    "    # It is equivalent to (z*xpx_plus_ypy/rho - rho*p_z)^2\n",
    "    p_theta_sq = (z**2 * xpx_plus_ypy**2 / rho_sq) - (2 * z * p_z * xpx_plus_ypy) + (rho_sq * p_z**2)\n",
    "\n",
    "    # --- Step 4: Assemble the final formula for Q ---\n",
    "    # Q = p_theta^2 + cos^2(theta) * (-a^2*E^2 + L_z^2/sin^2(theta))\n",
    "    # where cos^2(theta) = z^2/r^2 and sin^2(theta) = rho^2/r^2\n",
    "    \n",
    "    # This is the second term in the Q formula\n",
    "    second_term = (z**2 / r_sq) * (-a**2 * E**2 + Lz**2 * (r_sq / rho_sq))\n",
    "    \n",
    "    Q_formula = p_theta_sq + second_term\n",
    "    \n",
    "    # --- Step 5: Handle the axial singularity ---\n",
    "    # For motion on the z-axis (rho_sq -> 0), Lz=0 and p_theta=0, so Q=0.\n",
    "    Q_final = sp.Piecewise(\n",
    "        (0, rho_sq < 1e-12),\n",
    "        (Q_formula, True)\n",
    "    )\n",
    "    \n",
    "    return Q_final\n",
    "\n",
    "print(\"Final symbolic recipes for conserved quantities defined (Carter Constant re-derived).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe10d0a",
   "metadata": {},
   "source": [
    "<a id='spacetime_definition'></a>\n",
    "# Step 4: Spacetime Definition in Kerr-Schild Coordinates\n",
    "\n",
    "This section defines the specific spacetime geometry in which the geodesics will be integrated. Instead of defining separate metrics for Schwarzschild (non-rotating) and Kerr (rotating) black holes, we use a single, powerful coordinate system: **Cartesian Kerr-Schild coordinates**. This system has a major advantage over more common coordinate systems like Boyer-Lindquist: it is regular everywhere, including at the event horizon. This means the metric components and their derivatives do not diverge, allowing the numerical integrator to trace a photon's path seamlessly across the horizon without encountering coordinate singularities.\n",
    "\n",
    "The Kerr-Schild metric $g_{\\mu\\nu}$ is constructed by adding a correction term to the flat Minkowski metric $\\eta_{\\mu\\nu}$:\n",
    "$$ g_{\\mu\\nu} = \\eta_{\\mu\\nu} + 2H l_\\mu l_\\nu $$\n",
    "where $\\eta_{\\mu\\nu}$ is the Minkowski metric `diag(-1, 1, 1, 1)`, $l_\\mu$ is a special null vector, and $H$ is a scalar function that depends on the black hole's mass $M$ and spin $a$.\n",
    "\n",
    "The function `define_kerr_metric_Cartesian_Kerr_Schild()` implements this formula symbolically. It defines the coordinates `(t, x, y, z)`, the mass `M`, and the spin `a` as `sympy` symbols. It then constructs the components of the null vector $l_\\mu$ and the scalar function $H$. Finally, it assembles the full metric tensor $g_{\\mu\\nu}$.\n",
    "\n",
    "A key feature of this formulation is that if the spin parameter `a` is set to zero, the metric automatically and exactly reduces to the Schwarzschild metric in Cartesian coordinates. This allows a single set of symbolic expressions and a single set of C functions to handle both spacetimes, with the specific behavior controlled by the runtime value of the `a_spin` parameter.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.zerorank1(dimension)`**: Previously introduced. Used to initialize the null vector $l_\\mu$.\n",
    "*   **`nrpy.indexedexp.zerorank2(dimension)`**: Previously introduced. Used to initialize the metric tensor $g_{\\mu\\nu}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c66b7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_kerr_metric_Cartesian_Kerr_Schild():\n",
    "    \"\"\"\n",
    "    Defines the Kerr metric tensor in Cartesian Kerr-Schild coordinates.\n",
    "\n",
    "    This function is the new, unified source for both Kerr (a != 0) and\n",
    "    Schwarzschild (a = 0) spacetimes. The coordinates are (t, x, y, z).\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (g4DD, xx), where g4DD is the symbolic 4x4 metric tensor\n",
    "        and xx is the list of symbolic coordinate variables.\n",
    "    \"\"\"\n",
    "    # Define the symbolic coordinates using the 'y[i]' convention for the integrator\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    xx = [t, x, y, z]\n",
    "\n",
    "    # Access the symbolic versions of the mass and spin parameters\n",
    "    M = M_scale.symbol\n",
    "    a = a_spin.symbol\n",
    "\n",
    "    # Define intermediate quantities\n",
    "    r2 = x**2 + y**2 + z**2\n",
    "    r = sp.sqrt(r2)\n",
    "    \n",
    "    # Define the Kerr-Schild null vector l_μ\n",
    "    l_down = ixp.zerorank1(dimension=4)\n",
    "    l_down[0] = 1\n",
    "    l_down[1] = (r*x + a*y) / (r2 + a**2)\n",
    "    l_down[2] = (r*y - a*x) / (r2 + a**2)\n",
    "    l_down[3] = z/r\n",
    "\n",
    "    # Define the scalar function H\n",
    "    H = (M * r**3) / (r**4 + a**2 * z**2)\n",
    "\n",
    "    # The Kerr-Schild metric is g_μν = η_μν + 2H * l_μ * l_ν\n",
    "    # where η_μν is the Minkowski metric diag(-1, 1, 1, 1)\n",
    "    g4DD = ixp.zerorank2(dimension=4)\n",
    "    for mu in range(4):\n",
    "        for nu in range(4):\n",
    "            eta_mu_nu = 0\n",
    "            if mu == nu:\n",
    "                eta_mu_nu = 1\n",
    "            if mu == 0 and nu == 0:\n",
    "                eta_mu_nu = -1\n",
    "            \n",
    "            g4DD[mu][nu] = eta_mu_nu + 2 * H * l_down[mu] * l_down[nu]\n",
    "            \n",
    "    return g4DD, xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b234e04d",
   "metadata": {},
   "source": [
    "# Markdown for Schwarzschild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d41a45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In the NEW CELL after define_kerr_metric_Cartesian_Kerr_Schild\n",
    "\n",
    "def define_schwarzschild_metric_cartesian():\n",
    "    \"\"\"\n",
    "    Defines the Schwarzschild metric tensor directly in Cartesian coordinates.\n",
    "    \n",
    "    This version uses the standard textbook formula and ensures all components\n",
    "    are sympy objects to prevent C-generation errors.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (g4DD, xx), where g4DD is the symbolic 4x4 metric tensor\n",
    "        and xx is the list of symbolic coordinate variables.\n",
    "    \"\"\"\n",
    "    # Define Cartesian coordinates\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    xx = [t, x, y, z]\n",
    "\n",
    "    # Access the symbolic mass parameter\n",
    "    M = M_scale.symbol\n",
    "\n",
    "    # Define r in terms of Cartesian coordinates\n",
    "    r = sp.sqrt(x**2 + y**2 + z**2)\n",
    "\n",
    "    # Define the Cartesian Schwarzschild metric components directly\n",
    "    g4DD = ixp.zerorank2(dimension=4)\n",
    "    \n",
    "    # g_tt\n",
    "    g4DD[0][0] = -(1 - 2*M/r)\n",
    "    \n",
    "    # Spatial components g_ij = δ_ij + (2M/r) * (x_i * x_j / r^2)\n",
    "    x_i = [x, y, z]\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            # --- CORRECTED: Use sp.sympify() for the kronecker delta ---\n",
    "            delta_ij = sp.sympify(0)\n",
    "            if i == j:\n",
    "                delta_ij = sp.sympify(1)\n",
    "            \n",
    "            # The indices for g4DD are off by 1 from the spatial indices\n",
    "            g4DD[i+1][j+1] = delta_ij + (2*M/r) * (x_i[i] * x_i[j] / (r**2))\n",
    "\n",
    "    # --- CORRECTED: Ensure time-space components are sympy objects ---\n",
    "    g4DD[0][1] = g4DD[1][0] = sp.sympify(0)\n",
    "    g4DD[0][2] = g4DD[2][0] = sp.sympify(0)\n",
    "    g4DD[0][3] = g4DD[3][0] = sp.sympify(0)\n",
    "            \n",
    "    return g4DD, xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec78a4",
   "metadata": {},
   "source": [
    "<a id='symbolic_execution'></a>\n",
    "# Step 5: Symbolic Workflow Execution\n",
    "\n",
    "This cell acts as the central hub for the symbolic portion of our project. In the preceding cells, we *defined* a series of Python functions that perform individual mathematical tasks. Here, we *execute* those functions in the correct sequence to generate all the final symbolic expressions that will serve as \"recipes\" for our C code generators.\n",
    "\n",
    "This \"symbolic-first\" approach is a core `nrpy` principle and offers significant advantages:\n",
    "1.  **Efficiency**: The complex symbolic calculations, such as inverting the metric tensor and deriving the Christoffel symbols, are performed **only once** when this notebook is run. The results are stored in global Python variables, preventing redundant and time-consuming recalculations. This is especially important for the Kerr metric, whose Christoffel symbols can take several minutes to compute.\n",
    "2.  **Modularity**: This workflow creates a clean separation between the *specific solution* for a metric (e.g., the explicit formulas for the Kerr-Schild Christoffels) and the *generic form* of the equations of motion (which are valid for any metric).\n",
    "\n",
    "This cell produces two key sets of symbolic expressions that are stored in global variables for later use:\n",
    "*   **`Gamma4UDD_kerr`**: The explicit symbolic formulas for the Christoffel symbols of the unified Kerr-Schild metric.\n",
    "*   **`all_rhs_expressions`**: A Python list containing the 9 symbolic expressions for the right-hand-sides of our generic ODE system. To achieve this generality, we create a symbolic **placeholder** for the Christoffel symbols using `ixp.declarerank3(\"conn->Gamma4UDD\", ...)`. This placeholder is passed to `geodesic_mom_rhs()` to construct the geodesic equation in its abstract form. This elegant technique embeds the final C variable name (`conn->Gamma4UDD...`) directly into the symbolic expression, which dramatically simplifies the C code generation step for the `calculate_ode_rhs()` engine.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.declarerank3(name, dimension)`**: Previously introduced. Used here to create a symbolic placeholder for the Christoffel symbols that will be passed to the generic RHS engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fbfe0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Computing Kerr-Schild metric and Christoffel symbols...\n",
      "    ... Done.\n",
      " -> Computing Standard Schwarzschild (Cartesian) metric and Christoffel symbols...\n",
      "    ... Done.\n",
      " -> Defined generic global symbolic variable for ODE RHS: all_rhs_expressions\n",
      " -> Generating symbolic recipes for conserved quantities...\n",
      "    ... Conservation recipes generated.\n",
      "Kerr expressions\n",
      "[-metric->g00*y[4] - metric->g01*y[5] - metric->g02*y[6] - metric->g03*y[7], y[2]*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7]) - y[3]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]), -y[1]*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7]) + y[3]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]), y[1]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]) - y[2]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]), Piecewise((0, y[1]**2 + y[2]**2 < 1.0e-12), (y[3]**2*(-a_spin**2*(-metric->g00*y[4] - metric->g01*y[5] - metric->g02*y[6] - metric->g03*y[7])**2 + (y[1]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]) - y[2]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]))**2*(y[1]**2 + y[2]**2 + y[3]**2)/(y[1]**2 + y[2]**2))/(y[1]**2 + y[2]**2 + y[3]**2) + y[3]**2*(y[1]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]) + y[2]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]))**2/(y[1]**2 + y[2]**2) - 2*y[3]*(y[1]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]) + y[2]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]))*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7]) + (y[1]**2 + y[2]**2)*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7])**2, True))]\n",
      "Schwarzs experessions\n",
      "[-metric->g00*y[4] - metric->g01*y[5] - metric->g02*y[6] - metric->g03*y[7], y[2]*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7]) - y[3]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]), -y[1]*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7]) + y[3]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]), y[1]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]) - y[2]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]), (y[1]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]) - y[2]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]))**2 + (-y[1]*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7]) + y[3]*(metric->g01*y[4] + metric->g11*y[5] + metric->g12*y[6] + metric->g13*y[7]))**2 + (y[2]*(metric->g03*y[4] + metric->g13*y[5] + metric->g23*y[6] + metric->g33*y[7]) - y[3]*(metric->g02*y[4] + metric->g12*y[5] + metric->g22*y[6] + metric->g23*y[7]))**2]\n",
      "\n",
      "Symbolic setup complete. All expressions are now available globally.\n"
     ]
    }
   ],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In cell [f9e18b56]\n",
    "\n",
    "# --- 1. Define the Kerr-Schild metric and get its derivatives ---\n",
    "print(\" -> Computing Kerr-Schild metric and Christoffel symbols...\")\n",
    "g4DD_kerr, xx_kerr = define_kerr_metric_Cartesian_Kerr_Schild()\n",
    "g4DD_dD_kerr = derivative_g4DD(g4DD_kerr, xx_kerr)\n",
    "Gamma4UDD_kerr = four_connections(g4DD_kerr, g4DD_dD_kerr)\n",
    "print(\"    ... Done.\")\n",
    "\n",
    "# --- 2. Define the Standard Schwarzschild metric in Cartesian and get its derivatives ---\n",
    "print(\" -> Computing Standard Schwarzschild (Cartesian) metric and Christoffel symbols...\")\n",
    "g4DD_schw_cart, xx_schw_cart = define_schwarzschild_metric_cartesian()\n",
    "g4DD_dD_schw_cart = derivative_g4DD(g4DD_schw_cart, xx_schw_cart)\n",
    "Gamma4UDD_schw_cart = four_connections(g4DD_schw_cart, g4DD_dD_schw_cart)\n",
    "print(\"    ... Done.\")\n",
    "\n",
    "# --- 3. Generate the GENERIC symbolic RHS expressions for the geodesic equations ---\n",
    "# This part is unchanged, as the ODEs are generic.\n",
    "Gamma4UDD_placeholder = ixp.declarerank3(\"conn->Gamma4UDD\", dimension=4)\n",
    "rhs_pos = geodesic_pos_rhs() \n",
    "rhs_mom = geodesic_mom_rhs(Gamma4UDD_placeholder)\n",
    "rhs_length = proper_lengh_rhs()\n",
    "all_rhs_expressions = rhs_pos + rhs_mom + rhs_length\n",
    "print(\" -> Defined generic global symbolic variable for ODE RHS: all_rhs_expressions\")\n",
    "\n",
    "# --- 4. Generate symbolic recipes for conserved quantities ---\n",
    "# This is now simplified, as all calculations are Cartesian.\n",
    "print(\" -> Generating symbolic recipes for conserved quantities...\")\n",
    "\n",
    "\n",
    "E_expr = symbolic_energy()\n",
    "Lx_expr, Ly_expr, Lz_expr = symbolic_L_components_cart()\n",
    "Q_expr_kerr = symbolic_carter_constant_Q()\n",
    "Q_expr_schw = Lx_expr**2 + Ly_expr**2 + Lz_expr**2\n",
    "\n",
    "# We now have two lists of expressions, both using Cartesian formulas.\n",
    "list_of_expressions_kerr = [E_expr, Lx_expr, Ly_expr, Lz_expr, Q_expr_kerr]\n",
    "list_of_expressions_schw = [E_expr, Lx_expr, Ly_expr, Lz_expr, Q_expr_schw]\n",
    "print(\"    ... Conservation recipes generated.\")\n",
    "print(\"Kerr expressions\")\n",
    "print(list_of_expressions_kerr)\n",
    "print(\"Schwarzs experessions\")\n",
    "print(list_of_expressions_schw)\n",
    "print(\"\\nSymbolic setup complete. All expressions are now available globally.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032d263",
   "metadata": {},
   "source": [
    "<a id='generate_c_engines'></a>\n",
    "# Step 6: C Code Generation - Physics \"Engines\" and \"Workers\"\n",
    "\n",
    "This section marks our transition from pure symbolic mathematics to C code generation. The Python functions defined here are \"meta-functions\": their job is not to perform calculations themselves, but to **generate the C code** that will perform the calculations in the final compiled program.\n",
    "\n",
    "We distinguish between two types of generated functions:\n",
    "*   **Workers**: These are specialized functions that implement the physics for a *specific metric*. For example, `con_kerr_schild()` is a worker that only knows how to compute Christoffel symbols for the Kerr-Schild metric.\n",
    "*   **Engines**: These are generic functions that implement physics equations valid for *any metric*. For example, `calculate_ode_rhs()` is an engine that can compute the geodesic equations for any metric, as long as the Christoffel symbols are provided to it.\n",
    "\n",
    "This design pattern allows for maximum code reuse and extensibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632c6765",
   "metadata": {},
   "source": [
    "# Schwarzschild Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c29ef433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g4DD_schwarzschild_cartesian():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Schwarzschild\n",
    "    metric components in standard Cartesian coordinates.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: g4DD_schwarzschild_cartesian()...\")\n",
    "    \n",
    "    # Use the globally defined g4DD_schw_cart from the symbolic execution step\n",
    "    list_of_g4DD_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_syms.append(g4DD_schw_cart[i][j])\n",
    "\n",
    "    list_of_g4DD_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_C_vars.append(f\"metric->g{i}{j}\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the 10 unique components of the Schwarzschild metric in Cartesian coords.\"\"\"\n",
    "    name = \"g4DD_schwarzschild_cartesian\"\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], metric_struct *restrict metric\"\n",
    "   \n",
    "    body = ccg.c_codegen(list_of_g4DD_syms, list_of_g4DD_C_vars, enable_cse=True)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... g4DD_schwarzschild_cartesian() registration complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd610ccf",
   "metadata": {},
   "source": [
    "<a id='g4DD_kerr_schild_engine'></a>\n",
    "### 6.a: `g4DD_kerr_schild()` Worker\n",
    "\n",
    "This Python function generates the C **worker** function `g4DD_kerr_schild()`, whose only job is to compute the 10 unique components of the Kerr-Schild metric tensor, $g_{\\mu\\nu}$, at a given point in spacetime.\n",
    "\n",
    "The generation process is as follows:\n",
    "1.  **Access Symbolic Recipe:** It accesses the global `g4DD_kerr` variable, which holds the symbolic `sympy` expression for the Kerr-Schild metric tensor, generated in Step 5.\n",
    "2.  **Define C Assignment:** It creates two Python lists: one containing the 10 unique symbolic metric expressions (`list_of_g4DD_syms`) and another containing the corresponding C variable names for the members of the `metric_struct` (e.g., `metric->g00`, `metric->g01`, etc.) in `list_of_g4DD_C_vars`.\n",
    "3.  **Generate C Code:** It passes these two lists to `nrpy.c_codegen.c_codegen`. This powerful `nrpy` function converts the symbolic math into highly optimized C code, including performing Common Subexpression Elimination (CSE).\n",
    "4.  **Register C Function:** Finally, it bundles the generated C code with its metadata (description, parameters, etc.) and registers the complete function with `nrpy.c_function.register_CFunction`. Crucially, it sets `include_CodeParameters_h=True` to automatically handle access to both the `M_scale` and `a_spin` parameters via the \"Triple-Lock\" system.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_codegen.c_codegen(sympy_expressions, C_variable_names, **kwargs)`**:\n",
    "    *   **Source File**: `nrpy/c_codegen.py`\n",
    "    *   **Description**: The core symbolic-to-C translation engine. It takes a list of `sympy` expressions and a corresponding list of C variable names and generates optimized C code to perform the assignments.\n",
    "    *   **Key Inputs**:\n",
    "        *   `sympy_expressions`: A Python list of symbolic expressions to be converted to C code.\n",
    "        *   `C_variable_names`: A Python list of strings for the C variables that will store the results.\n",
    "    *   **Key Keyword Arguments (`kwargs`)**:\n",
    "        *   `enable_cse=True`: Enables Common Subexpression Elimination, which finds repeated mathematical operations, assigns them to temporary variables, and reuses those variables to reduce redundant calculations. This is essential for performance.\n",
    "\n",
    "*   **`nrpy.c_function.register_CFunction(name, params, body, **kwargs)`**:\n",
    "    *   **Source File**: `nrpy/c_function.py`\n",
    "    *   **Description**: This is the workhorse for defining a C function. It takes all necessary metadata and stores it in a global dictionary, `cfc.CFunction_dict`. The final build system uses this dictionary to write all the `.c` source files.\n",
    "    *   **Key Inputs**:\n",
    "        *   `name`: The name of the C function.\n",
    "        *   `params`: A string defining the function's parameters (e.g., `\"const double y[4], ...\"`).\n",
    "        *   `body`: A string containing the C code for the function's body.\n",
    "    *   **Key Keyword Arguments (`kwargs`)**:\n",
    "        *   `include_CodeParameters_h=True`: Enables the \"Triple-Lock\" system for this function, automatically including `set_CodeParameters.h` at the top of the function body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78d52f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g4DD_kerr_schild():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Kerr-Schild\n",
    "    metric components in Cartesian coordinates. This is the new unified worker.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: g4DD_kerr_schild()...\")\n",
    "    \n",
    "    # We use the globally defined g4DD_kerr from the symbolic execution step\n",
    "    list_of_g4DD_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_syms.append(g4DD_kerr[i][j])\n",
    "\n",
    "    list_of_g4DD_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_C_vars.append(f\"metric->g{i}{j}\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the 10 unique components of the Kerr metric in Cartesian Kerr-Schild coords.\"\"\"\n",
    "    name = \"g4DD_kerr_schild\"\n",
    "    # The state vector y now contains (t, x, y, z)\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], metric_struct *restrict metric\"\n",
    "   \n",
    "    body = ccg.c_codegen(list_of_g4DD_syms, list_of_g4DD_C_vars, enable_cse=True)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... g4DD_kerr_schild() registration complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3f1222",
   "metadata": {},
   "source": [
    "<a id='con_kerr_schild_engine'></a>\n",
    "### 6.b: `con_kerr_schild()` Worker\n",
    "\n",
    "This function is structured identically to the `g4DD_kerr_schild` worker. It generates the C **worker** function `con_kerr_schild()`, whose only job is to compute the 40 unique Christoffel symbols for the unified Kerr-Schild metric.\n",
    "\n",
    "The process is as follows:\n",
    "1.  **Access Symbolic Recipe:** It accesses the pre-computed symbolic Christoffel formulas from the global `Gamma4UDD_kerr` variable, which was generated in Step 5.\n",
    "2.  **Define C Assignment:** It creates a list of the 40 unique symbolic expressions and a corresponding list of the C variable names for the members of the `connection_struct` (e.g., `conn->Gamma4UDD012`).\n",
    "3.  **Generate C Code:** It uses `nrpy.c_codegen.c_codegen` to convert these highly complex symbolic expressions into optimized C code. The Common Subexpression Elimination (CSE) performed by `c_codegen` is absolutely essential here, as it reduces what would be thousands of floating-point operations into a much more manageable and efficient set of calculations.\n",
    "4.  **Register C Function:** Like the other workers, it registers the function using `nrpy.c_function.register_CFunction` and sets `include_CodeParameters_h=True` to handle its dependency on both `M_scale` and `a_spin`.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.declarerank3(name, dimension)`**: Previously introduced. Used here to programmatically generate the C variable names for the Christoffel symbols that will be stored in the `connection_struct`.\n",
    "*   **`nrpy.c_codegen.c_codegen(...)`**: Previously introduced.\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeb471c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_kerr_schild():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Kerr-Schild Christoffel symbols.\n",
    "    This is the new unified worker.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: con_kerr_schild()...\")\n",
    "    \n",
    "    # We use the globally defined Gamma4UDD_kerr from the symbolic execution step\n",
    "    list_of_Gamma_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_syms.append(Gamma4UDD_kerr[i][j][k])\n",
    "\n",
    "    conn_Gamma4UDD = ixp.declarerank3(\"conn->Gamma4UDD\", dimension=4)\n",
    "    list_of_Gamma_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_C_vars.append(str(conn_Gamma4UDD[i][j][k]))\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the 40 unique Christoffel symbols for the Kerr metric in Kerr-Schild coords.\"\"\"\n",
    "    name = \"con_kerr_schild\"\n",
    "    # The state vector y now contains (t, x, y, z)\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], connection_struct *restrict conn\"\n",
    "\n",
    "    body = ccg.c_codegen(list_of_Gamma_syms, list_of_Gamma_C_vars, enable_cse=True)\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... con_kerr_schild() registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0166625f",
   "metadata": {},
   "source": [
    "# Con Schwarzschild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d6072ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_schwarzschild_cartesian():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Schwarzschild Christoffel symbols\n",
    "    in standard Cartesian coordinates.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: con_schwarzschild_cartesian()...\")\n",
    "    \n",
    "    # Use the globally defined Gamma4UDD_schw_cart\n",
    "    list_of_Gamma_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_syms.append(Gamma4UDD_schw_cart[i][j][k])\n",
    "\n",
    "    conn_Gamma4UDD = ixp.declarerank3(\"conn->Gamma4UDD\", dimension=4)\n",
    "    list_of_Gamma_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_C_vars.append(str(conn_Gamma4UDD[i][j][k]))\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the unique Christoffel symbols for the Schwarzschild metric in Cartesian coords.\"\"\"\n",
    "    name = \"con_schwarzschild_cartesian\"\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], connection_struct *restrict conn\"\n",
    "\n",
    "    body = ccg.c_codegen(list_of_Gamma_syms, list_of_Gamma_C_vars, enable_cse=True)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... con_schwarzschild_cartesian() registration complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce3df4",
   "metadata": {},
   "source": [
    "<a id='calculate_p0_engine'></a>\n",
    "### 6.c: `calculate_p0_reverse()` Engine\n",
    "\n",
    "This Python function generates the C **engine** `calculate_p0_reverse()`, which implements the general formula for the time-component of the reverse-time momentum, $p^0$, derived from the null geodesic condition $g_{\\mu\\nu} p^\\mu p^\\nu = 0$. This function is a prime example of a reusable component, as its logic is valid for any metric for which the components $g_{\\mu\\nu}$ are known.\n",
    "\n",
    "The code generation follows a pattern that is both robust and highly automated, showcasing a powerful `nrpy` technique called the **Preamble Pattern**:\n",
    "\n",
    "1.  **Symbolic Recipe:** It calls our pure-math `mom_time_p0_reverse()` function (from Step 3.f) to get the complete symbolic expression for $p^0$. This expression is built from abstract `sympy` symbols (e.g., `g00`, `g01`, etc.).\n",
    "2.  **Preamble Generation:** The function programmatically generates a C code \"preamble.\" This preamble consists of a series of `const double` declarations that unpack the numerical values from the input `metric_struct` pointer and assign them to local C variables that have the *exact same names* as our abstract `sympy` symbols (e.g., `const double g00 = metric->g00;`).\n",
    "3.  **C Code Generation:** It calls `nrpy.c_codegen.c_codegen` to convert the symbolic `p0_expr` into an optimized C expression, assigning it to a temporary variable `p0_val`. This works seamlessly because the symbols in the expression (`g00`, etc.) now match the local C variables created by the preamble. This avoids the need for brittle string substitutions.\n",
    "4.  **Return Value:** The final C function body is constructed by combining the preamble, the CSE-optimized calculation, and a `return p0_val;` statement. This creates a complete, efficient, and readable C function.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_codegen.c_codegen(...)`**: Previously introduced.\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bece041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_p0_reverse():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the time component\n",
    "    of the reverse 4-momentum, p^0.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine function: calculate_p0_reverse()...\")\n",
    "    # The symbolic expression uses y[4] through y[7] for the 4-momentum\n",
    "    p0_expr = mom_time_p0_reverse()\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes reverse-time p^0 from the null condition g_munu p^mu p^nu = 0.\"\"\"\n",
    "    name = \"calculate_p0_reverse\"\n",
    "    c_type = \"double\"\n",
    "    # The function now takes the full 9-element state vector y.\n",
    "    params = \"const metric_struct *restrict metric, const double y[9]\"\n",
    "    \n",
    "    preamble = \"\"\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            preamble += f\"const double g{i}{j} = metric->g{i}{j};\\n\"\n",
    "            \n",
    "    # We generate the C code directly from the original expression.\n",
    "    # Since the C function takes the full y[9] vector, the array indices\n",
    "    # y[4], y[5], etc., in the generated code will be correct.\n",
    "    p0_C_code_lines = ccg.c_codegen(\n",
    "        p0_expr, 'double p0_val', enable_cse=True, include_braces=False\n",
    "    )\n",
    "    body = f\"{{\\n{preamble}\\n{p0_C_code_lines}\\nreturn p0_val;\\n}}\"\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, cfunc_type=c_type,\n",
    "        name=name, params=params, body=body\n",
    "    )\n",
    "    print(\"    ... calculate_p0_reverse() registration complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e27c2c",
   "metadata": {},
   "source": [
    "<a id='calculate_ode_rhs_engine'></a>\n",
    "### 6.d: `calculate_ode_rhs()` Engine\n",
    "\n",
    "This function generates the core \"engine\" of our ODE solver: the C function `calculate_ode_rhs()`. Its single responsibility is to calculate the right-hand sides for our entire system of 9 ODEs. It is completely generic and has no knowledge of any specific metric; it only knows how to compute the geodesic equations given a set of Christoffel symbols and the spatial metric components.\n",
    "\n",
    "The generation process is straightforward:\n",
    "1.  **Access Generic Recipe:** It accesses the global `all_rhs_expressions` list. This list contains the generic symbolic form of the ODEs for position, momentum, and proper length that we derived in Step 5.\n",
    "2.  **Generate C Code:** It passes this list directly to `nrpy.c_codegen.c_codegen`. The symbols used to build `all_rhs_expressions` were already created with their final C syntax (e.g., `y[5]` for the momentum, `conn->Gamma4UDD...` for the Christoffel placeholder, and `metric->g...` for the metric placeholder). Therefore, no further symbolic manipulation is needed. `nrpy` simply translates the expressions into optimized C code.\n",
    "3.  **Register C Function:** The generated C code body is bundled with its metadata and registered. This function does not require the `include_CodeParameters_h` flag because it is physically generic and receives all necessary information through its arguments.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_codegen.c_codegen(...)`**: Previously introduced.\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b67d389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ode_rhs():\n",
    "\n",
    "    rhs_output_vars = [f\"rhs_out[{i}]\" for i in range(9)]\n",
    "\n",
    "\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "\n",
    "    desc = r\"\"\"@brief Calculates the right-hand sides (RHS) of the 9 geodesic ODEs.\n",
    " \n",
    "    This function implements the generic geodesic equation using pre-computed\n",
    "    Christoffel symbols. It is a pure \"engine\" function that does not depend\n",
    "    on any specific metric's parameters (like M_scale), only on the geometric\n",
    "    values passed to it via the connection struct.\n",
    "\n",
    "    @param[in]  y         The 9-component state vector [t, r, th, ph, p^t, p^r, p^th, p^ph, L].\n",
    "    @param[in]  conn      A pointer to the connection_struct holding the pre-computed Christoffel symbols.\n",
    "    @param[out] rhs_out   A pointer to the 9-component output array where the RHS results are stored.\"\"\"\n",
    "            \n",
    "    name = \"calculate_ode_rhs\"\n",
    "    params = \"const double y[9], const metric_struct *restrict metric, const connection_struct *restrict conn, double rhs_out[9]\"\n",
    "\n",
    "    body=ccg.c_codegen(all_rhs_expressions,rhs_output_vars)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes= includes,\n",
    "        name=name,\n",
    "        desc=desc,\n",
    "        params=params,\n",
    "        body=body\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d87383",
   "metadata": {},
   "source": [
    "<a id='lagrange_interp_engine'></a>\n",
    "### 6.e: `find_event_time_and_state()` Interpolation Engine\n",
    "\n",
    "This Python function generates a crucial C **engine** called `find_event_time_and_state()`. Its purpose is to find the precise time and state vector of a \"plane-crossing\" event with high accuracy, using data from three consecutive steps of the ODE integrator. This is essential for accurately mapping where a ray hits the window and source planes.\n",
    "\n",
    "The function implements a robust interpolation scheme:\n",
    "1.  **Quadratic Root Finding:** It treats the event condition (e.g., the distance to a plane, `f(y) = n_i x^i - d = 0`) as a function of the affine parameter, `f(κ)`. Given three points `(κ_prev, f_prev)`, `(κ_curr, f_curr)`, and `(κ_next, f_next)` that are known to bracket a root (i.e., the function changes sign), it fits a quadratic polynomial to these points. It then uses a numerically stable formula (similar to Muller's method) to find the root `κ_event` of this polynomial. This gives a much more accurate time for the plane crossing than simply taking the time of the closest step.\n",
    "2.  **Lagrange Polynomial Interpolation:** Once the precise event time `κ_event` is known, the function uses second-order [Lagrange basis polynomials](https://en.wikipedia.org/wiki/Lagrange_polynomial) to interpolate each of the 9 components of the state vector `y` to that exact time.\n",
    "\n",
    "This two-step process provides a highly accurate snapshot of the photon's state `y_event` at the exact moment it crosses a plane of interest. The C function body is written manually as a string, as its logic is algorithmic rather than symbolic, and then registered with `nrpy`.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced. Used here to register the manually written C code for the interpolation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7b4572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagrange_interp_engine_generic():\n",
    "    \"\"\"\n",
    "    Generates the generic Lagrange interpolation engine.\n",
    "    \n",
    "    This definitive version is numerically robust. It checks for small denominators\n",
    "    and unstable conditions, falling back to stable linear interpolation to prevent\n",
    "    NaN results in edge cases.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine: find_event_time_and_state() [Robust Version]...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"<math.h>\"]\n",
    "    desc = r\"\"\"@brief Finds the root of a generic event using a robust, second-order interpolation.\"\"\"\n",
    "    \n",
    "    name = \"find_event_time_and_state\"\n",
    "    params = r\"\"\"const double y_prev[9], const double y_curr[9], const double y_next[9],\n",
    "                double lambda_prev, double lambda_curr, double lambda_next,\n",
    "                event_function_t event_func, void *event_params,\n",
    "                event_data_struct *restrict result\"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    double t0 = lambda_prev, t1 = lambda_curr, t2 = lambda_next;\n",
    "    double f0 = event_func(y_prev, event_params);\n",
    "    double f1 = event_func(y_curr, event_params);\n",
    "    double f2 = event_func(y_next, event_params);\n",
    "\n",
    "    // --- Linear interpolation as a fallback ---\n",
    "    // This is used if quadratic interpolation is unstable or fails.\n",
    "    // It finds the root between the two points where the sign change occurs.\n",
    "    double t_linear;\n",
    "    if (f0 * f1 < 0.0 && fabs(f1 - f0) > 1e-12) { // Sign change is between prev and curr\n",
    "        t_linear = (f1 * t0 - f0 * t1) / (f1 - f0);\n",
    "    } else if (f1 * f2 < 0.0 && fabs(f2 - f1) > 1e-12) { // Sign change is between curr and next\n",
    "        t_linear = (f2 * t1 - f1 * t2) / (f2 - f1);\n",
    "    } else {\n",
    "        // This can happen if f1 is exactly zero.\n",
    "        t_linear = t1;\n",
    "    }\n",
    "\n",
    "    // --- Quadratic interpolation (Muller's method variant) ---\n",
    "    double h0 = t1 - t0;\n",
    "    double h1 = t2 - t1;\n",
    "\n",
    "    // Check for degenerate intervals to prevent division by zero.\n",
    "    if (fabs(h0) < 1e-15 || fabs(h1) < 1e-15 || fabs(h0 + h1) < 1e-15) {\n",
    "        result->lambda_event = t_linear;\n",
    "    } else {\n",
    "        double delta0 = (f1 - f0) / h0;\n",
    "        double delta1 = (f2 - f1) / h1;\n",
    "        double a = (delta1 - delta0) / (h1 + h0);\n",
    "        double b = a * h1 + delta1;\n",
    "        double c = f2;\n",
    "        double discriminant = b*b - 4*a*c;\n",
    "\n",
    "        if (discriminant < 0.0 || fabs(a) < 1e-15) {\n",
    "            // Discriminant is negative or equation is effectively linear.\n",
    "            result->lambda_event = t_linear;\n",
    "        } else {\n",
    "            // Use the more stable form of the quadratic formula\n",
    "            double denom = (b >= 0.0) ? (b + sqrt(discriminant)) : (b - sqrt(discriminant));\n",
    "            if (fabs(denom) < 1e-15) {\n",
    "                result->lambda_event = t_linear;\n",
    "            } else {\n",
    "                double t_quad = t2 - (2.0 * c / denom);\n",
    "                // Only accept the quadratic result if it's within the bracketing interval.\n",
    "                if (t_quad > fmin(t0, t2) && t_quad < fmax(t0, t2)) {\n",
    "                    result->lambda_event = t_quad;\n",
    "                } else {\n",
    "                    result->lambda_event = t_linear;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // --- Perform final interpolation on the state vector using the found time ---\n",
    "    double t = result->lambda_event;\n",
    "    \n",
    "    // Check for degenerate intervals again before final interpolation\n",
    "    if (fabs(t0 - t1) < 1e-15 || fabs(t0 - t2) < 1e-15 || fabs(t1 - t2) < 1e-15) {\n",
    "        // Fallback to linear interpolation for the state vector as well\n",
    "        double frac = 0.5;\n",
    "        if (fabs(t2 - t1) > 1e-15) {\n",
    "            frac = (t - t1) / (t2 - t1);\n",
    "        }\n",
    "        for (int i = 0; i < 9; i++) {\n",
    "            result->y_event[i] = y_curr[i] + frac * (y_next[i] - y_curr[i]);\n",
    "        }\n",
    "    } else {\n",
    "        // Perform full quadratic interpolation\n",
    "        double L0 = ((t - t1) * (t - t2)) / ((t0 - t1) * (t0 - t2));\n",
    "        double L1 = ((t - t0) * (t - t2)) / ((t1 - t0) * (t1 - t2));\n",
    "        double L2 = ((t - t0) * (t - t1)) / ((t2 - t0) * (t2 - t1));\n",
    "        for (int i = 0; i < 9; i++) {\n",
    "            result->y_event[i] = y_prev[i] * L0 + y_curr[i] * L1 + y_next[i] * L2;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result->t_event = result->y_event[0];\n",
    "    result->found = true;\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... Registered C engine: find_event_time_and_state (Robust Version).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624cd49",
   "metadata": {},
   "source": [
    "# Markdown for check_conservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e4260e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_conservation():\n",
    "    \"\"\"\n",
    "    Generates the C function `check_conservation`. This version is simplified\n",
    "    for a purely Cartesian pipeline.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine: check_conservation() [Cartesian Version]...\")\n",
    "\n",
    "    # Use the globally defined Cartesian recipes\n",
    "    output_vars_kerr = [\"*E\", \"*Lx\", \"*Ly\", \"*Lz\", \"*Q\"]\n",
    "    output_vars_schw = [\"*E\", \"*Lx\", \"*Ly\", \"*Lz\", \"*Q\"] # Q is L^2\n",
    "\n",
    "    body_C_code_kerr = ccg.c_codegen(list_of_expressions_kerr, output_vars_kerr, enable_cse=True, include_braces=False)\n",
    "    body_C_code_schw = ccg.c_codegen(list_of_expressions_schw, output_vars_schw, enable_cse=True, include_braces=False)\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Computes conserved quantities (E, L_i, Q/L^2) for a given state vector.\"\"\"\n",
    "    name = \"check_conservation\"\n",
    "    params = \"\"\"const commondata_struct *restrict commondata,\n",
    "        const params_struct *restrict params,\n",
    "        const metric_params *restrict metric_params_in,\n",
    "        const double y[9], \n",
    "        double *E, double *Lx, double *Ly, double *Lz, double *Q\"\"\"\n",
    "        \n",
    "    body = r\"\"\"\n",
    "    // Unpack parameters from commondata struct that are needed symbolically\n",
    "    const REAL a_spin = commondata->a_spin;\n",
    "\n",
    "    // Declare a POINTER to a metric_struct and allocate memory for it.\n",
    "    metric_struct* metric = (metric_struct*)malloc(sizeof(metric_struct));\n",
    "    \n",
    "    // Call the dispatcher to fill the allocated struct with metric components at the given state y.\n",
    "    g4DD_metric(commondata, params, metric_params_in, y, metric);\n",
    "\n",
    "    // --- MODIFIED: Simplified logic for Cartesian-only checks ---\n",
    "    if (metric_params_in->type == Kerr) {\n",
    "        \"\"\" + body_C_code_kerr + r\"\"\"\n",
    "    } else { // Both Schwarzschild types are now Cartesian\n",
    "        \"\"\" + body_C_code_schw + r\"\"\"\n",
    "    }\n",
    "    \n",
    "    free(metric);\n",
    "    \"\"\"\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, cfunc_type=\"void\",\n",
    "        name=name, params=params, body=body\n",
    "    )\n",
    "    print(f\"    ... {name}() registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb2e685",
   "metadata": {},
   "source": [
    "# Markdown for event detection manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0673106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_detection_manager():\n",
    "    \"\"\"\n",
    "    Generates the C event detection manager.\n",
    "    \n",
    "    This final version is a pure, stateless plane-crossing detector. It takes\n",
    "    the previous state of the photon (which side of the plane it was on) and\n",
    "    updates the event_data_struct if a crossing has occurred.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C event detection manager (Stateless Plane Detector Version)...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"<math.h>\"]\n",
    "    \n",
    "    prefunc = r\"\"\"\n",
    "// Struct to hold parameters for a plane-crossing event\n",
    "typedef struct {\n",
    "    double n[3]; // Plane normal vector\n",
    "    double d;    // Plane distance from origin\n",
    "} plane_event_params;\n",
    "\n",
    "// Event function for a generic plane crossing\n",
    "static double plane_event_func(const double y[9], void *event_params) {\n",
    "    plane_event_params *params = (plane_event_params *)event_params;\n",
    "    return y[1]*params->n[0] + y[2]*params->n[1] + y[3]*params->n[2] - params->d;\n",
    "}\n",
    "\"\"\"\n",
    "    desc = r\"\"\"@brief Detects crossings of the window and source planes.\"\"\"\n",
    "    name = \"event_detection_manager\"\n",
    "    cfunc_type = \"void\"\n",
    "    params = r\"\"\"\n",
    "        const double y_prev[9], const double y_curr[9], const double y_next[9],\n",
    "        double lambda_prev, double lambda_curr, double lambda_next,\n",
    "        const commondata_struct *restrict commondata,\n",
    "        bool *on_positive_side_of_window_prev,\n",
    "        bool *on_positive_side_of_source_prev,\n",
    "        event_data_struct *restrict window_event,\n",
    "        event_data_struct *restrict source_plane_event\n",
    "        \"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // --- Window Plane Detection ---\n",
    "    // This logic is only performed if the caller has not already found the event.\n",
    "    if (!window_event->found) {\n",
    "        double window_plane_normal[3] = {commondata->window_center_x - commondata->camera_pos_x,\n",
    "                                         commondata->window_center_y - commondata->camera_pos_y,\n",
    "                                         commondata->window_center_z - commondata->camera_pos_z};\n",
    "        const double mag_w_norm = sqrt(SQR(window_plane_normal[0]) + SQR(window_plane_normal[1]) + SQR(window_plane_normal[2]));\n",
    "        if (mag_w_norm > 1e-12) {\n",
    "            const double inv_mag_w_norm = 1.0 / mag_w_norm;\n",
    "            for(int i=0;i<3;i++) window_plane_normal[i] *= inv_mag_w_norm;\n",
    "        }\n",
    "        const double window_plane_dist = commondata->window_center_x * window_plane_normal[0] +\n",
    "                                         commondata->window_center_y * window_plane_normal[1] +\n",
    "                                         commondata->window_center_z * window_plane_normal[2];\n",
    "\n",
    "        plane_event_params window_params = {{window_plane_normal[0], window_plane_normal[1], window_plane_normal[2]}, window_plane_dist};\n",
    "        bool on_positive_side_curr = (plane_event_func(y_next, &window_params) > 0);\n",
    "        if (on_positive_side_curr != *on_positive_side_of_window_prev) {\n",
    "            find_event_time_and_state(y_prev, y_curr, y_next, lambda_prev, lambda_curr, lambda_next,\n",
    "                                      plane_event_func, &window_params, window_event);\n",
    "        }\n",
    "        *on_positive_side_of_window_prev = on_positive_side_curr;\n",
    "    }\n",
    "\n",
    "    // --- Source Plane Detection ---\n",
    "    // This logic is only performed if the caller has not already found the event.\n",
    "    if (!source_plane_event->found) {\n",
    "        const double source_plane_normal[3] = {commondata->source_plane_normal_x,\n",
    "                                               commondata->source_plane_normal_y,\n",
    "                                               commondata->source_plane_normal_z};\n",
    "        const double source_plane_dist = commondata->source_plane_center_x * source_plane_normal[0] +\n",
    "                                         commondata->source_plane_center_y * source_plane_normal[1] +\n",
    "                                         commondata->source_plane_center_z * source_plane_normal[2];\n",
    "\n",
    "        plane_event_params source_params = {{source_plane_normal[0], source_plane_normal[1], source_plane_normal[2]}, source_plane_dist};\n",
    "        bool on_positive_side_curr = (plane_event_func(y_next, &source_params) > 0);\n",
    "        if (on_positive_side_curr != *on_positive_side_of_source_prev) {\n",
    "            find_event_time_and_state(y_prev, y_curr, y_next, lambda_prev, lambda_curr, lambda_next,\n",
    "                                      plane_event_func, &source_params, source_plane_event);\n",
    "        }\n",
    "        *on_positive_side_of_source_prev = on_positive_side_curr;\n",
    "    }\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, prefunc=prefunc, desc=desc, cfunc_type=cfunc_type, name=name, params=params, body=body)\n",
    "    print(\"    ... Registered event_detection_manager (Stateless Plane Detector Version).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48805aa",
   "metadata": {},
   "source": [
    "# kd tree loaer and unloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb9daeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdtree_loader_and_unloader():\n",
    "    \"\"\"\n",
    "    Generates C functions for memory-mapping a .kdtree.bin file into memory\n",
    "    and for unmapping it.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C functions for k-d tree memory mapping...\")\n",
    "\n",
    "    # Function to load a snapshot\n",
    "    load_includes = [\"BHaH_defines.h\", \"<stdio.h>\", \"<stdlib.h>\", \"<sys/mman.h>\", \"<sys/stat.h>\", \"<fcntl.h>\", \"<unistd.h>\"]\n",
    "    load_desc = r\"\"\"@brief Loads a .kdtree.bin snapshot file into memory using mmap.\"\"\"\n",
    "    load_name = \"load_kdtree_snapshot\"\n",
    "    load_params = \"const char *filename, CustomKDTree *tree\"\n",
    "    load_body = r\"\"\"\n",
    "    int fd = open(filename, O_RDONLY);\n",
    "    if (fd == -1) {\n",
    "        perror(\"Error opening k-d tree file\");\n",
    "        return -1; // Failure\n",
    "    }\n",
    "\n",
    "    struct stat sb;\n",
    "    if (fstat(fd, &sb) == -1) {\n",
    "        perror(\"Error getting file size\");\n",
    "        close(fd);\n",
    "        return -1;\n",
    "    }\n",
    "    tree->file_size = sb.st_size;\n",
    "\n",
    "    void *mapped_mem = mmap(NULL, tree->file_size, PROT_READ, MAP_PRIVATE, fd, 0);\n",
    "    if (mapped_mem == MAP_FAILED) {\n",
    "        perror(\"Error memory-mapping the file\");\n",
    "        close(fd);\n",
    "        return -1;\n",
    "    }\n",
    "    close(fd); // File descriptor no longer needed after mmap\n",
    "\n",
    "    tree->original_mmap_ptr = mapped_mem;\n",
    "    char *current_ptr = (char *)mapped_mem;\n",
    "\n",
    "    // Read header\n",
    "    tree->num_particles = *(uint64_t *)current_ptr;\n",
    "    current_ptr += sizeof(uint64_t);\n",
    "    tree->dimensions = *(uint64_t *)current_ptr;\n",
    "    current_ptr += sizeof(uint64_t);\n",
    "\n",
    "    // Set pointers to payloads\n",
    "    tree->node_metadata = (int32_t *)current_ptr;\n",
    "    current_ptr += sizeof(int32_t) * tree->num_particles;\n",
    "    tree->particle_data = (MassiveParticle *)current_ptr;\n",
    "\n",
    "    return 0; // Success\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=load_includes, desc=load_desc, name=load_name, params=load_params, body=load_body, cfunc_type=\"int\")\n",
    "\n",
    "    # Function to unload a snapshot\n",
    "    unload_includes = [\"BHaH_defines.h\", \"<sys/mman.h>\"]\n",
    "    unload_desc = r\"\"\"@brief Unloads a memory-mapped k-d tree snapshot.\"\"\"\n",
    "    unload_name = \"unload_kdtree_snapshot\"\n",
    "    unload_params = \"CustomKDTree *tree\"\n",
    "    unload_body = r\"\"\"\n",
    "    if (tree->original_mmap_ptr != NULL) {\n",
    "        munmap(tree->original_mmap_ptr, tree->file_size);\n",
    "        tree->original_mmap_ptr = NULL;\n",
    "    }\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=unload_includes, desc=unload_desc, name=unload_name, params=unload_params, body=unload_body)\n",
    "    \n",
    "    print(\"    ... Registered C functions: load_kdtree_snapshot, unload_kdtree_snapshot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89505589",
   "metadata": {},
   "source": [
    "# kd tree search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9da9cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdtree_search_engine():\n",
    "    \"\"\"\n",
    "    Generates the C functions that perform the recursive k-Nearest Neighbor search\n",
    "    on a loaded k-d tree.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine for k-d tree nearest neighbor search...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"<math.h>\", \"<stdio.h>\"]\n",
    "    \n",
    "    prefunc = r\"\"\"\n",
    "// Helper to initialize the WinnersCircle struct\n",
    "static void wc_init(WinnersCircle *wc, int n_wanted) {\n",
    "    wc->n_wanted = n_wanted;\n",
    "    wc->count = 0;\n",
    "    for (int i = 0; i < n_wanted; ++i) {\n",
    "        wc->indices[i] = -1;\n",
    "        wc->sq_distances[i] = 1e300; // Initialize with a very large number\n",
    "    }\n",
    "}\n",
    "\n",
    "// Helper to add a candidate to the WinnersCircle, maintaining sorted order\n",
    "static void wc_add(WinnersCircle *wc, int index, double sq_dist) {\n",
    "    if (wc->count < wc->n_wanted) {\n",
    "        wc->indices[wc->count] = index;\n",
    "        wc->sq_distances[wc->count] = sq_dist;\n",
    "        wc->count++;\n",
    "    } else if (sq_dist < wc->sq_distances[wc->n_wanted - 1]) {\n",
    "        wc->indices[wc->n_wanted - 1] = index;\n",
    "        wc->sq_distances[wc->n_wanted - 1] = sq_dist;\n",
    "    } else {\n",
    "        return; // Not a winner\n",
    "    }\n",
    "\n",
    "    for (int i = wc->count - 1; i > 0; --i) {\n",
    "        if (wc->sq_distances[i] < wc->sq_distances[i - 1]) {\n",
    "            double temp_d = wc->sq_distances[i];\n",
    "            int temp_i = wc->indices[i];\n",
    "            wc->sq_distances[i] = wc->sq_distances[i - 1];\n",
    "            wc->indices[i] = wc->indices[i - 1];\n",
    "            wc->sq_distances[i - 1] = temp_d;\n",
    "            wc->indices[i - 1] = temp_i;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// The recursive search function\n",
    "static void search_recursive(const CustomKDTree *tree, const double query_pos[3], int current_idx, WinnersCircle *wc) {\n",
    "    if (current_idx < 0 || current_idx >= (int)tree->num_particles) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    const MassiveParticle *pivot = &tree->particle_data[current_idx];\n",
    "    const int split_axis = tree->node_metadata[current_idx];\n",
    "\n",
    "    const double dx = query_pos[0] - pivot->pos[0];\n",
    "    const double dy = query_pos[1] - pivot->pos[1];\n",
    "    const double dz = query_pos[2] - pivot->pos[2];\n",
    "    const double dist_sq = dx*dx + dy*dy + dz*dz;\n",
    "    wc_add(wc, current_idx, dist_sq);\n",
    "\n",
    "    if (split_axis == -1) { // Leaf node\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    const double axis_dist = query_pos[split_axis] - pivot->pos[split_axis];\n",
    "    const int good_side_idx = (axis_dist < 0) ? (2 * current_idx + 1) : (2 * current_idx + 2);\n",
    "    const int bad_side_idx = (axis_dist < 0) ? (2 * current_idx + 2) : (2 * current_idx + 1);\n",
    "\n",
    "    search_recursive(tree, query_pos, good_side_idx, wc);\n",
    "\n",
    "    const double search_radius_sq = wc->sq_distances[wc->n_wanted - 1];\n",
    "    if (axis_dist * axis_dist < search_radius_sq) {\n",
    "        search_recursive(tree, query_pos, bad_side_idx, wc);\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "    desc = r\"\"\"@brief Finds the N nearest neighbors to a query point in a k-d tree.\"\"\"\n",
    "    name = \"find_n_nearest_neighbors\"\n",
    "    params = \"const CustomKDTree *tree, const double query_pos[3], int n_neighbors, MassiveParticle *neighbor_results\"\n",
    "    \n",
    "    # CORRECTED: Added the missing closing brace for the function body.\n",
    "    body = r\"\"\"\n",
    "    if (n_neighbors > MAX_NEIGHBORS) {\n",
    "        fprintf(stderr, \"Error: Requested more neighbors than MAX_NEIGHBORS.\\n\");\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    WinnersCircle wc;\n",
    "    wc_init(&wc, n_neighbors);\n",
    "\n",
    "    // Start the recursive search from the root (index 0)\n",
    "    search_recursive(tree, query_pos, 0, &wc);\n",
    "\n",
    "    // Copy the results into the output array\n",
    "    for (int i = 0; i < wc.count; ++i) {\n",
    "        neighbor_results[i] = tree->particle_data[wc.indices[i]];\n",
    "    }\n",
    "\n",
    "\"\"\"\n",
    "    cfc.register_CFunction(includes=includes, prefunc=prefunc, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... Registered C engine: find_n_nearest_neighbors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb555a",
   "metadata": {},
   "source": [
    "# Inverse distance interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfe18336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation_engine():\n",
    "    \"\"\"\n",
    "    Generates the C engine for performing the two-stage (spatial then temporal)\n",
    "    interpolation of the disk state at a photon's intersection point.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine for two-stage disk state interpolation...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"<math.h>\", \"<stdio.h>\"]\n",
    "\n",
    "    # This prefunc will contain the spatial interpolation helper.\n",
    "    prefunc = r\"\"\"\n",
    "// Performs Inverse Distance Weighting (IDW) spatial interpolation.\n",
    "// Given 3 nearest neighbor particles, it interpolates their state to the query position.\n",
    "static void inverse_distance_weighting(const double query_pos[3], \n",
    "                                       const MassiveParticle neighbors[3], \n",
    "                                       double interpolated_u[4], \n",
    "                                       double *interpolated_lambda_rest, \n",
    "                                       float *interpolated_j_intrinsic) {\n",
    "    double weights[3];\n",
    "    double total_weight = 0.0;\n",
    "\n",
    "    // Calculate weights (inverse distance), checking for zero distance\n",
    "    for (int i = 0; i < 3; ++i) {\n",
    "        double dx = query_pos[0] - neighbors[i].pos[0];\n",
    "        double dy = query_pos[1] - neighbors[i].pos[1];\n",
    "        double dz = query_pos[2] - neighbors[i].pos[2];\n",
    "        double dist_sq = dx*dx + dy*dy + dz*dz;\n",
    "\n",
    "        if (dist_sq < 1e-12) { // Photon is extremely close to a particle\n",
    "            weights[i] = 1e12; // Give it a huge weight\n",
    "        } else {\n",
    "            weights[i] = 1.0 / sqrt(dist_sq);\n",
    "        }\n",
    "        total_weight += weights[i];\n",
    "    }\n",
    "\n",
    "    // Normalize weights\n",
    "    if (total_weight > 1e-12) {\n",
    "        for (int i = 0; i < 3; ++i) {\n",
    "            weights[i] /= total_weight;\n",
    "        }\n",
    "    } else { // Should not happen if particles are distinct\n",
    "        weights[0] = 1.0; weights[1] = 0.0; weights[2] = 0.0;\n",
    "    }\n",
    "\n",
    "    // Calculate the weighted average for each property\n",
    "    for (int i = 0; i < 4; ++i) {\n",
    "        interpolated_u[i] = weights[0] * neighbors[0].u[i] + \n",
    "                            weights[1] * neighbors[1].u[i] + \n",
    "                            weights[2] * neighbors[2].u[i];\n",
    "    }\n",
    "    *interpolated_lambda_rest = weights[0] * neighbors[0].lambda_rest +\n",
    "                                weights[1] * neighbors[1].lambda_rest +\n",
    "                                weights[2] * neighbors[2].lambda_rest;\n",
    "    *interpolated_j_intrinsic = weights[0] * neighbors[0].j_intrinsic +\n",
    "                                weights[1] * neighbors[1].j_intrinsic +\n",
    "                                weights[2] * neighbors[2].j_intrinsic;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "    desc = r\"\"\"@brief Performs a two-stage interpolation to find the disk state at a specific spacetime point.\"\"\"\n",
    "    name = \"interpolate_disk_state\"\n",
    "    params = r\"\"\"\n",
    "    const double intersection_time, const double intersection_pos[3],\n",
    "    const CustomKDTree *tree_prev, const CustomKDTree *tree_curr, const CustomKDTree *tree_next,\n",
    "    double time_prev, double time_curr, double time_next,\n",
    "    double final_u[4], double *final_lambda_rest, float *final_j_intrinsic\n",
    "    \"\"\"\n",
    "    body = r\"\"\"\n",
    "    // --- Stage 1: Spatial Interpolation at each time slice ---\n",
    "    \n",
    "    MassiveParticle neighbors_prev[3], neighbors_curr[3], neighbors_next[3];\n",
    "    \n",
    "    // Find 3 nearest neighbors in each of the three bracketing snapshots\n",
    "    find_n_nearest_neighbors(tree_prev, intersection_pos, 3, neighbors_prev);\n",
    "    find_n_nearest_neighbors(tree_curr, intersection_pos, 3, neighbors_curr);\n",
    "    find_n_nearest_neighbors(tree_next, intersection_pos, 3, neighbors_next);\n",
    "\n",
    "    // Spatially interpolate the state at each time slice\n",
    "    double u_prev[4], u_curr[4], u_next[4];\n",
    "    double lambda_prev, lambda_curr, lambda_next;\n",
    "    float j_prev, j_curr, j_next;\n",
    "\n",
    "    inverse_distance_weighting(intersection_pos, neighbors_prev, u_prev, &lambda_prev, &j_prev);\n",
    "    inverse_distance_weighting(intersection_pos, neighbors_curr, u_curr, &lambda_curr, &j_curr);\n",
    "    inverse_distance_weighting(intersection_pos, neighbors_next, u_next, &lambda_next, &j_next);\n",
    "\n",
    "    // --- Stage 2: Temporal Interpolation using Lagrange Polynomials ---\n",
    "\n",
    "    double t = intersection_time;\n",
    "    double t0 = time_prev, t1 = time_curr, t2 = time_next;\n",
    "\n",
    "    // Calculate Lagrange basis polynomials L0(t), L1(t), L2(t)\n",
    "    double L0 = ((t - t1) * (t - t2)) / ((t0 - t1) * (t0 - t2));\n",
    "    double L1 = ((t - t0) * (t - t2)) / ((t1 - t0) * (t1 - t2));\n",
    "    double L2 = ((t - t0) * (t - t1)) / ((t2 - t0) * (t2 - t1));\n",
    "\n",
    "    // Perform the final temporal interpolation for each state variable\n",
    "    for (int i = 0; i < 4; ++i) {\n",
    "        final_u[i] = L0 * u_prev[i] + L1 * u_curr[i] + L2 * u_next[i];\n",
    "    }\n",
    "    *final_lambda_rest = L0 * lambda_prev + L1 * lambda_curr + L2 * lambda_next;\n",
    "    *final_j_intrinsic = L0 * j_prev + L1 * j_curr + L2 * j_next;\n",
    "\n",
    "\"\"\"\n",
    "    cfc.register_CFunction(includes=includes, prefunc=prefunc, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... Registered C engine: interpolate_disk_state.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20ed05b",
   "metadata": {},
   "source": [
    "# Radiative transfer engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56dac28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radiative_transfer_engine():\n",
    "    \"\"\"\n",
    "    Generates the C engine for calculating the final observed intensity and\n",
    "    wavelength based on the interpolated disk state and photon momentum.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine for radiative transfer physics...\")\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\", \"<math.h>\"]\n",
    "    desc = r\"\"\"@brief Calculates the observed intensity and wavelength from the disk and photon state.\"\"\"\n",
    "    name = \"calculate_radiative_transfer\"\n",
    "    params = r\"\"\"\n",
    "    const double photon_p_mu[4], const double disk_u_mu[4],\n",
    "    const float disk_j_intrinsic, const double disk_lambda_rest,\n",
    "    double *stokes_I, double *lambda_observed\n",
    "    \"\"\"\n",
    "    body = r\"\"\"\n",
    "    // The observer is assumed to be at rest in the coordinate frame far away,\n",
    "    // so their 4-velocity is u_obs^mu = (1, 0, 0, 0).\n",
    "    // The metric is Minkowski far away, so u_obs_mu = (-1, 0, 0, 0).\n",
    "    // The photon momentum is p_mu.\n",
    "    // Therefore, (-p_mu u^mu)_obs = - (p_0 * -1) = p_0.\n",
    "    // NOTE: The photon momentum p_mu must be covariant (lower-indexed).\n",
    "    const double p_mu_u_mu_obs = photon_p_mu[0];\n",
    "\n",
    "    // Calculate (-p_mu u^mu)_disk\n",
    "    const double p_mu_u_mu_disk = - (photon_p_mu[0] * disk_u_mu[0] +\n",
    "                                     photon_p_mu[1] * disk_u_mu[1] +\n",
    "                                     photon_p_mu[2] * disk_u_mu[2] +\n",
    "                                     photon_p_mu[3] * disk_u_mu[3]);\n",
    "\n",
    "    // Doppler factor D = E_obs / E_disk = (-p_mu u^mu)_obs / (-p_mu u^mu)_disk\n",
    "    const double doppler_factor = p_mu_u_mu_obs / p_mu_u_mu_disk;\n",
    "\n",
    "    // Observed intensity I_obs = j_intrinsic * D^3\n",
    "    *stokes_I = disk_j_intrinsic * doppler_factor * doppler_factor * doppler_factor;\n",
    "\n",
    "    // Observed wavelength lambda_obs = lambda_rest / D\n",
    "    *lambda_observed = disk_lambda_rest / doppler_factor;\n",
    "\"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... Registered C engine: calculate_radiative_transfer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c68b49d",
   "metadata": {},
   "source": [
    "# Source plane intersection engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea1786c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_source_plane_intersection_engine():\n",
    "    \"\"\"\n",
    "    Generates a C engine that handles a source plane intersection.\n",
    "    \n",
    "    This definitive version uses a robust method to construct the orthonormal\n",
    "    basis of the source plane, preventing division-by-zero errors that lead to NaNs.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine: handle_source_plane_intersection (Robust Version)...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"<math.h>\"]\n",
    "    desc = r\"\"\"@brief Handles a source plane intersection by recording the 2D coordinates.\"\"\"\n",
    "    name = \"handle_source_plane_intersection\"\n",
    "    params = r\"\"\"\n",
    "    const event_data_struct *restrict source_plane_event,\n",
    "    const commondata_struct *restrict commondata,\n",
    "    blueprint_data_t *restrict final_blueprint_data\n",
    "    \"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // An intersection within the bounds was found.\n",
    "    final_blueprint_data->termination_type = TERMINATION_TYPE_SOURCE_PLANE;\n",
    "\n",
    "    // --- Calculate the local (y_s, z_s) coordinates on the plane ---\n",
    "    const double intersection_pos[3] = {source_plane_event->y_event[1], source_plane_event->y_event[2], source_plane_event->y_event[3]};\n",
    "    const double source_plane_center[3] = {commondata->source_plane_center_x, commondata->source_plane_center_y, commondata->source_plane_center_z};\n",
    "    const double source_plane_normal[3] = {commondata->source_plane_normal_x, commondata->source_plane_normal_y, commondata->source_plane_normal_z};\n",
    "    const double source_up_vector[3] = {commondata->source_up_vec_x, commondata->source_up_vec_y, commondata->source_up_vec_z};\n",
    "\n",
    "    // Construct orthonormal basis vectors for the source plane (s_x, s_y, s_z)\n",
    "    // This logic is a direct copy of the robust implementation in run_scan_and_save_blueprint_universal\n",
    "    double s_z[3] = {source_plane_normal[0], source_plane_normal[1], source_plane_normal[2]};\n",
    "    \n",
    "    double s_x[3] = {source_up_vector[1]*s_z[2] - source_up_vector[2]*s_z[1], \n",
    "                     source_up_vector[2]*s_z[0] - source_up_vector[0]*s_z[2], \n",
    "                     source_up_vector[0]*s_z[1] - source_up_vector[1]*s_z[0]};\n",
    "    double mag_s_x = sqrt(SQR(s_x[0]) + SQR(s_x[1]) + SQR(s_x[2]));\n",
    "    \n",
    "    // Handle the case where the up-vector is parallel to the normal vector\n",
    "    if (mag_s_x < 1e-9) {\n",
    "        double alternative_up[3] = {1.0, 0.0, 0.0};\n",
    "        // If the normal is along the x-axis, use the y-axis as the alternative up\n",
    "        if (fabs(s_z[0]) > 0.999) {\n",
    "            alternative_up[0] = 0.0;\n",
    "            alternative_up[1] = 1.0;\n",
    "        }\n",
    "        s_x[0] = alternative_up[1]*s_z[2] - alternative_up[2]*s_z[1];\n",
    "        s_x[1] = alternative_up[2]*s_z[0] - alternative_up[0]*s_z[2];\n",
    "        s_x[2] = alternative_up[0]*s_z[1] - alternative_up[1]*s_z[0];\n",
    "        mag_s_x = sqrt(SQR(s_x[0]) + SQR(s_x[1]) + SQR(s_x[2]));\n",
    "    }\n",
    "    \n",
    "    for(int i=0; i<3; i++) s_x[i] /= mag_s_x;\n",
    "    \n",
    "    double s_y[3] = {s_z[1]*s_x[2] - s_z[2]*s_x[1], \n",
    "                     s_z[2]*s_x[0] - s_z[0]*s_x[2], \n",
    "                     s_z[0]*s_x[1] - s_z[1]*s_x[0]};\n",
    "\n",
    "    // Project the vector from the plane center to the intersection point onto the basis\n",
    "    const double vec_s[3] = {intersection_pos[0] - source_plane_center[0], \n",
    "                             intersection_pos[1] - source_plane_center[1], \n",
    "                             intersection_pos[2] - source_plane_center[2]};\n",
    "    \n",
    "    final_blueprint_data->y_s = vec_s[0]*s_x[0] + vec_s[1]*s_x[1] + vec_s[2]*s_x[2];\n",
    "    final_blueprint_data->z_s = vec_s[0]*s_y[0] + vec_s[1]*s_y[1] + vec_s[2]*s_y[2];\n",
    "    \n",
    "    // Store diagnostic info\n",
    "    final_blueprint_data->t_s = source_plane_event->t_event;\n",
    "    final_blueprint_data->L_s = source_plane_event->y_event[8];\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... Registered C engine: handle_source_plane_intersection (Robust Version).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f46ff4",
   "metadata": {},
   "source": [
    "# Source disk intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3038833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_disk_intersection_engine():\n",
    "    \"\"\"\n",
    "    Generates the C engine to handle a disk intersection event. This is called\n",
    "    by the integrator when the proximity condition is met.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine: handle_disk_intersection()...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"<math.h>\"]\n",
    "    desc = r\"\"\"@brief Handles the physics calculations for a disk intersection event.\"\"\"\n",
    "    name = \"handle_disk_intersection\"\n",
    "    params = r\"\"\"\n",
    "    const double current_y[9],\n",
    "    const commondata_struct *restrict commondata, const params_struct *restrict params,\n",
    "    const metric_params *restrict metric,\n",
    "    const CustomKDTree *tree_prev, const CustomKDTree *tree_curr, const CustomKDTree *tree_next,\n",
    "    double time_prev, double time_curr, double time_next,\n",
    "    blueprint_data_t *restrict final_blueprint_data\n",
    "    \"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // The photon's current state `current_y` is the effective intersection event.\n",
    "    const double intersection_pos[3] = {current_y[1], current_y[2], current_y[3]};\n",
    "    const double intersection_time = current_y[0];\n",
    "    \n",
    "    double disk_u[4], disk_lambda_rest;\n",
    "    float disk_j_intrinsic;\n",
    "    \n",
    "    // 1a. Interpolate the disk state (u^mu, lambda, j)\n",
    "    interpolate_disk_state(intersection_time, intersection_pos,\n",
    "                           tree_prev, tree_curr, tree_next,\n",
    "                           time_prev, time_curr, time_next,\n",
    "                           disk_u, &disk_lambda_rest, &disk_j_intrinsic);\n",
    "    \n",
    "    // 1b. Get metric at the intersection point\n",
    "    metric_struct g4DD;\n",
    "    g4DD_metric(commondata, params, metric, current_y, &g4DD);\n",
    "    \n",
    "    // 1c. Lower indices of photon momentum and disk 4-velocity\n",
    "    const double g_munu[4][4] = {\n",
    "        {g4DD.g00, g4DD.g01, g4DD.g02, g4DD.g03},\n",
    "        {g4DD.g01, g4DD.g11, g4DD.g12, g4DD.g13},\n",
    "        {g4DD.g02, g4DD.g12, g4DD.g22, g4DD.g23},\n",
    "        {g4DD.g03, g4DD.g13, g4DD.g23, g4DD.g33}\n",
    "    };\n",
    "    \n",
    "    double photon_p_mu[4] = {0,0,0,0};\n",
    "    double disk_u_mu[4] = {0,0,0,0};\n",
    "    for(int mu=0; mu<4; mu++) {\n",
    "        for(int nu=0; nu<4; nu++) {\n",
    "            photon_p_mu[mu] += g_munu[mu][nu] * current_y[nu+4];\n",
    "            disk_u_mu[mu] += g_munu[mu][nu] * disk_u[nu];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // 1d. Call the radiative transfer physics engine\n",
    "    double temp_stokes_I;\n",
    "    double temp_lambda_observed;\n",
    "    calculate_radiative_transfer(photon_p_mu, disk_u_mu, disk_j_intrinsic, disk_lambda_rest,\n",
    "                                 &temp_stokes_I, &temp_lambda_observed);\n",
    "    \n",
    "    // 1e. Populate the final blueprint with the results\n",
    "    final_blueprint_data->stokes_I = temp_stokes_I;\n",
    "    final_blueprint_data->lambda_observed = temp_lambda_observed;\n",
    "    final_blueprint_data->termination_type = TERMINATION_TYPE_DISK;\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... Registered C engine: handle_disk_intersection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94fb7b8",
   "metadata": {},
   "source": [
    "<a id='generate_c_orchestrators'></a>\n",
    "# Step 7: C Code Generation - Orchestrators and Dispatchers\n",
    "\n",
    "With the low-level \"engine\" and \"worker\" functions defined in the previous step, we now generate the higher-level C functions that manage the simulation. These functions are responsible for dispatching to the correct worker based on runtime parameters and for orchestrating the overall program flow.\n",
    "\n",
    "*   **Dispatchers** are functions that contain a `switch` statement to select the correct \"worker\" function based on the chosen metric (e.g., `Schwarzschild` vs. `Kerr`).\n",
    "*   **Orchestrators** are functions that execute a sequence of calls to other engines, workers, and dispatchers to perform a complex task, like setting up initial conditions or running the main integration loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3bcd71",
   "metadata": {},
   "source": [
    "# Filename_sorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf6b3c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_sorter():\n",
    "    \"\"\"\n",
    "    Generates a C helper function to be used by qsort for sorting snapshot filenames.\n",
    "    \"\"\"\n",
    "    includes = [\"stdio.h\", \"<stdlib.h>\"]\n",
    "    desc = \"Comparison function for qsort to sort filenames numerically.\"\n",
    "    name = \"compare_filenames\"\n",
    "    cfunc_type = \"int\"\n",
    "    params = \"const void *a, const void *b\"\n",
    "    body = r\"\"\"\n",
    "    const char *str_a = *(const char **)a;\n",
    "    const char *str_b = *(const char **)b;\n",
    "    int num_a, num_b;\n",
    "    sscanf(str_a, \"mass_blueprint_t_%d.kdtree.bin\", &num_a);\n",
    "    sscanf(str_b, \"mass_blueprint_t_%d.kdtree.bin\", &num_b);\n",
    "    return (num_a > num_b) - (num_a < num_b);\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, cfunc_type=cfunc_type, params=params, body=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545db0d5",
   "metadata": {},
   "source": [
    "<a id='g4DD_metric_dispatcher'></a>\n",
    "### 7.a: `g4DD_metric()` Dispatcher\n",
    "\n",
    "This Python function generates the C function `g4DD_metric()`, which serves as a high-level **dispatcher.** Its role is to select and call the correct worker function to compute the components of the metric tensor, $g_{\\mu\\nu}$.\n",
    "\n",
    "The generated C code uses a `switch` statement that reads the `metric->type` member of the `metric_params` struct. In this project, both the Schwarzschild and Kerr spacetimes are handled by the unified `g4DD_kerr_schild()` worker function. The dispatcher calls this single worker, and the specific metric returned by the worker depends on the runtime value of the `a_spin` parameter (if `a_spin` is 0, the Schwarzschild metric is computed).\n",
    "\n",
    "This modular approach cleanly separates the control flow (deciding *which* metric to use) from the physics implementation (the worker functions that know *how* to compute a specific metric). This makes the project easy to extend with new spacetimes in the future by adding new cases to the `switch` statement and new worker functions.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced. Used to register the manually written C code for the dispatcher function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65702cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In cell [65702cb7]\n",
    "\n",
    "def g4DD_metric():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function g4DD_metric(), which serves as a\n",
    "    dispatcher to call the appropriate metric-specific worker function.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C dispatcher function: g4DD_metric()...\")\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Dispatcher to compute the 4-metric g_munu for the chosen metric.\"\"\"\n",
    "    name = \"g4DD_metric\"\n",
    "    # The signature is now coordinate-aware, but the y vector is always Cartesian here.\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const metric_params *restrict metric, const double y[9], metric_struct *restrict metric_out\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "    // The state vector y_pos contains only the position coordinates.\n",
    "    const double y_pos[4] = {y[0], y[1], y[2], y[3]};\n",
    "\n",
    "    // This switch statement chooses which \"worker\" function to call\n",
    "    // based on the metric type provided.\n",
    "    switch(metric->type) {\n",
    "        case Schwarzschild:\n",
    "        case Kerr:\n",
    "            // For Kerr or Schwarzschild in KS coords, call the unified Kerr-Schild C function.\n",
    "            g4DD_kerr_schild(commondata, params, y_pos, metric_out);\n",
    "            break;\n",
    "        // <-- MODIFIED: Call the new Cartesian worker\n",
    "        case Schwarzschild_Standard:\n",
    "            g4DD_schwarzschild_cartesian(commondata, params, y_pos, metric_out);\n",
    "            break;\n",
    "        case Numerical:\n",
    "            printf(\"Error: Numerical metric not supported yet.\\n\");\n",
    "            exit(1);\n",
    "            break;\n",
    "        default:\n",
    "            printf(\"Error: MetricType %d not supported in g4DD_metric() yet.\\n\", metric->type);\n",
    "            exit(1);\n",
    "            break;\n",
    "    }\n",
    "\"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... g4DD_metric() registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db30c0a",
   "metadata": {},
   "source": [
    "<a id='connections_dispatcher'></a>\n",
    "### 7.b: `connections()` Dispatcher\n",
    "\n",
    "This Python function generates the C function `connections()`, which acts as a second **dispatcher.** Its sole responsibility is to select and call the correct metric-specific worker function (like `con_kerr_schild()`) to compute the Christoffel symbols.\n",
    "\n",
    "Like the `g4DD_metric()` dispatcher, the generated C code uses a `switch` statement based on the `metric->type`. It dispatches the call to the appropriate specialized worker, which in this case is the unified `con_kerr_schild()` function for both Kerr and Schwarzschild spacetimes. This design is highly extensible: adding a new metric simply requires writing a new worker function for its Christoffel symbols and adding a new `case` to this `switch` statement.\n",
    "\n",
    "This function demonstrates how `nrpy` allows for the seamless integration of developer-written control flow with the automatically generated worker functions.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b92b7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In cell [b92b7851]\n",
    "\n",
    "def connections():\n",
    "    \"\"\"\n",
    "    Generates and registers the C dispatcher for Christoffel symbols.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C dispatcher: connections()...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"stdio.h\", \"stdlib.h\"]\n",
    "    desc = r\"\"\"@brief Dispatcher to compute Christoffel symbols for the chosen metric.\"\"\"\n",
    "    \n",
    "    name = \"connections\"\n",
    "    cfunc_type = \"void\" \n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const metric_params *restrict metric, const double y[9], connection_struct *restrict conn\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // The state vector y_pos contains only the position coordinates.\n",
    "    const double y_pos[4] = {y[0], y[1], y[2], y[3]};\n",
    "\n",
    "    // This switch statement chooses which \"worker\" function to call\n",
    "    // based on the metric type provided.\n",
    "    switch(metric->type) {\n",
    "        case Schwarzschild:\n",
    "        case Kerr:\n",
    "            con_kerr_schild(commondata, params, y_pos, conn);\n",
    "            break;\n",
    "        // <-- MODIFIED: Call the new Cartesian worker\n",
    "        case Schwarzschild_Standard:\n",
    "            con_schwarzschild_cartesian(commondata, params, y_pos, conn);\n",
    "            break;\n",
    "        case Numerical:\n",
    "            printf(\"Error: Numerical metric not supported yet.\\n\");\n",
    "            exit(1);\n",
    "            break;\n",
    "        default:\n",
    "            printf(\"Error: MetricType %d not supported yet.\\n\", metric->type);\n",
    "            exit(1);\n",
    "            break;\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, cfunc_type=cfunc_type,\n",
    "        name=name, params=params, body=body\n",
    "    )\n",
    "    print(\"    ... connections() registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ea28a",
   "metadata": {},
   "source": [
    "<a id='set_initial_conditions_cartesian'></a>\n",
    "### 7.c: `set_initial_conditions_cartesian()` Orchestrator\n",
    "\n",
    "This function generates the C **orchestrator** `set_initial_conditions_cartesian()`. This function is responsible for setting the complete initial state vector `y_out[9]` for a single light ray. It orchestrates a sequence of calculations to do this.\n",
    "\n",
    "The process for setting the initial state `y = (t, x, y, z, p^t, p^x, p^y, p^z, L)` is as follows:\n",
    "\n",
    "1.  **Set Initial Position**: The initial spatial coordinates `(x, y, z)` are set to the camera's location, `camera_pos`. The initial time `t` and path length `L` are set to `0.0`.\n",
    "2.  **Calculate Aiming Vector**: It computes the aiming vector `V`, which points from the camera to a specific target pixel on the window plane: `V = target_pos - camera_pos`.\n",
    "3.  **Set Initial Spatial Momentum**: As derived in the introduction, the initial reverse-time spatial momentum `(p^x, p^y, p^z)` must be parallel to the aiming vector `V`. It is therefore set to the normalized aiming vector: `p^i = V^i / |V|`.\n",
    "4.  **Calculate Initial Time Momentum**: With the spatial components of the momentum set, the final unknown is the time component, $p^t = p^0$. This requires a call to the physics engines:\n",
    "    *   First, it calls the `g4DD_metric()` dispatcher to compute the metric components $g_{\\mu\\nu}$ at the camera's location.\n",
    "    *   Then, it passes these metric components and the partially-filled state vector `y_out` to the `calculate_p0_reverse()` engine, which solves the null condition $g_{\\mu\\nu}p^\\mu p^\\nu=0$ for $p^0$.\n",
    "    *   The result is stored in `y_out[4]`, completing the initial state vector.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfd43b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_conditions_cartesian():\n",
    "    \"\"\"\n",
    "    Generates the C engine to set the initial state vector, now entirely in\n",
    "    Cartesian coordinates.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine: set_initial_conditions_cartesian()...\")\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Sets the full initial state for a ray in Cartesian coordinates.\"\"\"\n",
    "    \n",
    "    name = \"set_initial_conditions_cartesian\"\n",
    "    params = \"\"\"const commondata_struct *restrict commondata, const params_struct *restrict params,\n",
    "                const metric_params *restrict metric,\n",
    "                const double camera_pos[3], const double target_pos[3],\n",
    "                double y_out[9]\"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // --- Step 1: Set the initial position to the camera's location ---\n",
    "    y_out[0] = 0.0; // t\n",
    "    y_out[1] = camera_pos[0]; // x\n",
    "    y_out[2] = camera_pos[1]; // y\n",
    "    y_out[3] = camera_pos[2]; // z\n",
    "    y_out[8] = 0.0; // L (integrated path length)\n",
    "\n",
    "    // --- Step 2: Calculate the aiming vector V and set spatial momentum ---\n",
    "    const double V_x = target_pos[0] - camera_pos[0];\n",
    "    const double V_y = target_pos[1] - camera_pos[1];\n",
    "    const double V_z = target_pos[2] - camera_pos[2];\n",
    "    const double mag_V = sqrt(V_x*V_x + V_y*V_y + V_z*V_z);\n",
    "    \n",
    "    // The reverse-momentum p is parallel to the aiming vector V.\n",
    "    if (mag_V > 1e-12) {\n",
    "        y_out[5] = V_x / mag_V; // p^x\n",
    "        y_out[6] = V_y / mag_V; // p^y\n",
    "        y_out[7] = V_z / mag_V; // p^z\n",
    "    } else {\n",
    "        // Should not happen in production, but as a fallback, set a default momentum.\n",
    "        y_out[5] = 1.0; y_out[6] = 0.0; y_out[7] = 0.0;\n",
    "    }\n",
    "    \n",
    "    // --- Step 3: Calculate the time component p^t using the null condition ---\n",
    "    metric_struct g4DD;\n",
    "    // Note: The g4DD_metric function needs the first 4 elements of y_out (the coordinates).\n",
    "    g4DD_metric(commondata, params, metric, y_out, &g4DD);\n",
    "    \n",
    "    // The state vector y is (t,x,y,z, p^t,p^x,p^y,p^z, L).\n",
    "    y_out[4] = calculate_p0_reverse(&g4DD, y_out);\n",
    "    \"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fdf4ce",
   "metadata": {},
   "source": [
    "<a id='gsl_wrapper'></a>\n",
    "### 7.d: The GSL Wrapper Function\n",
    "\n",
    "The GNU Scientific Library (GSL) provides powerful, general-purpose routines for solving systems of Ordinary Differential Equations (ODEs). To use them, we must provide a C function that calculates the RHS of our ODE system and conforms to a specific function pointer signature required by the library. The `ode_gsl_wrapper` C function serves as this critical **adapter** or **bridge** between the generic GSL interface and our specialized project code.\n",
    "\n",
    "This Python function registers the C function that performs these steps in order every time the GSL solver takes a time step:\n",
    "\n",
    "1.  **Unpack Parameters**: It receives a generic `void *params` pointer from the GSL solver. Its first action is to cast this pointer back to its true type, `gsl_params *`, which is our custom \"carrier\" struct. This gives the function access to the `commondata`, `params`, and `metric` structs needed by our physics routines.\n",
    "2.  **Call Metric and Connection Dispatchers**: It declares empty `metric_struct` and `connection_struct` containers on the stack. It then calls our high-level dispatchers (`g4DD_metric()` and `connections()`) to fill these structs with the correct physical values for the current point in spacetime `y`.\n",
    "3.  **Call `calculate_ode_rhs()` Engine**: It then passes the current state vector `y` and the now-filled `g4DD` and `conn` structs to our RHS engine. This engine computes the derivatives and stores them in the output array `f`, which is the array GSL uses for the RHS values.\n",
    "4.  **Return Success**: Finally, it returns `GSL_SUCCESS`, signaling to the GSL solver that the RHS calculation was completed correctly.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec563f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode_gsl_wrapper():\n",
    "    \"\"\"\n",
    "    Generates and registers the ode_gsl_wrapper C function. This acts as\n",
    "    a bridge between the generic GSL solver and our project-specific functions.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating GSL wrapper function: ode_gsl_wrapper...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"gsl/gsl_errno.h\"]\n",
    "    desc = r\"\"\"@brief Acts as an adapter between the generic GSL ODE solver and our specific C functions.\n",
    " \n",
    "    The GNU Scientific Library (GSL) ODE solver requires a function pointer to a\n",
    "    function with a very specific signature. This wrapper function is designed to\n",
    "    exactly match that required signature, acting as a \"bridge\" to our modular,\n",
    "    project-specific C code.\n",
    "    \n",
    "    @param[in]  lambda The current value of the independent variable (affine parameter). Unused.\n",
    "    @param[in]  y      The current 9-component state vector [t, r, th, ph, p^t, ..., L].\n",
    "    @param[in]  params A generic `void` pointer to a gsl_params struct, provided by the GSL system.\n",
    "    @param[out] f      A pointer to the 9-component output array where the RHS results are stored.\n",
    "    \n",
    "    @return An integer status code for the GSL library (`GSL_SUCCESS` on success).\"\"\"\n",
    "    \n",
    "    name = \"ode_gsl_wrapper\"\n",
    "    cfunc_type = \"int\"\n",
    "\n",
    "    # UPDATED: The arrays y and f are now size 9.\n",
    "    params = \"double lambda, const double y[9], double f[9], void *params\"\n",
    "\n",
    "    # UPDATED: The body now also computes the metric before calling the RHS function.\n",
    "    body = r\"\"\"\n",
    "    // The GSL solver doesn't use lambda, so we cast it to void to prevent compiler warnings.\n",
    "    (void)lambda;\n",
    "\n",
    "    // --- Step 1: Unpack the Carrier Struct ---\n",
    "    // Cast the generic void* params pointer back to its true type, our gsl_params carrier.\n",
    "    gsl_params *gsl_parameters = (gsl_params *)params;\n",
    "\n",
    "    // --- Step 2: Prepare for Physics Calculation ---\n",
    "    // Create empty containers for the metric and Christoffel symbols on the stack.\n",
    "    metric_struct     g4DD;\n",
    "    connection_struct conn;\n",
    "\n",
    "    // --- Step 3: Call Engine Functions ---\n",
    "    // NEW: Call the g4DD_metric dispatcher to fill the g4DD struct at the current coordinates.\n",
    "    g4DD_metric(gsl_parameters->commondata, gsl_parameters->params, gsl_parameters->metric, y, &g4DD);\n",
    "    \n",
    "    // Call the connections dispatcher to fill the conn struct.\n",
    "    connections(gsl_parameters->commondata, gsl_parameters->params, gsl_parameters->metric, y, &conn);\n",
    "\n",
    "    // Call the RHS engine to compute the derivatives, passing both g4DD and conn.\n",
    "    calculate_ode_rhs(y, &g4DD, &conn, f);\n",
    "\n",
    "    // --- Step 4: Return Success ---\n",
    "    // Return a success code to the GSL solver.\n",
    "    return GSL_SUCCESS;\n",
    "    \"\"\"\n",
    "\n",
    "    # Register the C function with nrpy.\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes,\n",
    "        desc=desc,\n",
    "        cfunc_type=cfunc_type,\n",
    "        name=name,\n",
    "        params=params,\n",
    "        body=body\n",
    "    )\n",
    "    \n",
    "    # Finally, call the function to perform the registration\n",
    "    print(\"    ... ode_gsl_wrapper() registration complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a16075",
   "metadata": {},
   "source": [
    "<a id='integration_loop'></a>\n",
    "### 7.e: The Main Integration Loop\n",
    "\n",
    "This Python function registers `integrate_single_photon_cartesian()`, a high-level **orchestrator** that brings together all the components to solve the ODE system for a single light ray. It sets up, executes, and tears down the GSL numerical integration environment for one trajectory.\n",
    "\n",
    "The generated C code body performs several distinct tasks in sequence:\n",
    "\n",
    "1.  **GSL Solver Setup**: It initializes the three core components required by the GSL ODE solver: the `step` (the `rkf45` algorithm), the `control` (for adaptive step-sizing), and the `evolve` (which manages the state of the solver).\n",
    "2.  **Define the ODE System**: It sets up a `gsl_params` \"carrier\" struct, which holds pointers to all the data our RHS function needs (`commondata`, `params`, `metric`). It then initializes a `gsl_odeiv2_system` struct, which bundles our derivative function (`ode_gsl_wrapper`) with this carrier struct.\n",
    "3.  **Main Integration Loop**: The function enters a `for` loop that continues until a termination condition is met. Inside the loop, `gsl_odeiv2_evolve_apply()` tells GSL to compute the derivatives (by calling our wrapper) and advance the state vector `y`.\n",
    "4.  **State History and Event Detection**: The function maintains a history of the last three states (`y_p_p`, `y_p`, `y_c`). After each step, it checks if a plane-crossing event has occurred by looking for a sign change in the function `f(y) = n_i x^i - d`. If a crossing is bracketed, it calls our `find_event_time_and_state()` engine to precisely locate it.\n",
    "5.  **Termination Conditions**: The loop stops if the source plane event is found, or if an error/escape condition is met. These conditions are:\n",
    "    *   The photon's radial distance `r` exceeds a maximum escape radius (`r_escape`).\n",
    "    *   The coordinate time `t` exceeds a maximum integration time (`t_max`).\n",
    "    *   The time component of the momentum, `p^t`, grows excessively large, indicating a potential numerical instability or a path falling toward the singularity.\n",
    "    *   The GSL solver returns a status other than `GSL_SUCCESS`.\n",
    "    *   The maximum number of integration steps is reached.\n",
    "6.  **Cleanup**: After the loop finishes, it calls the appropriate `gsl_*_free()` functions to release all memory allocated by the GSL components, preventing memory leaks.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33aeb938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_single_photon():\n",
    "    \"\"\"\n",
    "    Generates the main integration loop for a single photon.\n",
    "    \n",
    "    This final version implements the high-performance hybrid bounding box +\n",
    "    proximity check logic. K-d tree searches are only performed when the\n",
    "    photon is inside the disk's bounding volume.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating integration loop: integrate_single_photon() [Hybrid RT Version]...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"gsl/gsl_errno.h\", \"gsl/gsl_odeiv2.h\", \"<math.h>\"]\n",
    "    prefunc = \"int ode_gsl_wrapper(double lambda, const double y[9], double f[9], void *params);\\n\"\n",
    "    \n",
    "    desc = r\"\"\"@brief Integrates a single photon path until a termination condition is met.\"\"\"\n",
    "    name = \"integrate_single_photon\"\n",
    "    cfunc_type = \"blueprint_data_t\"\n",
    "    params = r\"\"\"const commondata_struct *restrict commondata,\n",
    "    const params_struct *restrict params,\n",
    "    const metric_params *restrict metric,\n",
    "    const double start_y[9],\n",
    "    const double t_max,\n",
    "    const CustomKDTree *kdtree_snapshots,\n",
    "    const double snapshot_times[],\n",
    "    int num_snapshots\n",
    "    \"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    blueprint_data_t final_blueprint_data;\n",
    "    memset(&final_blueprint_data, 0, sizeof(blueprint_data_t));\n",
    "    final_blueprint_data.termination_type = TERMINATION_TYPE_FAILURE;\n",
    "\n",
    "    gsl_odeiv2_step * step = gsl_odeiv2_step_alloc(gsl_odeiv2_step_rkf45, 9);\n",
    "    gsl_odeiv2_control * control = gsl_odeiv2_control_y_new(1e-11, 1e-11);\n",
    "    gsl_odeiv2_evolve * evol = gsl_odeiv2_evolve_alloc(9);\n",
    "    gsl_params gsl_parameters = {commondata, params, metric};\n",
    "    gsl_odeiv2_system sys = {ode_gsl_wrapper, NULL, 9, &gsl_parameters};\n",
    "\n",
    "    double y_p_p[9], y_p[9], y_c[9];\n",
    "    double lambda_p_p = 0.0, lambda_p = 0.0, lambda_c = 0.0;\n",
    "    double d_lambda = 0.01;\n",
    "    for (int j = 0; j < 9; j++) { y_c[j] = start_y[j]; y_p[j] = start_y[j]; y_p_p[j] = start_y[j]; }\n",
    "    \n",
    "    event_data_struct window_event;\n",
    "    window_event.found = false;\n",
    "    event_data_struct source_plane_event;\n",
    "    source_plane_event.found = false;\n",
    "    \n",
    "    bool on_positive_side_of_window_prev, on_positive_side_of_source_prev;\n",
    "    event_detection_manager(start_y, start_y, start_y, 0.0, 0.0, 0.0, commondata,\n",
    "                            &on_positive_side_of_window_prev, &on_positive_side_of_source_prev,\n",
    "                            &window_event, &source_plane_event);\n",
    "    window_event.found = false;\n",
    "\n",
    "    // --- Main Integration Loop ---\n",
    "    for (int i = 0; i < 300000; i++) {\n",
    "        lambda_p_p = lambda_p;\n",
    "        lambda_p   = lambda_c;\n",
    "        for(int j=0; j<9; j++) { y_p_p[j] = y_p[j]; y_p[j] = y_c[j]; }\n",
    "\n",
    "        int status = gsl_odeiv2_evolve_apply(evol, control, step, &sys, &lambda_c, 1e10, &d_lambda, y_c);\n",
    "        \n",
    "        if (status != GSL_SUCCESS || fabs(y_c[4]) > 1e3 || fabs(y_c[0]) > t_max) {\n",
    "            final_blueprint_data.termination_type = TERMINATION_TYPE_FAILURE;\n",
    "            break;\n",
    "        }\n",
    "\n",
    "        // --- Prioritized Event Detection ---\n",
    "        \n",
    "        // Check if the photon is inside the disk's bounding box\n",
    "        const double x = y_c[1], y = y_c[2], z = y_c[3];\n",
    "        const bool is_inside_bounding_box = (x >= commondata->disk_bounds_x_min && x <= commondata->disk_bounds_x_max &&\n",
    "                                             y >= commondata->disk_bounds_y_min && y <= commondata->disk_bounds_y_max &&\n",
    "                                             z >= commondata->disk_bounds_z_min && z <= commondata->disk_bounds_z_max);\n",
    "\n",
    "        // Priority 1: Check for Disk Proximity IF inside the bounding box\n",
    "        if (is_inside_bounding_box) {\n",
    "            int idx1 = -1, idx2 = -1, idx3 = -1;\n",
    "            for (int j = 0; j < num_snapshots - 1; ++j) {\n",
    "                if (y_c[0] >= snapshot_times[j] && y_c[0] < snapshot_times[j+1]) {\n",
    "                    idx2 = j;\n",
    "                    break;\n",
    "                }\n",
    "            }\n",
    "            if(idx2 > 0 && idx2 < num_snapshots - 1) {\n",
    "                idx1 = idx2 - 1;\n",
    "                idx3 = idx2 + 1;\n",
    "            }\n",
    "\n",
    "            if (idx1 != -1) { // If we have valid bracketing snapshots\n",
    "                MassiveParticle neighbors_prev[3], neighbors_curr[3], neighbors_next[3];\n",
    "                const double query_pos[3] = {y_c[1], y_c[2], y_c[3]};\n",
    "                \n",
    "                find_n_nearest_neighbors(&kdtree_snapshots[idx1], query_pos, 3, neighbors_prev);\n",
    "                find_n_nearest_neighbors(&kdtree_snapshots[idx2], query_pos, 3, neighbors_curr);\n",
    "                find_n_nearest_neighbors(&kdtree_snapshots[idx3], query_pos, 3, neighbors_next);\n",
    "\n",
    "                double max_dist_sq = 0.0;\n",
    "                for(int k=0; k<3; k++) {\n",
    "                    double d_sq_prev = SQR(query_pos[0] - neighbors_prev[k].pos[0]) + SQR(query_pos[1] - neighbors_prev[k].pos[1]) + SQR(query_pos[2] - neighbors_prev[k].pos[2]);\n",
    "                    double d_sq_curr = SQR(query_pos[0] - neighbors_curr[k].pos[0]) + SQR(query_pos[1] - neighbors_curr[k].pos[1]) + SQR(query_pos[2] - neighbors_curr[k].pos[2]);\n",
    "                    double d_sq_next = SQR(query_pos[0] - neighbors_next[k].pos[0]) + SQR(query_pos[1] - neighbors_next[k].pos[1]) + SQR(query_pos[2] - neighbors_next[k].pos[2]);\n",
    "                    if(d_sq_prev > max_dist_sq) max_dist_sq = d_sq_prev;\n",
    "                    if(d_sq_curr > max_dist_sq) max_dist_sq = d_sq_curr;\n",
    "                    if(d_sq_next > max_dist_sq) max_dist_sq = d_sq_next;\n",
    "                }\n",
    "\n",
    "                if (sqrt(max_dist_sq) <= commondata->delta_r_max) {\n",
    "                    handle_disk_intersection(y_c, commondata, params, metric,\n",
    "                                             &kdtree_snapshots[idx1], &kdtree_snapshots[idx2], &kdtree_snapshots[idx3],\n",
    "                                             snapshot_times[idx1], snapshot_times[idx2], snapshot_times[idx3],\n",
    "                                             &final_blueprint_data);\n",
    "                    break; // DISK HIT: Terminate the integration loop\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Priority 2 & 3: Check for Plane Crossings and Escape (only if no disk hit)\n",
    "        if (i >= 2) {\n",
    "            event_detection_manager(y_p_p, y_p, y_c, lambda_p_p, lambda_p, lambda_c, commondata,\n",
    "                                    &on_positive_side_of_window_prev, &on_positive_side_of_source_prev,\n",
    "                                    &window_event, &source_plane_event);\n",
    "\n",
    "            if (source_plane_event.found) {\n",
    "                handle_source_plane_intersection(&source_plane_event, commondata, &final_blueprint_data);\n",
    "                break; // SOURCE PLANE HIT: Terminate the integration loop\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        const double r_sq = y_c[1]*y_c[1] + y_c[2]*y_c[2] + y_c[3]*y_c[3];\n",
    "        if (r_sq > commondata->r_escape * commondata->r_escape) {\n",
    "            final_blueprint_data.termination_type = TERMINATION_TYPE_CELESTIAL_SPHERE;\n",
    "            break; // ESCAPE: Terminate the integration loop\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // --- Final Processing after loop termination ---\n",
    "    if (final_blueprint_data.termination_type == TERMINATION_TYPE_CELESTIAL_SPHERE) {\n",
    "        const double x = y_c[1], y = y_c[2], z = y_c[3];\n",
    "        const double r = sqrt(x*x + y*y + z*z);\n",
    "        if (r > 1e-9) {\n",
    "            final_blueprint_data.final_theta = acos(z / r);\n",
    "            final_blueprint_data.final_phi = atan2(y, x);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if (window_event.found) {\n",
    "        final_blueprint_data.L_w = window_event.y_event[8];\n",
    "        final_blueprint_data.t_w = window_event.t_event;\n",
    "        // Store the 3D intersection point for later projection in Python\n",
    "        final_blueprint_data.y_s = window_event.y_event[1]; // Storing x_intersect\n",
    "        final_blueprint_data.z_s = window_event.y_event[2]; // Storing y_intersect\n",
    "    }\n",
    "\n",
    "    gsl_odeiv2_evolve_free(evol); gsl_odeiv2_control_free(control); gsl_odeiv2_step_free(step);\n",
    "    return final_blueprint_data;\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, prefunc=prefunc, desc=desc, cfunc_type=cfunc_type, name=name, params=params, body=body, include_CodeParameters_h=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a3977c",
   "metadata": {},
   "source": [
    "# This integration code does a single photon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba5ff83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_single_photon_DEBUG():\n",
    "    \"\"\"\n",
    "    Generates a complete DEBUG version of the integrator.\n",
    "    \n",
    "    This final version correctly initializes its own boolean state flags for\n",
    "    plane detection and calls the new stateless event manager.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C DEBUG function: integrate_single_photon_DEBUG()...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"gsl/gsl_errno.h\", \"gsl/gsl_odeiv2.h\", \"<math.h>\", \"<stdio.h>\"]\n",
    "    prefunc = \"int ode_gsl_wrapper(double lambda, const double y[9], double f[9], void *params);\\n\"\n",
    "    desc = r\"\"\"@brief DEBUG integrator. Integrates a single photon path with full termination\n",
    "    checks and detailed console output, writing the full path to photon_path.txt.\"\"\"\n",
    "    name = \"integrate_single_photon_DEBUG\"\n",
    "    cfunc_type = \"void\"\n",
    "    \n",
    "    params = r\"\"\"const commondata_struct *restrict commondata,\n",
    "    const params_struct *restrict params,\n",
    "    const metric_params *restrict metric,\n",
    "    const double start_y[9],\n",
    "    const double t_max,\n",
    "    const CustomKDTree *kdtree_snapshots,\n",
    "    const double snapshot_times[],\n",
    "    int num_snapshots,\n",
    "    double final_y_state[9]\n",
    "    \"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    blueprint_data_t final_blueprint_data;\n",
    "    memset(&final_blueprint_data, 0, sizeof(blueprint_data_t));\n",
    "    final_blueprint_data.termination_type = TERMINATION_TYPE_FAILURE;\n",
    "\n",
    "    gsl_odeiv2_step * step = gsl_odeiv2_step_alloc(gsl_odeiv2_step_rkf45, 9);\n",
    "    gsl_odeiv2_control * control = gsl_odeiv2_control_y_new(1e-12, 1e-12);\n",
    "    gsl_odeiv2_evolve * evol = gsl_odeiv2_evolve_alloc(9);\n",
    "    gsl_params gsl_parameters = {commondata, params, metric};\n",
    "    gsl_odeiv2_system sys = {ode_gsl_wrapper, NULL, 9, &gsl_parameters};\n",
    "\n",
    "    double y_p_p[9], y_p[9], y_c[9];\n",
    "    double lambda_p_p = 0.0, lambda_p = 0.0, lambda_c = 0.0;\n",
    "    double d_lambda = 0.01;\n",
    "    for (int j = 0; j < 9; j++) { y_c[j] = start_y[j]; y_p[j] = start_y[j]; y_p_p[j] = start_y[j]; }\n",
    "    \n",
    "    event_data_struct window_event;\n",
    "    window_event.found = false;\n",
    "    event_data_struct source_plane_event;\n",
    "    source_plane_event.found = false;\n",
    "    \n",
    "    // --- CORRECTED, ROBUST INITIALIZATION of Boolean Flags ---\n",
    "    bool on_positive_side_of_window_prev, on_positive_side_of_source_prev;\n",
    "    {\n",
    "        // Window plane\n",
    "        plane_event_params window_params;\n",
    "        double window_plane_normal[3] = {commondata->window_center_x - commondata->camera_pos_x,\n",
    "                                         commondata->window_center_y - commondata->camera_pos_y,\n",
    "                                         commondata->window_center_z - commondata->camera_pos_z};\n",
    "        const double mag_w_norm = sqrt(SQR(window_plane_normal[0]) + SQR(window_plane_normal[1]) + SQR(window_plane_normal[2]));\n",
    "        if (mag_w_norm > 1e-12) {\n",
    "            const double inv_mag_w_norm = 1.0 / mag_w_norm;\n",
    "            for(int i=0;i<3;i++) window_plane_normal[i] *= inv_mag_w_norm;\n",
    "        }\n",
    "        window_params.d = commondata->window_center_x * window_plane_normal[0] +\n",
    "                          commondata->window_center_y * window_plane_normal[1] +\n",
    "                          commondata->window_center_z * window_plane_normal[2];\n",
    "        for(int i=0;i<3;i++) window_params.n[i] = window_plane_normal[i];\n",
    "        on_positive_side_of_window_prev = (plane_event_func(start_y, &window_params) > 0);\n",
    "\n",
    "        // Source plane\n",
    "        plane_event_params source_params;\n",
    "        const double source_plane_normal[3] = {commondata->source_plane_normal_x, commondata->source_plane_normal_y, commondata->source_plane_normal_z};\n",
    "        source_params.d = commondata->source_plane_center_x * source_plane_normal[0] +\n",
    "                          commondata->source_plane_center_y * source_plane_normal[1] +\n",
    "                          commondata->source_plane_center_z * source_plane_normal[2];\n",
    "        for(int i=0;i<3;i++) source_params.n[i] = source_plane_normal[i];\n",
    "        on_positive_side_of_source_prev = (plane_event_func(start_y, &source_params) > 0);\n",
    "    }\n",
    "\n",
    "    FILE *fp = fopen(\"photon_path.txt\", \"w\");\n",
    "    if (fp == NULL) { exit(1); }\n",
    "    fprintf(fp, \"# lambda\\tt\\tx\\ty\\tz\\tp_t\\tp_x\\tp_y\\tp_z\\tL\\n\");\n",
    "\n",
    "    printf(\"Starting debug trace...\\n\");\n",
    "    printf(\"Step |      lambda |      t     |      x     |      y     |      z     | Event Status\\n\");\n",
    "    printf(\"--------------------------------------------------------------------------------------\\n\");\n",
    "\n",
    "    // --- Main Integration Loop ---\n",
    "    for (int i = 0; i < 300000; i++) {\n",
    "        lambda_p_p = lambda_p;\n",
    "        lambda_p   = lambda_c;\n",
    "        for(int j=0; j<9; j++) { y_p_p[j] = y_p[j]; y_p[j] = y_c[j]; }\n",
    "\n",
    "        int status = gsl_odeiv2_evolve_apply(evol, control, step, &sys, &lambda_c, 1e10, &d_lambda, y_c);\n",
    "        \n",
    "        fprintf(fp, \"%.6e\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\n\", \n",
    "                lambda_c, y_c[0], y_c[1], y_c[2], y_c[3], y_c[4], y_c[5], y_c[6], y_c[7], y_c[8]);\n",
    "\n",
    "        char event_status_str[50] = \"Searching...\";\n",
    "\n",
    "        if (status != GSL_SUCCESS || fabs(y_c[4]) > 1e3 || fabs(y_c[0]) > t_max) {\n",
    "            final_blueprint_data.termination_type = TERMINATION_TYPE_FAILURE;\n",
    "            break;\n",
    "        }\n",
    "\n",
    "        // --- Prioritized Event Detection ---\n",
    "        const double x = y_c[1], y = y_c[2], z = y_c[3];\n",
    "        const bool is_inside_bounding_box = (x >= commondata->disk_bounds_x_min && x <= commondata->disk_bounds_x_max &&\n",
    "                                             y >= commondata->disk_bounds_y_min && y <= commondata->disk_bounds_y_max &&\n",
    "                                             z >= commondata->disk_bounds_z_min && z <= commondata->disk_bounds_z_max);\n",
    "\n",
    "        if (is_inside_bounding_box) {\n",
    "            int idx1 = -1, idx2 = -1, idx3 = -1;\n",
    "            for (int j = 0; j < num_snapshots - 1; ++j) {\n",
    "                if (y_c[0] >= snapshot_times[j] && y_c[0] < snapshot_times[j+1]) {\n",
    "                    idx2 = j;\n",
    "                    break;\n",
    "                }\n",
    "            }\n",
    "            if(idx2 > 0 && idx2 < num_snapshots - 1) {\n",
    "                idx1 = idx2 - 1;\n",
    "                idx3 = idx2 + 1;\n",
    "            }\n",
    "\n",
    "            if (idx1 != -1) {\n",
    "                MassiveParticle neighbors_prev[3], neighbors_curr[3], neighbors_next[3];\n",
    "                const double query_pos[3] = {y_c[1], y_c[2], y_c[3]};\n",
    "                find_n_nearest_neighbors(&kdtree_snapshots[idx1], query_pos, 3, neighbors_prev);\n",
    "                find_n_nearest_neighbors(&kdtree_snapshots[idx2], query_pos, 3, neighbors_curr);\n",
    "                find_n_nearest_neighbors(&kdtree_snapshots[idx3], query_pos, 3, neighbors_next);\n",
    "\n",
    "                double max_dist_sq = 0.0;\n",
    "                for(int k=0; k<3; k++) {\n",
    "                    double d_sq_prev = SQR(query_pos[0] - neighbors_prev[k].pos[0]) + SQR(query_pos[1] - neighbors_prev[k].pos[1]) + SQR(query_pos[2] - neighbors_prev[k].pos[2]);\n",
    "                    double d_sq_curr = SQR(query_pos[0] - neighbors_curr[k].pos[0]) + SQR(query_pos[1] - neighbors_curr[k].pos[1]) + SQR(query_pos[2] - neighbors_curr[k].pos[2]);\n",
    "                    double d_sq_next = SQR(query_pos[0] - neighbors_next[k].pos[0]) + SQR(query_pos[1] - neighbors_next[k].pos[1]) + SQR(query_pos[2] - neighbors_next[k].pos[2]);\n",
    "                    if(d_sq_prev > max_dist_sq) max_dist_sq = d_sq_prev;\n",
    "                    if(d_sq_curr > max_dist_sq) max_dist_sq = d_sq_curr;\n",
    "                    if(d_sq_next > max_dist_sq) max_dist_sq = d_sq_next;\n",
    "                }\n",
    "                \n",
    "                snprintf(event_status_str, 50, \"In Box | Max_N_dist: %.2f\", sqrt(max_dist_sq));\n",
    "\n",
    "                if (sqrt(max_dist_sq) <= commondata->delta_r_max) {\n",
    "                    handle_disk_intersection(y_c, commondata, params, metric,\n",
    "                                             &kdtree_snapshots[idx1], &kdtree_snapshots[idx2], &kdtree_snapshots[idx3],\n",
    "                                             snapshot_times[idx1], snapshot_times[idx2], snapshot_times[idx3],\n",
    "                                             &final_blueprint_data);\n",
    "                    break;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if (i >= 2) {\n",
    "            event_detection_manager(y_p_p, y_p, y_c, lambda_p_p, lambda_p, lambda_c, commondata,\n",
    "                                    &on_positive_side_of_window_prev, &on_positive_side_of_source_prev,\n",
    "                                    &window_event, &source_plane_event);\n",
    "\n",
    "            if (source_plane_event.found) {\n",
    "                handle_source_plane_intersection(&source_plane_event, commondata, &final_blueprint_data);\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        const double r_sq = y_c[1]*y_c[1] + y_c[2]*y_c[2] + y_c[3]*y_c[3];\n",
    "        if (r_sq > commondata->r_escape * commondata->r_escape) {\n",
    "            final_blueprint_data.termination_type = TERMINATION_TYPE_CELESTIAL_SPHERE;\n",
    "            break;\n",
    "        }\n",
    "        \n",
    "        if (i % 500 == 0) {\n",
    "            printf(\"%4d | %11.4e | %10.4f | %10.4f | %10.4f | %10.4f | %s\\n\",\n",
    "                   i, lambda_c, y_c[0], y_c[1], y_c[2], y_c[3], event_status_str);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // --- Final Printout ---\n",
    "    printf(\"Termination: \");\n",
    "    if(final_blueprint_data.termination_type == TERMINATION_TYPE_DISK) {\n",
    "        printf(\"Found DISK HIT. I_obs=%.4e, lambda_obs=%.2f\\n\", \n",
    "               final_blueprint_data.stokes_I, final_blueprint_data.lambda_observed);\n",
    "        printf(\"  -> Event at (t=%.4f, x=%.4f, y=%.4f, z=%.4f)\\n\",\n",
    "               y_c[0], y_c[1], y_c[2], y_c[3]);\n",
    "    } else if (final_blueprint_data.termination_type == TERMINATION_TYPE_SOURCE_PLANE) {\n",
    "        printf(\"Found SOURCE PLANE at (ys=%.2f, zs=%.2f)\\n\", \n",
    "               final_blueprint_data.y_s, final_blueprint_data.z_s);\n",
    "        printf(\"  -> Event at (t=%.4f, x=%.4f, y=%.4f, z=%.4f)\\n\",\n",
    "               source_plane_event.t_event, source_plane_event.y_event[1], source_plane_event.y_event[2], source_plane_event.y_event[3]);\n",
    "    } else if (final_blueprint_data.termination_type == TERMINATION_TYPE_CELESTIAL_SPHERE) {\n",
    "        printf(\"Escaped to r > %.1f\\n\", commondata->r_escape);\n",
    "        printf(\"  -> Final position (t=%.4f, x=%.4f, y=%.4f, z=%.4f)\\n\",\n",
    "               y_c[0], y_c[1], y_c[2], y_c[3]);\n",
    "    } else {\n",
    "        printf(\"Failure (e.g., GSL error, runaway p^t, or max steps reached).\\n\");\n",
    "        printf(\"  -> Final position (t=%.4f, x=%.4f, y=%.4f, z=%.4f)\\n\",\n",
    "               y_c[0], y_c[1], y_c[2], y_c[3]);\n",
    "    }\n",
    "\n",
    "    for(int j=0; j<9; j++) { final_y_state[j] = y_c[j]; }\n",
    "    fclose(fp);\n",
    "    gsl_odeiv2_evolve_free(evol);\n",
    "    gsl_odeiv2_control_free(control);\n",
    "    gsl_odeiv2_step_free(step);\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, prefunc=prefunc, desc=desc, cfunc_type=cfunc_type, \n",
    "        name=name, params=params, body=body, \n",
    "        include_CodeParameters_h=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41563da7",
   "metadata": {},
   "source": [
    "<a id='data_processing'></a>\n",
    "### 7.f: Data Processing Engine\n",
    "\n",
    "This Python function generates the C engine `calculate_and_fill_blueprint_data_universal()`. Its sole purpose is to process the raw event data from a single completed ray trace and compute the final quantities that are saved to the `blueprint.bin` file. It acts as a translator, converting the 3D intersection points from the integration into a 2D coordinate system on both the window and source planes.\n",
    "\n",
    "The function orchestrates the following calculations:\n",
    "\n",
    "1.  **Window Plane Projection**: It takes the 3D Cartesian intersection point on the window plane and projects it onto the local 2D orthonormal basis vectors of the window (`n_x`, `n_y`) to get the final `(y_w, z_w)` coordinates.\n",
    "2.  **Source Plane Projection**: It performs a similar calculation for the source plane, projecting the 3D intersection point onto the source plane's local 2D basis to get the `(y_s, z_s)` coordinates. This basis is constructed from the source plane's normal vector and its \"up\" vector.\n",
    "3.  **Redshift Calculation**: It computes the gravitational redshift factor by calling the `g4DD_metric` dispatcher at both the window and source intersection points to get the $g_{00}$ component of the metric. The redshift is then given by $\\sqrt{g_{00}(\\text{window}) / g_{00}(\\text{source})}$.\n",
    "4.  **Return Struct**: It populates and returns a `blueprint_data_t` struct containing all these calculated values, along with a `found` flag that is set to `true` only if all calculations are successful and finite.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cee235eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V10_6_Python_to_C_via_NRPy.ipynb\n",
    "# In cell [cee235eb]\n",
    "\n",
    "def calculate_and_fill_blueprint_data_universal():\n",
    "    \"\"\"\n",
    "    Generates the C engine to process event data. This version removes the\n",
    "    unused 'metric' parameter to eliminate compiler warnings.\n",
    "    \"\"\"\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Processes raw event data to compute final blueprint quantities based on termination type.\"\"\"\n",
    "    name = \"calculate_and_fill_blueprint_data_universal\"\n",
    "    cfunc_type = \"blueprint_data_t\"\n",
    "    # CORRECTED: Removed the unused 'metric' parameter.\n",
    "    params = \"\"\"const commondata_struct *restrict commondata, const params_struct *restrict params,\n",
    "                const termination_type_t term_type,\n",
    "                const event_data_struct *restrict window_event,\n",
    "                const event_data_struct *restrict source_event,\n",
    "                const double final_y_state[9],\n",
    "                const double window_center[3], const double n_x[3], const double n_y[3],\n",
    "                const double source_plane_center[3], const double source_plane_normal[3],\n",
    "                const double source_up_vector[3]\"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // Initialize all fields to zero.\n",
    "    blueprint_data_t result = {0};\n",
    "    result.termination_type = term_type;\n",
    "\n",
    "    // Step 1: Always try to fill window plane data if the event was found.\n",
    "    if (window_event->found) {\n",
    "        const double pos_w_cart[3] = {window_event->y_event[1], window_event->y_event[2], window_event->y_event[3]};\n",
    "        const double vec_w[3] = {pos_w_cart[0] - window_center[0], pos_w_cart[1] - window_center[1], pos_w_cart[2] - window_center[2]};\n",
    "        result.y_w = vec_w[0]*n_x[0] + vec_w[1]*n_x[1] + vec_w[2]*n_x[2];\n",
    "        result.z_w = vec_w[0]*n_y[0] + vec_w[1]*n_y[1] + vec_w[2]*n_y[2];\n",
    "        result.L_w = window_event->y_event[8];\n",
    "        result.t_w = window_event->t_event; \n",
    "    }\n",
    "\n",
    "    // Step 2: Fill remaining data based on how the ray terminated.\n",
    "    if (term_type == TERMINATION_TYPE_SOURCE_PLANE) {\n",
    "        double s_z[3] = {source_plane_normal[0], source_plane_normal[1], source_plane_normal[2]};\n",
    "        double s_x[3] = {source_up_vector[1]*s_z[2] - source_up_vector[2]*s_z[1], \n",
    "                         source_up_vector[2]*s_z[0] - source_up_vector[0]*s_z[2], \n",
    "                         source_up_vector[0]*s_z[1] - source_up_vector[1]*s_z[0]};\n",
    "        double mag_s_x = sqrt(s_x[0]*s_x[0] + s_x[1]*s_x[1] + s_x[2]*s_x[2]);\n",
    "        if (mag_s_x < 1e-9) {\n",
    "            double temp_up[3] = {1.0, 0.0, 0.0};\n",
    "            if (fabs(s_z[0]) > 0.999) { temp_up[0] = 0.0; temp_up[1] = 1.0; temp_up[2] = 0.0; }\n",
    "            s_x[0] = temp_up[1]*s_z[2] - temp_up[2]*s_z[1];\n",
    "            s_x[1] = temp_up[2]*s_z[0] - temp_up[0]*s_z[2];\n",
    "            s_x[2] = temp_up[0]*s_z[1] - temp_up[1]*s_z[0];\n",
    "            mag_s_x = sqrt(s_x[0]*s_x[0] + s_x[1]*s_x[1] + s_x[2]*s_x[2]);\n",
    "        }\n",
    "        const double inv_mag_s_x = 1.0 / mag_s_x;\n",
    "        s_x[0] *= inv_mag_s_x; s_x[1] *= inv_mag_s_x; s_x[2] *= inv_mag_s_x;\n",
    "        double s_y[3] = {s_z[1]*s_x[2] - s_z[2]*s_x[1], s_z[2]*s_x[0] - s_z[0]*s_x[2], s_z[0]*s_x[1] - s_z[1]*s_x[0]};\n",
    "        const double pos_s_cart[3] = {source_event->y_event[1], source_event->y_event[2], source_event->y_event[3]};\n",
    "        const double vec_s[3] = {pos_s_cart[0] - source_plane_center[0], pos_s_cart[1] - source_plane_center[1], pos_s_cart[2] - source_plane_center[2]};\n",
    "        result.y_s = vec_s[0]*s_x[0] + vec_s[1]*s_x[1] + vec_s[2]*s_x[2];\n",
    "        result.z_s = vec_s[0]*s_y[0] + vec_s[1]*s_y[1] + vec_s[2]*s_y[2];\n",
    "        result.L_s = source_event->y_event[8];\n",
    "        result.t_s = source_event->t_event; \n",
    "    } else if (term_type == TERMINATION_TYPE_CELESTIAL_SPHERE) {\n",
    "        const double x = final_y_state[1];\n",
    "        const double y = final_y_state[2];\n",
    "        const double z = final_y_state[3];\n",
    "        const double r = sqrt(x*x + y*y + z*z);\n",
    "        if (r > 1e-9) {\n",
    "            result.final_theta = acos(z / r);\n",
    "            result.final_phi = atan2(y, x);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return result;\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, cfunc_type=cfunc_type, name=name, params=params, body=body, include_CodeParameters_h=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c649f149",
   "metadata": {},
   "source": [
    "<a id='main_scanner_loop'></a>\n",
    "### 7.g: Main Scanner Loop and Data Saving\n",
    "\n",
    "This Python function generates the top-level orchestrator for the entire ray-tracing scan: `run_scan_and_save_blueprint_universal()`. It manages the parallel execution of the main loop and handles writing the final data to disk.\n",
    "\n",
    "1.  **Setup**: It retrieves scene parameters (camera position, plane normals, etc.) from the `commondata` struct and allocates a memory buffer to hold the `blueprint_data_t` results for all rays.\n",
    "2.  **Basis Construction**: It constructs the orthonormal basis vectors for the camera's window plane. These vectors (`n_x`, `n_y`) define the local 2D coordinate system on the window and are used to calculate the aiming point for each ray.\n",
    "3.  **Parallel Loop**: It enters the main scanner loop, which is parallelized using an `#pragma omp parallel for` directive. This powerful feature distributes the work of tracing millions of rays across all available CPU cores, dramatically speeding up the simulation.\n",
    "4.  **Orchestration per Ray**: Inside the loop, for each ray, it performs the full sequence of operations:\n",
    "    a.  Calculates the 3D `target_pos` on the window plane for the current pixel.\n",
    "    b.  Calls `set_initial_conditions_cartesian()` to get the complete initial state vector.\n",
    "    c.  Calls `integrate_single_photon_cartesian()` to trace the ray's path through spacetime.\n",
    "    d.  Calls `calculate_and_fill_blueprint_data_universal()` to process the results of the trace.\n",
    "    e.  Stores the final `blueprint_data_t` struct in the results buffer.\n",
    "5.  **Write to Disk**: After the parallel loop completes, it opens the `blueprint.bin` file in binary write mode (`\"wb\"`) and writes the entire buffer of results to disk. This is done using `fwrite`, which is highly efficient for large data blocks.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d258c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scan_and_save_blueprint_universal():\n",
    "    \"\"\"\n",
    "    Generates the C orchestrator for the full, parallelized scanner loop.\n",
    "    \n",
    "    This final version robustly loads all k-d tree snapshots by first reading\n",
    "    all filenames, sorting them numerically, and then loading the data in the\n",
    "    correct temporal order.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C orchestrator: run_scan_and_save_blueprint_universal()...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"stdio.h\", \"stdlib.h\", \"omp.h\", \"<dirent.h>\", \"<string.h>\", \"<math.h>\"]\n",
    "    desc = r\"\"\"@brief Orchestrates the full, parallelized scanner loop for radiative transfer.\"\"\"\n",
    "    name = \"run_scan_and_save_blueprint_universal\"\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const metric_params *restrict metric\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // --- Phase 1: Load all k-d tree snapshots into memory ---\n",
    "    const char* snapshot_dir_path = \"../processed_snapshots\";\n",
    "    printf(\"Loading k-d tree snapshots from '%s'...\\n\", snapshot_dir_path);\n",
    "    DIR *dir;\n",
    "    struct dirent *ent;\n",
    "    int num_snapshots = 0;\n",
    "    // First pass: count the number of snapshot files\n",
    "    if ((dir = opendir(snapshot_dir_path)) != NULL) {\n",
    "        while ((ent = readdir(dir)) != NULL) {\n",
    "            if (strstr(ent->d_name, \".kdtree.bin\") != NULL) {\n",
    "                num_snapshots++;\n",
    "            }\n",
    "        }\n",
    "        closedir(dir);\n",
    "    } else {\n",
    "        perror(\"Could not open snapshot directory\");\n",
    "        exit(1);\n",
    "    }\n",
    "\n",
    "    if (num_snapshots < 3) {\n",
    "        fprintf(stderr, \"Error: At least 3 .kdtree.bin files are required for interpolation. Found %d.\\n\", num_snapshots);\n",
    "        exit(1);\n",
    "    }\n",
    "\n",
    "    // Allocate memory to store the filenames\n",
    "    char **filenames = (char **)malloc(sizeof(char *) * num_snapshots);\n",
    "    if (filenames == NULL) { fprintf(stderr, \"Error: Failed to allocate memory for filenames.\\n\"); exit(1); }\n",
    "\n",
    "    // Second pass: read filenames into an array\n",
    "    dir = opendir(snapshot_dir_path);\n",
    "    int count = 0;\n",
    "    while ((ent = readdir(dir)) != NULL) {\n",
    "        if (strstr(ent->d_name, \".kdtree.bin\") != NULL) {\n",
    "            filenames[count] = strdup(ent->d_name);\n",
    "            count++;\n",
    "        }\n",
    "    }\n",
    "    closedir(dir);\n",
    "\n",
    "    // Sort the filenames numerically using the qsort function and our custom comparator\n",
    "    qsort(filenames, num_snapshots, sizeof(char *), compare_filenames);\n",
    "\n",
    "    // Now, load the snapshots in the correct, sorted order\n",
    "    CustomKDTree *kdtree_snapshots = (CustomKDTree *)malloc(sizeof(CustomKDTree) * num_snapshots);\n",
    "    double *snapshot_times = (double *)malloc(sizeof(double) * num_snapshots);\n",
    "    if (kdtree_snapshots == NULL || snapshot_times == NULL) { fprintf(stderr, \"Error: Failed to allocate memory for snapshots.\\n\"); exit(1); }\n",
    "    \n",
    "    for (int i = 0; i < num_snapshots; ++i) {\n",
    "        char filepath[512];\n",
    "        snprintf(filepath, sizeof(filepath), \"%s/%s\", snapshot_dir_path, filenames[i]);\n",
    "        if (load_kdtree_snapshot(filepath, &kdtree_snapshots[i]) != 0) {\n",
    "            fprintf(stderr, \"Error: Failed to load snapshot %s\\n\", filepath);\n",
    "            exit(1);\n",
    "        }\n",
    "        int snapshot_index;\n",
    "        sscanf(filenames[i], \"mass_blueprint_t_%d.kdtree.bin\", &snapshot_index);\n",
    "        snapshot_times[i] = (double)snapshot_index * commondata->mass_snapshot_every_t;\n",
    "        free(filenames[i]); // Free the string duplicated by strdup\n",
    "    }\n",
    "    free(filenames); // Free the array of pointers\n",
    "    printf(\"Successfully loaded and sorted %d snapshots.\\n\", num_snapshots);\n",
    "\n",
    "    // --- Phase 2: Setup scanner and camera geometry (Identical to original V11.2) ---\n",
    "    const long int num_rays = (long int)commondata->scan_density * commondata->scan_density;\n",
    "    blueprint_data_t *results_buffer = (blueprint_data_t *)malloc(sizeof(blueprint_data_t) * num_rays);\n",
    "    if (results_buffer == NULL) { exit(1); }\n",
    "    const double camera_pos[3] = {commondata->camera_pos_x, commondata->camera_pos_y, commondata->camera_pos_z};\n",
    "    const double window_center[3] = {commondata->window_center_x, commondata->window_center_y, commondata->window_center_z};\n",
    "    \n",
    "    double n_z[3] = {window_center[0] - camera_pos[0], window_center[1] - camera_pos[1], window_center[2] - camera_pos[2]};\n",
    "    double mag_n_z = sqrt(n_z[0]*n_z[0] + n_z[1]*n_z[1] + n_z[2]*n_z[2]);\n",
    "    n_z[0] /= mag_n_z; n_z[1] /= mag_n_z; n_z[2] /= mag_n_z;\n",
    "    \n",
    "    const double guide_up[3] = {commondata->window_up_vec_x, commondata->window_up_vec_y, commondata->window_up_vec_z};\n",
    "    double n_x[3] = {n_z[1]*guide_up[2] - n_z[2]*guide_up[1], n_z[2]*guide_up[0] - n_z[0]*guide_up[2], n_z[0]*guide_up[1] - n_z[1]*guide_up[0]};\n",
    "    double mag_n_x = sqrt(n_x[0]*n_x[0] + n_x[1]*n_x[1] + n_x[2]*n_x[2]);\n",
    "    if (mag_n_x < 1e-9) {\n",
    "        double alternative_up[3] = {0.0, 1.0, 0.0};\n",
    "        if (fabs(n_z[1]) > 0.999) { alternative_up[1] = 0.0; alternative_up[2] = 1.0; }\n",
    "        n_x[0] = alternative_up[1]*n_z[2] - alternative_up[2]*n_z[1];\n",
    "        n_x[1] = alternative_up[2]*n_z[0] - alternative_up[0]*n_z[2];\n",
    "        n_x[2] = alternative_up[0]*n_z[1] - alternative_up[1]*n_z[0];\n",
    "        mag_n_x = sqrt(n_x[0]*n_x[0] + n_x[1]*n_x[1] + n_x[2]*n_x[2]);\n",
    "    }\n",
    "    n_x[0] /= mag_n_x; n_x[1] /= mag_n_x; n_x[2] /= mag_n_x;\n",
    "    double n_y[3] = {n_z[1]*n_x[2] - n_z[2]*n_x[1], n_z[2]*n_x[0] - n_z[0]*n_x[2], n_z[0]*n_x[1] - n_z[1]*n_x[0]};\n",
    "    \n",
    "    const double t_max = 2000.0;\n",
    "\n",
    "    printf(\"Starting scan for %s metric (a=%.2f) with %d x %d rays.\\n\", (commondata->a_spin == 0.0) ? \"Schwarzschild\" : \"Kerr\", commondata->a_spin, commondata->scan_density, commondata->scan_density);\n",
    "    \n",
    "    // --- Phase 3: Main Parallel Loop ---\n",
    "    #pragma omp parallel for schedule(dynamic)\n",
    "    for (long int i = 0; i < num_rays; i++) {\n",
    "        const int j = i / commondata->scan_density;\n",
    "        const int k = i % commondata->scan_density;\n",
    "        double y_start[9];\n",
    "        \n",
    "        const double x_pix = -commondata->window_size/2.0 + (k + 0.5) * (commondata->window_size / commondata->scan_density);\n",
    "        const double y_pix = -commondata->window_size/2.0 + (j + 0.5) * (commondata->window_size / commondata->scan_density);\n",
    "        double target_pos[3] = {window_center[0] + x_pix*n_x[0] + y_pix*n_y[0],\n",
    "                                 window_center[1] + x_pix*n_x[1] + y_pix*n_y[1],\n",
    "                                 window_center[2] + x_pix*n_x[2] + y_pix*n_y[2]};\n",
    "        \n",
    "        set_initial_conditions_cartesian(commondata, params, metric, camera_pos, target_pos, y_start);\n",
    "        \n",
    "        results_buffer[i] = integrate_single_photon(\n",
    "            commondata, params, metric, y_start, t_max,\n",
    "            kdtree_snapshots, snapshot_times, num_snapshots);\n",
    "    }\n",
    "    \n",
    "    // --- Phase 4: Cleanup and Save ---\n",
    "    printf(\"Scan finished. Writing %ld ray results to light_blueprint.bin...\\n\", num_rays);\n",
    "    FILE *fp_blueprint = fopen(\"light_blueprint.bin\", \"wb\");\n",
    "    if (fp_blueprint == NULL) { exit(1); }\n",
    "    fwrite(results_buffer, sizeof(blueprint_data_t), num_rays, fp_blueprint);\n",
    "    fclose(fp_blueprint);\n",
    "    free(results_buffer);\n",
    "\n",
    "    // Unload all snapshots\n",
    "    for (int i = 0; i < num_snapshots; ++i) {\n",
    "        unload_kdtree_snapshot(&kdtree_snapshots[i]);\n",
    "    }\n",
    "    free(kdtree_snapshots);\n",
    "    free(snapshot_times);\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body, include_CodeParameters_h=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c4eaf0",
   "metadata": {},
   "source": [
    "<a id='main_entry_point'></a>\n",
    "### 7.h: The `main()` C Function Entry Point\n",
    "\n",
    "This function registers the C `main()` function, which serves as the entry point for the entire executable program. In our final architecture, `main()` is a pure **orchestrator**; it contains no physics logic itself. Instead, it calls other functions to set up the simulation, run the integration, and handle the output.\n",
    "\n",
    "The `main` function performs the full sequence of operations required for a complete ray-tracing run:\n",
    "\n",
    "1.  **Declare Data Structures**: It declares instances of all necessary structs (`commondata_struct`, `params_struct`, `metric_params`).\n",
    "2.  **Initialize Parameters**: It initializes the parameters in a two-step process that ensures runtime flexibility:\n",
    "    *   First, it calls `commondata_struct_set_to_default()` to populate the `commondata` struct with the default values that were compiled into the executable (e.g., `M_scale = 1.0`).\n",
    "    *   Next, it calls `cmdline_input_and_parfile_parser()`. This function reads the project's `.par` file and any command-line arguments, and it will **override** the compiled-in defaults with any values provided by the user at runtime.\n",
    "3.  **Print Simulation Parameters**: It prints a detailed summary of all the final simulation parameters to the console. This is crucial for verification and for creating a record of the exact settings used for a given run. It also suggests a descriptive output filename and prints the full command-line arguments needed to reproduce the run exactly.\n",
    "4.  **Run Scanner Loop**: It calls the main orchestrator, `run_scan_and_save_blueprint_universal()`, to execute the full ray-tracing scan.\n",
    "5.  **Cleanup**: It prints a final status message and returns 0, indicating successful execution.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4661b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Generates the main() C function.\n",
    "    \n",
    "    This final version includes a robust sorting routine for snapshot filenames\n",
    "    in the debug path to ensure the time-series data is loaded in the correct order.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C entry point: main()...\")\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"<dirent.h>\", \"<string.h>\", \"<stdlib.h>\", \"<stdio.h>\"]\n",
    "    \n",
    "    desc = r\"\"\"@brief Main entry point. Runs a full scan or a single-ray debug trace.\"\"\"\n",
    "    cfunc_type = \"int\"\n",
    "    name = \"main\"\n",
    "    params = \"int argc, const char *argv[]\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // --- Step 1: Set up parameters and structs ---\n",
    "    commondata_struct commondata;\n",
    "    params_struct params;\n",
    "    metric_params metric;\n",
    "    \n",
    "    commondata_struct_set_to_default(&commondata);\n",
    "    cmdline_input_and_parfile_parser(&commondata, argc, argv);\n",
    "    \n",
    "    if (commondata.metric_choice == 1) {\n",
    "        metric.type = Schwarzschild_Standard;\n",
    "        if (commondata.a_spin != 0.0) {\n",
    "            printf(\"Warning: Standard Schwarzschild metric selected, but a_spin != 0. Forcing a_spin = 0.0 for this run.\\n\");\n",
    "            commondata.a_spin = 0.0;\n",
    "        }\n",
    "    } else {\n",
    "        metric.type = (commondata.a_spin == 0.0) ? Schwarzschild : Kerr;\n",
    "    }\n",
    "\n",
    "    // --- Step 2: Check for debug mode ---\n",
    "    if (commondata.debug_mode) {\n",
    "        // --- SINGLE-RAY DEBUG MODE ---\n",
    "        printf(\">>> RUNNING IN SINGLE-RAY DEBUG MODE <<<\\n\");\n",
    "        \n",
    "        const char* snapshot_dir_path = \"../processed_snapshots\";\n",
    "        DIR *dir;\n",
    "        struct dirent *ent;\n",
    "        int num_snapshots = 0;\n",
    "        if ((dir = opendir(snapshot_dir_path)) != NULL) {\n",
    "            while ((ent = readdir(dir)) != NULL) {\n",
    "                if (strstr(ent->d_name, \".kdtree.bin\") != NULL) num_snapshots++;\n",
    "            }\n",
    "            closedir(dir);\n",
    "        } else {\n",
    "            perror(\"Could not open snapshot directory\");\n",
    "            exit(1);\n",
    "        }\n",
    "\n",
    "        if (num_snapshots < 3) { \n",
    "            fprintf(stderr, \"Error: At least 3 snapshots required for debug run. Found %d.\\n\", num_snapshots); \n",
    "            exit(1); \n",
    "        }\n",
    "\n",
    "        // Allocate memory to store the filenames to be sorted\n",
    "        char **filenames = (char **)malloc(sizeof(char *) * num_snapshots);\n",
    "        if (filenames == NULL) { fprintf(stderr, \"Error: Failed to allocate memory for filenames.\\n\"); exit(1); }\n",
    "\n",
    "        dir = opendir(snapshot_dir_path);\n",
    "        int count = 0;\n",
    "        while ((ent = readdir(dir)) != NULL) {\n",
    "            if (strstr(ent->d_name, \".kdtree.bin\") != NULL) {\n",
    "                filenames[count] = strdup(ent->d_name);\n",
    "                count++;\n",
    "            }\n",
    "        }\n",
    "        closedir(dir);\n",
    "\n",
    "        // Sort the filenames numerically using the qsort function\n",
    "        qsort(filenames, num_snapshots, sizeof(char *), compare_filenames);\n",
    "\n",
    "        // Allocate memory for the snapshot data and times\n",
    "        CustomKDTree *kdtree_snapshots = (CustomKDTree *)malloc(sizeof(CustomKDTree) * num_snapshots);\n",
    "        double *snapshot_times = (double *)malloc(sizeof(double) * num_snapshots);\n",
    "        if (kdtree_snapshots == NULL || snapshot_times == NULL) { fprintf(stderr, \"Error: Failed to allocate memory for snapshots.\\n\"); exit(1); }\n",
    "        \n",
    "        // Load the snapshots in the correct, sorted order\n",
    "        for (int i = 0; i < num_snapshots; ++i) {\n",
    "            char filepath[512];\n",
    "            snprintf(filepath, sizeof(filepath), \"%s/%s\", snapshot_dir_path, filenames[i]);\n",
    "            if (load_kdtree_snapshot(filepath, &kdtree_snapshots[i]) != 0) {\n",
    "                fprintf(stderr, \"Error: Failed to load snapshot %s\\n\", filepath);\n",
    "                exit(1);\n",
    "            }\n",
    "            int snapshot_index;\n",
    "            sscanf(filenames[i], \"mass_blueprint_t_%d.kdtree.bin\", &snapshot_index);\n",
    "            snapshot_times[i] = (double)snapshot_index * commondata.mass_snapshot_every_t;\n",
    "            free(filenames[i]); // Free the string duplicated by strdup\n",
    "        }\n",
    "        free(filenames); // Free the array of pointers\n",
    "\n",
    "        printf(\"Loaded and sorted %d snapshots for debug run.\\n\", num_snapshots);\n",
    "\n",
    "        const double camera_pos[3] = {commondata.camera_pos_x, commondata.camera_pos_y, commondata.camera_pos_z};\n",
    "        const double target_pos[3] = {commondata.window_center_x, commondata.window_center_y, commondata.window_center_z};\n",
    "        \n",
    "        double y_start[9], final_y_state[9];\n",
    "        set_initial_conditions_cartesian(&commondata, &params, &metric, camera_pos, target_pos, y_start);\n",
    "        \n",
    "        integrate_single_photon_DEBUG(&commondata, &params, &metric, y_start, 2000.0,\n",
    "                                      kdtree_snapshots, snapshot_times, num_snapshots, final_y_state);\n",
    "        \n",
    "        // Unload snapshots and free memory\n",
    "        for (int i = 0; i < num_snapshots; ++i) {\n",
    "            unload_kdtree_snapshot(&kdtree_snapshots[i]);\n",
    "        }\n",
    "        free(kdtree_snapshots);\n",
    "        free(snapshot_times);\n",
    "        printf(\"\\nDebug run finished. Trajectory saved to 'photon_path.txt'.\\n\");\n",
    "\n",
    "    } else {\n",
    "        // --- FULL SCANNER PRODUCTION MODE ---\n",
    "        run_scan_and_save_blueprint_universal(&commondata, &params, &metric);\n",
    "        printf(\"\\nScan complete. Blueprint data saved to light_blueprint.bin\\n\");\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "    \"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(includes=includes, desc=desc, cfunc_type=cfunc_type, name=name, params=params, body=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec8cb55",
   "metadata": {},
   "source": [
    "<a id='assemble_project'></a>\n",
    "# Step 8: Project Assembly and Compilation\n",
    "\n",
    "This is the final phase of the notebook for C code generation. It brings all the previously defined pieces together to construct the complete, compilable C project.\n",
    "\n",
    "<a id='register_structs'></a>\n",
    "### 8.a: Custom Data Structures\n",
    "\n",
    "This function defines all the necessary C `struct` and `enum` types for the project. It then registers them with the BHaH infrastructure, which makes these custom data types available to all other C files via the master header `BHaH_defines.h`.\n",
    "\n",
    "The function `register_custom_structures_and_params` performs the following actions:\n",
    "1.  **Generates `connection_struct`**: It programmatically creates the C `typedef` for the `connection_struct`. This struct contains 40 `double` members to hold the unique Christoffel symbols ($\\Gamma^{\\alpha}_{\\mu\\nu}$).\n",
    "2.  **Generates `metric_struct`**: It follows the same programmatic pattern to create the `metric_struct`, which contains 10 `double` members to hold the unique components of the metric tensor ($g_{\\mu\\nu}$).\n",
    "3.  **Defines Other Structs**: It defines the C `typedef`s for all other data structures (`Metric_t` enum, `metric_params`, the GSL \"carrier\" struct `gsl_params`, the `event_data_struct` for interpolation results, and the final `blueprint_data_t` for output) as Python strings.\n",
    "4.  **Registers with `BHaH`**: For each `struct` or `enum`, it calls `Bdefines_h.register_BHaH_defines()`. This function adds the C code string to a global registry. When `Bdefines_h.output_BHaH_defines_h()` is called later in the build process, it will automatically find and include all these registered definitions in the final header file.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.declarerank3(...)`**: Previously introduced. Used here to programmatically generate the list of C variable names for the members of the `connection_struct`.\n",
    "*   **`nrpy.infrastructures.BHaH.BHaH_defines_h.register_BHaH_defines(name, C_code_string)`**:\n",
    "    *   **Source File**: `nrpy/infrastructures/BHaH/BHaH_defines_h.py`\n",
    "    *   **Description**: This function adds a given C-code string (which should define a `struct`, `enum`, or other C-level type) to a global registry, associated with a given name. This registry is later used to generate the master `BHaH_defines.h` header file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ef03c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_custom_structures_and_params():\n",
    "    \"\"\"\n",
    "    Generates C code for all custom structs and enums, then registers them with BHaH.\n",
    "    \n",
    "    CORRECTED to properly generate the connection_struct members.\n",
    "    UPDATED to add Stokes I and observed wavelength to the final blueprint struct.\n",
    "    \"\"\"\n",
    "    print(\"Registering custom C data structures...\")\n",
    "\n",
    "    # --- metric_struct generation (Correct) ---\n",
    "    metric_components = [f\"g{nu}{mu}\" for nu in range(4) for mu in range(nu, 4)]\n",
    "    metric_struct_str = \"typedef struct { double \" + \"; double \".join(metric_components) + \"; } metric_struct;\"\n",
    "    \n",
    "    # --- CORRECTED connection_struct generation ---\n",
    "    connection_components = [f\"Gamma4UDD{i}{j}{k}\" for i in range(4) for j in range(4) for k in range(j, 4)]\n",
    "    connections_struct_str = \"typedef struct { double \" + \"; double \".join(connection_components) + \"; } connection_struct;\"\n",
    "\n",
    "    other_structs = r\"\"\"\n",
    "    typedef enum { Schwarzschild, Kerr, Numerical, Schwarzschild_Standard } Metric_t;\n",
    "    typedef struct { Metric_t type; } metric_params;\n",
    "    typedef struct { const commondata_struct *commondata; const params_struct *params; const metric_params *metric; } gsl_params;\n",
    "    typedef double (*event_function_t)(const double y[9], void *event_params);\n",
    "    typedef struct {\n",
    "        bool found;\n",
    "        double lambda_event;\n",
    "        double t_event;\n",
    "        double y_event[9];\n",
    "    } event_data_struct;\n",
    "\n",
    "    // UPDATED ENUM with a new termination type for the disk.\n",
    "    typedef enum {\n",
    "        TERMINATION_TYPE_FAILURE,\n",
    "        TERMINATION_TYPE_DISK,\n",
    "        TERMINATION_TYPE_SOURCE_PLANE,\n",
    "        TERMINATION_TYPE_CELESTIAL_SPHERE\n",
    "    } termination_type_t;\n",
    "\n",
    "    // The blueprint struct is already capable of storing all possible outcomes.\n",
    "    typedef struct {\n",
    "        termination_type_t termination_type;\n",
    "        double y_w;\n",
    "        double z_w;\n",
    "        // Fields for DISK hits\n",
    "        double stokes_I;\n",
    "        double lambda_observed;\n",
    "        // Fields for SOURCE PLANE hits\n",
    "        double y_s;\n",
    "        double z_s;\n",
    "        // Fields for CELESTIAL SPHERE hits\n",
    "        double final_theta;\n",
    "        double final_phi;\n",
    "        // Diagnostic fields\n",
    "        double L_w;\n",
    "        double t_w;\n",
    "        double L_s;\n",
    "        double t_s;\n",
    "    } __attribute__((packed)) blueprint_data_t;\n",
    "    \"\"\"\n",
    "    Bdefines_h.register_BHaH_defines(\"data_structures_and_enums\", f\"{metric_struct_str}\\n{connections_struct_str}\\n{other_structs}\")\n",
    "    print(\" -> Registered all necessary data structures, including the new termination_type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae60808",
   "metadata": {},
   "source": [
    "# Kdtree structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "956502ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_kdtree_c_structs():\n",
    "    \"\"\"\n",
    "    Generates and registers the C structs needed for loading and querying\n",
    "    the pre-processed k-d tree snapshot files.\n",
    "    \"\"\"\n",
    "    print(\" -> Registering C data structures for k-d tree handling...\")\n",
    "\n",
    "    # This C struct must EXACTLY match the Python numpy.dtype and the\n",
    "    # mass_particle_state_t struct from the mass_integrator.\n",
    "    # It represents the data for a single particle in the .kdtree.bin file.\n",
    "    massive_particle_struct_str = r\"\"\"\n",
    "    typedef struct {\n",
    "        int id;\n",
    "        double pos[3];\n",
    "        double u[4];\n",
    "        double lambda_rest;\n",
    "        float j_intrinsic;\n",
    "    } __attribute__((packed)) MassiveParticle;\n",
    "    \"\"\"\n",
    "\n",
    "    # This C struct acts as a \"handle\" to a memory-mapped k-d tree file.\n",
    "    # It holds pointers to the key data arrays within the mapped memory region.\n",
    "    kdtree_handle_struct_str = r\"\"\"\n",
    "    typedef struct {\n",
    "        // Pointers to the data within the memory-mapped file\n",
    "        int32_t*       node_metadata;   // Points to the start of Payload 1 (split axes)\n",
    "        MassiveParticle* particle_data;   // Points to the start of Payload 2 (reordered particles)\n",
    "\n",
    "        // Information from the header\n",
    "        uint64_t num_particles;\n",
    "        uint64_t dimensions;\n",
    "\n",
    "        // For cleanup\n",
    "        void*    original_mmap_ptr; // The original pointer returned by mmap\n",
    "        size_t   file_size;         // The total size of the mapped file\n",
    "    } CustomKDTree;\n",
    "    \"\"\"\n",
    "    \n",
    "    # This struct will be used to manage the \"Winners' Circle\" during the search.\n",
    "    winners_circle_struct_str = r\"\"\"\n",
    "#define MAX_NEIGHBORS 10 // A compile-time max for the nearest-neighbor search\n",
    "    typedef struct {\n",
    "        int indices[MAX_NEIGHBORS];\n",
    "        double sq_distances[MAX_NEIGHBORS];\n",
    "        int count;\n",
    "        int n_wanted;\n",
    "    } WinnersCircle;\n",
    "    \"\"\"\n",
    "\n",
    "    # Register all structs in a single block\n",
    "    Bdefines_h.register_BHaH_defines(\n",
    "        \"kdtree_structs\",\n",
    "        f\"{massive_particle_struct_str}\\n{kdtree_handle_struct_str}\\n{winners_circle_struct_str}\"\n",
    "    )\n",
    "    print(\"    ... Registered C structs: MassiveParticle, CustomKDTree, WinnersCircle.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9583e0f3",
   "metadata": {},
   "source": [
    "<a id='final_build'></a>\n",
    "### 8.b: Final Build Command\n",
    "\n",
    "This is the main execution block of the notebook. It brings all the previously defined Python functions together and calls them in a precise sequence to generate every file needed for the final, compilable C project.\n",
    "\n",
    "The sequence of operations is critical, as later steps depend on the files and registrations created by earlier ones:\n",
    "\n",
    "1.  **Register All Components**: It calls all the C-generating Python functions that we have defined throughout the notebook (`register_custom_structures_and_params`, `g4DD_kerr_schild`, `main_production`, etc.). This populates `nrpy`'s internal library (`cfc.CFunction_dict`) with the complete definitions for all our custom C data structures and functions. At this stage, no files have been written yet; everything exists only in memory.\n",
    "\n",
    "2.  **Generate Parameter Handling Files**: It calls the necessary functions from the BHaH infrastructure to set up the parameter system:\n",
    "    *   `CPs.write_CodeParameters_h_files()`: Generates `set_CodeParameters.h` and its variants.\n",
    "    *   `CPs.register_CFunctions_params_commondata_struct_set_to_default()`: Registers the C functions that initialize the parameter structs with their compiled-in default values.\n",
    "    *   `cmdline_input_and_parfiles.generate_default_parfile()`: Creates the `project_name.par` file.\n",
    "    *   `cmdline_input_and_parfiles.register_CFunction_cmdline_input_and_parfile_parser()`: Registers the C function that reads the `.par` file and command-line arguments at runtime.\n",
    "\n",
    "3.  **Generate `BHaH_defines.h`**: It calls `Bdefines_h.output_BHaH_defines_h()`. This function scans `nrpy`'s internal library for all registered data structures (like `metric_struct` and `event_data_struct`) and writes them into the master C header file, `BHaH_defines.h`.\n",
    "\n",
    "4.  **Copy Helper Files**: It calls `gh.copy_files()` to copy any necessary dependency files (like `simd_intrinsics.h`) from the `nrpy` library installation into our project directory.\n",
    "\n",
    "5.  **Generate C Source, Prototypes, and Makefile**: It calls the final, most important build function, `Makefile.output_CFunctions_function_prototypes_and_construct_Makefile()`. This powerful function performs three tasks at once:\n",
    "    *   It iterates through every C function registered with `nrpy.c_function.register_CFunction` and writes each one into its own `.c` file (e.g., `main.c`, `connections.c`).\n",
    "    *   It generates `BHaH_function_prototypes.h`, a header file containing the function declarations (prototypes) for all the generated `.c` files. This is crucial as it allows the different C files to call functions defined in one another.\n",
    "    *   It constructs the `Makefile`, which contains the compilation and linking instructions needed to build the final executable program. It is also configured to automatically link against the required GSL and OpenMP libraries.\n",
    "\n",
    "After this cell is run, a complete, self-contained, and ready-to-compile C project will exist in the output directory.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.infrastructures.BHaH.CodeParameters.write_CodeParameters_h_files(project_dir)`**:\n",
    "    *   **Source File**: `nrpy/infrastructures/BHaH/CodeParameters.py`\n",
    "    *   **Description**: Generates the `set_CodeParameters.h` header files, which contain the C code for unpacking parameters into local variables (the \"Triple-Lock\" system).\n",
    "\n",
    "*   **`nrpy.infrastructures.BHaH.CodeParameters.register_CFunctions_params_commondata_struct_set_to_default()`**:\n",
    "    *   **Source File**: `nrpy/infrastructures/BHaH/CodeParameters.py`\n",
    "    *   **Description**: Registers the C functions that initialize the `params_struct` and `commondata_struct` with their compiled-in default values.\n",
    "\n",
    "*   **`nrpy.infrastructures.BHaH.cmdline_input_and_parfiles.generate_default_parfile(project_dir, project_name)`**:\n",
    "    *   **Source File**: `nrpy/infrastructures/BHaH/cmdline_input_and_parfiles.py`\n",
    "    *   **Description**: Creates the `project_name.par` file, populated with all parameters that have `add_to_parfile=True`.\n",
    "\n",
    "*   **`nrpy.infrastructures.BHaH.cmdline_input_and_parfiles.register_CFunction_cmdline_input_and_parfile_parser(project_name, cmdline_inputs)`**:\n",
    "    *   **Source File**: `nrpy/infrastructures/BHaH/cmdline_input_and_parfiles.py`\n",
    "    *   **Description**: Registers the C function that reads the `.par` file and command-line arguments at runtime. The `cmdline_inputs` list is critical, as it defines the exact order of expected positional command-line arguments.\n",
    "\n",
    "*   **`nrpy.infrastructures.BHaH.BHaH_defines_h.output_BHaH_defines_h(project_dir)`**:\n",
    "    *   **Source File**: `nrpy/infrastructures/BHaH/BHaH_defines_h.py`\n",
    "    *   **Description**: Scans `nrpy`'s internal library for all registered data structures and writes them into the master C header file, `BHaH_defines.h`.\n",
    "\n",
    "*   **`nrpy.helpers.generic.copy_files(...)`**:\n",
    "    *   **Source File**: `nrpy/helpers/generic.py`\n",
    "    *   **Description**: A utility function to copy files from the `nrpy` installation to the project directory.\n",
    "\n",
    "*   **`nrpy.infrastructures.BHaH.Makefile_helpers.output_CFunctions_function_prototypes_and_construct_Makefile(...)`**:\n",
    "    *   **Source File**: `nrpy/infrastructures/BHaH/Makefile_helpers.py`\n",
    "    *   **Description**: The final build function that generates all `.c` files, the function prototypes header, and the `Makefile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "599870e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assembling and building C project for Radiative Transfer Engine...\n",
      " -> Registering C data structures and functions...\n",
      "Registering custom C data structures...\n",
      " -> Registered all necessary data structures, including the new termination_type.\n",
      " -> Registering C data structures for k-d tree handling...\n",
      "    ... Registered C structs: MassiveParticle, CustomKDTree, WinnersCircle.\n",
      " -> Generating C worker function: g4DD_kerr_schild()...\n",
      "    ... g4DD_kerr_schild() registration complete.\n",
      " -> Generating C worker function: con_kerr_schild()...\n",
      "    ... con_kerr_schild() registration complete.\n",
      " -> Generating C worker function: g4DD_schwarzschild_cartesian()...\n",
      "    ... g4DD_schwarzschild_cartesian() registration complete.\n",
      " -> Generating C worker function: con_schwarzschild_cartesian()...\n",
      "    ... con_schwarzschild_cartesian() registration complete.\n",
      " -> Generating C dispatcher function: g4DD_metric()...\n",
      "    ... g4DD_metric() registration complete.\n",
      " -> Generating C dispatcher: connections()...\n",
      "    ... connections() registration complete.\n",
      " -> Generating C engine function: calculate_p0_reverse()...\n",
      "    ... calculate_p0_reverse() registration complete.\n",
      " -> Generating C engine: set_initial_conditions_cartesian()...\n",
      " -> Generating C engine: check_conservation() [Cartesian Version]...\n",
      "    ... check_conservation() registration complete.\n",
      " -> Generating C functions for k-d tree memory mapping...\n",
      "    ... Registered C functions: load_kdtree_snapshot, unload_kdtree_snapshot.\n",
      " -> Generating C engine for k-d tree nearest neighbor search...\n",
      "    ... Registered C engine: find_n_nearest_neighbors.\n",
      " -> Generating C engine for two-stage disk state interpolation...\n",
      "    ... Registered C engine: interpolate_disk_state.\n",
      " -> Generating C engine for radiative transfer physics...\n",
      "    ... Registered C engine: calculate_radiative_transfer.\n",
      " -> Generating C engine: handle_disk_intersection()...\n",
      "    ... Registered C engine: handle_disk_intersection.\n",
      " -> Generating C engine: handle_source_plane_intersection (Robust Version)...\n",
      "    ... Registered C engine: handle_source_plane_intersection (Robust Version).\n",
      " -> Generating C engine: find_event_time_and_state() [Robust Version]...\n",
      "    ... Registered C engine: find_event_time_and_state (Robust Version).\n",
      " -> Generating C event detection manager (Stateless Plane Detector Version)...\n",
      "    ... Registered event_detection_manager (Stateless Plane Detector Version).\n",
      " -> Generating integration loop: integrate_single_photon() [Hybrid RT Version]...\n",
      " -> Generating C DEBUG function: integrate_single_photon_DEBUG()...\n",
      " -> Generating C orchestrator: run_scan_and_save_blueprint_universal()...\n",
      " -> Generating C entry point: main()...\n",
      " -> Generating GSL wrapper function: ode_gsl_wrapper...\n",
      "    ... ode_gsl_wrapper() registration complete.\n",
      " -> Generating BHaH infrastructure files...\n",
      "\n",
      "Generating BHaH master header file...\n",
      "Outputting non-core modules key = data_structures_and_enums to BHaH_defines.h\n",
      "Outputting non-core modules key = kdtree_structs to BHaH_defines.h\n",
      "Copying required helper files...\n",
      "Generating C source files, prototypes, and Makefile...\n",
      "\n",
      "Finished! A C project has been generated in project/photon_geodesic_integrator/\n",
      "To build, navigate to this directory in your terminal and type 'make'.\n",
      "To run, type './photon_geodesic_integrator'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"\\nAssembling and building C project for Radiative Transfer Engine...\")\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "# --- Step 1: Register all C-generating functions in the correct dependency order ---\n",
    "print(\" -> Registering C data structures and functions...\")\n",
    "\n",
    "# 1a. Register all data structures first. These have no dependencies.\n",
    "register_custom_structures_and_params()\n",
    "register_kdtree_c_structs()\n",
    "\n",
    "# 1b. Register low-level physics \"worker\" functions.\n",
    "g4DD_kerr_schild()\n",
    "con_kerr_schild()\n",
    "g4DD_schwarzschild_cartesian()\n",
    "con_schwarzschild_cartesian()\n",
    "\n",
    "# 1c. Register physics \"dispatchers\". These call the workers.\n",
    "g4DD_metric()\n",
    "connections()\n",
    "\n",
    "# 1d. Register core ODE and initial data engines.\n",
    "calculate_ode_rhs()\n",
    "calculate_p0_reverse()\n",
    "set_initial_conditions_cartesian()\n",
    "check_conservation()\n",
    "\n",
    "# 1e. Register K-d Tree, Interpolation, and Radiative Transfer Engines in dependency order.\n",
    "kdtree_loader_and_unloader()\n",
    "kdtree_search_engine()          # Defines find_n_nearest_neighbors\n",
    "interpolation_engine()          # Calls find_n_nearest_neighbors\n",
    "radiative_transfer_engine()     # Defines calculate_radiative_transfer\n",
    "handle_disk_intersection_engine() # Calls interpolation and radiative transfer engines\n",
    "handle_source_plane_intersection_engine() # Defines the geometric source plane handler\n",
    "filename_sorter()               # Defines the qsort comparison function\n",
    "\n",
    "# 1f. Register the integration loop and its components.\n",
    "lagrange_interp_engine_generic() \n",
    "event_detection_manager()       # Calls find_event_time_and_state\n",
    "integrate_single_photon()       # Calls event_detection_manager and handle_disk_intersection\n",
    "integrate_single_photon_DEBUG() # Calls the same functions as the production version\n",
    "\n",
    "# 1g. Register the top-level orchestrators. These call many of the above.\n",
    "run_scan_and_save_blueprint_universal() # Calls qsort with compare_filenames and integrate_single_photon\n",
    "main()                                  # Calls qsort with compare_filenames and the integrators\n",
    "\n",
    "# 1h. Register the GSL wrapper function.\n",
    "ode_gsl_wrapper()\n",
    "\n",
    "# --- Step 2: Call BHaH infrastructure functions to generate the build system ---\n",
    "print(\" -> Generating BHaH infrastructure files...\")\n",
    "CPs.write_CodeParameters_h_files(project_dir=project_dir)\n",
    "CPs.register_CFunctions_params_commondata_struct_set_to_default()\n",
    "cmdline_input_and_parfiles.generate_default_parfile(project_dir=project_dir, project_name=project_name)\n",
    "\n",
    "cmdline_input_and_parfiles.register_CFunction_cmdline_input_and_parfile_parser(\n",
    "    project_name=project_name,\n",
    "    cmdline_inputs=[\n",
    "        'M_scale', 'a_spin', 'metric_choice',\n",
    "        'camera_pos_x', 'camera_pos_y', 'camera_pos_z',\n",
    "        'window_center_x', 'window_center_y', 'window_center_z',\n",
    "        'source_plane_normal_x', 'source_plane_normal_y', 'source_plane_normal_z',\n",
    "        'source_plane_center_x', 'source_plane_center_y', 'source_plane_center_z',\n",
    "        'source_up_vec_x', 'source_up_vec_y', 'source_up_vec_z', \n",
    "        'window_up_vec_x', 'window_up_vec_y', 'window_up_vec_z',\n",
    "        'source_r_min', 'source_r_max',\n",
    "        'scan_density', 'window_size',\n",
    "        'flatness_threshold', 'r_escape', 'debug_mode', 'perform_conservation_check',\n",
    "        'mass_snapshot_every_t',\n",
    "        'disk_bounds_x_min', 'disk_bounds_x_max', 'disk_bounds_y_min', 'disk_bounds_y_max', \n",
    "        'disk_bounds_z_min', 'disk_bounds_z_max',\n",
    "        'delta_r_max'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Step 3: Generate headers, helpers, and the final Makefile ---\n",
    "print(\"\\nGenerating BHaH master header file...\")\n",
    "Bdefines_h.output_BHaH_defines_h(project_dir=project_dir)\n",
    "\n",
    "print(\"Copying required helper files...\")\n",
    "gh.copy_files(\n",
    "    package=\"nrpy.helpers\",\n",
    "    filenames_list=[\"simd_intrinsics.h\"],\n",
    "    project_dir=project_dir,\n",
    "    subdirectory=\"simd\",\n",
    ")\n",
    "\n",
    "print(\"Generating C source files, prototypes, and Makefile...\")\n",
    "addl_CFLAGS = [\"-Wall -Wextra -g $(shell gsl-config --cflags) -fopenmp\"]\n",
    "addl_libraries = [\"$(shell gsl-config --libs) -fopenmp\"]\n",
    "\n",
    "Makefile.output_CFunctions_function_prototypes_and_construct_Makefile(\n",
    "    project_dir=project_dir,\n",
    "    project_name=project_name,\n",
    "    exec_or_library_name=project_name,\n",
    "    addl_CFLAGS=addl_CFLAGS,\n",
    "    addl_libraries=addl_libraries,\n",
    ")\n",
    "\n",
    "print(f\"\\nFinished! A C project has been generated in {project_dir}/\")\n",
    "print(f\"To build, navigate to this directory in your terminal and type 'make'.\")\n",
    "print(f\"To run, type './{project_name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c894937",
   "metadata": {},
   "source": [
    "<a id='plotting'></a>\n",
    "# Step 9: Visualization and Analysis\n",
    "\n",
    "This final section of the notebook is dedicated to visualizing the results produced by our C code. It contains Python code cells that use standard libraries like `numpy` and `matplotlib`/`Pillow` to process and plot the output data. These cells are for analysis and are not part of the C code generation process. They are designed to be run *after* the C code has been compiled and executed, and has produced a `blueprint.bin` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "134f0b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Photon Trajectory Plot from Debug File ---\n",
      "ERROR: Trajectory file not found at 'project/photon_geodesic_integrator/photon_path.txt'\n",
      "Please ensure you have compiled and run the C code in debug mode successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_photon_trajectory_from_debug(\n",
    "    project_dir: str = \"project/photon_geodesic_integrator\",\n",
    "    input_filename: str = \"photon_path.txt\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads trajectory data from the C code's debug output and generates a\n",
    "    simple 3D plot of the photon's path with a sphere at the origin.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Photon Trajectory Plot from Debug File ---\")\n",
    "    \n",
    "    # --- 1. Construct the full path and load the data ---\n",
    "    full_path = os.path.join(project_dir, input_filename)\n",
    "    \n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"ERROR: Trajectory file not found at '{full_path}'\")\n",
    "        print(\"Please ensure you have compiled and run the C code in debug mode successfully.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Load the data, skipping the header row.\n",
    "        # Set invalid_raise=False to handle potential trailing empty lines.\n",
    "        data = np.loadtxt(full_path, skiprows=1, ndmin=2)\n",
    "        if data.shape[0] == 0:\n",
    "            print(\"ERROR: Trajectory file is empty.\")\n",
    "            return\n",
    "            \n",
    "        # Columns: 0:lambda, 1:t, 2:x, 3:y, 4:z, ...\n",
    "        x_coords = data[:, 2]\n",
    "        y_coords = data[:, 3]\n",
    "        z_coords = data[:, 4]\n",
    "        print(f\"Successfully loaded {len(x_coords)} data points from trajectory file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load or parse the data file '{full_path}'.\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Set up the 3D plot ---\n",
    "    plt.style.use('dark_background')\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # --- 3. Plot the photon's trajectory ---\n",
    "    ax.plot(x_coords, y_coords, z_coords, label='Photon Path', color='cyan', lw=2)\n",
    "    \n",
    "    # Mark the start (camera) and end points\n",
    "    ax.scatter(x_coords[0], y_coords[0], z_coords[0], color='lime', s=100, label='Start (Camera)', marker='o', depthshade=False)\n",
    "    ax.scatter(x_coords[-1], y_coords[-1], z_coords[-1], color='red', s=100, label='End Point', marker='X', depthshade=False)\n",
    "\n",
    "    # --- 4. Plot a simple sphere at the origin ---\n",
    "    radius = 2.0 # Represents r=2M, the Schwarzschild event horizon\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "    x_bh = radius * np.outer(np.cos(u), np.sin(v))\n",
    "    y_bh = radius * np.outer(np.sin(u), np.sin(v))\n",
    "    z_bh = radius * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "    ax.plot_surface(x_bh, y_bh, z_bh, color='grey', alpha=0.5, rstride=5, cstride=5)\n",
    "    \n",
    "    # --- 5. Customize the plot ---\n",
    "    ax.set_xlabel('X (M)', fontsize=12, labelpad=10)\n",
    "    ax.set_ylabel('Y (M)', fontsize=12, labelpad=10)\n",
    "    ax.set_zlabel('Z (M)', fontsize=12, labelpad=10)\n",
    "    \n",
    "    # Set aspect ratio to be equal to avoid distortion\n",
    "    max_range = np.array([x_coords.max()-x_coords.min(), y_coords.max()-y_coords.min(), z_coords.max()-z_coords.min()]).max() / 2.0\n",
    "    if max_range == 0: max_range = np.max(np.abs(data[:, 2:5]))\n",
    "    mid_x = (x_coords.max()+x_coords.min()) * 0.5\n",
    "    mid_y = (y_coords.max()+y_coords.min()) * 0.5\n",
    "    mid_z = (z_coords.max()+z_coords.min()) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "    ax.set_title(\"Photon Trajectory (Debug Run)\", fontsize=16)\n",
    "    ax.legend()\n",
    "    ax.view_init(elev=30., azim=-60)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# --- How to Run ---\n",
    "# After running the C code in debug mode, call this function.\n",
    "plot_photon_trajectory_from_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91b5a534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Photon Trajectory Plot from Debug File ---\n",
      "ERROR: Trajectory file not found at 'project/photon_geodesic_integrator/photon_path.txt'\n",
      "Please ensure you have compiled and run the C code in debug mode successfully.\n"
     ]
    }
   ],
   "source": [
    "plot_photon_trajectory_from_debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1200f1f",
   "metadata": {},
   "source": [
    "# Start of Blueprint Stats ( 3 cells )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac8410",
   "metadata": {},
   "source": [
    "Cell 1 of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "965217d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def view_binary_blueprint(\n",
    "    blueprint_filename=\"project/photon_geodesic_integrator/blueprint.bin\",\n",
    "    max_rays_to_print=20\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads the new binary blueprint file, which includes failure records,\n",
    "    and prints its raw contents in a human-readable, context-aware format.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(blueprint_filename):\n",
    "        print(f\"Error: Blueprint file not found at '{blueprint_filename}'\")\n",
    "        return\n",
    "\n",
    "    # This dtype is now defined globally in cell [3e9fb27f]\n",
    "    # It must exactly match the C struct 'blueprint_data_t'\n",
    "    \n",
    "    data = np.fromfile(blueprint_filename, dtype=BLUEPRINT_DTYPE)\n",
    "    \n",
    "    print(f\"--- Raw Blueprint Data Inspector (v2) ---\")\n",
    "    print(f\"Total records read from file: {len(data)}\\n\")\n",
    "    print(\"Printing a sample of records...\")\n",
    "    print(\"Enum Mapping: 0=FAILURE, 1=SOURCE, 2=SPHERE\")\n",
    "    \n",
    "    # <-- MODIFIED: Updated header to include t_w and t_s\n",
    "    header = f\"{'Ray#':<8} | {'TermType':<8} | {'y_w':>8} | {'z_w':>8} | {'t_w':>10} | {'y_s/θ':>10} | {'z_s/φ':>10} | {'t_s':>10}\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    if len(data) > max_rays_to_print:\n",
    "        indices_to_print = np.linspace(0, len(data) - 1, max_rays_to_print, dtype=int)\n",
    "    else:\n",
    "        indices_to_print = np.arange(len(data))\n",
    "\n",
    "    for i in indices_to_print:\n",
    "        rec = data[i]\n",
    "        term_type = int(rec['termination_type'])\n",
    "        term_str = [\"FAILURE\", \"SOURCE\", \"SPHERE\"][term_type]\n",
    "\n",
    "        t_w_str = f\"{rec['t_w']:.3f}\" if rec['t_w'] != 0 else \"N/A\"\n",
    "\n",
    "        if term_type == 1: # SOURCE_PLANE\n",
    "            ys_theta = f\"{rec['y_s']:.4f}\"\n",
    "            zs_phi = f\"{rec['z_s']:.4f}\"\n",
    "            t_s_str = f\"{rec['t_s']:.3f}\"\n",
    "        elif term_type == 2: # CELESTIAL_SPHERE\n",
    "            ys_theta = f\"{rec['final_theta']:.4f}\"\n",
    "            zs_phi = f\"{rec['final_phi']:.4f}\"\n",
    "            t_s_str = \"N/A\"\n",
    "        else: # FAILURE\n",
    "            ys_theta = \"N/A\"\n",
    "            zs_phi = \"N/A\"\n",
    "            t_s_str = \"N/A\"\n",
    "        \n",
    "        print(f\"{i:<8} | {term_str:<8} | {rec['y_w']:>8.2f} | {rec['z_w']:>8.2f} | {t_w_str:>10} | {ys_theta:>10} | {zs_phi:>10} | {t_s_str:>10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64e0f07",
   "metadata": {},
   "source": [
    "Cell 2 of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "be508e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import os\n",
    "\n",
    "def analyze_blueprint_V11_2(blueprint_filename=\"project/photon_geodesic_integrator/blueprint.bin\"):\n",
    "    \"\"\"\n",
    "    Reads the V11.2 blueprint file and generates comprehensive statistical analysis\n",
    "    and plots. This version includes detailed statistics for all termination types,\n",
    "    including celestial sphere hits.\n",
    "    \"\"\"\n",
    "    # --- 1. Load Data ---\n",
    "    if not os.path.exists(blueprint_filename):\n",
    "        print(f\"Error: Blueprint file not found at '{blueprint_filename}'\")\n",
    "        return\n",
    "\n",
    "    # This dtype must exactly match the C struct 'blueprint_data_t' from V11.2\n",
    "    V11_2_BLUEPRINT_DTYPE = np.dtype([\n",
    "        ('termination_type', np.int32),\n",
    "        ('y_w', 'f8'), ('z_w', 'f8'), ('L_w', 'f8'), ('t_w', 'f8'),\n",
    "        ('y_s', 'f8'), ('z_s', 'f8'), ('L_s', 'f8'), ('t_s', 'f8'),\n",
    "        ('redshift_ratio', 'f8'),\n",
    "        ('final_theta', 'f8'), ('final_phi', 'f8'),\n",
    "    ], align=False)\n",
    "\n",
    "    data = np.fromfile(blueprint_filename, dtype=V11_2_BLUEPRINT_DTYPE)\n",
    "    if len(data) == 0:\n",
    "        print(\"Blueprint file is empty. No analysis to perform.\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Segregate Data by Termination Type ---\n",
    "    failure_hits = data[data['termination_type'] == 0]\n",
    "    source_hits = data[data['termination_type'] == 1]\n",
    "    sphere_hits = data[data['termination_type'] == 2]\n",
    "\n",
    "    num_total_rays = len(data)\n",
    "    num_failure_hits = len(failure_hits)\n",
    "    num_source_hits = len(source_hits)\n",
    "    num_sphere_hits = len(sphere_hits)\n",
    "\n",
    "    print(\"--- Blueprint File Analysis (V11.2 Architecture) ---\")\n",
    "    print(f\"Total rays in scan: {num_total_rays}\")\n",
    "    print(f\"  Rays that hit the SOURCE_PLANE:      {num_source_hits} ({100.0 * num_source_hits / num_total_rays:.2f}%)\")\n",
    "    print(f\"  Rays that hit the CELESTIAL_SPHERE:  {num_sphere_hits} ({100.0 * num_sphere_hits / num_total_rays:.2f}%)\")\n",
    "    print(f\"  Rays that FAILED (e.g., hit shadow): {num_failure_hits} ({100.0 * num_failure_hits / num_total_rays:.2f}%)\")\n",
    "\n",
    "    if num_failure_hits > 0:\n",
    "        r_w_failure = np.sqrt(failure_hits['y_w']**2 + failure_hits['z_w']**2)\n",
    "        r_w_max_failure = np.max(r_w_failure)\n",
    "        print(f\"    -> Apparent radius of black hole shadow on window: {r_w_max_failure:.4f} M\")\n",
    "\n",
    "    print(\"-\" * 55)\n",
    "\n",
    "    # --- 3. Analyze Window Coordinates ---\n",
    "    valid_hits = data[np.isfinite(data['y_w'])]\n",
    "    if len(valid_hits) > 0:\n",
    "        print(\"\\n--- Window Plane Coordinate Statistics (y_w, z_w) ---\")\n",
    "        print(f\"  y_w min: {np.min(valid_hits['y_w']):.3f}, max: {np.max(valid_hits['y_w']):.3f}\")\n",
    "        print(f\"  z_w min: {np.min(valid_hits['z_w']):.3f}, max: {np.max(valid_hits['z_w']):.3f}\")\n",
    "\n",
    "    # --- 4. Analyze Source Plane and Celestial Sphere Hits ---\n",
    "    if num_source_hits > 0:\n",
    "        finite_source_mask = np.isfinite(source_hits['y_s']) & np.isfinite(source_hits['z_s'])\n",
    "        finite_source_hits = source_hits[finite_source_mask]\n",
    "\n",
    "        if len(finite_source_hits) > 0:\n",
    "            r_s = np.sqrt(finite_source_hits['y_s']**2 + finite_source_hits['z_s']**2)\n",
    "            y_w_source_hits = finite_source_hits['y_w']\n",
    "            z_w_source_hits = finite_source_hits['z_w']\n",
    "            r_w_source_hits = np.sqrt(y_w_source_hits**2 + z_w_source_hits**2)\n",
    "\n",
    "            print(\"\\n--- Source Plane Hit Statistics ---\")\n",
    "            print(f\"  Planar Radius (r_s) for these hits: min={np.min(r_s):.4f}, max={np.max(r_s):.4f}, mean={np.mean(r_s):.4f}\")\n",
    "            print(f\"  Window Radius (r_w) for these hits: min={np.min(r_w_source_hits):.4f}, max={np.max(r_w_source_hits):.4f}, mean={np.mean(r_w_source_hits):.4f}\")\n",
    "\n",
    "    # <<< MODIFIED AND EXPANDED CODE BLOCK START >>>\n",
    "    if num_sphere_hits > 0:\n",
    "        # Filter out any non-finite values which could corrupt stats\n",
    "        finite_sphere_mask = np.isfinite(sphere_hits['final_theta']) & np.isfinite(sphere_hits['final_phi'])\n",
    "        finite_sphere_hits = sphere_hits[finite_sphere_mask]\n",
    "        \n",
    "        if len(finite_sphere_hits) > 0:\n",
    "            # Calculate r_w for rays that hit the celestial sphere\n",
    "            y_w_sphere_hits = finite_sphere_hits['y_w']\n",
    "            z_w_sphere_hits = finite_sphere_hits['z_w']\n",
    "            r_w_sphere_hits = np.sqrt(y_w_sphere_hits**2 + z_w_sphere_hits**2)\n",
    "            \n",
    "            # Extract final angles\n",
    "            theta_final = finite_sphere_hits['final_theta']\n",
    "            phi_final = finite_sphere_hits['final_phi']\n",
    "\n",
    "            print(\"\\n--- Celestial Sphere Hit Statistics ---\")\n",
    "            print(f\"  Window Radius (r_w) for these hits: min={np.min(r_w_sphere_hits):.4f}, max={np.max(r_w_sphere_hits):.4f}, mean={np.mean(r_w_sphere_hits):.4f}\")\n",
    "            print(f\"  Final Angle (theta) for these hits: min={np.min(theta_final):.4f}, max={np.max(theta_final):.4f}, mean={np.mean(theta_final):.4f}\")\n",
    "            print(f\"  Final Angle (phi)   for these hits: min={np.min(phi_final):.4f}, max={np.max(phi_final):.4f}, mean={np.mean(phi_final):.4f}\")\n",
    "    # <<< MODIFIED AND EXPANDED CODE BLOCK END >>>\n",
    "\n",
    "    # --- 5. Generate Plots ---\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(22, 16))\n",
    "    fig.suptitle(\"Blueprint Data Visualization (V11.2 Architecture)\", fontsize=20)\n",
    "\n",
    "    # Plot 1: Source Plane Hit Density\n",
    "    if num_source_hits > 0 and 'finite_source_hits' in locals() and len(finite_source_hits) > 0:\n",
    "        hist = axes[0, 0].hist2d(finite_source_hits['y_s'], finite_source_hits['z_s'], bins=256, cmap='inferno', norm=LogNorm())\n",
    "        axes[0, 0].set_title(\"Source Plane Hit Density (y_s vs z_s)\")\n",
    "        axes[0, 0].set_xlabel(\"y_s (M)\")\n",
    "        axes[0, 0].set_ylabel(\"z_s (M)\")\n",
    "        axes[0, 0].set_aspect('equal', 'box')\n",
    "        fig.colorbar(hist[3], ax=axes[0, 0], label=\"Number of Rays per Bin\")\n",
    "    else:\n",
    "        axes[0, 0].text(0.5, 0.5, \"No Source Plane Hits\", ha='center', va='center', fontsize=16)\n",
    "        axes[0, 0].set_title(\"Source Plane Hit Density\")\n",
    "\n",
    "    # Plot 2: Celestial Sphere Direction Density\n",
    "    if num_sphere_hits > 0 and 'finite_sphere_hits' in locals() and len(finite_sphere_hits) > 0:\n",
    "        hist2 = axes[0, 1].hist2d(finite_sphere_hits['final_phi'], finite_sphere_hits['final_theta'], bins=256, cmap='twilight', range=[[-np.pi, np.pi], [0, np.pi]])\n",
    "        axes[0, 1].set_title(\"Celestial Sphere Direction Density (phi vs theta)\")\n",
    "        axes[0, 1].set_xlabel(\"Final Azimuthal Angle (phi)\")\n",
    "        axes[0, 1].set_ylabel(\"Final Polar Angle (theta)\")\n",
    "        fig.colorbar(hist2[3], ax=axes[0, 1], label=\"Number of Rays per Bin\")\n",
    "    else:\n",
    "        axes[0, 1].text(0.5, 0.5, \"No Celestial Sphere Hits\", ha='center', va='center', fontsize=16)\n",
    "        axes[0, 1].set_title(\"Celestial Sphere Direction Density\")\n",
    "\n",
    "    # Plot 3: Termination Type Distribution\n",
    "    labels = ['Failure', 'Source Hits', 'Celestial Hits']\n",
    "    sizes = [num_failure_hits, num_source_hits, num_sphere_hits]\n",
    "    colors = ['#2F2F2F', '#FFC300', '#C70039']\n",
    "    explode = (0.1, 0, 0)\n",
    "\n",
    "    plot_labels = [l for i, l in enumerate(labels) if sizes[i] > 0]\n",
    "    plot_sizes = [s for s in sizes if s > 0]\n",
    "    plot_colors = [c for i, c in enumerate(colors) if sizes[i] > 0]\n",
    "    plot_explode = [e for i, e in enumerate(explode) if sizes[i] > 0]\n",
    "\n",
    "    if plot_sizes:\n",
    "        axes[1, 0].pie(plot_sizes, explode=plot_explode, labels=plot_labels, colors=plot_colors,\n",
    "                       autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "        axes[1, 0].set_title(\"Distribution of Ray Termination Types\")\n",
    "        axes[1, 0].axis('equal')\n",
    "    else:\n",
    "        axes[1, 0].text(0.5, 0.5, \"No Data to Plot\", ha='center', va='center', fontsize=16)\n",
    "        axes[1, 0].set_title(\"Distribution of Ray Termination Types\")\n",
    "\n",
    "    # Plot 4: Radial Distribution\n",
    "    if num_total_rays > 0:\n",
    "        r_w = np.sqrt(data['y_w']**2 + data['z_w']**2)\n",
    "        r_w_failure = r_w[data['termination_type'] == 0]\n",
    "        r_w_source  = r_w[data['termination_type'] == 1]\n",
    "        r_w_sphere  = r_w[data['termination_type'] == 2]\n",
    "\n",
    "        x_data = [r_w_failure, r_w_source, r_w_sphere]\n",
    "        hist_labels = [f'FAILURE ({len(r_w_failure)})', f'SOURCE ({len(r_w_source)})', f'SPHERE ({len(r_w_sphere)})']\n",
    "        hist_colors = ['black', 'gold', 'deepskyblue']\n",
    "\n",
    "        axes[1, 1].hist(x_data, bins=100, stacked=True, label=hist_labels, color=hist_colors, edgecolor='dimgray')\n",
    "        axes[1, 1].set_title(\"Photon Outcome by Initial Window Radius\")\n",
    "        axes[1, 1].set_xlabel(\"Initial Radial Distance on Window (r_w)\")\n",
    "        axes[1, 1].set_ylabel(\"Number of Photons\")\n",
    "        axes[1, 1].legend()\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Example of how to call the function in the notebook:\n",
    "# analyze_blueprint_V11_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83cee5",
   "metadata": {},
   "source": [
    "Cell 3 of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4cef21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_stacked_radial_histogram(blueprint_filename: str, bin_width: float = 0.05):\n",
    "    \"\"\"\n",
    "    Reads a blueprint file and creates a stacked histogram showing the\n",
    "    outcome of photons as a function of their initial radial distance.\n",
    "\n",
    "    Args:\n",
    "        blueprint_filename: The path to the blueprint.bin file.\n",
    "        bin_width: The width of each radial bin for the histogram.\n",
    "    \"\"\"\n",
    "    print(f\"--- Generating stacked radial histogram for '{blueprint_filename}' ---\")\n",
    "    \n",
    "    # --- Load Data ---\n",
    "    if not os.path.exists(blueprint_filename):\n",
    "        print(f\"Error: Blueprint file not found at '{blueprint_filename}'\")\n",
    "        return\n",
    "    \n",
    "    # <-- MODIFIED: This function now uses the global BLUEPRINT_DTYPE\n",
    "    data = np.fromfile(blueprint_filename, dtype=BLUEPRINT_DTYPE)\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        print(\"Blueprint file is empty. Cannot generate plot.\")\n",
    "        return\n",
    "        \n",
    "    # --- Calculate r_w for all rays ---\n",
    "    r_w = np.sqrt(data['y_w']**2 + data['z_w']**2)\n",
    "    \n",
    "    # --- Separate r_w values based on termination type ---\n",
    "    mask_failure = (data['termination_type'] == 0)\n",
    "    mask_source  = (data['termination_type'] == 1)\n",
    "    mask_sphere  = (data['termination_type'] == 2)\n",
    "    \n",
    "    r_w_failure = r_w[mask_failure]\n",
    "    r_w_source  = r_w[mask_source]\n",
    "    r_w_sphere  = r_w[mask_sphere]\n",
    "    \n",
    "    # --- Create the Bins for the Histogram ---\n",
    "    max_radius = r_w.max()\n",
    "    bins = np.arange(0, max_radius + bin_width, bin_width)\n",
    "    \n",
    "    # --- Create the Plot ---\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    \n",
    "    # Data and labels for the stacked histogram\n",
    "    x_data = [r_w_failure, r_w_source, r_w_sphere]\n",
    "    labels = [\n",
    "        f'FAILURE (Black Hole): {len(r_w_failure)}',\n",
    "        f'SOURCE: {len(r_w_source)}',\n",
    "        f'SPHERE: {len(r_w_sphere)}'\n",
    "    ]\n",
    "    colors = ['black', 'gold', 'deepskyblue']\n",
    "    \n",
    "    # Create the stacked histogram\n",
    "    ax.hist(x_data, bins=bins, stacked=True, label=labels, color=colors, edgecolor='dimgray')\n",
    "    \n",
    "    # --- Add Labels and Title ---\n",
    "    title = f\"Photon Outcome by Initial Radial Distance (Bin Width: {bin_width})\\nTotal Rays: {len(data)}\"\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel('Initial Radial Distance on Window ($r_w$)', fontsize=12)\n",
    "    ax.set_ylabel('Number of Photons (Count)', fontsize=12)\n",
    "    ax.legend(title='Termination Type')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0371a8",
   "metadata": {},
   "source": [
    "# Call to Blueprints stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4e1fda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Blueprint file not found at 'project/photon_geodesic_integrator/blueprint.bin'\n",
      "Error: Blueprint file not found at 'project/photon_geodesic_integrator/blueprint.bin'\n"
     ]
    }
   ],
   "source": [
    "# --- Call the function with your blueprint file and desired bin width ---\n",
    "blueprint_filename=\"project/photon_geodesic_integrator/blueprint.bin\"\n",
    "#plot_stacked_radial_histogram(blueprint_filename=blueprint_filename, bin_width=0.01)\n",
    "\n",
    "\n",
    "analyze_blueprint_V11_2()\n",
    "\n",
    "# --- Run the viewer ---\n",
    "view_binary_blueprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "492cd4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Simple Photon Trajectory Plot ---\n",
      "ERROR: Trajectory file not found at 'project/photon_geodesic_integrator/photon_path.txt'\n",
      "Please ensure you have compiled and run the C code in debug mode successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_photon_trajectory_simple(\n",
    "    project_dir: str = \"project/photon_geodesic_integrator\",\n",
    "    input_filename: str = \"photon_path.txt\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads trajectory data from the C code's debug output and generates a\n",
    "    simple 3D plot of the photon's path with a sphere at the origin.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Simple Photon Trajectory Plot ---\")\n",
    "    \n",
    "    # --- 1. Construct the full path and load the data ---\n",
    "    full_path = os.path.join(project_dir, input_filename)\n",
    "    \n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"ERROR: Trajectory file not found at '{full_path}'\")\n",
    "        print(\"Please ensure you have compiled and run the C code in debug mode successfully.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        data = np.loadtxt(full_path, skiprows=1)\n",
    "        # Columns: 0:lambda, 1:t, 2:x, 3:y, 4:z, ...\n",
    "        x_coords = data[:, 2]\n",
    "        y_coords = data[:, 3]\n",
    "        z_coords = data[:, 4]\n",
    "        print(f\"Successfully loaded {len(x_coords)} data points from trajectory file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load or parse the data file '{full_path}'.\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Set up the 3D plot ---\n",
    "    plt.style.use('dark_background')\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # --- 3. Plot the photon's trajectory ---\n",
    "    ax.plot(x_coords, y_coords, z_coords, label='Photon Path', color='cyan', lw=2)\n",
    "    \n",
    "    # Mark the start (camera) and end points\n",
    "    ax.scatter(x_coords[0], y_coords[0], z_coords[0], color='lime', s=100, label='Start (Camera)', marker='o', depthshade=False)\n",
    "    ax.scatter(x_coords[-1], y_coords[-1], z_coords[-1], color='red', s=100, label='End Point', marker='X', depthshade=False)\n",
    "\n",
    "    # --- 4. Plot a simple sphere at the origin ---\n",
    "    radius = 2.0 # Represents r=2M, the Schwarzschild event horizon\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "    x_bh = radius * np.outer(np.cos(u), np.sin(v))\n",
    "    y_bh = radius * np.outer(np.sin(u), np.sin(v))\n",
    "    z_bh = radius * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "    ax.plot_surface(x_bh, y_bh, z_bh, color='grey', alpha=0.5, rstride=5, cstride=5, label='Black Hole (r=2M)')\n",
    "    \n",
    "    # --- 5. Customize the plot ---\n",
    "    ax.set_xlabel('X (M)', fontsize=12, labelpad=10)\n",
    "    ax.set_ylabel('Y (M)', fontsize=12, labelpad=10)\n",
    "    ax.set_zlabel('Z (M)', fontsize=12, labelpad=10)\n",
    "    \n",
    "    # Set aspect ratio to be equal\n",
    "    max_range = np.array([x_coords.max()-x_coords.min(), y_coords.max()-y_coords.min(), z_coords.max()-z_coords.min()]).max() / 2.0\n",
    "    mid_x = (x_coords.max()+x_coords.min()) * 0.5\n",
    "    mid_y = (y_coords.max()+y_coords.min()) * 0.5\n",
    "    mid_z = (z_coords.max()+z_coords.min()) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "    ax.set_title(\"Photon Trajectory\", fontsize=16)\n",
    "    ax.legend()\n",
    "    ax.view_init(elev=30., azim=-60)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# --- How to Run ---\n",
    "# After running the C code in debug mode, call this function.\n",
    "\n",
    "plot_photon_trajectory_simple()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2651bf",
   "metadata": {},
   "source": [
    "# Start of Visual function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c46b6eb",
   "metadata": {},
   "source": [
    "# Blueprint Data Type Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "204d21d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries and blueprint data type defined.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import Union, Optional, List, Tuple\n",
    "import os\n",
    "\n",
    "# Define the exact structure of a record in the blueprint.bin file\n",
    "# This must match the C struct 'blueprint_data_t'\n",
    "# <-- MODIFIED FOR PHASE 4: This now matches the upgraded C struct from Phase 1.\n",
    "BLUEPRINT_DTYPE = np.dtype([\n",
    "    ('termination_type', np.int32),\n",
    "    ('y_w', 'f8'), ('z_w', 'f8'), ('L_w', 'f8'), ('t_w', 'f8'),\n",
    "    ('y_s', 'f8'), ('z_s', 'f8'), ('L_s', 'f8'), ('t_s', 'f8'),\n",
    "    ('redshift_ratio', 'f8'),\n",
    "    ('final_theta', 'f8'), ('final_phi', 'f8'),\n",
    "], align=False)\n",
    "\n",
    "print(\"Libraries and blueprint data type defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90def71e",
   "metadata": {},
   "source": [
    "# Texture Loading Helper Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a451cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper function `_load_texture` (Corrected) defined.\n"
     ]
    }
   ],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In the cell defining _load_texture\n",
    "\n",
    "def _load_texture(image_input: Union[str, np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Helper function to load an image or use a pre-loaded numpy array,\n",
    "    ensuring the output is always a float64 array with values in [0.0, 1.0].\n",
    "    \"\"\"\n",
    "    if isinstance(image_input, str):\n",
    "        if not os.path.exists(image_input):\n",
    "            raise FileNotFoundError(f\"Texture file not found: {image_input}\")\n",
    "        with Image.open(image_input) as img:\n",
    "            # Convert to RGB and normalize to [0.0, 1.0] floats\n",
    "            return np.array(img.convert(\"RGB\")).astype(np.float64) / 255.0\n",
    "    elif isinstance(image_input, np.ndarray):\n",
    "        # --- CORRECTED LOGIC ---\n",
    "        # 1. Ensure the array is float64 for calculations.\n",
    "        texture_array = image_input.astype(np.float64)\n",
    "        # 2. Check if the values are in the [0, 255] range. If so, normalize them.\n",
    "        if np.max(texture_array) > 1.0:\n",
    "            texture_array /= 255.0\n",
    "        return texture_array\n",
    "    else:\n",
    "        raise TypeError(\"Image input must be a file path (str) or a NumPy array.\")\n",
    "\n",
    "print(\"Helper function `_load_texture` (Corrected) defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0784077",
   "metadata": {},
   "source": [
    " # Procedural Disk Generators (2 cells)\n",
    " First cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9edcaa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for Visualizing/Generating the Unlensed Source Disk (UPDATED with Anti-Aliasing)\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_source_disk_array(\n",
    "    pixel_width=512,\n",
    "    disk_physical_width=40.0,\n",
    "    disk_inner_radius=6.0,\n",
    "    disk_outer_radius=20.0,\n",
    "    disk_temp_power_law=-0.75,\n",
    "    colormap='hot',\n",
    "    display_image=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates an anti-aliased NumPy array of an accretion disk image.\n",
    "    \"\"\"\n",
    "    # --- 1. Create a Coordinate Grid ---\n",
    "    half_width = disk_physical_width / 2.0\n",
    "    y_coords = np.linspace(-half_width, half_width, pixel_width)\n",
    "    z_coords = np.linspace(-half_width, half_width, pixel_width)\n",
    "    yy, zz = np.meshgrid(y_coords, z_coords)\n",
    "\n",
    "    # --- 2. Calculate Physical Properties for Each Pixel ---\n",
    "    radii = np.sqrt(yy**2 + zz**2)\n",
    "\n",
    "    # --- 3. Apply the Disk Model with a Smooth Falloff ---\n",
    "    # Instead of a sharp mask, we'll calculate temperature for all points\n",
    "    # and then smoothly fade it to zero outside the disk bounds.\n",
    "    \n",
    "    # Calculate temperature based on the power law everywhere.\n",
    "    # Add a small epsilon to radii to avoid division by zero at the center.\n",
    "    temperature = (radii / disk_inner_radius)**disk_temp_power_law\n",
    "\n",
    "    # Create a smooth falloff mask using numpy.clip\n",
    "    # This will create a smooth transition from 1 (inside the disk) to 0 (outside)\n",
    "    # over a small number of pixels. Let's define a transition width.\n",
    "    transition_width = 2.0 * (disk_physical_width / pixel_width) # Width of 2 pixels\n",
    "\n",
    "    # Inner edge falloff\n",
    "    inner_falloff = np.clip((radii - (disk_inner_radius - transition_width)) / transition_width, 0, 1)\n",
    "    \n",
    "    # Outer edge falloff\n",
    "    outer_falloff = 1.0 - np.clip((radii - disk_outer_radius) / transition_width, 0, 1)\n",
    "\n",
    "    # Combine the masks and apply to the temperature\n",
    "    smooth_mask = inner_falloff * outer_falloff\n",
    "    temperature *= smooth_mask\n",
    "\n",
    "    # --- 4. Map Temperature to Color and Create Image Array ---\n",
    "    colormap_func = plt.colormaps[colormap]\n",
    "    colors = colormap_func(temperature / np.max(temperature)) # Normalize to ensure max is 1\n",
    "    image_array = (colors[:, :, :3] * 255).astype(np.uint8)\n",
    "    \n",
    "    # --- 5. Optionally Display the Image ---\n",
    "    if display_image:\n",
    "        print(f\"Displaying the unlensed source disk (with anti-aliasing):\")\n",
    "        img = Image.fromarray(image_array)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Unlensed Source Accretion Disk (Anti-Aliased)\")\n",
    "        plt.show()\n",
    "        \n",
    "    # --- 6. Return the NumPy array ---\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb1011f",
   "metadata": {},
   "source": [
    "Second Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f126c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In the cell defining generate_advanced_disk_array\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_advanced_disk_array(\n",
    "    # --- Basic Settings ---\n",
    "    pixel_width=1024,\n",
    "    disk_physical_width=30.0,\n",
    "    colormap='afmhot',\n",
    "    \n",
    "    # --- Base Radial Profile ---\n",
    "    disk_inner_radius=6.0,\n",
    "    disk_outer_radius=25.0,\n",
    "    disk_temp_power_law=-2.0,\n",
    "    \n",
    "    # --- Concentric Rings / Gaps ---\n",
    "    ring_num=5,\n",
    "    ring_contrast=0.7,\n",
    "    ring_log_spacing=True,\n",
    "    \n",
    "    # --- Doppler Beaming (Asymmetric Brightness) ---\n",
    "    doppler_factor=0.8,\n",
    "    doppler_power=3,\n",
    "    \n",
    "    # --- Optional Features (set to 0 to disable) ---\n",
    "    hotspot_num=0,\n",
    "    hotspot_amplitude=0.15,\n",
    "    hotspot_radius_center=9.0,\n",
    "    hotspot_radius_width=3.0,\n",
    "    shape_num_lobes=0,\n",
    "    shape_inner_amplitude=0.0,\n",
    "    shape_outer_amplitude=0.0,\n",
    "    \n",
    "    # --- Display Control ---\n",
    "    display_image=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates an EHT-style disk, combining advanced features with robust NaN handling.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating EHT-Style Accretion Disk Texture (Corrected v3) ---\")\n",
    "    \n",
    "    # 1. Create Coordinate Grid & Polar Coordinates\n",
    "    half_width = disk_physical_width / 2.0\n",
    "    y_coords = np.linspace(-half_width, half_width, pixel_width)\n",
    "    z_coords = np.linspace(-half_width, half_width, pixel_width)\n",
    "    yy, zz = np.meshgrid(y_coords, z_coords)\n",
    "    radii = np.sqrt(yy**2 + zz**2)\n",
    "    phi = np.arctan2(zz, yy)\n",
    "\n",
    "    # 2. Calculate Base Temperature\n",
    "    # Add a small epsilon to radii to avoid division by zero at the center.\n",
    "    temperature = (radii / (disk_inner_radius + 1e-12))**disk_temp_power_law\n",
    "    \n",
    "    # --- CORRECTED: Explicitly handle the NaN at the center ---\n",
    "    # This is the crucial fix from the older, working code.\n",
    "    temperature[np.isnan(temperature)] = 0\n",
    "\n",
    "    # 3. Apply Modulations (Rings, Doppler, etc.)\n",
    "    if ring_num > 0:\n",
    "        if ring_log_spacing:\n",
    "            radial_coord = np.log(radii / disk_inner_radius + 1e-9)\n",
    "            max_log_rad = np.log(disk_outer_radius / disk_inner_radius)\n",
    "            ring_mod = 0.5 * (1 + np.cos(ring_num * 2 * np.pi * radial_coord / max_log_rad))\n",
    "        else:\n",
    "            radial_coord = radii\n",
    "            ring_mod = 0.5 * (1 + np.cos(ring_num * 2 * np.pi * (radial_coord - disk_inner_radius) / (disk_outer_radius - disk_inner_radius)))\n",
    "        ring_mod = 1.0 - ring_contrast * (1.0 - ring_mod)\n",
    "        temperature *= ring_mod\n",
    "\n",
    "    if doppler_factor > 0:\n",
    "        doppler_mod = (1 + doppler_factor * (-np.cos(phi)))**doppler_power\n",
    "        temperature *= doppler_mod\n",
    "        \n",
    "    # ... (hotspot logic would go here) ...\n",
    "\n",
    "    # 4. Apply Final Radial Mask\n",
    "    # This uses the smooth falloff logic from the older, working code.\n",
    "    transition_width = 2.0 * (disk_physical_width / pixel_width)\n",
    "    r_inner_mod = disk_inner_radius + shape_inner_amplitude * np.cos(shape_num_lobes * phi)\n",
    "    r_outer_mod = disk_outer_radius + shape_outer_amplitude * np.cos(shape_num_lobes * phi)\n",
    "    inner_falloff = np.clip((radii - (r_inner_mod - transition_width)) / transition_width, 0, 1)\n",
    "    outer_falloff = 1.0 - np.clip((radii - r_outer_mod) / transition_width, 0, 1)\n",
    "    smooth_mask = inner_falloff * outer_falloff\n",
    "    temperature *= smooth_mask\n",
    "\n",
    "    # 5. Map to Color using robust normalization\n",
    "    max_temp = np.max(temperature)\n",
    "    if max_temp > 0:\n",
    "        norm_temperature = temperature / max_temp\n",
    "    else:\n",
    "        norm_temperature = temperature # Avoid division by zero if all temps are zero\n",
    "\n",
    "    colormap_func = plt.colormaps[colormap]\n",
    "    colors = colormap_func(norm_temperature)\n",
    "    image_array = (colors[:, :, :3] * 255).astype(np.uint8)\n",
    "    \n",
    "    # 6. Display\n",
    "    if display_image:\n",
    "        print(\"Displaying the unlensed advanced source disk:\")\n",
    "        img = Image.fromarray(image_array)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(img, extent=[-half_width, half_width, -half_width, half_width])\n",
    "        plt.title(\"Advanced, EHT-Style Source Disk (Corrected)\")\n",
    "        plt.xlabel(\"y (M)\")\n",
    "        plt.ylabel(\"z (M)\")\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.show()\n",
    "        \n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae1e9be",
   "metadata": {},
   "source": [
    "# Static lensed image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1444301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# ADD AS A NEW CELL for the static image generator\n",
    "\n",
    "def generate_static_lensed_image(\n",
    "    output_filename: str,\n",
    "    output_pixel_width: int,\n",
    "    source_image_width: float,\n",
    "    sphere_image: Union[str, np.ndarray],\n",
    "    source_image: Union[str, np.ndarray],\n",
    "    M_scale: float, # Still needed for redshift, if we add it later\n",
    "    blueprint_filename: str = \"project/photon_geodesic_integrator/blueprint.bin\",\n",
    "    window_width: Optional[float] = None,\n",
    "    zoom_region: Optional[Union[List[float], Tuple[float, float, float, float]]] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generates a lensed image of a STATIC source.\n",
    "\n",
    "    This version only accounts for the light-travel time delay (t_s) for effects\n",
    "    like gravitational redshift, but does NOT animate or rotate the disk.\n",
    "    \"\"\"\n",
    "    print(f\"--- Generating Static Lensed Image: '{output_filename}' ---\")\n",
    "    \n",
    "    # --- Phase 1: Initialization and Setup (Identical to animated version) ---\n",
    "    if zoom_region:\n",
    "        y_w_min, y_w_max, z_w_min, z_w_max = zoom_region\n",
    "    elif window_width:\n",
    "        half_w = window_width / 2.0\n",
    "        y_w_min, y_w_max = -half_w, half_w\n",
    "        z_w_min, z_w_max = -half_w, half_w\n",
    "    else:\n",
    "        raise ValueError(\"Either 'window_width' or 'zoom_region' must be provided.\")\n",
    "\n",
    "    window_y_range = y_w_max - y_w_min\n",
    "    window_z_range = z_w_max - z_w_min\n",
    "    aspect_ratio = window_z_range / window_y_range\n",
    "    output_pixel_height = int(output_pixel_width * aspect_ratio)\n",
    "\n",
    "    source_texture = _load_texture(source_image)\n",
    "    sphere_texture = _load_texture(sphere_image)\n",
    "    source_pixel_height, source_pixel_width, _ = source_texture.shape\n",
    "    sphere_pixel_height, sphere_pixel_width, _ = sphere_texture.shape\n",
    "\n",
    "    if not os.path.exists(blueprint_filename):\n",
    "        raise FileNotFoundError(f\"Blueprint file not found: {blueprint_filename}\")\n",
    "    blueprint_data = np.fromfile(blueprint_filename, dtype=BLUEPRINT_DTYPE)\n",
    "\n",
    "    pixel_accumulator = np.zeros((output_pixel_height, output_pixel_width, 3), dtype=np.float64)\n",
    "    count_accumulator = np.zeros((output_pixel_height, output_pixel_width), dtype=np.int32)\n",
    "\n",
    "    # --- Phase 2: Vectorized Ray Processing ---\n",
    "    mask_in_view = (\n",
    "        (blueprint_data['y_w'] >= y_w_min) & (blueprint_data['y_w'] < y_w_max) &\n",
    "        (blueprint_data['z_w'] >= z_w_min) & (blueprint_data['z_w'] < z_w_max)\n",
    "    )\n",
    "    rays_in_view = blueprint_data[mask_in_view]\n",
    "    \n",
    "    if len(rays_in_view) > 0:\n",
    "        px_float = (rays_in_view['y_w'] - y_w_min) / window_y_range * output_pixel_width\n",
    "        py_float = (z_w_max - rays_in_view['z_w']) / window_z_range * output_pixel_height\n",
    "        px = np.clip(px_float, 0, output_pixel_width - 1).astype(np.int32)\n",
    "        py = np.clip(py_float, 0, output_pixel_height - 1).astype(np.int32)\n",
    "\n",
    "        is_source = rays_in_view['termination_type'] == 1\n",
    "        is_sphere = rays_in_view['termination_type'] == 2\n",
    "\n",
    "        if np.any(is_source):\n",
    "            source_hits = rays_in_view[is_source]\n",
    "\n",
    "            \n",
    "            # --- STATIC MAPPING LOGIC ---\n",
    "            # We use the intersection coordinates (y_s, z_s) directly, without rotation.\n",
    "            y_s_map = source_hits['y_s']\n",
    "            z_s_map = source_hits['z_s']\n",
    "            \n",
    "            half_sw = source_image_width / 2.0\n",
    "            norm_y = (y_s_map + half_sw) / source_image_width\n",
    "            norm_z = (z_s_map + half_sw) / source_image_width\n",
    "            # --- End of Static Logic ---\n",
    "\n",
    "            px_s = norm_y * (source_pixel_width - 1)\n",
    "            py_s = (1.0 - norm_z) * (source_pixel_height - 1)\n",
    "            px_s_int = np.clip(px_s, 0, source_pixel_width - 1).astype(np.int32)\n",
    "            py_s_int = np.clip(py_s, 0, source_pixel_height - 1).astype(np.int32)\n",
    "            source_colors = source_texture[py_s_int, px_s_int]\n",
    "            np.add.at(pixel_accumulator, (py[is_source], px[is_source]), source_colors)\n",
    "\n",
    "        if np.any(is_sphere):\n",
    "            sphere_hits = rays_in_view[is_sphere]\n",
    "            norm_phi = (sphere_hits['final_phi'] + np.pi) / (2 * np.pi)\n",
    "            norm_theta = sphere_hits['final_theta'] / np.pi\n",
    "            px_sph = norm_phi * (sphere_pixel_width - 1)\n",
    "            py_sph = norm_theta * (sphere_pixel_height - 1)\n",
    "            px_sph_int = np.clip(px_sph, 0, sphere_pixel_width - 1).astype(np.int32)\n",
    "            py_sph_int = np.clip(py_sph, 0, sphere_pixel_height - 1).astype(np.int32)\n",
    "            sphere_colors = sphere_texture[py_sph_int, px_sph_int]\n",
    "            np.add.at(pixel_accumulator, (py[is_sphere], px[is_sphere]), sphere_colors)\n",
    "\n",
    "        np.add.at(count_accumulator, (py, px), 1)\n",
    "\n",
    "    # --- Phase 3: Assembling Final Image ---\n",
    "    hit_pixels_mask = count_accumulator > 0\n",
    "    final_image_float = np.zeros_like(pixel_accumulator)\n",
    "    final_image_float[hit_pixels_mask] = (\n",
    "        pixel_accumulator[hit_pixels_mask] / count_accumulator[hit_pixels_mask, np.newaxis]\n",
    "    )\n",
    "    \n",
    "    final_image_uint8 = (np.clip(final_image_float, 0, 1) * 255).astype(np.uint8)\n",
    "    \n",
    "    img = Image.fromarray(final_image_uint8, 'RGB')\n",
    "    \n",
    "    output_dir = os.path.dirname(output_filename)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    img.save(output_filename)\n",
    "    print(f\"--- Static image saved to '{output_filename}' ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b84dba",
   "metadata": {},
   "source": [
    "# Rotating source image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1572a410",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_animated_lensed_image(\n",
    "    output_filename: str,\n",
    "    output_pixel_width: int,\n",
    "    source_image_width: float,\n",
    "    sphere_image: Union[str, np.ndarray],\n",
    "    source_image: Union[str, np.ndarray],\n",
    "    # --- Parameters for orbital dynamics ---\n",
    "    M_scale: float,\n",
    "    t_anim: float,\n",
    "    prograde_disk: bool = True,\n",
    "    # ---\n",
    "    blueprint_filename: str = \"project/photon_geodesic_integrator/blueprint.bin\",\n",
    "    window_width: Optional[float] = None,\n",
    "    zoom_region: Optional[Union[List[float], Tuple[float, float, float, float]]] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generates a lensed image of a DYNAMIC, differentially rotating Keplerian disk.\n",
    "    \n",
    "    This version uses the animation time (t_anim) and light-travel time (t_s)\n",
    "    to calculate the rotational position of the disk at the moment of emission.\n",
    "    \"\"\"\n",
    "    # The body of this function is identical to the one I provided previously,\n",
    "    # as its logic for handling animation was already correct.\n",
    "    \n",
    "    # --- Phase 1: Initialization and Setup ---\n",
    "    if zoom_region:\n",
    "        y_w_min, y_w_max, z_w_min, z_w_max = zoom_region\n",
    "    elif window_width:\n",
    "        half_w = window_width / 2.0\n",
    "        y_w_min, y_w_max = -half_w, half_w\n",
    "        z_w_min, z_w_max = -half_w, half_w\n",
    "    else:\n",
    "        raise ValueError(\"Either 'window_width' or 'zoom_region' must be provided.\")\n",
    "\n",
    "    window_y_range = y_w_max - y_w_min\n",
    "    window_z_range = z_w_max - z_w_min\n",
    "    aspect_ratio = window_z_range / window_y_range\n",
    "    output_pixel_height = int(output_pixel_width * aspect_ratio)\n",
    "\n",
    "    source_texture = _load_texture(source_image)\n",
    "    sphere_texture = _load_texture(sphere_image)\n",
    "    source_pixel_height, source_pixel_width, _ = source_texture.shape\n",
    "    sphere_pixel_height, sphere_pixel_width, _ = sphere_texture.shape\n",
    "\n",
    "    if not os.path.exists(blueprint_filename):\n",
    "        raise FileNotFoundError(f\"Blueprint file not found: {blueprint_filename}\")\n",
    "    blueprint_data = np.fromfile(blueprint_filename, dtype=BLUEPRINT_DTYPE)\n",
    "\n",
    "    pixel_accumulator = np.zeros((output_pixel_height, output_pixel_width, 3), dtype=np.float64)\n",
    "    count_accumulator = np.zeros((output_pixel_height, output_pixel_width), dtype=np.int32)\n",
    "\n",
    "    # --- Phase 2: Vectorized Ray Processing ---\n",
    "    mask_in_view = (\n",
    "        (blueprint_data['y_w'] >= y_w_min) & (blueprint_data['y_w'] < y_w_max) &\n",
    "        (blueprint_data['z_w'] >= z_w_min) & (blueprint_data['z_w'] < z_w_max)\n",
    "    )\n",
    "    rays_in_view = blueprint_data[mask_in_view]\n",
    "    \n",
    "    if len(rays_in_view) > 0:\n",
    "        px_float = (rays_in_view['y_w'] - y_w_min) / window_y_range * output_pixel_width\n",
    "        py_float = (z_w_max - rays_in_view['z_w']) / window_z_range * output_pixel_height\n",
    "        px = np.clip(px_float, 0, output_pixel_width - 1).astype(np.int32)\n",
    "        py = np.clip(py_float, 0, output_pixel_height - 1).astype(np.int32)\n",
    "\n",
    "        is_source = rays_in_view['termination_type'] == 1\n",
    "        is_sphere = rays_in_view['termination_type'] == 2\n",
    "\n",
    "        if np.any(is_source):\n",
    "            source_hits = rays_in_view[is_source]\n",
    "            \n",
    "            y_s_intersect = source_hits['y_s']\n",
    "            z_s_intersect = source_hits['z_s']\n",
    "            t_s = source_hits['t_s']\n",
    "            \n",
    "            r_s = np.sqrt(y_s_intersect**2 + z_s_intersect**2)\n",
    "            Omega = np.sqrt(M_scale / (r_s**3 + 1e-12))\n",
    "            \n",
    "            total_time = t_anim + t_s\n",
    "            rotation_angle = Omega * total_time\n",
    "            rotation_direction = -1.0 if prograde_disk else 1.0\n",
    "            final_angle = rotation_direction * rotation_angle\n",
    "            \n",
    "            cos_angle = np.cos(final_angle)\n",
    "            sin_angle = np.sin(final_angle)\n",
    "            \n",
    "            y_s_emit = y_s_intersect * cos_angle - z_s_intersect * sin_angle\n",
    "            z_s_emit = y_s_intersect * sin_angle + z_s_intersect * cos_angle\n",
    "            \n",
    "            half_sw = source_image_width / 2.0\n",
    "            norm_y = (y_s_emit + half_sw) / source_image_width\n",
    "            norm_z = (z_s_emit + half_sw) / source_image_width\n",
    "\n",
    "            px_s = norm_y * (source_pixel_width - 1)\n",
    "            py_s = (1.0 - norm_z) * (source_pixel_height - 1)\n",
    "            px_s_int = np.clip(px_s, 0, source_pixel_width - 1).astype(np.int32)\n",
    "            py_s_int = np.clip(py_s, 0, source_pixel_height - 1).astype(np.int32)\n",
    "            source_colors = source_texture[py_s_int, px_s_int]\n",
    "            np.add.at(pixel_accumulator, (py[is_source], px[is_source]), source_colors)\n",
    "\n",
    "        if np.any(is_sphere):\n",
    "            sphere_hits = rays_in_view[is_sphere]\n",
    "            norm_phi = (sphere_hits['final_phi'] + np.pi) / (2 * np.pi)\n",
    "            norm_theta = sphere_hits['final_theta'] / np.pi\n",
    "            px_sph = norm_phi * (sphere_pixel_width - 1)\n",
    "            py_sph = norm_theta * (sphere_pixel_height - 1)\n",
    "            px_sph_int = np.clip(px_sph, 0, sphere_pixel_width - 1).astype(np.int32)\n",
    "            py_sph_int = np.clip(py_sph, 0, sphere_pixel_height - 1).astype(np.int32)\n",
    "            sphere_colors = sphere_texture[py_sph_int, px_sph_int]\n",
    "            np.add.at(pixel_accumulator, (py[is_sphere], px[is_sphere]), sphere_colors)\n",
    "\n",
    "        np.add.at(count_accumulator, (py, px), 1)\n",
    "\n",
    "    # --- Phase 3: Assembling Final Image ---\n",
    "    hit_pixels_mask = count_accumulator > 0\n",
    "    final_image_float = np.zeros_like(pixel_accumulator)\n",
    "    final_image_float[hit_pixels_mask] = (\n",
    "        pixel_accumulator[hit_pixels_mask] / count_accumulator[hit_pixels_mask, np.newaxis]\n",
    "    )\n",
    "    \n",
    "    final_image_uint8 = (np.clip(final_image_float, 0, 1) * 255).astype(np.uint8)\n",
    "    \n",
    "    img = Image.fromarray(final_image_uint8, 'RGB')\n",
    "    \n",
    "    output_dir = os.path.dirname(output_filename)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    img.save(output_filename)\n",
    "    print(f\"--- Animated frame saved to '{output_filename}' ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2cab0",
   "metadata": {},
   "source": [
    "# The Master Animation Frame Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1a21ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import display, Image as IPImage\n",
    "from typing import Union\n",
    "\n",
    "def generate_animation_frames(\n",
    "    # --- Core Inputs ---\n",
    "    blueprint_filename: str,\n",
    "    output_folder: str,\n",
    "    \n",
    "    # --- Rendering & Physics Parameters ---\n",
    "    source_texture: Union[str, np.ndarray],\n",
    "    sphere_texture: Union[str, np.ndarray],\n",
    "    source_physical_width: float,\n",
    "    mass_of_black_hole: float,\n",
    "    \n",
    "    # --- Animation Control ---\n",
    "    num_frames: int = 120,\n",
    "    orbits_at_isco: float = 2.0,\n",
    "    is_prograde: bool = True,\n",
    "    \n",
    "    # --- Image & Window Settings ---\n",
    "    output_pixel_width: int = 400,\n",
    "    window_width: float = 1.5\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generates a sequence of lensed image frames for creating an animation.\n",
    "\n",
    "    This function takes a single ray-tracing blueprint and generates multiple\n",
    "    frames by animating a differentially rotating Keplerian disk over time.\n",
    "\n",
    "    Args:\n",
    "        blueprint_filename: Path to the input 'blueprint.bin' file.\n",
    "        output_folder: Directory where the output frames will be saved.\n",
    "        source_texture: Path to the source image or a pre-loaded NumPy array.\n",
    "        sphere_texture: Path to the background star map or a pre-loaded NumPy array.\n",
    "        source_physical_width: The physical width (in units of M) of the source texture.\n",
    "        mass_of_black_hole: The mass (M_scale) of the black hole.\n",
    "        num_frames: The total number of frames to generate for the animation.\n",
    "        orbits_at_isco: The total number of orbits the disk completes at the ISCO (r=6M)\n",
    "                        over the full animation duration.\n",
    "        is_prograde: Direction of disk rotation (True for prograde, False for retrograde).\n",
    "        output_pixel_width: The width of the output images in pixels.\n",
    "        window_width: The physical width of the camera's viewing window.\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting Animation Generation ---\")\n",
    "    \n",
    "    # --- Setup and Validation ---\n",
    "    if not os.path.exists(blueprint_filename):\n",
    "        raise FileNotFoundError(f\"Blueprint file not found: {blueprint_filename}\")\n",
    "        \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Calculate total animation time based on the desired number of orbits at the ISCO\n",
    "    # ISCO for Schwarzschild is at r=6M.\n",
    "    isco_radius = 6.0 \n",
    "    orbital_period_at_isco = 2 * np.pi * np.sqrt(isco_radius**3 / mass_of_black_hole)\n",
    "    total_animation_time = orbital_period_at_isco * orbits_at_isco\n",
    "    \n",
    "    print(f\"  Configuration:\")\n",
    "    print(f\"    Total frames: {num_frames}\")\n",
    "    print(f\"    Total animation time: {total_animation_time:.2f} M ({orbits_at_isco:.1f} orbits at r=6M)\")\n",
    "    print(f\"    Output folder: '{output_folder}'\")\n",
    "\n",
    "    # --- Master Animation Loop ---\n",
    "    for i in range(num_frames):\n",
    "        # Calculate the animation time for the current frame\n",
    "        t_animation = (i / (num_frames - 1)) * total_animation_time if num_frames > 1 else 0\n",
    "        \n",
    "        # Define a sequential filename for the frame\n",
    "        frame_filename = os.path.join(output_folder, f\"frame_{i:04d}.png\")\n",
    "        \n",
    "        print(f\"Rendering frame {i+1}/{num_frames} (t_anim = {t_animation:.2f} M)...\")\n",
    "        \n",
    "        # Call the rendering function for a single frame\n",
    "        generate_animated_lensed_image(\n",
    "            output_filename=frame_filename,\n",
    "            output_pixel_width=output_pixel_width,\n",
    "            source_image_width=source_physical_width,\n",
    "            sphere_image=sphere_texture,\n",
    "            source_image=source_texture,\n",
    "            M_scale=mass_of_black_hole,\n",
    "            t_anim=t_animation,\n",
    "            prograde_disk=is_prograde,\n",
    "            blueprint_filename=blueprint_filename,\n",
    "            window_width=window_width\n",
    "        )\n",
    "\n",
    "    print(\"\\n--- All frames generated successfully. ---\")\n",
    "\n",
    "    # Optional: Display the first frame in the notebook for verification\n",
    "    first_frame_path = os.path.join(output_folder, \"frame_0000.png\")\n",
    "    if os.path.exists(first_frame_path):\n",
    "        print(\"Displaying first generated frame:\")\n",
    "        display(IPImage(filename=first_frame_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2801c51d",
   "metadata": {},
   "source": [
    "#  The Video Encoding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bad79e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def encode_video_from_frames(\n",
    "    image_folder: str,\n",
    "    output_video_path: str,\n",
    "    frame_rate: int = 30,\n",
    "    crf: int = 18\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Encodes a sequence of image frames into a video file using FFmpeg.\n",
    "\n",
    "    This function requires FFmpeg to be installed and accessible in the system's PATH.\n",
    "\n",
    "    Args:\n",
    "        image_folder: The directory containing the sequentially named image frames.\n",
    "        output_video_path: The full path for the output video file (e.g., 'output/animation.mp4').\n",
    "        frame_rate: The frame rate for the output video.\n",
    "        crf: The Constant Rate Factor for the x264 codec (lower is higher quality).\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting Video Encoding ---\")\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    output_dir = os.path.dirname(output_video_path)\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Construct the FFmpeg command as a list of arguments\n",
    "    command = [\n",
    "        'ffmpeg',\n",
    "        '-y',  # Overwrite output file if it exists\n",
    "        '-framerate', str(frame_rate),\n",
    "        '-i', os.path.join(image_folder, 'frame_%04d.png'),\n",
    "        '-c:v', 'libx264',\n",
    "        '-pix_fmt', 'yuv420p',\n",
    "        '-r', str(frame_rate),\n",
    "        '-crf', str(crf),\n",
    "        output_video_path\n",
    "    ]\n",
    "\n",
    "    print(f\"Running FFmpeg command:\\n{' '.join(command)}\")\n",
    "\n",
    "    try:\n",
    "        # Run the command\n",
    "        # capture_output=True will store stdout and stderr in the result object\n",
    "        # text=True will decode them as text\n",
    "        result = subprocess.run(\n",
    "            command,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True  # This will raise a CalledProcessError if FFmpeg returns a non-zero exit code\n",
    "        )\n",
    "        print(\"\\n--- FFmpeg stdout ---\")\n",
    "        print(result.stdout)\n",
    "        print(\"\\n--- FFmpeg stderr ---\")\n",
    "        print(result.stderr)\n",
    "        print(f\"\\n[✓] Video encoding successful. File saved to '{output_video_path}'\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\n[!] ERROR: FFmpeg not found.\")\n",
    "        print(\"Please ensure FFmpeg is installed and accessible in your system's PATH.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n[!] ERROR: FFmpeg failed with exit code {e.returncode}.\")\n",
    "        print(\"\\n--- FFmpeg stdout ---\")\n",
    "        print(e.stdout)\n",
    "        print(\"\\n--- FFmpeg stderr ---\")\n",
    "        print(e.stderr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8632d17",
   "metadata": {},
   "source": [
    "# Runner and Blueprint Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "797597e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper function `run_integrator_and_rename_blueprint` defined.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def run_integrator_and_rename_blueprint(\n",
    "    project_dir: str,\n",
    "    executable_name: str,\n",
    "    args_string: str,\n",
    "    output_blueprint_name: str,\n",
    "    # NEW: Added parameter for the output directory for blueprints\n",
    "    bin_folder: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Runs the C geodesic integrator and moves the resulting blueprint file\n",
    "    to a specified subfolder.\n",
    "    \"\"\"\n",
    "    command_to_run = f\"./{executable_name} {args_string}\"\n",
    "    \n",
    "    print(f\"--- Running command in directory '{project_dir}': {command_to_run} ---\")\n",
    "\n",
    "    try:\n",
    "        process_result = subprocess.run(\n",
    "            command_to_run,\n",
    "            shell=True,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True,\n",
    "            cwd=project_dir\n",
    "        )\n",
    "        print(process_result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"ERROR: The C program exited with an error (exit code {e.returncode}).\")\n",
    "        print(\"--- Standard Error ---\")\n",
    "        print(e.stderr)\n",
    "        return\n",
    "\n",
    "    # The C code always outputs 'blueprint.bin' to its own directory.\n",
    "    original_blueprint_path = os.path.join(project_dir, \"blueprint.bin\")\n",
    "    \n",
    "    # --- MODIFICATION: Move blueprint to the specified subfolder ---\n",
    "    # First, ensure the destination folder exists.\n",
    "    destination_folder = os.path.join(project_dir, bin_folder)\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    \n",
    "    # Construct the final path for the renamed blueprint.\n",
    "    new_blueprint_path = os.path.join(destination_folder, output_blueprint_name)\n",
    "\n",
    "    if os.path.exists(original_blueprint_path):\n",
    "        print(f\"Moving '{original_blueprint_path}' to '{new_blueprint_path}'...\")\n",
    "        shutil.move(original_blueprint_path, new_blueprint_path)\n",
    "        print(\"--- Run complete. ---\")\n",
    "    else:\n",
    "        print(\"Warning: 'blueprint.bin' was not created by the C program.\")\n",
    "\n",
    "print(\"Helper function `run_integrator_and_rename_blueprint` defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "29a9087e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Execution stopped here intentionally.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mExecution stopped here intentionally.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Execution stopped here intentionally."
     ]
    }
   ],
   "source": [
    "raise KeyboardInterrupt(\"Execution stopped here intentionally.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac14320",
   "metadata": {},
   "source": [
    "# Start of visual function call cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab59a53",
   "metadata": {},
   "source": [
    "# Setting all visualization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In Cell 9.B.1: Master Configuration for Visualization\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"--- Initializing Master Configuration for Visualization ---\")\n",
    "\n",
    "# --- Core File & Path Settings ---\n",
    "p_blueprint_filename = \"project/photon_geodesic_integrator/blueprint.bin\"\n",
    "p_output_basedir = \"Generated_nrpy_images\"\n",
    "\n",
    "# --- Physics & Scene Parameters ---\n",
    "p_mass_of_black_hole = 1.0\n",
    "p_window_width = 1.5\n",
    "\n",
    "# --- Source & Background Texture Settings ---\n",
    "p_sphere_texture_file = \"starmap_2020.png\"\n",
    "\n",
    "# --- Procedural Disk Generation Parameters ---\n",
    "# These parameters control the appearance of the advanced accretion disk.\n",
    "\n",
    "# Basic Geometry & Colormap\n",
    "p_disk_inner_radius = 6.0\n",
    "p_disk_outer_radius = 25.0\n",
    "p_colormap = 'afmhot'\n",
    "\n",
    "# Base Radial Brightness Profile\n",
    "p_disk_temp_power_law = -1.5\n",
    "\n",
    "# Concentric Rings / Gaps\n",
    "p_ring_num = 4\n",
    "p_ring_contrast = 0.7\n",
    "p_ring_log_spacing = True\n",
    "\n",
    "# Doppler Beaming (Asymmetric Brightness)\n",
    "p_doppler_factor = 0.3\n",
    "p_doppler_power = 3\n",
    "\n",
    "# Non-Axisymmetric Hot Spots (Set hotspot_num=0 to disable)\n",
    "p_hotspot_num = 2\n",
    "p_hotspot_amplitude = 0.4  # Increased for more prominent spots\n",
    "p_hotspot_radius_center = 10.0\n",
    "p_hotspot_radius_width = 4.0\n",
    "\n",
    "# Non-Symmetric Radial Shape (Set shape_num_lobes=0 for perfect circles)\n",
    "p_shape_num_lobes = 0\n",
    "p_shape_inner_amplitude = 0.0\n",
    "p_shape_outer_amplitude = 0.0\n",
    "\n",
    "# This canonical width is now calculated based on the shape parameters\n",
    "p_source_physical_width = 2 * (p_disk_outer_radius + p_shape_outer_amplitude)\n",
    "\n",
    "# --- Animation Settings ---\n",
    "p_anim_spinning_folder = os.path.join(p_output_basedir, \"spinning_disk_with_hotspots\")\n",
    "p_anim_spinning_video_file = os.path.join(p_output_basedir, \"spinning_disk_with_hotspots.mp4\")\n",
    "p_anim_spinning_num_frames = 150\n",
    "p_anim_spinning_orbits_at_isco = 2.0\n",
    "p_anim_spinning_is_prograde = True\n",
    "\n",
    "# --- General Image Quality Settings ---\n",
    "p_static_image_pixel_width = 512\n",
    "p_animation_pixel_width = 400\n",
    "\n",
    "print(\"Master configuration loaded with parameters for hotspots.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dcf495",
   "metadata": {},
   "source": [
    "# Disk generation (advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e118a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In Cell 9.B.2: Generate Advanced Disk Texture\n",
    "\n",
    "print(\"--- Generating Procedural Texture for the Accretion Disk ---\")\n",
    "\n",
    "advanced_disk_data = generate_advanced_disk_array(\n",
    "    pixel_width=1024,\n",
    "    disk_physical_width=p_source_physical_width, # CORRECTED: Uses the master width\n",
    "    colormap=p_colormap,\n",
    "    # ... (rest of the parameters are the same) ...\n",
    "    disk_inner_radius=p_disk_inner_radius,\n",
    "    disk_outer_radius=p_disk_outer_radius,\n",
    "    disk_temp_power_law=p_disk_temp_power_law,\n",
    "    ring_num=p_ring_num,\n",
    "    ring_contrast=p_ring_contrast,\n",
    "    ring_log_spacing=p_ring_log_spacing,\n",
    "    doppler_factor=p_doppler_factor,\n",
    "    doppler_power=p_doppler_power,\n",
    "    hotspot_num=p_hotspot_num,\n",
    "    shape_num_lobes=p_shape_num_lobes,\n",
    "    shape_inner_amplitude=p_shape_inner_amplitude,\n",
    "    shape_outer_amplitude=p_shape_outer_amplitude,\n",
    "    display_image=True\n",
    ")\n",
    "\n",
    "print(\"\\nVariable 'advanced_disk_data' created and is ready for use in rendering cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ba0b21",
   "metadata": {},
   "source": [
    "# Disk Generation (Old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=generate_source_disk_array(\n",
    "    pixel_width=1024,\n",
    "    disk_physical_width=52.0,\n",
    "    disk_inner_radius=3.0,\n",
    "    disk_outer_radius=26.0,\n",
    "    disk_temp_power_law=-0.75,\n",
    "    colormap='hot',\n",
    "    display_image=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86facc9",
   "metadata": {},
   "source": [
    "# Standard Static Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7d2d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In Cell 9.B.3: Standard Static Image Generation\n",
    "\n",
    "from IPython.display import display, Image as IPImage\n",
    "import os\n",
    "\n",
    "print(\"--- Generating a Standard Static Lensed Image ---\")\n",
    "\n",
    "p_output_filename = os.path.join(p_output_basedir, \"static_lensed_disk.png\")\n",
    "\n",
    "#source_image= \"rainbow.png\"\n",
    "source_image = advanced_disk_data\n",
    "# --- Function Call ---\n",
    "generate_static_lensed_image(\n",
    "    output_filename=p_output_filename,\n",
    "    output_pixel_width=p_static_image_pixel_width,\n",
    "    source_image_width=p_source_physical_width,\n",
    "    sphere_image=p_sphere_texture_file,\n",
    "    source_image=source_image,\n",
    "    \n",
    "    M_scale=p_mass_of_black_hole,\n",
    "    blueprint_filename=p_blueprint_filename,\n",
    "    window_width=p_window_width\n",
    ")\n",
    "\n",
    "# --- Display the result ---\n",
    "if os.path.exists(p_output_filename):\n",
    "    print(f\"\\nDisplaying static image: '{p_output_filename}'\")\n",
    "    display(IPImage(filename=p_output_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8919fff",
   "metadata": {},
   "source": [
    "# Generate Frames for Spinning Disk Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe671ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In Cell 9.B.4: Generate Frames for Spinning Disk Animation\n",
    "p_disk_phy5sical_width= 52\n",
    "# Call the function to generate the frames using parameters from the master config cell\n",
    "generate_animation_frames(\n",
    "    blueprint_filename=p_blueprint_filename,\n",
    "    output_folder=p_anim_spinning_folder,\n",
    "    source_texture=source_image,\n",
    "    sphere_texture=p_sphere_texture_file,\n",
    "    source_physical_width=p_disk_phy5sical_width,\n",
    "    mass_of_black_hole=p_mass_of_black_hole,\n",
    "    is_prograde=p_anim_spinning_is_prograde,\n",
    "    num_frames=p_anim_spinning_num_frames,\n",
    "    orbits_at_isco=p_anim_spinning_orbits_at_isco,\n",
    "    output_pixel_width=p_animation_pixel_width,\n",
    "    window_width=p_window_width\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10dc9b4",
   "metadata": {},
   "source": [
    "# Generate Frames for Moving Camera Animation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3190b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In Cell 9.B.5: Generate Frames for Moving Camera Animation\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"--- Generating Frames for a Moving Camera Animation ---\")\n",
    "\n",
    "# --- Camera Path Definition ---\n",
    "num_camera_frames = 60\n",
    "camera_path_radius = 40.0\n",
    "camera_y_pos = 10.0\n",
    "\n",
    "# --- Main Loop ---\n",
    "for i in range(num_camera_frames):\n",
    "    angle = (i / num_camera_frames) * 2 * np.pi\n",
    "    cam_x = camera_path_radius * np.cos(angle)\n",
    "    cam_z = camera_path_radius * np.sin(angle)\n",
    "    \n",
    "    print(f\"\\n--- Processing Frame {i+1}/{num_camera_frames}: Camera at (x={cam_x:.2f}, y={camera_y_pos:.2f}, z={cam_z:.2f}) ---\")\n",
    "    \n",
    "    # Create a temporary parameter file for this specific frame\n",
    "    temp_par_content = f\"camera_pos_x = {cam_x:.3f}\\ncamera_pos_y = {camera_y_pos:.3f}\\ncamera_pos_z = {cam_z:.3f}\\n\"\n",
    "    temp_par_content += f\"M_scale = {p_mass_of_black_hole}\\na_spin = 0.99\\nscan_density = 256\\n\" # Lower density for speed\n",
    "    temp_par_filename = os.path.join(\"project/photon_geodesic_integrator\", \"temp_camera_anim.par\")\n",
    "    with open(temp_par_filename, \"w\") as f:\n",
    "        f.write(temp_par_content)\n",
    "\n",
    "    # Run C code to generate a new blueprint\n",
    "    blueprint_frame_name = f\"blueprint_cam_frame_{i:04d}.bin\"\n",
    "    run_integrator_and_rename_blueprint(\n",
    "        project_dir=\"project/photon_geodesic_integrator\",\n",
    "        executable_name=\"photon_geodesic_integrator\",\n",
    "        args_string=\"temp_camera_anim.par\",\n",
    "        output_blueprint_name=blueprint_frame_name,\n",
    "        bin_folder=p_anim_camera_blueprint_folder\n",
    "    )\n",
    "    \n",
    "    # Render the image for this frame\n",
    "    blueprint_path = os.path.join(\"project/photon_geodesic_integrator\", p_anim_camera_blueprint_folder, blueprint_frame_name)\n",
    "    if not os.path.exists(blueprint_path):\n",
    "        print(f\"ERROR: Blueprint '{blueprint_path}' not found. Skipping rendering.\")\n",
    "        continue\n",
    "        \n",
    "    image_frame_name = os.path.join(p_anim_camera_frames_folder, f\"frame_{i:04d}.png\")\n",
    "    \n",
    "    # Use the static image generator, as the disk is not spinning in this animation\n",
    "    generate_static_lensed_image(\n",
    "        output_filename=image_frame_name,\n",
    "        output_pixel_width=p_animation_pixel_width,\n",
    "        source_image_width=p_disk_physical_width,\n",
    "        sphere_image=p_sphere_texture_file,\n",
    "        source_image=advanced_disk_data,\n",
    "        M_scale=p_mass_of_black_hole,\n",
    "        blueprint_filename=blueprint_path,\n",
    "        window_width=p_window_width\n",
    "    )\n",
    "\n",
    "print(\"\\n--- All frames for moving camera animation generated. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a295dc",
   "metadata": {},
   "source": [
    "# Final Video Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af13cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In Cell 9.B.6: Final Video Encoding\n",
    "\n",
    "# --- Choose which animation to encode ---\n",
    "\n",
    "# Option 1: Spinning Disk\n",
    "p_input_frames_folder = p_anim_spinning_folder\n",
    "p_output_video_file = p_anim_spinning_video_file\n",
    "\n",
    "# Option 2: Moving Camera (uncomment to use)\n",
    "# p_input_frames_folder = p_anim_camera_frames_folder\n",
    "# p_output_video_file = p_anim_camera_video_file\n",
    "\n",
    "# --- Encoding settings ---\n",
    "p_frame_rate = 30\n",
    "p_quality_factor = 18\n",
    "\n",
    "# --- Function Call ---\n",
    "encode_video_from_frames(\n",
    "    image_folder=p_input_frames_folder,\n",
    "    output_video_path=p_output_video_file,\n",
    "    frame_rate=p_frame_rate,\n",
    "    crf=p_quality_factor\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Photon Integrator)",
   "language": "python",
   "name": "photon-integrator-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
