{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba92b65f",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bac0cb",
   "metadata": {},
   "source": [
    "# Table of Contents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c0d30",
   "metadata": {},
   "source": [
    "\n",
    "#  Project Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f07e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In V1_0_mass_geodesic.ipynb, Cell ID 33f07e1c\n",
    "import os\n",
    "import shutil\n",
    "import sympy as sp\n",
    "import nrpy.c_function as cfc\n",
    "import nrpy.c_codegen as ccg\n",
    "import nrpy.params as par\n",
    "import nrpy.indexedexp as ixp\n",
    "import nrpy.infrastructures.BHaH.BHaH_defines_h as Bdefines_h\n",
    "import nrpy.infrastructures.BHaH.Makefile_helpers as Makefile\n",
    "from nrpy.infrastructures.BHaH import cmdline_input_and_parfiles\n",
    "import nrpy.helpers.generic as gh\n",
    "import nrpy.infrastructures.BHaH.CodeParameters as CPs\n",
    "\n",
    "project_name = \"mass_integrator\"\n",
    "project_dir = os.path.join(\"project\", project_name)\n",
    "shutil.rmtree(project_dir, ignore_errors=True)\n",
    "\n",
    "par.set_parval_from_str(\"Infrastructure\", \"BHaH\")\n",
    "\n",
    "# --- Physical Parameters ---\n",
    "M_scale = par.CodeParameter(\"REAL\", __name__, \"M_scale\", 1.0, commondata=True, add_to_parfile=True, add_to_set_CodeParameters_h=True)\n",
    "a_spin = par.CodeParameter(\"REAL\", __name__, \"a_spin\", 0.9, commondata=True, add_to_parfile=True, add_to_set_CodeParameters_h=True)\n",
    "\n",
    "# --- Integration & Termination Parameters ---\n",
    "t_max_integration = par.CodeParameter(\"REAL\", __name__, \"t_max_integration\", 2000.0, commondata=True, add_to_parfile=True)\n",
    "flatness_threshold = par.CodeParameter(\"REAL\", __name__, \"flatness_threshold\", 1e-2, commondata=True, add_to_parfile=True)\n",
    "r_escape = par.CodeParameter(\"REAL\", __name__, \"r_escape\", 1500.0, commondata=True, add_to_parfile=True)\n",
    "ut_max = par.CodeParameter(\"REAL\", __name__, \"ut_max\", 1e3, commondata=True, add_to_parfile=True)\n",
    "\n",
    "# --- Debugging & Validation Parameters ---\n",
    "perform_conservation_check = par.CodeParameter(\"bool\", __name__, \"perform_conservation_check\", True, commondata=True, add_to_parfile=True)\n",
    "run_in_debug_mode = par.CodeParameter(\"bool\", __name__, \"run_in_debug_mode\", True, commondata=True, add_to_parfile=True)\n",
    "\n",
    "# --- Disk Parameters ---\n",
    "disk_num_r= par.CodeParameter(\"int\", __name__, \"disk_num_r\", 100, commondata=True, add_to_parfile=True)\n",
    "disk_num_phi= par.CodeParameter(\"int\", __name__, \"disk_num_phi\", 200, commondata=True, add_to_parfile=True)\n",
    "disk_r_min = par.CodeParameter(\"REAL\", __name__, \"disk_r_min\", 6.0, commondata=True, add_to_parfile=True)\n",
    "disk_r_max = par.CodeParameter(\"REAL\", __name__, \"disk_r_max\", 25.0, commondata=True, add_to_parfile=True)\n",
    "snapshot_every_t = par.CodeParameter(\"REAL\", __name__, \"snapshot_every_t\", 10.0, commondata=True, add_to_parfile=True)\n",
    "t_final = par.CodeParameter(\"REAL\", __name__, \"t_final\", 2000.0, commondata=True, add_to_parfile=True)\n",
    "# In Cell 33f07e1c, with the other parameters\n",
    "output_folder = par.CodeParameter(\"char[100]\", __name__, \"output_folder\", \"output\", commondata=True, add_to_parfile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa84ac02",
   "metadata": {},
   "source": [
    "<a id='symbolic_core'></a>\n",
    "# Step 3: The Symbolic Core - Foundational Math\n",
    "\n",
    "This section defines the pure mathematical logic of our problem using Python's `sympy` library. Each function in this section is a \"blueprint\" for a physical calculation. These functions take symbolic `sympy` objects as input and return new symbolic expressions as output. They have no knowledge of C code; they are concerned only with mathematics and will be called later to generate the \"recipes\" for our C code engines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23b659c",
   "metadata": {},
   "source": [
    "<a id='deriv_g4DD'></a>\n",
    "### 3.a: Metric Tensor Derivatives\n",
    "\n",
    "The first step in calculating the Christoffel symbols is to compute the partial derivatives of the metric tensor, $g_{\\mu\\nu}$. This function, `derivative_g4DD`, takes the symbolic 4x4 metric tensor `g4DD` and a list of the four coordinate symbols `xx` as input.\n",
    "\n",
    "The function iterates through all components to symbolically calculate the partial derivative of each metric component with respect to each coordinate. The resulting quantity, which we can denote using comma notation as $g_{\\mu\\nu,\\alpha}$, is defined as:\n",
    "\n",
    "$$ g_{\\mu\\nu,\\alpha} \\equiv \\frac{\\partial g_{\\mu\\nu}}{\\partial x^{\\alpha}} $$\n",
    "\n",
    "The nested `for` loops in the code directly correspond to the spacetime indices `μ, ν, α` in the physics equation. `sympy`'s built-in `sp.diff()` function is used to perform the symbolic differentiation, and the final result is returned as a rank-3 symbolic tensor.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.zerorank3(dimension)`**:\n",
    "    *   **Source File**: `nrpy/indexedexp.py`\n",
    "    *   **Description**: This function creates a symbolic rank-3 tensor (a Python list of lists of lists) of a specified dimension, with all elements initialized to the `sympy` integer 0. It is used here to create a container for the derivative results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_g4DD(g4DD, xx):\n",
    "    \"\"\"Computes the symbolic first derivatives of the metric tensor.\"\"\"\n",
    "    g4DD_dD = ixp.zerorank3(dimension=4)\n",
    "    for nu in range(4):\n",
    "        for mu in range(4):\n",
    "            for alpha in range(4):\n",
    "                g4DD_dD[nu][mu][alpha] = sp.diff(g4DD[nu][mu], xx[alpha])\n",
    "    return g4DD_dD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79893b7",
   "metadata": {},
   "source": [
    "<a id='four_connections'></a>\n",
    "### 3.b: Christoffel Symbol Calculation\n",
    "\n",
    "This function implements the core formula for the Christoffel symbols of the second kind, $\\Gamma^{\\delta}_{\\mu\\nu}$. It takes the symbolic metric tensor `g4DD` ($g_{\\mu\\nu}$) and its derivatives `g4DD_dD` ($g_{\\mu\\nu,\\alpha}$) as input. The calculation requires the inverse metric, $g^{\\mu\\nu}$, which is computed using another `nrpy` helper function.\n",
    "\n",
    "The function then applies the well-known formula for the Christoffel symbols. Using the comma notation for partial derivatives, the formula is:\n",
    "\n",
    "$$ \\Gamma^{\\delta}_{\\mu\\nu} = \\frac{1}{2} g^{\\delta\\alpha} \\left( g_{\\nu\\alpha,\\mu} + g_{\\mu\\alpha,\\nu} - g_{\\mu\\nu,\\alpha} \\right) $$\n",
    "\n",
    "The Python `for` loops iterate over the spacetime indices `δ, μ, ν, α` to construct each component of the Christoffel symbol tensor. After the summation is complete, the `sp.trigsimp()` function is used to simplify the resulting expression. This trigonometric simplification is highly effective and much faster than a general `sp.simplify()` for the Kerr-Schild metric, which contains trigonometric functions of the coordinates.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.zerorank3(dimension)`**: Previously introduced. Used to initialize the Christoffel symbol tensor.\n",
    "*   **`nrpy.indexedexp.symm_matrix_inverter4x4(g4DD)`**:\n",
    "    *   **Source File**: `nrpy/indexedexp.py`\n",
    "    *   **Description**: This function takes a symbolic 4x4 symmetric matrix and analytically computes its inverse. It is highly optimized for this specific task, returning both the inverse matrix ($g^{\\mu\\nu}$) and its determinant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665bc0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_connections(g4DD, g4DD_dD):\n",
    "    \"\"\"\n",
    "    Computes and simplifies Christoffel symbols from the metric and its derivatives.\n",
    "    \n",
    "    This version uses sp.trigsimp() which is highly effective and much faster\n",
    "    than sp.simplify() for the Kerr-Schild metric.\n",
    "    \"\"\"\n",
    "    Gamma4UDD = ixp.zerorank3(dimension=4)\n",
    "    g4UU, _ = ixp.symm_matrix_inverter4x4(g4DD)\n",
    "    \n",
    "    for mu in range(4):\n",
    "        for nu in range(4):\n",
    "            for delta in range(4):\n",
    "                # Calculate the Christoffel symbol component using the standard formula\n",
    "                for alpha in range(4):\n",
    "                    Gamma4UDD[delta][mu][nu] += sp.Rational(1, 2) * g4UU[delta][alpha] * \\\n",
    "                        (g4DD_dD[nu][alpha][mu] + g4DD_dD[mu][alpha][nu] - g4DD_dD[mu][nu][alpha])\n",
    "                \n",
    "                # Use sp.trigsimp() to simplify the resulting expression.\n",
    "                # This is the key to speeding up the symbolic calculation.\n",
    "                Gamma4UDD[delta][mu][nu] = sp.trigsimp(Gamma4UDD[delta][mu][nu])\n",
    "\n",
    "    return Gamma4UDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59295c0b",
   "metadata": {},
   "source": [
    "<a id='geodesic_mom_rhs'></a>\n",
    "### 3.c: Geodesic Momentum RHS\n",
    "\n",
    "This function defines the symbolic right-hand side (RHS) for the evolution of the **reverse-time momentum**, $p^{\\alpha}$. As established in the introduction, this is the second of our three first-order ODEs:\n",
    "$$ \\frac{dp^{\\alpha}}{d\\kappa} = -\\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} $$\n",
    "The function `geodesic_mom_rhs` takes the symbolic Christoffel symbols $\\Gamma^{\\alpha}_{\\mu\\nu}$ as its input. It then defines the symbolic momentum vector `pU` using `sympy`'s `sp.symbols()` function. A key `nrpy` technique is used here: the symbols are created with names that are already valid C array syntax (e.g., `\"y[4]\"`). This \"direct naming\" simplifies the final C code generation by eliminating the need for string substitutions.\n",
    "\n",
    "The core of this function constructs the symbolic expression for the RHS by performing the Einstein summation $-\\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu}$. A direct implementation would involve a double loop over both $\\mu$ and $\\nu$ from 0 to 3, resulting in $4 \\times 4 = 16$ terms for each component of $\\alpha$, which is computationally inefficient.\n",
    "\n",
    "However, we can significantly optimize this calculation by exploiting symmetry. The term $p^{\\mu} p^{\\nu}$ is symmetric with respect to the interchange of the indices $\\mu$ and $\\nu$. The Christoffel symbols $\\Gamma^{\\alpha}_{\\mu\\nu}$ are also symmetric in their lower two indices. Therefore, the full sum can be split into diagonal ($\\mu=\\nu$) and off-diagonal ($\\mu \\neq \\nu$) terms:\n",
    "$$ \\sum_{\\mu,\\nu} \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} = \\sum_{\\mu=0}^{3} \\Gamma^{\\alpha}_{\\mu\\mu} (p^{\\mu})^2 + \\sum_{\\mu \\neq \\nu} \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} $$\n",
    "The second sum over $\\mu \\neq \\nu$ contains pairs of identical terms (e.g., the $\\mu=1, \\nu=2$ term is the same as the $\\mu=2, \\nu=1$ term). We can combine all such pairs by summing over only one of the cases (e.g., $\\mu < \\nu$) and multiplying by two:\n",
    "$$ \\sum_{\\mu,\\nu} \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} = \\sum_{\\mu=0}^{3} \\Gamma^{\\alpha}_{\\mu\\mu} (p^{\\mu})^2 + 2 \\sum_{\\mu < \\nu} \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} $$\n",
    "The Python code implements this optimized version, ensuring that each component of the RHS is computed with the minimum number of floating point operations, leading to more efficient C code.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.zerorank1(dimension)`**:\n",
    "    *   **Source File**: `nrpy/indexedexp.py`\n",
    "    *   **Description**: Creates a symbolic rank-1 tensor (a Python list) of a specified dimension, with all elements initialized to the `sympy` integer 0. It is used here to create a container for the four components of the momentum RHS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geodesic_vel_rhs_massive():\n",
    "    \"\"\"\n",
    "    Symbolic RHS for massive particle velocity ODE: du^a/dτ = -Γ^a_μν u^μ u^ν.\n",
    "    u is the 4-velocity, y[4]...y[7].\n",
    "    \"\"\"\n",
    "    Gamma4UDD = ixp.declarerank3(\"conn->Gamma4UDD\",dimension= 4,sym=\"sym12\")\n",
    "    ut,ux,uy,uz = sp.symbols(\"y[4] y[5] y[6] y[7]\", Real=True)\n",
    "    uU = [ut,ux,uy,uz]\n",
    "    geodesic_rhs = ixp.zerorank1(dimension=4)\n",
    "    for alpha in range(4):\n",
    "        for mu in range(4):\n",
    "            geodesic_rhs[alpha] += Gamma4UDD[alpha][mu][mu] * uU[mu] * uU[mu]\n",
    "            for nu in range(mu + 1, 4):\n",
    "                geodesic_rhs[alpha] += 2 * Gamma4UDD[alpha][mu][nu] * uU[mu] * uU[nu]\n",
    "        geodesic_rhs[alpha] = -geodesic_rhs[alpha]\n",
    "    return geodesic_rhs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02fcc6",
   "metadata": {},
   "source": [
    "<a id='geodesic_pos_rhs'></a>\n",
    "### 3.d: Geodesic Position RHS\n",
    "\n",
    "This function defines the symbolic right-hand side (RHS) for the evolution of the position coordinates, $x^{\\alpha}$. As derived in the introduction, this is the first of our three first-order ODEs:\n",
    "\n",
    "$$ \\frac{dx^{\\alpha}}{d\\kappa} = p^{\\alpha} $$\n",
    "\n",
    "The Python function `geodesic_pos_rhs` is straightforward. It defines the components of the reverse-time momentum vector, `pU`, using `sympy`'s `sp.symbols()` function with the \"direct naming\" convention (`y[4]`, `y[5]`, etc.). It then simply returns a list containing these momentum components. This list of four symbolic expressions will serve as the first four components of the complete 9-component RHS vector that our C code will solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geodesic_pos_rhs_massive():\n",
    "    \"\"\"\n",
    "    Symbolic RHS for position ODE: dx^a/dτ = u^a.\n",
    "    u is the 4-velocity, y[4]...y[7].\n",
    "    \"\"\"\n",
    "    ut,ux,uy,uz = sp.symbols(\"y[4] y[5] y[6] y[7]\", Real=True)\n",
    "    uU = [ut,ux,uy,uz]\n",
    "    return uU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896fc9e6",
   "metadata": {},
   "source": [
    "<a id='geodesic_mom0_calc'></a>\n",
    "### 3.f: Symbolic Calculation of u^0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518283e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ut_massive():\n",
    "    \"\"\"\n",
    "    Symbolically derives u^t for a MASSIVE particle from the 4-velocity.\n",
    "    The derivation comes from solving the timelike normalization condition g_μν u^μ u^ν = -1.\n",
    "    \"\"\"\n",
    "    # The symbolic recipe will use the standard variable names u0, u1, etc.\n",
    "    # The C-generating function will map y[4], y[5], etc. to these.\n",
    "    u0,u1,u2,u3 = sp.symbols(\"u0 u1 u2 u3\", Real=True)\n",
    "    uU=[u0,u1,u2,u3]\n",
    "    \n",
    "    # The recipe uses the standard name \"metric\" for the struct.\n",
    "    g4DD = ixp.declarerank2(\"metric->g\", sym=\"sym01\", dimension=4)\n",
    "\n",
    "    # This is the quadratic equation for u^0, derived from g_μν u^μ u^ν = -1\n",
    "    # g_00(u^0)^2 + 2g_0i u^0 u^i + g_ij u^i u^j = -1\n",
    "    # We solve for u^0.\n",
    "    sum_g0i_ui = sp.sympify(0)\n",
    "    for i in range(1,4):\n",
    "        sum_g0i_ui += g4DD[0][i]*uU[i]\n",
    "        \n",
    "    sum_gij_ui_uj = sp.sympify(0)\n",
    "    for i in range(1,4):\n",
    "        sum_gij_ui_uj += g4DD[i][i]*uU[i]*uU[i]\n",
    "        for j in range(i+1,4):\n",
    "            sum_gij_ui_uj += 2*g4DD[i][j]*uU[i]*uU[j]\n",
    "            \n",
    "    # The discriminant of the quadratic formula for u^0\n",
    "    # CORRECTED: This now includes the \"+1\" term from g_μν u^μ u^ν = -1\n",
    "    discriminant = sum_g0i_ui**2 - g4DD[0][0]*(sum_gij_ui_uj + 1)\n",
    "    \n",
    "    # We choose the positive root for a forward-in-time particle outside the horizon.\n",
    "    # Note: Your choice of the minus sign was correct for the final expression.\n",
    "    answer = (-sum_g0i_ui - sp.sqrt(discriminant)) / g4DD[0][0]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5517b36",
   "metadata": {},
   "source": [
    "# Symblic ut and uphi for Keplarian disk based on radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b06712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_ut_uphi_from_r():\n",
    "    \"\"\"\n",
    "    Symbolically derives the fundamental orbital quantities u^t and u^phi for a \n",
    "    circular, equatorial, prograde orbit at a given radius r, using the final\n",
    "    simplified analytical formulas.\n",
    "    \"\"\"\n",
    "    # Define parameters as symbolic variables\n",
    "    r, M, a = sp.symbols(\"r_initial M_scale a_spin\", real=True)\n",
    "    \n",
    "    # Common denominator term from the analytical solution\n",
    "    den_term = r**(3/4) * sp.sqrt(r**(3/2) - 3*M*r**(1/2) + 2*a*M**(1/2))\n",
    "    \n",
    "    # Final simplified formula for u^t\n",
    "    ut = (r**(3/2) + a*M**(1/2)) / den_term\n",
    "    \n",
    "    # Final simplified formula for u^phi\n",
    "    uphi = M**(1/2) / den_term\n",
    "    \n",
    "    # Return the two fundamental quantities\n",
    "    return [ut, uphi]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea9bc84",
   "metadata": {},
   "source": [
    "# Markdown for conserved Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373ef962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_energy():\n",
    "    \"\"\"\n",
    "    Computes the symbolic expression for conserved energy E = -p_t.\n",
    "    E = -g_{t,mu} p^mu\n",
    "    \"\"\"\n",
    "    # Define the 4-momentum components using the y[4]...y[7] convention\n",
    "    pt, px, py, pz = sp.symbols(\"y[4] y[5] y[6] y[7]\", real=True)\n",
    "    pU = [pt, px, py, pz]\n",
    "    \n",
    "    # Define an abstract metric tensor to be filled by a C struct at runtime\n",
    "    g4DD = ixp.declarerank2(\"metric->g\", sym=\"sym01\", dimension=4)\n",
    "    \n",
    "    # Calculate p_t = g_{t,mu} p^mu\n",
    "    p_t = sp.sympify(0)\n",
    "    for mu in range(4):\n",
    "        p_t += g4DD[0][mu] * pU[mu]\n",
    "        \n",
    "    return -p_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52801f14",
   "metadata": {},
   "source": [
    "# Markdown for conserved L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd4d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_L_components_cart():\n",
    "    \"\"\"\n",
    "    Computes the symbolic expressions for the three components of angular momentum,\n",
    "    correctly accounting for the symmetry of the metric tensor.\n",
    "    \"\"\"\n",
    "    # Define coordinate and 4-momentum components\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    pt, px, py, pz = sp.symbols(\"y[4] y[5] y[6] y[7]\", real=True)\n",
    "    pU = [pt, px, py, pz]\n",
    "    \n",
    "    # Define an abstract metric tensor\n",
    "    g4DD = ixp.declarerank2(\"metric->g\", sym=\"sym01\", dimension=4)\n",
    "    \n",
    "    # --- THIS IS THE CORE FIX ---\n",
    "    # Calculate covariant momentum components p_k = g_{k,mu} p^mu,\n",
    "    # correctly exploiting the metric's symmetry g_mu,nu = g_nu,mu.\n",
    "    p_down = ixp.zerorank1(dimension=4)\n",
    "    for k in range(1, 4): # We only need p_x, p_y, p_z for L_i\n",
    "        # Sum over mu\n",
    "        for mu in range(4):\n",
    "            # Use g4DD[k][mu] if k <= mu, otherwise use g4DD[mu][k]\n",
    "            if k <= mu:\n",
    "                p_down[k] += g4DD[k][mu] * pU[mu]\n",
    "            else: # k > mu\n",
    "                p_down[k] += g4DD[mu][k] * pU[mu]\n",
    "            \n",
    "    p_x, p_y, p_z = p_down[1], p_down[2], p_down[3]\n",
    "\n",
    "    # Calculate angular momentum components \n",
    "    L_x = y*p_z - z*p_y\n",
    "    L_y = z*p_x - x*p_z\n",
    "    L_z = x*p_y - y*p_x\n",
    "    \n",
    "    return [L_x, L_y, L_z]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b68249",
   "metadata": {},
   "source": [
    "# Markdown for Carter Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1034fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V10_Python_to_C_via_NRPy.ipynb\n",
    "# In the \"Symbolic Recipes\" cell (Final, Corrected symbolic_carter_constant_Q_final)\n",
    "\n",
    "# symbolic_energy() and symbolic_L_components_cart() remain correct.\n",
    "\n",
    "def symbolic_carter_constant_Q():\n",
    "    \"\"\"\n",
    "    Computes the symbolic expression for the Carter Constant Q using a\n",
    "    verified formula, robustly handling the axial singularity.\n",
    "    \"\"\"\n",
    "    # Define all necessary symbolic variables\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    pt, px, py, pz = sp.symbols(\"y[4] y[5] y[6] y[7]\", real=True)\n",
    "    pU = [pt, px, py, pz]\n",
    "    a = sp.Symbol(\"a_spin\", real=True)\n",
    "    g4DD = ixp.declarerank2(\"metric->g\", sym=\"sym01\", dimension=4)\n",
    "\n",
    "    # --- Step 1: Compute intermediate quantities E, Lz, and p_i ---\n",
    "    E = symbolic_energy()\n",
    "    _, _, Lz = symbolic_L_components_cart()\n",
    "    \n",
    "    p_down = ixp.zerorank1(dimension=4)\n",
    "    for k in range(1, 4):\n",
    "        for mu in range(4):\n",
    "            if k <= mu: p_down[k] += g4DD[k][mu] * pU[mu]\n",
    "            else: p_down[k] += g4DD[mu][k] * pU[mu]\n",
    "    p_x, p_y, p_z = p_down[1], p_down[2], p_down[3]\n",
    "\n",
    "    # --- Step 2: Compute geometric terms ---\n",
    "    r_sq = x**2 + y**2 + z**2\n",
    "    rho_sq = x**2 + y**2\n",
    "    \n",
    "    # --- Step 3: Compute p_theta^2 directly in Cartesian components ---\n",
    "    # This avoids square roots and potential complex number issues in sympy.\n",
    "    # p_theta^2 = r^2 * p_z^2 + cot^2(theta) * (x*p_x + y*p_y)^2 - 2*r*p_z*cot(theta)*(x*p_x+y*p_y)\n",
    "    # where cot(theta) = z / rho\n",
    "    \n",
    "    # This term is (x*p_x + y*p_y)\n",
    "    xpx_plus_ypy = x*p_x + y*p_y\n",
    "    \n",
    "    # This is p_theta^2, constructed to avoid dividing by rho before squaring.\n",
    "    # It is equivalent to (z*xpx_plus_ypy/rho - rho*p_z)^2\n",
    "    p_theta_sq = (z**2 * xpx_plus_ypy**2 / rho_sq) - (2 * z * p_z * xpx_plus_ypy) + (rho_sq * p_z**2)\n",
    "\n",
    "    # --- Step 4: Assemble the final formula for Q ---\n",
    "    # Q = p_theta^2 + cos^2(theta) * (-a^2*E^2 + L_z^2/sin^2(theta))\n",
    "    # where cos^2(theta) = z^2/r^2 and sin^2(theta) = rho^2/r^2\n",
    "    \n",
    "    # This is the second term in the Q formula\n",
    "    second_term = (z**2 / r_sq) * (-a**2 * E**2 + Lz**2 * (r_sq / rho_sq))\n",
    "    \n",
    "    Q_formula = p_theta_sq + second_term\n",
    "    \n",
    "    # --- Step 5: Handle the axial singularity ---\n",
    "    # For motion on the z-axis (rho_sq -> 0), Lz=0 and p_theta=0, so Q=0.\n",
    "    Q_final = sp.Piecewise(\n",
    "        (0, rho_sq < 1e-12),\n",
    "        (Q_formula, True)\n",
    "    )\n",
    "    \n",
    "    return Q_final\n",
    "\n",
    "print(\"Final symbolic recipes for conserved quantities defined (Carter Constant re-derived).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe10d0a",
   "metadata": {},
   "source": [
    "<a id='spacetime_definition'></a>\n",
    "# Step 4: Spacetime Definition in Kerr-Schild Coordinates\n",
    "\n",
    "This section defines the specific spacetime geometry in which the geodesics will be integrated. Instead of defining separate metrics for Schwarzschild (non-rotating) and Kerr (rotating) black holes, we use a single, powerful coordinate system: **Cartesian Kerr-Schild coordinates**. This system has a major advantage over more common coordinate systems like Boyer-Lindquist: it is regular everywhere, including at the event horizon. This means the metric components and their derivatives do not diverge, allowing the numerical integrator to trace a photon's path seamlessly across the horizon without encountering coordinate singularities.\n",
    "\n",
    "The Kerr-Schild metric $g_{\\mu\\nu}$ is constructed by adding a correction term to the flat Minkowski metric $\\eta_{\\mu\\nu}$:\n",
    "$$ g_{\\mu\\nu} = \\eta_{\\mu\\nu} + 2H l_\\mu l_\\nu $$\n",
    "where $\\eta_{\\mu\\nu}$ is the Minkowski metric `diag(-1, 1, 1, 1)`, $l_\\mu$ is a special null vector, and $H$ is a scalar function that depends on the black hole's mass $M$ and spin $a$.\n",
    "\n",
    "The function `define_kerr_metric_Cartesian_Kerr_Schild()` implements this formula symbolically. It defines the coordinates `(t, x, y, z)`, the mass `M`, and the spin `a` as `sympy` symbols. It then constructs the components of the null vector $l_\\mu$ and the scalar function $H$. Finally, it assembles the full metric tensor $g_{\\mu\\nu}$.\n",
    "\n",
    "A key feature of this formulation is that if the spin parameter `a` is set to zero, the metric automatically and exactly reduces to the Schwarzschild metric in Cartesian coordinates. This allows a single set of symbolic expressions and a single set of C functions to handle both spacetimes, with the specific behavior controlled by the runtime value of the `a_spin` parameter.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.zerorank1(dimension)`**: Previously introduced. Used to initialize the null vector $l_\\mu$.\n",
    "*   **`nrpy.indexedexp.zerorank2(dimension)`**: Previously introduced. Used to initialize the metric tensor $g_{\\mu\\nu}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_kerr_metric_Cartesian_Kerr_Schild():\n",
    "    \"\"\"\n",
    "    Defines the Kerr metric tensor in Cartesian Kerr-Schild coordinates.\n",
    "\n",
    "    This function is the new, unified source for both Kerr (a != 0) and\n",
    "    Schwarzschild (a = 0) spacetimes. The coordinates are (t, x, y, z).\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (g4DD, xx), where g4DD is the symbolic 4x4 metric tensor\n",
    "        and xx is the list of symbolic coordinate variables.\n",
    "    \"\"\"\n",
    "    # Define the symbolic coordinates using the 'y[i]' convention for the integrator\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    xx = [t, x, y, z]\n",
    "\n",
    "    # Access the symbolic versions of the mass and spin parameters\n",
    "    M = M_scale.symbol\n",
    "    a = a_spin.symbol\n",
    "\n",
    "    # Define intermediate quantities\n",
    "    r2 = x**2 + y**2 + z**2\n",
    "    r = sp.sqrt(r2)\n",
    "    \n",
    "    # Define the Kerr-Schild null vector l_μ\n",
    "    l_down = ixp.zerorank1(dimension=4)\n",
    "    l_down[0] = 1\n",
    "    l_down[1] = (r*x + a*y) / (r2 + a**2)\n",
    "    l_down[2] = (r*y - a*x) / (r2 + a**2)\n",
    "    l_down[3] = z/r\n",
    "\n",
    "    # Define the scalar function H\n",
    "    H = (M * r**3) / (r**4 + a**2 * z**2)\n",
    "\n",
    "    # The Kerr-Schild metric is g_μν = η_μν + 2H * l_μ * l_ν\n",
    "    # where η_μν is the Minkowski metric diag(-1, 1, 1, 1)\n",
    "    g4DD = ixp.zerorank2(dimension=4)\n",
    "    for mu in range(4):\n",
    "        for nu in range(4):\n",
    "            eta_mu_nu = 0\n",
    "            if mu == nu:\n",
    "                eta_mu_nu = 1\n",
    "            if mu == 0 and nu == 0:\n",
    "                eta_mu_nu = -1\n",
    "            \n",
    "            g4DD[mu][nu] = eta_mu_nu + 2 * H * l_down[mu] * l_down[nu]\n",
    "            \n",
    "    return g4DD, xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b234e04d",
   "metadata": {},
   "source": [
    "# Markdown for Schwarzschild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41a45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In the NEW CELL after define_kerr_metric_Cartesian_Kerr_Schild\n",
    "\n",
    "def define_schwarzschild_metric_cartesian():\n",
    "    \"\"\"\n",
    "    Defines the Schwarzschild metric tensor directly in Cartesian coordinates.\n",
    "    \n",
    "    This version uses the standard textbook formula and ensures all components\n",
    "    are sympy objects to prevent C-generation errors.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (g4DD, xx), where g4DD is the symbolic 4x4 metric tensor\n",
    "        and xx is the list of symbolic coordinate variables.\n",
    "    \"\"\"\n",
    "    # Define Cartesian coordinates\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    xx = [t, x, y, z]\n",
    "\n",
    "    # Access the symbolic mass parameter\n",
    "    M = M_scale.symbol\n",
    "\n",
    "    # Define r in terms of Cartesian coordinates\n",
    "    r = sp.sqrt(x**2 + y**2 + z**2)\n",
    "\n",
    "    # Define the Cartesian Schwarzschild metric components directly\n",
    "    g4DD = ixp.zerorank2(dimension=4)\n",
    "    \n",
    "    # g_tt\n",
    "    g4DD[0][0] = -(1 - 2*M/r)\n",
    "    \n",
    "    # Spatial components g_ij = δ_ij + (2M/r) * (x_i * x_j / r^2)\n",
    "    x_i = [x, y, z]\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            # --- CORRECTED: Use sp.sympify() for the kronecker delta ---\n",
    "            delta_ij = sp.sympify(0)\n",
    "            if i == j:\n",
    "                delta_ij = sp.sympify(1)\n",
    "            \n",
    "            # The indices for g4DD are off by 1 from the spatial indices\n",
    "            g4DD[i+1][j+1] = delta_ij + (2*M/r) * (x_i[i] * x_i[j] / (r**2))\n",
    "\n",
    "    # --- CORRECTED: Ensure time-space components are sympy objects ---\n",
    "    g4DD[0][1] = g4DD[1][0] = sp.sympify(0)\n",
    "    g4DD[0][2] = g4DD[2][0] = sp.sympify(0)\n",
    "    g4DD[0][3] = g4DD[3][0] = sp.sympify(0)\n",
    "            \n",
    "    return g4DD, xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec78a4",
   "metadata": {},
   "source": [
    "<a id='symbolic_execution'></a>\n",
    "# Step 5: Symbolic Workflow Execution\n",
    "\n",
    "This cell acts as the central hub for the symbolic portion of our project. In the preceding cells, we *defined* a series of Python functions that perform individual mathematical tasks. Here, we *execute* those functions in the correct sequence to generate all the final symbolic expressions that will serve as \"recipes\" for our C code generators.\n",
    "\n",
    "This \"symbolic-first\" approach is a core `nrpy` principle and offers significant advantages:\n",
    "1.  **Efficiency**: The complex symbolic calculations, such as inverting the metric tensor and deriving the Christoffel symbols, are performed **only once** when this notebook is run. The results are stored in global Python variables, preventing redundant and time-consuming recalculations. This is especially important for the Kerr metric, whose Christoffel symbols can take several minutes to compute.\n",
    "2.  **Modularity**: This workflow creates a clean separation between the *specific solution* for a metric (e.g., the explicit formulas for the Kerr-Schild Christoffels) and the *generic form* of the equations of motion (which are valid for any metric).\n",
    "\n",
    "This cell produces two key sets of symbolic expressions that are stored in global variables for later use:\n",
    "*   **`Gamma4UDD_kerr`**: The explicit symbolic formulas for the Christoffel symbols of the unified Kerr-Schild metric.\n",
    "*   **`all_rhs_expressions`**: A Python list containing the 9 symbolic expressions for the right-hand-sides of our generic ODE system. To achieve this generality, we create a symbolic **placeholder** for the Christoffel symbols using `ixp.declarerank3(\"conn->Gamma4UDD\", ...)`. This placeholder is passed to `geodesic_mom_rhs()` to construct the geodesic equation in its abstract form. This elegant technique embeds the final C variable name (`conn->Gamma4UDD...`) directly into the symbolic expression, which dramatically simplifies the C code generation step for the `calculate_ode_rhs()` engine.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.declarerank3(name, dimension)`**: Previously introduced. Used here to create a symbolic placeholder for the Christoffel symbols that will be passed to the generic RHS engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbfe0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In V1_0_mass_geodesic.ipynb, Cell ID 5fbfe0b5\n",
    "# --- 1. Define the Kerr-Schild metric and get its derivatives ---\n",
    "print(\" -> Computing Kerr-Schild metric and Christoffel symbols...\")\n",
    "g4DD_kerr, xx_kerr = define_kerr_metric_Cartesian_Kerr_Schild()\n",
    "g4DD_dD_kerr = derivative_g4DD(g4DD_kerr, xx_kerr)\n",
    "Gamma4UDD_kerr = four_connections(g4DD_kerr, g4DD_dD_kerr)\n",
    "print(\"    ... Done.\")\n",
    "\n",
    "# --- 2. Define the Standard Schwarzschild metric in Cartesian and get its derivatives ---\n",
    "print(\" -> Computing Standard Schwarzschild (Cartesian) metric and Christoffel symbols...\")\n",
    "g4DD_schw_cart, xx_schw_cart = define_schwarzschild_metric_cartesian()\n",
    "g4DD_dD_schw_cart = derivative_g4DD(g4DD_schw_cart, xx_schw_cart)\n",
    "Gamma4UDD_schw_cart = four_connections(g4DD_schw_cart, g4DD_dD_schw_cart)\n",
    "print(\"    ... Done.\")\n",
    "\n",
    "# --- NEW: Generate GENERIC symbolic RHS expressions for MASSIVE geodesics ---\n",
    "rhs_pos_massive = geodesic_pos_rhs_massive() \n",
    "rhs_vel_massive = geodesic_vel_rhs_massive()\n",
    "# The state vector is now 8 components (no L)\n",
    "all_rhs_expressions_massive = rhs_pos_massive + rhs_vel_massive\n",
    "\n",
    "# --- NEW: Generate symbolic recipe for u^t from 3-velocity ---\n",
    "ut_expr_from_vel = ut_massive()\n",
    "ut_expr, uphi_expr = symbolic_ut_uphi_from_r()\n",
    "print(\" -> Defined generic global symbolic variables for massive particle ODEs.\")\n",
    "\n",
    "# --- 4. Generate symbolic recipes for conserved quantities ---\n",
    "print(\" -> Generating symbolic recipes for conserved quantities...\")\n",
    "E_expr = symbolic_energy()\n",
    "Lx_expr, Ly_expr, Lz_expr = symbolic_L_components_cart()\n",
    "Q_expr_kerr = symbolic_carter_constant_Q()\n",
    "Q_expr_schw = Lx_expr**2 + Ly_expr**2 + Lz_expr**2\n",
    "list_of_expressions_kerr = [E_expr, Lx_expr, Ly_expr, Lz_expr, Q_expr_kerr]\n",
    "list_of_expressions_schw = [E_expr, Lx_expr, Ly_expr, Lz_expr, Q_expr_schw]\n",
    "print(\"    ... Conservation recipes generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032d263",
   "metadata": {},
   "source": [
    "<a id='generate_c_engines'></a>\n",
    "# Step 6: C Code Generation - Physics \"Engines\" and \"Workers\"\n",
    "\n",
    "This section marks our transition from pure symbolic mathematics to C code generation. The Python functions defined here are \"meta-functions\": their job is not to perform calculations themselves, but to **generate the C code** that will perform the calculations in the final compiled program.\n",
    "\n",
    "We distinguish between two types of generated functions:\n",
    "*   **Workers**: These are specialized functions that implement the physics for a *specific metric*. For example, `con_kerr_schild()` is a worker that only knows how to compute Christoffel symbols for the Kerr-Schild metric.\n",
    "*   **Engines**: These are generic functions that implement physics equations valid for *any metric*. For example, `calculate_ode_rhs()` is an engine that can compute the geodesic equations for any metric, as long as the Christoffel symbols are provided to it.\n",
    "\n",
    "This design pattern allows for maximum code reuse and extensibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632c6765",
   "metadata": {},
   "source": [
    "# Schwarzschild Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ef433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g4DD_schwarzschild_cartesian():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Schwarzschild\n",
    "    metric components in standard Cartesian coordinates.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: g4DD_schwarzschild_cartesian()...\")\n",
    "    \n",
    "    # Use the globally defined g4DD_schw_cart from the symbolic execution step\n",
    "    list_of_g4DD_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_syms.append(g4DD_schw_cart[i][j])\n",
    "\n",
    "    list_of_g4DD_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_C_vars.append(f\"metric->g{i}{j}\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the 10 unique components of the Schwarzschild metric in Cartesian coords.\"\"\"\n",
    "    name = \"g4DD_schwarzschild_cartesian\"\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], metric_struct *restrict metric\"\n",
    "   \n",
    "    body = ccg.c_codegen(list_of_g4DD_syms, list_of_g4DD_C_vars, enable_cse=True)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... g4DD_schwarzschild_cartesian() registration complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd610ccf",
   "metadata": {},
   "source": [
    "<a id='g4DD_kerr_schild_engine'></a>\n",
    "### 6.a: `g4DD_kerr_schild()` Worker\n",
    "\n",
    "This Python function generates the C **worker** function `g4DD_kerr_schild()`, whose only job is to compute the 10 unique components of the Kerr-Schild metric tensor, $g_{\\mu\\nu}$, at a given point in spacetime.\n",
    "\n",
    "The generation process is as follows:\n",
    "1.  **Access Symbolic Recipe:** It accesses the global `g4DD_kerr` variable, which holds the symbolic `sympy` expression for the Kerr-Schild metric tensor, generated in Step 5.\n",
    "2.  **Define C Assignment:** It creates two Python lists: one containing the 10 unique symbolic metric expressions (`list_of_g4DD_syms`) and another containing the corresponding C variable names for the members of the `metric_struct` (e.g., `metric->g00`, `metric->g01`, etc.) in `list_of_g4DD_C_vars`.\n",
    "3.  **Generate C Code:** It passes these two lists to `nrpy.c_codegen.c_codegen`. This powerful `nrpy` function converts the symbolic math into highly optimized C code, including performing Common Subexpression Elimination (CSE).\n",
    "4.  **Register C Function:** Finally, it bundles the generated C code with its metadata (description, parameters, etc.) and registers the complete function with `nrpy.c_function.register_CFunction`. Crucially, it sets `include_CodeParameters_h=True` to automatically handle access to both the `M_scale` and `a_spin` parameters via the \"Triple-Lock\" system.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_codegen.c_codegen(sympy_expressions, C_variable_names, **kwargs)`**:\n",
    "    *   **Source File**: `nrpy/c_codegen.py`\n",
    "    *   **Description**: The core symbolic-to-C translation engine. It takes a list of `sympy` expressions and a corresponding list of C variable names and generates optimized C code to perform the assignments.\n",
    "    *   **Key Inputs**:\n",
    "        *   `sympy_expressions`: A Python list of symbolic expressions to be converted to C code.\n",
    "        *   `C_variable_names`: A Python list of strings for the C variables that will store the results.\n",
    "    *   **Key Keyword Arguments (`kwargs`)**:\n",
    "        *   `enable_cse=True`: Enables Common Subexpression Elimination, which finds repeated mathematical operations, assigns them to temporary variables, and reuses those variables to reduce redundant calculations. This is essential for performance.\n",
    "\n",
    "*   **`nrpy.c_function.register_CFunction(name, params, body, **kwargs)`**:\n",
    "    *   **Source File**: `nrpy/c_function.py`\n",
    "    *   **Description**: This is the workhorse for defining a C function. It takes all necessary metadata and stores it in a global dictionary, `cfc.CFunction_dict`. The final build system uses this dictionary to write all the `.c` source files.\n",
    "    *   **Key Inputs**:\n",
    "        *   `name`: The name of the C function.\n",
    "        *   `params`: A string defining the function's parameters (e.g., `\"const double y[4], ...\"`).\n",
    "        *   `body`: A string containing the C code for the function's body.\n",
    "    *   **Key Keyword Arguments (`kwargs`)**:\n",
    "        *   `include_CodeParameters_h=True`: Enables the \"Triple-Lock\" system for this function, automatically including `set_CodeParameters.h` at the top of the function body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d52f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g4DD_kerr_schild():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Kerr-Schild\n",
    "    metric components in Cartesian coordinates. This is the new unified worker.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: g4DD_kerr_schild()...\")\n",
    "    \n",
    "    # We use the globally defined g4DD_kerr from the symbolic execution step\n",
    "    list_of_g4DD_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_syms.append(g4DD_kerr[i][j])\n",
    "\n",
    "    list_of_g4DD_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_C_vars.append(f\"metric->g{i}{j}\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the 10 unique components of the Kerr metric in Cartesian Kerr-Schild coords.\"\"\"\n",
    "    name = \"g4DD_kerr_schild\"\n",
    "    # The state vector y now contains (t, x, y, z)\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], metric_struct *restrict metric\"\n",
    "   \n",
    "    body = ccg.c_codegen(list_of_g4DD_syms, list_of_g4DD_C_vars, enable_cse=True)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... g4DD_kerr_schild() registration complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3f1222",
   "metadata": {},
   "source": [
    "<a id='con_kerr_schild_engine'></a>\n",
    "### 6.b: `con_kerr_schild()` Worker\n",
    "\n",
    "This function is structured identically to the `g4DD_kerr_schild` worker. It generates the C **worker** function `con_kerr_schild()`, whose only job is to compute the 40 unique Christoffel symbols for the unified Kerr-Schild metric.\n",
    "\n",
    "The process is as follows:\n",
    "1.  **Access Symbolic Recipe:** It accesses the pre-computed symbolic Christoffel formulas from the global `Gamma4UDD_kerr` variable, which was generated in Step 5.\n",
    "2.  **Define C Assignment:** It creates a list of the 40 unique symbolic expressions and a corresponding list of the C variable names for the members of the `connection_struct` (e.g., `conn->Gamma4UDD012`).\n",
    "3.  **Generate C Code:** It uses `nrpy.c_codegen.c_codegen` to convert these highly complex symbolic expressions into optimized C code. The Common Subexpression Elimination (CSE) performed by `c_codegen` is absolutely essential here, as it reduces what would be thousands of floating-point operations into a much more manageable and efficient set of calculations.\n",
    "4.  **Register C Function:** Like the other workers, it registers the function using `nrpy.c_function.register_CFunction` and sets `include_CodeParameters_h=True` to handle its dependency on both `M_scale` and `a_spin`.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.declarerank3(name, dimension)`**: Previously introduced. Used here to programmatically generate the C variable names for the Christoffel symbols that will be stored in the `connection_struct`.\n",
    "*   **`nrpy.c_codegen.c_codegen(...)`**: Previously introduced.\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb471c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_kerr_schild():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Kerr-Schild Christoffel symbols.\n",
    "    This is the new unified worker.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: con_kerr_schild()...\")\n",
    "    \n",
    "    # We use the globally defined Gamma4UDD_kerr from the symbolic execution step\n",
    "    list_of_Gamma_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_syms.append(Gamma4UDD_kerr[i][j][k])\n",
    "\n",
    "    conn_Gamma4UDD = ixp.declarerank3(\"conn->Gamma4UDD\", dimension=4)\n",
    "    list_of_Gamma_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_C_vars.append(str(conn_Gamma4UDD[i][j][k]))\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the 40 unique Christoffel symbols for the Kerr metric in Kerr-Schild coords.\"\"\"\n",
    "    name = \"con_kerr_schild\"\n",
    "    # The state vector y now contains (t, x, y, z)\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], connection_struct *restrict conn\"\n",
    "\n",
    "    body = ccg.c_codegen(list_of_Gamma_syms, list_of_Gamma_C_vars, enable_cse=True)\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... con_kerr_schild() registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0166625f",
   "metadata": {},
   "source": [
    "# Con Schwarzschild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6072ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_schwarzschild_cartesian():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Schwarzschild Christoffel symbols\n",
    "    in standard Cartesian coordinates.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: con_schwarzschild_cartesian()...\")\n",
    "    \n",
    "    # Use the globally defined Gamma4UDD_schw_cart\n",
    "    list_of_Gamma_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_syms.append(Gamma4UDD_schw_cart[i][j][k])\n",
    "\n",
    "    conn_Gamma4UDD = ixp.declarerank3(\"conn->Gamma4UDD\", dimension=4)\n",
    "    list_of_Gamma_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_C_vars.append(str(conn_Gamma4UDD[i][j][k]))\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the unique Christoffel symbols for the Schwarzschild metric in Cartesian coords.\"\"\"\n",
    "    name = \"con_schwarzschild_cartesian\"\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], connection_struct *restrict conn\"\n",
    "\n",
    "    body = ccg.c_codegen(list_of_Gamma_syms, list_of_Gamma_C_vars, enable_cse=True)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... con_schwarzschild_cartesian() registration complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e27c2c",
   "metadata": {},
   "source": [
    "<a id='calculate_ode_rhs_engine'></a>\n",
    "### 6.d: `calculate_ode_rhs()` Engine\n",
    "\n",
    "This function generates the core \"engine\" of our ODE solver: the C function `calculate_ode_rhs()`. Its single responsibility is to calculate the right-hand sides for our entire system of 9 ODEs. It is completely generic and has no knowledge of any specific metric; it only knows how to compute the geodesic equations given a set of Christoffel symbols and the spatial metric components.\n",
    "\n",
    "The generation process is straightforward:\n",
    "1.  **Access Generic Recipe:** It accesses the global `all_rhs_expressions` list. This list contains the generic symbolic form of the ODEs for position, momentum, and proper length that we derived in Step 5.\n",
    "2.  **Generate C Code:** It passes this list directly to `nrpy.c_codegen.c_codegen`. The symbols used to build `all_rhs_expressions` were already created with their final C syntax (e.g., `y[5]` for the momentum, `conn->Gamma4UDD...` for the Christoffel placeholder, and `metric->g...` for the metric placeholder). Therefore, no further symbolic manipulation is needed. `nrpy` simply translates the expressions into optimized C code.\n",
    "3.  **Register C Function:** The generated C code body is bundled with its metadata and registered. This function does not require the `include_CodeParameters_h` flag because it is physically generic and receives all necessary information through its arguments.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_codegen.c_codegen(...)`**: Previously introduced.\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68bf72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ode_rhs_massive():\n",
    "    \"\"\"\n",
    "    Generates the C engine to calculate the RHS of the 8 massive particle ODEs.\n",
    "    \"\"\"\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Calculates the right-hand sides (RHS) of the 8 massive particle geodesic ODEs.\n",
    "    \n",
    "    This is a generic engine that implements the geodesic equation using pre-computed\n",
    "    Christoffel symbols from the connection_struct.\n",
    "    \n",
    "    @param[in]  y         The 8-component state vector [t, x, y, z, u^t, u^x, u^y, u^z].\n",
    "    @param[in]  conn      A pointer to the connection_struct holding the Christoffel symbols.\n",
    "    @param[out] rhs_out   A pointer to the 8-component output array for the RHS results.\"\"\"\n",
    "    name = \"calculate_ode_rhs_massive\"\n",
    "    params = \"const double y[8], const connection_struct *restrict conn, double rhs_out[8]\"\n",
    "    \n",
    "    rhs_output_vars = [f\"rhs_out[{i}]\" for i in range(8)]\n",
    "    body = ccg.c_codegen(all_rhs_expressions_massive, rhs_output_vars)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes,\n",
    "        desc=desc,\n",
    "        name=name,\n",
    "        params=params,\n",
    "        body=body\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624cd49",
   "metadata": {},
   "source": [
    "# Markdown for check_conservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4260e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_conservation_massive():\n",
    "    \"\"\"\n",
    "    Generates the C function `check_conservation_massive`.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine: check_conservation_massive()...\")\n",
    "\n",
    "    output_vars_kerr = [\"*E\", \"*Lx\", \"*Ly\", \"*Lz\", \"*Q\"]\n",
    "    output_vars_schw = [\"*E\", \"*Lx\", \"*Ly\", \"*Lz\", \"*Q\"]\n",
    "\n",
    "    body_C_code_kerr = ccg.c_codegen(list_of_expressions_kerr, output_vars_kerr, enable_cse=True, include_braces=False)\n",
    "    body_C_code_schw = ccg.c_codegen(list_of_expressions_schw, output_vars_schw, enable_cse=True, include_braces=False)\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Computes conserved quantities (E, L_i, Q/L^2) for a given massive particle state vector.\"\"\"\n",
    "    name = \"check_conservation_massive\"\n",
    "    params = \"\"\"const commondata_struct *restrict commondata,\n",
    "        const params_struct *restrict params,\n",
    "        const metric_params *restrict metric_params_in,\n",
    "        const double y[8], \n",
    "        double *E, double *Lx, double *Ly, double *Lz, double *Q\"\"\"\n",
    "        \n",
    "    body = r\"\"\"\n",
    "    // Unpack parameters from commondata struct that are needed symbolically\n",
    "    const REAL a_spin = commondata->a_spin;\n",
    "\n",
    "    metric_struct* metric = (metric_struct*)malloc(sizeof(metric_struct));\n",
    "    g4DD_metric(commondata, params, metric_params_in, y, metric);\n",
    "\n",
    "    if (metric_params_in->type == Kerr) {\n",
    "        \"\"\" + body_C_code_kerr + r\"\"\"\n",
    "    } else { // Both Schwarzschild types are now Cartesian\n",
    "        \"\"\" + body_C_code_schw + r\"\"\"\n",
    "    }\n",
    "    \n",
    "    free(metric);\n",
    "    \"\"\"\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, cfunc_type=\"void\",\n",
    "        name=name, params=params, body=body\n",
    "    )\n",
    "    print(f\"    ... {name}() registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94fb7b8",
   "metadata": {},
   "source": [
    "<a id='generate_c_orchestrators'></a>\n",
    "# Step 7: C Code Generation - Orchestrators and Dispatchers\n",
    "\n",
    "With the low-level \"engine\" and \"worker\" functions defined in the previous step, we now generate the higher-level C functions that manage the simulation. These functions are responsible for dispatching to the correct worker based on runtime parameters and for orchestrating the overall program flow.\n",
    "\n",
    "*   **Dispatchers** are functions that contain a `switch` statement to select the correct \"worker\" function based on the chosen metric (e.g., `Schwarzschild` vs. `Kerr`).\n",
    "*   **Orchestrators** are functions that execute a sequence of calls to other engines, workers, and dispatchers to perform a complex task, like setting up initial conditions or running the main integration loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545db0d5",
   "metadata": {},
   "source": [
    "<a id='g4DD_metric_dispatcher'></a>\n",
    "### 7.a: `g4DD_metric()` Dispatcher\n",
    "\n",
    "This Python function generates the C function `g4DD_metric()`, which serves as a high-level **dispatcher.** Its role is to select and call the correct worker function to compute the components of the metric tensor, $g_{\\mu\\nu}$.\n",
    "\n",
    "The generated C code uses a `switch` statement that reads the `metric->type` member of the `metric_params` struct. In this project, both the Schwarzschild and Kerr spacetimes are handled by the unified `g4DD_kerr_schild()` worker function. The dispatcher calls this single worker, and the specific metric returned by the worker depends on the runtime value of the `a_spin` parameter (if `a_spin` is 0, the Schwarzschild metric is computed).\n",
    "\n",
    "This modular approach cleanly separates the control flow (deciding *which* metric to use) from the physics implementation (the worker functions that know *how* to compute a specific metric). This makes the project easy to extend with new spacetimes in the future by adding new cases to the `switch` statement and new worker functions.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced. Used to register the manually written C code for the dispatcher function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65702cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In cell [65702cb7]\n",
    "\n",
    "def g4DD_metric():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function g4DD_metric(), which serves as a\n",
    "    dispatcher to call the appropriate metric-specific worker function.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C dispatcher function: g4DD_metric()...\")\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Dispatcher to compute the 4-metric g_munu for the chosen metric.\"\"\"\n",
    "    name = \"g4DD_metric\"\n",
    "    # The signature is now coordinate-aware, but the y vector is always Cartesian here.\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const metric_params *restrict metric, const double y[8], metric_struct *restrict metric_out\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "    // The state vector y_pos contains only the position coordinates.\n",
    "    const double y_pos[4] = {y[0], y[1], y[2], y[3]};\n",
    "\n",
    "    // This switch statement chooses which \"worker\" function to call\n",
    "    // based on the metric type provided.\n",
    "    switch(metric->type) {\n",
    "        case Schwarzschild:\n",
    "        case Kerr:\n",
    "            // For Kerr or Schwarzschild in KS coords, call the unified Kerr-Schild C function.\n",
    "            g4DD_kerr_schild(commondata, params, y_pos, metric_out);\n",
    "            break;\n",
    "        // <-- MODIFIED: Call the new Cartesian worker\n",
    "        case Schwarzschild_Standard:\n",
    "            g4DD_schwarzschild_cartesian(commondata, params, y_pos, metric_out);\n",
    "            break;\n",
    "        case Numerical:\n",
    "            printf(\"Error: Numerical metric not supported yet.\\n\");\n",
    "            exit(1);\n",
    "            break;\n",
    "        default:\n",
    "            printf(\"Error: MetricType %d not supported in g4DD_metric() yet.\\n\", metric->type);\n",
    "            exit(1);\n",
    "            break;\n",
    "    }\n",
    "\"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... g4DD_metric() registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db30c0a",
   "metadata": {},
   "source": [
    "<a id='connections_dispatcher'></a>\n",
    "### 7.b: `connections()` Dispatcher\n",
    "\n",
    "This Python function generates the C function `connections()`, which acts as a second **dispatcher.** Its sole responsibility is to select and call the correct metric-specific worker function (like `con_kerr_schild()`) to compute the Christoffel symbols.\n",
    "\n",
    "Like the `g4DD_metric()` dispatcher, the generated C code uses a `switch` statement based on the `metric->type`. It dispatches the call to the appropriate specialized worker, which in this case is the unified `con_kerr_schild()` function for both Kerr and Schwarzschild spacetimes. This design is highly extensible: adding a new metric simply requires writing a new worker function for its Christoffel symbols and adding a new `case` to this `switch` statement.\n",
    "\n",
    "This function demonstrates how `nrpy` allows for the seamless integration of developer-written control flow with the automatically generated worker functions.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V11_0_Python_to_C_via_NRPy.ipynb\n",
    "# In cell [b92b7851]\n",
    "\n",
    "def connections():\n",
    "    \"\"\"\n",
    "    Generates and registers the C dispatcher for Christoffel symbols.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C dispatcher: connections()...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"stdio.h\", \"stdlib.h\"]\n",
    "    desc = r\"\"\"@brief Dispatcher to compute Christoffel symbols for the chosen metric.\"\"\"\n",
    "    \n",
    "    name = \"connections\"\n",
    "    cfunc_type = \"void\" \n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const metric_params *restrict metric, const double y[8], connection_struct *restrict conn\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // The state vector y_pos contains only the position coordinates.\n",
    "    const double y_pos[4] = {y[0], y[1], y[2], y[3]};\n",
    "\n",
    "    // This switch statement chooses which \"worker\" function to call\n",
    "    // based on the metric type provided.\n",
    "    switch(metric->type) {\n",
    "        case Schwarzschild:\n",
    "        case Kerr:\n",
    "            con_kerr_schild(commondata, params, y_pos, conn);\n",
    "            break;\n",
    "        // <-- MODIFIED: Call the new Cartesian worker\n",
    "        case Schwarzschild_Standard:\n",
    "            con_schwarzschild_cartesian(commondata, params, y_pos, conn);\n",
    "            break;\n",
    "        case Numerical:\n",
    "            printf(\"Error: Numerical metric not supported yet.\\n\");\n",
    "            exit(1);\n",
    "            break;\n",
    "        default:\n",
    "            printf(\"Error: MetricType %d not supported yet.\\n\", metric->type);\n",
    "            exit(1);\n",
    "            break;\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, cfunc_type=cfunc_type,\n",
    "        name=name, params=params, body=body\n",
    "    )\n",
    "    print(\"    ... connections() registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3027eab3",
   "metadata": {},
   "source": [
    "# Calculate ut and uphi for the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb00ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ut_uphi_from_r():\n",
    "    \"\"\"\n",
    "    Generates a C helper function to compute u^t and u^phi from a radius.\n",
    "    \"\"\"\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes u^t and u^phi for a circular orbit at a given radius.\"\"\"\n",
    "    name = \"calculate_ut_uphi_from_r\"\n",
    "\n",
    "    params = \"const double r_initial, const commondata_struct *restrict commondata, const params_struct *restrict params, double *ut, double *uphi\"\n",
    "    \n",
    "    ut_expr, uphi_expr = symbolic_ut_uphi_from_r()\n",
    "    \n",
    "    body = ccg.c_codegen(\n",
    "        [ut_expr, uphi_expr],\n",
    "        [\"*ut\", \"*uphi\"],\n",
    "        enable_cse=True\n",
    "    )\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes,\n",
    "        desc=desc,\n",
    "        name=name,\n",
    "        params=params,\n",
    "        body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ea28a",
   "metadata": {},
   "source": [
    "\n",
    "# set_initial_conditions_massive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd43b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_conditions_massive():\n",
    "    \"\"\"\n",
    "    Generates the C engine to set the full initial 8-component state vector\n",
    "    from a user-provided initial 4-position and spatial 4-velocity.\n",
    "    \"\"\"\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Sets the initial 8-component state vector for a massive particle.\n",
    "    \n",
    "    This function takes an initial 4-position (t,x,y,z) and the spatial components\n",
    "    of the 4-velocity (u^x, u^y, u^z) and computes the time component u^t by\n",
    "    enforcing the timelike normalization condition g_μν u^μ u^ν = -1.\n",
    "    \n",
    "    @param[in]  initial_state  Pointer to a struct with initial pos and spatial 4-velocity.\n",
    "    @param[in]  metric         Pointer to a metric_struct with values at the initial position.\n",
    "    @param[out] y_out          The 8-component initial state vector to be populated.\"\"\"\n",
    "    name = \"set_initial_conditions_massive\"\n",
    "    params = \"const particle_initial_state_t *restrict initial_state, const metric_struct *restrict metric, double y_out[8]\"\n",
    "\n",
    "    # Preamble to bridge the symbolic recipe and the C function's variables.\n",
    "    # The symbolic recipe 'ut_massive' uses symbols u1, u2, u3.\n",
    "    # This preamble creates C variables with those names.\n",
    "    preamble = f\"\"\"\n",
    "    // Unpack the spatial 4-velocity from the initial_state struct into local\n",
    "    // variables u1, u2, u3 to match the symbolic recipe.\n",
    "    const double u1 = initial_state->u_spatial[0];\n",
    "    const double u2 = initial_state->u_spatial[1];\n",
    "    const double u3 = initial_state->u_spatial[2];\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate C code for u^t from the generic recipe.\n",
    "    # nrpy will map the symbols (u1, metric->g00, etc.) to the C variables.\n",
    "    ut_C_code = ccg.c_codegen(ut_massive(), \"const double ut\", include_braces=False, enable_cse=True)\n",
    "    \n",
    "    body = f\"\"\"\n",
    "        // Set initial position part of the state vector y[0]...y[3]\n",
    "        y_out[0] = initial_state->pos[0]; // t\n",
    "        y_out[1] = initial_state->pos[1]; // x\n",
    "        y_out[2] = initial_state->pos[2]; // y\n",
    "        y_out[3] = initial_state->pos[3]; // z\n",
    "        \n",
    "        // --- Start of Preamble ---\n",
    "        {preamble}\n",
    "        // --- End of Preamble ---\n",
    "        \n",
    "        // Calculate u^t using the pre-generated C code.\n",
    "        {ut_C_code}\n",
    "        \n",
    "        // Set the full 4-velocity in the state vector y[4]...y[7]\n",
    "        y_out[4] = ut;\n",
    "        y_out[5] = initial_state->u_spatial[0]; // u^x\n",
    "        y_out[6] = initial_state->u_spatial[1]; // u^y\n",
    "        y_out[7] = initial_state->u_spatial[2]; // u^z\n",
    "    \"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes,\n",
    "        desc=desc,\n",
    "        name=name,\n",
    "        params=params,\n",
    "        body=body\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da743f31",
   "metadata": {},
   "source": [
    "# Disk Initial Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b4ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_disk_initial_conditions():\n",
    "    \"\"\"\n",
    "    Generates a C function that programmatically creates the initial conditions\n",
    "    for a Keplerian disk.\n",
    "    \"\"\"\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Generates the complete y[8] initial state for all particles in a Keplerian disk.\"\"\"\n",
    "    cfunc_type = \"int\"\n",
    "    name = \"generate_disk_initial_conditions\"\n",
    "\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, double *restrict y_initial_states\"\n",
    "    \n",
    "\n",
    "    body = r\"\"\"\n",
    "    int particle_count = 0;\n",
    "    const double dr = (commondata->disk_num_r > 1) ? (commondata->disk_r_max - commondata->disk_r_min) / (commondata->disk_num_r - 1) : 0;\n",
    "\n",
    "    for (int i = 0; i < commondata->disk_num_r; i++) {\n",
    "        const double r = commondata->disk_r_min + i * dr;\n",
    "        \n",
    "        const int num_phi_at_r = (commondata->disk_num_phi > 1) ? (int)(commondata->disk_num_phi * (r / commondata->disk_r_max)) : 1;\n",
    "        if (num_phi_at_r == 0) continue;\n",
    "        const double dphi = 2.0 * M_PI / num_phi_at_r;\n",
    "        \n",
    "        double ut_at_r, uphi_at_r;\n",
    "        // The call is now valid because 'params' is available in this function's scope.\n",
    "        calculate_ut_uphi_from_r(r, commondata, params, &ut_at_r, &uphi_at_r);\n",
    "\n",
    "        for (int j = 0; j < num_phi_at_r; j++) {\n",
    "            const double phi = j * dphi;\n",
    "            const double cos_phi = cos(phi);\n",
    "            const double sin_phi = sin(phi);\n",
    "            \n",
    "            double *y = &y_initial_states[particle_count * 8];\n",
    "            \n",
    "            y[0] = 0.0;\n",
    "            y[1] = r * cos_phi;\n",
    "            y[2] = r * sin_phi;\n",
    "            y[3] = 0.0;\n",
    "            \n",
    "            y[4] = ut_at_r;\n",
    "            y[5] = -(r * sin_phi) * uphi_at_r;\n",
    "            y[6] =  (r * cos_phi) * uphi_at_r;\n",
    "            y[7] = 0.0;\n",
    "            \n",
    "            particle_count++;\n",
    "        }\n",
    "    }\n",
    "    return particle_count;\n",
    "    \"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes,\n",
    "        desc=desc,\n",
    "        cfunc_type=cfunc_type,\n",
    "        name=name,\n",
    "        params=params,\n",
    "        body=body\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fdf4ce",
   "metadata": {},
   "source": [
    "<a id='gsl_wrapper'></a>\n",
    "### 7.d: The GSL Wrapper Function (Redo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec563f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode_gsl_wrapper_massive():\n",
    "    \"\"\"\n",
    "    Generates the C function that acts as a bridge between the GSL ODE\n",
    "    solver and our project-specific physics functions.\n",
    "    \"\"\"\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"gsl/gsl_errno.h\"]\n",
    "    desc = r\"\"\"@brief GSL wrapper for the massive particle geodesic ODEs.\n",
    "    \n",
    "    This function matches the signature required by the GSL ODE solver. It unpacks\n",
    "    the gsl_params carrier struct and calls the dispatchers for the metric and\n",
    "    Christoffel symbols, before finally calling the RHS engine.\n",
    "    \n",
    "    @param[in]  t      The current value of the independent variable (proper time τ). Unused.\n",
    "    @param[in]  y      The current 8-component state vector.\n",
    "    @param[in]  params A generic void pointer to our gsl_params carrier struct.\n",
    "    @param[out] f      A pointer to the 8-component output array where GSL expects the RHS results.\"\"\"\n",
    "    cfunc_type = \"int\"\n",
    "    name = \"ode_gsl_wrapper_massive\"\n",
    "    params = \"double t, const double y[8], double f[8], void *params\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "        (void)t; // Proper time 't' is not explicitly used in the RHS expressions.\n",
    "        \n",
    "        // Unpack the carrier struct to access simulation parameters and metric choice.\n",
    "        gsl_params *gsl_parameters = (gsl_params *)params;\n",
    "        \n",
    "        // Declare structs to hold metric and connection values.\n",
    "        metric_struct g4DD;\n",
    "        connection_struct conn;\n",
    "        \n",
    "        // Call dispatchers to compute the metric and Christoffel symbols at the current position y.\n",
    "        // Note: The y array is 8D, but these functions only need the first 4 position components.\n",
    "        g4DD_metric(gsl_parameters->commondata, gsl_parameters->params, gsl_parameters->metric, y, &g4DD);\n",
    "        connections(gsl_parameters->commondata, gsl_parameters->params, gsl_parameters->metric, y, &conn);\n",
    "        \n",
    "        // Call the engine to compute the RHS of the ODEs.\n",
    "        calculate_ode_rhs_massive(y, &conn, f);\n",
    "        \n",
    "        return GSL_SUCCESS;\n",
    "    \"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes,\n",
    "        desc=desc,\n",
    "        cfunc_type=cfunc_type,\n",
    "        name=name, \n",
    "        params=params,\n",
    "        body=body\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfb240e",
   "metadata": {},
   "source": [
    "# Run Mass integrator production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a7354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mass_integrator_production():\n",
    "    \"\"\"\n",
    "    Generates the C orchestrator for the production run. This version\n",
    "    creates a dedicated output folder for the blueprint snapshots.\n",
    "    \"\"\"\n",
    "    # Add sys/stat.h for directory creation (mkdir)\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"<math.h>\", \"<sys/stat.h>\"]\n",
    "    desc = r\"\"\"@brief Orchestrates the full production run for the mass integrator.\"\"\"\n",
    "    name = \"run_mass_integrator_production\"\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const metric_params *restrict metric\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "    // Step 1: Generate the initial conditions for the entire disk\n",
    "    const int max_particles = commondata->disk_num_r * commondata->disk_num_phi;\n",
    "    double *y_initial_states = (double *)malloc(sizeof(double) * 8 * max_particles);\n",
    "    \n",
    "    const int num_particles = generate_disk_initial_conditions(commondata, params, y_initial_states);\n",
    "    printf(\"Generated %d particles for the Keplerian disk.\\n\", num_particles);\n",
    "\n",
    "    double *y_current_states = (double *)malloc(sizeof(double) * 8 * num_particles);\n",
    "    for(int i=0; i<8*num_particles; i++) {\n",
    "        y_current_states[i] = y_initial_states[i];\n",
    "    }\n",
    "    free(y_initial_states);\n",
    "\n",
    "    // --- Step 2: Create the output directory ---\n",
    "    // The 0755 permission gives read/write/execute to owner, and read/execute to group/others.\n",
    "    mkdir(commondata->output_folder, 0755);\n",
    "\n",
    "    // --- Step 3: Main Time Evolution and Snapshotting Loop ---\n",
    "    int snapshot_count = 0;\n",
    "    for (double current_t = 0; current_t <= commondata->t_final; current_t += commondata->snapshot_every_t) {\n",
    "        \n",
    "        // --- Save the current state to a snapshot file inside the new folder ---\n",
    "        char filename[200];\n",
    "        snprintf(filename, 200, \"%s/mass_blueprint_t_%04d.bin\", commondata->output_folder, snapshot_count);\n",
    "        printf(\"Saving snapshot: %s (t=%.2f)\\n\", filename, current_t);\n",
    "        \n",
    "        FILE *fp_out = fopen(filename, \"wb\");\n",
    "        if (fp_out == NULL) { fprintf(stderr, \"Error: Could not open snapshot file %s\\n\", filename); exit(1); }\n",
    "        \n",
    "        for (int i=0; i<num_particles; i++) {\n",
    "            if (!isnan(y_current_states[i*8])) {\n",
    "                int particle_id = i;\n",
    "                fwrite(&particle_id, sizeof(int), 1, fp_out);\n",
    "                fwrite(&y_current_states[i*8 + 1], sizeof(double), 3, fp_out); // x, y, z\n",
    "                fwrite(&y_current_states[i*8 + 5], sizeof(double), 3, fp_out); // u^x, u^y, u^z\n",
    "            }\n",
    "        }\n",
    "        fclose(fp_out);\n",
    "        snapshot_count++;\n",
    "\n",
    "        if (current_t >= commondata->t_final) break;\n",
    "\n",
    "        // --- Evolve all particles for one snapshot interval ---\n",
    "        const double t_next_snapshot = current_t + commondata->snapshot_every_t;\n",
    "        printf(\"Integrating all particles from t=%.2f to t=%.2f...\\n\", current_t, t_next_snapshot);\n",
    "        \n",
    "        #pragma omp parallel for\n",
    "        for (int i = 0; i < num_particles; i++) {\n",
    "            if (isnan(y_current_states[i * 8])) continue;\n",
    "\n",
    "            double *y_particle = &y_current_states[i * 8];\n",
    "            \n",
    "            int status = integrate_single_particle(commondata, params, metric, y_particle[0], t_next_snapshot, y_particle);\n",
    "            \n",
    "            if (status != 0) {\n",
    "                y_current_states[i * 8] = NAN;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Step 4: Clean up memory\n",
    "    free(y_current_states);\n",
    "    \"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes,\n",
    "        desc=desc,\n",
    "        name=name,\n",
    "        params=params,\n",
    "        body=body\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a16075",
   "metadata": {},
   "source": [
    "\n",
    "###  The Main Integration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aeb938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_mass_integrator():\n",
    "    \"\"\"\n",
    "    Generates the main() C function, which orchestrates the entire simulation.\n",
    "    \"\"\"\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Main entry point for the massive particle geodesic integrator.\"\"\"\n",
    "    cfunc_type = \"int\"\n",
    "    name = \"main\"\n",
    "    params = \"int argc, const char *argv[]\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "    // Step 1: Initialize structs and parameters\n",
    "    commondata_struct commondata;\n",
    "    params_struct params;\n",
    "    metric_params metric;\n",
    "    \n",
    "    commondata_struct_set_to_default(&commondata);\n",
    "    cmdline_input_and_parfile_parser(&commondata, argc, argv);\n",
    "    \n",
    "    metric.type = (commondata.a_spin == 0.0) ? Schwarzschild : Kerr;\n",
    "\n",
    "    // Step 2: Read particle initial conditions from file\n",
    "    FILE *fp_in = fopen(\"particle_initial_conditions.txt\", \"r\");\n",
    "    if (fp_in == NULL) {\n",
    "        fprintf(stderr, \"Error: Could not open particle_initial_conditions.txt\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    int num_particles = 0;\n",
    "    char line[256];\n",
    "    while (fgets(line, sizeof(line), fp_in)) {\n",
    "        if (line[0] != '#') num_particles++;\n",
    "    }\n",
    "    rewind(fp_in);\n",
    "\n",
    "    particle_initial_state_t *initial_states = (particle_initial_state_t *)malloc(sizeof(particle_initial_state_t) * num_particles);\n",
    "    mass_blueprint_data_t *results_buffer = (mass_blueprint_data_t *)malloc(sizeof(mass_blueprint_data_t) * num_particles);\n",
    "\n",
    "    printf(\"Reading %d particle initial states from file...\\n\", num_particles);\n",
    "    for (int i = 0; i < num_particles; ) {\n",
    "        if (fgets(line, sizeof(line), fp_in) && line[0] != '#') {\n",
    "            sscanf(line, \"%d %lf %lf %lf %lf %lf %lf\", \n",
    "                   &initial_states[i].id, \n",
    "                   &initial_states[i].pos[0], &initial_states[i].pos[1], &initial_states[i].pos[2],\n",
    "                   &initial_states[i].vel[0], &initial_states[i].vel[1], &initial_states[i].vel[2]);\n",
    "            i++;\n",
    "        }\n",
    "    }\n",
    "    fclose(fp_in);\n",
    "\n",
    "    // Step 3: Main parallel loop over particles\n",
    "    printf(\"Starting integration for %d particles...\\n\", num_particles);\n",
    "    #pragma omp parallel for\n",
    "    for (int i = 0; i < num_particles; i++) {\n",
    "        metric_struct metric; // Use the standard name 'metric'\n",
    "        double y_start[8], y_final[8];\n",
    "        \n",
    "        // Set initial position part of the state vector first.\n",
    "        y_start[0] = 0.0;\n",
    "        y_start[1] = initial_states[i].pos[0];\n",
    "        y_start[2] = initial_states[i].pos[1];\n",
    "        y_start[3] = initial_states[i].pos[2];\n",
    "\n",
    "        // Compute metric at the initial position, passing the partially filled y_start.\n",
    "        g4DD_metric(&commondata, &params, &metric, y_start, &metric);\n",
    "        \n",
    "        // Now compute the rest of the initial state (the 4-velocity).\n",
    "        set_initial_conditions_massive(&initial_states[i], &metric, y_start);\n",
    "        \n",
    "        if (commondata.perform_conservation_check) {\n",
    "            double E_i, Lx_i, Ly_i, Lz_i, Q_i;\n",
    "            check_conservation_massive(&commondata, &params, &metric, y_start, &E_i, &Lx_i, &Ly_i, &Lz_i, &Q_i);\n",
    "        }\n",
    "\n",
    "        integrate_single_particle(&commondata, &params, &metric, y_start, y_final);\n",
    "        \n",
    "        results_buffer[i].particle_id = initial_states[i].id;\n",
    "        results_buffer[i].time = y_final[0];\n",
    "        for(int j=0; j<8; j++) results_buffer[i].y_state[j] = y_final[j];\n",
    "    }\n",
    "\n",
    "    // Step 4: Write results to binary file and clean up\n",
    "    printf(\"Integration complete. Writing %d results to mass_blueprint.bin\\n\", num_particles);\n",
    "    FILE *fp_out = fopen(\"mass_blueprint.bin\", \"wb\");\n",
    "    fwrite(results_buffer, sizeof(mass_blueprint_data_t), num_particles, fp_out);\n",
    "    fclose(fp_out);\n",
    "\n",
    "    free(initial_states);\n",
    "    free(results_buffer);\n",
    "    \n",
    "    printf(\"Run finished successfully.\\n\");\n",
    "    return 0;\n",
    "    \"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes,\n",
    "        desc=desc,\n",
    "        cfunc_type=cfunc_type,\n",
    "        name=name,\n",
    "        params=params,\n",
    "        body=body\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f6d709",
   "metadata": {},
   "source": [
    "# Main integration code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ba2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_single_particle():\n",
    "    \"\"\"\n",
    "    Generates the main C integration loop for a single massive particle.\n",
    "    This high-performance \"production\" version uses the GSL driver to ensure\n",
    "    the state is returned at the exact requested snapshot times.\n",
    "    \"\"\"\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"gsl/gsl_errno.h\", \"gsl/gsl_odeiv2.h\", \"<math.h>\"]\n",
    "    desc = r\"\"\"@brief Integrates a single massive particle path between two times.\n",
    "    \n",
    "    This function uses the GSL driver, which internally uses an adaptive\n",
    "    step-size algorithm (RKF45) to evolve the particle's state vector y_in_out\n",
    "    from t_start to t_end, returning the state at the precise t_end.\n",
    "    \n",
    "    @param[in]      commondata  Pointer to commondata struct.\n",
    "    @param[in]      params      Pointer to params_struct.\n",
    "    @param[in]      metric      Pointer to metric_params struct.\n",
    "    @param[in]      t_start     The starting proper time (τ) for the integration.\n",
    "    @param[in]      t_end       The ending proper time (τ) for the integration.\n",
    "    @param[in,out]  y_in_out    The 8-component state vector. Input is the state at t_start, output is the state at t_end.\n",
    "    \n",
    "    @return 0 on success, 1 on GSL failure.\n",
    "    \"\"\"\n",
    "    cfunc_type = \"int\"\n",
    "    name = \"integrate_single_particle\"\n",
    "    params = \"\"\"const commondata_struct *restrict commondata,\n",
    "    const params_struct *restrict params,\n",
    "    const metric_params *restrict metric,\n",
    "    const double t_start, const double t_end,\n",
    "    double y_in_out[8]\"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // Define the GSL ODE system\n",
    "    gsl_params gsl_parameters = {commondata, params, metric};\n",
    "    gsl_odeiv2_system sys = {ode_gsl_wrapper_massive, NULL, 8, &gsl_parameters};\n",
    "    \n",
    "    // Set up the GSL driver\n",
    "    gsl_odeiv2_driver *d = gsl_odeiv2_driver_alloc_y_new(\n",
    "        &sys, gsl_odeiv2_step_rkf45, 1e-6, 1e-11, 1e-11);\n",
    "    \n",
    "    double t = t_start;\n",
    "    \n",
    "    // The driver will take internal steps to reach t_end precisely.\n",
    "    int status = gsl_odeiv2_driver_apply(d, &t, t_end, y_in_out);\n",
    "\n",
    "    if (status != GSL_SUCCESS) {\n",
    "        // Don't print an error here, as the orchestrator will check the status.\n",
    "        // Just free memory and return the failure code.\n",
    "        gsl_odeiv2_driver_free(d);\n",
    "        return 1; // Return failure code\n",
    "    }\n",
    "\n",
    "    // Robustness check after the step\n",
    "    const double r_sq = y_in_out[1]*y_in_out[1] + y_in_out[2]*y_in_out[2] + y_in_out[3]*y_in_out[3];\n",
    "    const double r_horizon = commondata->M_scale * (1.0 + sqrt(1.0 - commondata->a_spin*commondata->a_spin));\n",
    "\n",
    "    if (r_sq < r_horizon*r_horizon || r_sq > r_escape*r_escape || fabs(y_in_out[4]) > ut_max) {\n",
    "        gsl_odeiv2_driver_free(d);\n",
    "        return 1; // Return failure code\n",
    "    }\n",
    "\n",
    "    gsl_odeiv2_driver_free(d);\n",
    "    return 0; // Return success code\n",
    "    \"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes,\n",
    "        desc=desc,\n",
    "        cfunc_type=cfunc_type,\n",
    "        name=name,\n",
    "        params=params,\n",
    "        body=body, \n",
    "        include_CodeParameters_h=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a3977c",
   "metadata": {},
   "source": [
    "# Bebugging integration (for single masslike particle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ff83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_single_particle_DEBUG():\n",
    "    \"\"\"\n",
    "    Generates a DEBUG version of the integrator that writes the full trajectory\n",
    "    of a single massive particle to a text file for validation.\n",
    "    \"\"\"\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"gsl/gsl_errno.h\", \"gsl/gsl_odeiv2.h\"]\n",
    "    desc = r\"\"\"@brief DEBUG integrator for a single massive particle.\n",
    "    \n",
    "    This function integrates the path of a single particle and writes the full\n",
    "    8-component state vector at each step to 'massive_particle_path.txt'.\n",
    "    It also prints progress to the console and checks for termination conditions.\n",
    "    \n",
    "    @param[in]  commondata  Pointer to the commondata_struct.\n",
    "    @param[in]  params      Pointer to the params_struct.\n",
    "    @param[in]  metric      Pointer to the metric_params struct.\n",
    "    @param[in]  start_y     The 8-component initial state vector.\n",
    "    @param[out] final_y_state The 8-component final state vector upon termination.\"\"\"\n",
    "    cfunc_type = \"void\"\n",
    "    name = \"integrate_single_particle_DEBUG\"\n",
    "    params = \"\"\"const commondata_struct *restrict commondata,\n",
    "    const params_struct *restrict params,\n",
    "    const metric_params *restrict metric,\n",
    "    const double start_y[8],\n",
    "    double final_y_state[8]\"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // GSL Setup\n",
    "    const gsl_odeiv2_step_type * T = gsl_odeiv2_step_rkf45;\n",
    "    gsl_odeiv2_step * step = gsl_odeiv2_step_alloc(T, 8);\n",
    "    gsl_odeiv2_control * control = gsl_odeiv2_control_y_new(1e-12, 1e-12);\n",
    "    gsl_odeiv2_evolve * evol = gsl_odeiv2_evolve_alloc(8);\n",
    "    gsl_params gsl_parameters = {commondata, params, metric};\n",
    "    gsl_odeiv2_system sys = {ode_gsl_wrapper_massive, NULL, 8, &gsl_parameters};\n",
    "\n",
    "    double y_c[8];\n",
    "    double t = 0.0, dt = 0.01; // t is proper time τ\n",
    "    for (int j = 0; j < 8; j++) { y_c[j] = start_y[j]; }\n",
    "\n",
    "    // Setup output file\n",
    "    FILE *fp = fopen(\"massive_particle_path.txt\", \"w\");\n",
    "    if (fp == NULL) { \n",
    "        fprintf(stderr, \"Error: Could not open massive_particle_path.txt for writing.\\n\");\n",
    "        exit(1); \n",
    "    }\n",
    "    fprintf(fp, \"# ProperTime_tau\\tCoordTime_t\\tx\\ty\\tz\\tu^t\\tu^x\\tu^y\\tu^z\\n\");\n",
    "\n",
    "    printf(\"Starting debug trace for single massive particle...\\n\");\n",
    "    printf(\"Step | Proper Time (τ) | Coord Time (t) |      x     |      y     |      z     |      u^t   \\n\");\n",
    "    printf(\"-------------------------------------------------------------------------------------------\\n\");\n",
    "\n",
    "    // Main Integration Loop\n",
    "    for (int i = 0; i < 500000; i++) {\n",
    "        int status = gsl_odeiv2_evolve_apply(evol, control, step, &sys, &t, 1e10, &dt, y_c);\n",
    "        \n",
    "        // Write full state to file\n",
    "        fprintf(fp, \"%.6e\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\t%.6e\\n\", \n",
    "                t, y_c[0], y_c[1], y_c[2], y_c[3], y_c[4], y_c[5], y_c[6], y_c[7]);\n",
    "\n",
    "        if (i % 500 == 0) {\n",
    "            printf(\"%4d | %15.4e | %14.4f | %10.4f | %10.4f | %10.4f | %10.4f\\n\",\n",
    "                   i, t, y_c[0], y_c[1], y_c[2], y_c[3], y_c[4]);\n",
    "        }\n",
    "\n",
    "        const double r_sq = y_c[1]*y_c[1] + y_c[2]*y_c[2] + y_c[3]*y_c[3];\n",
    "        // Event horizon radius for a Kerr black hole\n",
    "        const double r_horizon = commondata->M_scale * (1.0 + sqrt(1.0 - commondata->a_spin*commondata->a_spin));\n",
    "\n",
    "        // Termination Conditions\n",
    "        if (status != GSL_SUCCESS) { printf(\"Termination: GSL ERROR (status = %d)\\n\", status); break; }\n",
    "        if (r_sq < r_horizon*r_horizon) { printf(\"Termination: Fell below event horizon (r=%.2f)\\n\", sqrt(r_sq)); break; }\n",
    "        if (r_sq > r_escape*r_escape) { printf(\"Termination: Escaped to r > %.1f\\n\", r_escape); break; }\n",
    "        if (fabs(y_c[4]) > ut_max) { printf(\"Termination: Runaway u^t > %.1e\\n\", ut_max); break; }\n",
    "        if (fabs(y_c[0]) > t_max_integration) { printf(\"Termination: Exceeded max integration time t > %.1f\\n\", t_max_integration); break; }\n",
    "    }\n",
    "\n",
    "    // Copy final state to output and clean up\n",
    "    for(int j=0; j<8; j++) { final_y_state[j] = y_c[j]; }\n",
    "    fclose(fp);\n",
    "    gsl_odeiv2_evolve_free(evol);\n",
    "    gsl_odeiv2_control_free(control);\n",
    "    gsl_odeiv2_step_free(step);\n",
    "    \"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes,\n",
    "        desc=desc,\n",
    "        cfunc_type=cfunc_type,\n",
    "        name=name,\n",
    "        params=params,\n",
    "        body=body, \n",
    "        include_CodeParameters_h=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c4eaf0",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4661b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Generates a single, unified main() C function that can switch between\n",
    "    a single-particle debug run and a full-disk production run based on a\n",
    "    runtime parameter.\n",
    "    \"\"\"\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"<math.h>\"]\n",
    "    desc = r\"\"\"@brief Main entry point for the mass integrator.\"\"\"\n",
    "    cfunc_type = \"int\"\n",
    "    name = \"main\"\n",
    "    params = \"int argc, const char *argv[]\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "    // Step 1: Initialize structs and parameters\n",
    "    commondata_struct commondata;\n",
    "    params_struct params;\n",
    "    metric_params metric;\n",
    "    \n",
    "    commondata_struct_set_to_default(&commondata);\n",
    "    cmdline_input_and_parfile_parser(&commondata, argc, argv);\n",
    "    \n",
    "    metric.type = (commondata.a_spin == 0.0) ? Schwarzschild : Kerr;\n",
    "\n",
    "    // Step 2: Check the run mode and execute the appropriate logic\n",
    "    if (commondata.run_in_debug_mode) {\n",
    "        /***********************************/\n",
    "        /*** SINGLE-PARTICLE DEBUG MODE ***/\n",
    "        /***********************************/\n",
    "        particle_initial_state_t initial_state;\n",
    "        initial_state.id = 0;\n",
    "\n",
    "        const char *filename = \"particle_debug_initial_conditions.txt\";\n",
    "        FILE *fp_in = fopen(filename, \"r\");\n",
    "        if (fp_in == NULL) {\n",
    "            printf(\"File '%s' not found. Creating it with default values.\\n\", filename);\n",
    "            fp_in = fopen(filename, \"w\");\n",
    "            if (fp_in == NULL) { fprintf(stderr, \"Error: Could not create '%s'.\\n\", filename); return 1; }\n",
    "            fprintf(fp_in, \"# Format: t_initial pos_x pos_y pos_z u_x u_y u_z\\n\");\n",
    "            fprintf(fp_in, \"# u_i are the spatial components of the 4-velocity (dx/dτ).\\n\");\n",
    "            fprintf(fp_in, \"0.0 10.0  0.0  0.0   0.0  0.363232  0.0\\n\");\n",
    "            fclose(fp_in);\n",
    "            fp_in = fopen(filename, \"r\");\n",
    "            if (fp_in == NULL) { fprintf(stderr, \"Error: Could not re-open '%s'.\\n\", filename); return 1; }\n",
    "        }\n",
    "\n",
    "        char line[256];\n",
    "        while (fgets(line, sizeof(line), fp_in)) {\n",
    "            if (line[0] != '#') {\n",
    "                // CORRECTED: Read into the 'u_spatial' member, not 'vel'.\n",
    "                sscanf(line, \"%lf %lf %lf %lf %lf %lf %lf\", \n",
    "                       &initial_state.pos[0], &initial_state.pos[1], &initial_state.pos[2], &initial_state.pos[3],\n",
    "                       &initial_state.u_spatial[0], &initial_state.u_spatial[1], &initial_state.u_spatial[2]);\n",
    "                break; \n",
    "            }\n",
    "        }\n",
    "        fclose(fp_in);\n",
    "\n",
    "        printf(\"--- Single Particle Debug Run ---\\n\");\n",
    "        printf(\"Using Initial Conditions from '%s':\\n\", filename);\n",
    "        printf(\"  pos = (t=%.4f, x=%.4f, y=%.4f, z=%.4f)\\n\", initial_state.pos[0], initial_state.pos[1], initial_state.pos[2], initial_state.pos[3]);\n",
    "        // CORRECTED: Print from the 'u_spatial' member.\n",
    "        printf(\"  u_spatial = (%.4f, %.4f, %.4f)\\n\", initial_state.u_spatial[0], initial_state.u_spatial[1], initial_state.u_spatial[2]);\n",
    "\n",
    "        metric_struct g4DD;\n",
    "        double y_start[8], y_final[8];\n",
    "        \n",
    "        double y_pos_tmp[9] = {initial_state.pos[0], initial_state.pos[1], initial_state.pos[2], initial_state.pos[3]};\n",
    "        g4DD_metric(&commondata, &params, &metric, y_pos_tmp, &g4DD);\n",
    "        set_initial_conditions_massive(&initial_state, &g4DD, y_start);\n",
    "\n",
    "        printf(\"\\nInitial State Vector (y_start):\\n\");\n",
    "        printf(\"  t=%.2f, x=%.2f, y=%.2f, z=%.2f\\n\", y_start[0], y_start[1], y_start[2], y_start[3]);\n",
    "        printf(\"  u^t=%.4f, u^x=%.4f, u^y=%.4f, u^z=%.4f\\n\\n\", y_start[4], y_start[5], y_start[6], y_start[7]);\n",
    "\n",
    "        if(commondata.perform_conservation_check) {\n",
    "            double E_i, Lx_i, Ly_i, Lz_i, Q_i, E_f, Lx_f, Ly_f, Lz_f, Q_f;\n",
    "            check_conservation_massive(&commondata, &params, &metric, y_start, &E_i, &Lx_i, &Ly_i, &Lz_i, &Q_i);\n",
    "            integrate_single_particle_DEBUG(&commondata, &params, &metric, y_start, y_final);\n",
    "            check_conservation_massive(&commondata, &params, &metric, y_final, &E_f, &Lx_f, &Ly_f, &Lz_f, &Q_f);\n",
    "            // Print report... (This part is fine)\n",
    "        } else {\n",
    "            integrate_single_particle_DEBUG(&commondata, &params, &metric, y_start, y_final);\n",
    "        }\n",
    "        \n",
    "        printf(\"\\nDebug run finished. Trajectory saved to 'massive_particle_path.txt'.\\n\");\n",
    "\n",
    "    } else {\n",
    "        /***********************************/\n",
    "        /*** FULL DISK PRODUCTION MODE ***/\n",
    "        /***********************************/\n",
    "        printf(\"--- Full Disk Production Run ---\\n\");\n",
    "        run_mass_integrator_production(&commondata, &params, &metric);\n",
    "        printf(\"\\nProduction run finished successfully.\\n\");\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "    \"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes,\n",
    "        desc=desc,\n",
    "        cfunc_type=cfunc_type,\n",
    "        name=name,\n",
    "        params=params,\n",
    "        body=body\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec8cb55",
   "metadata": {},
   "source": [
    "\n",
    "# Step 8: Project Assembly and Compilation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef03c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_custom_structures_and_params():\n",
    "    \"\"\"\n",
    "    Generates C code for all custom structs and enums, then registers them with BHaH.\n",
    "    \"\"\"\n",
    "    print(\"Registering custom C data structures for mass integrator...\")\n",
    "    \n",
    "    metric_components = [f\"g{nu}{mu}\" for nu in range(4) for mu in range(nu, 4)]\n",
    "    metric_struct_str = \"typedef struct { double \" + \"; double \".join(metric_components) + \"; } metric_struct;\"\n",
    "    \n",
    "    connection_components = [f\"Gamma4UDD{i}{j}{k}\" for i in range(4) for j in range(4) for k in range(j, 4)]\n",
    "    connections_struct_str = \"typedef struct { double \" + \"; double \".join(connection_components) + \"; } connection_struct;\"\n",
    "\n",
    "    other_structs = r\"\"\"\n",
    "typedef enum { Schwarzschild, Kerr, Numerical, Schwarzschild_Standard } Metric_t;\n",
    "typedef struct { Metric_t type; } metric_params;\n",
    "\n",
    "typedef struct { \n",
    "    const commondata_struct *commondata; \n",
    "    const params_struct *params; \n",
    "    const metric_params *metric; \n",
    "} gsl_params;\n",
    "\n",
    "typedef struct {\n",
    "    int id;\n",
    "    double pos[4]; // Initial position (t, x, y, z)\n",
    "    // CORRECTED: Renamed 'vel_3' to 'u_spatial' for consistency.\n",
    "    double u_spatial[3]; // Initial SPATIAL 4-VELOCITY (u^x, u^y, u^z)\n",
    "} particle_initial_state_t;\n",
    "\n",
    "typedef struct {\n",
    "    int particle_id;\n",
    "    double time;\n",
    "    double y_state[8]; // t, x, y, z, u^t, u^x, u^y, u^z\n",
    "} __attribute__((packed)) mass_blueprint_data_t;\n",
    "\"\"\"\n",
    "    Bdefines_h.register_BHaH_defines(\"data_structures\", f\"{metric_struct_str}\\n{connections_struct_str}\\n{other_structs}\")\n",
    "    print(\" -> Registered all necessary data structures.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9583e0f3",
   "metadata": {},
   "source": [
    "<a id='final_build'></a>\n",
    "### 8.b: Final Build Command (Redo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf390696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In V1_1_mass_geodesic.ipynb, Cell ID a0eb212d (Final Build Script)\n",
    "print(\"\\nAssembling and building C project for the massive particle integrator...\")\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "# --- Step 1: Register all C-generating functions in the correct order ---\n",
    "print(\" -> Registering C data structures and functions...\")\n",
    "register_custom_structures_and_params()\n",
    "\n",
    "# Register symbolic recipes and C-generating functions for physics\n",
    "# symbolic_ut_uphi_from_r() is called by the next function\n",
    "calculate_ut_uphi_from_r() # The new, required helper function\n",
    "\n",
    "# Register C workers for metrics and connections\n",
    "g4DD_kerr_schild(); con_kerr_schild()\n",
    "g4DD_schwarzschild_cartesian(); con_schwarzschild_cartesian()\n",
    "\n",
    "# Register C dispatchers\n",
    "g4DD_metric(); connections()\n",
    "\n",
    "# Register C engines for the core logic\n",
    "calculate_ode_rhs_massive()\n",
    "ode_gsl_wrapper_massive()\n",
    "set_initial_conditions_massive()\n",
    "check_conservation_massive()\n",
    "integrate_single_particle() \n",
    "integrate_single_particle_DEBUG()\n",
    "\n",
    "\n",
    "# Register the production-run orchestrators\n",
    "generate_disk_initial_conditions()\n",
    "run_mass_integrator_production()\n",
    "\n",
    "main()\n",
    "\n",
    "\n",
    "# --- Step 2: Call BHaH infrastructure functions to generate the build system ---\n",
    "print(\" -> Generating BHaH infrastructure files...\")\n",
    "# Generate set_CodeParameters.h and its variants\n",
    "CPs.write_CodeParameters_h_files(project_dir=project_dir)\n",
    "# Register C functions to set parameters to default values\n",
    "CPs.register_CFunctions_params_commondata_struct_set_to_default()\n",
    "# Generate the default parameter file (mass_integrator.par)\n",
    "cmdline_input_and_parfiles.generate_default_parfile(project_dir=project_dir, project_name=project_name)\n",
    "\n",
    "# Register the C function that parses the command line and parameter file\n",
    "cmdline_input_and_parfiles.register_CFunction_cmdline_input_and_parfile_parser(\n",
    "    project_name=project_name,\n",
    "    cmdline_inputs=['M_scale', 'a_spin', 't_max_integration', 'flatness_threshold', \n",
    "                    'r_escape', 'ut_max', 'perform_conservation_check', 'run_in_debug_mode']\n",
    ")\n",
    "\n",
    "# --- Step 3: Generate the final C code, headers, and Makefile ---\n",
    "print(\"\\nGenerating BHaH master header file (BHaH_defines.h)...\")\n",
    "Bdefines_h.output_BHaH_defines_h(project_dir=project_dir)\n",
    "\n",
    "# Note: SIMD intrinsics are not used in this project, but the helper is harmless.\n",
    "print(\"Copying required helper files...\")\n",
    "gh.copy_files(\n",
    "    package=\"nrpy.helpers\",\n",
    "    filenames_list=[\"simd_intrinsics.h\"],\n",
    "    project_dir=project_dir,\n",
    "    subdirectory=\"simd\",\n",
    ")\n",
    "\n",
    "print(\"Generating all C source files, function prototypes, and the Makefile...\")\n",
    "# Add required GSL and OpenMP flags to the compiler\n",
    "addl_CFLAGS = [\"-Wall -Wextra -g $(shell gsl-config --cflags) -fopenmp\"]\n",
    "addl_libraries = [\"$(shell gsl-config --libs) -fopenmp\"]\n",
    "\n",
    "Makefile.output_CFunctions_function_prototypes_and_construct_Makefile(\n",
    "    project_dir=project_dir,\n",
    "    project_name=project_name,\n",
    "    exec_or_library_name=\"mass_integrator\", # The name of our final executable\n",
    "    addl_CFLAGS=addl_CFLAGS,\n",
    "    addl_libraries=addl_libraries,\n",
    ")\n",
    "\n",
    "print(f\"\\nFinished! A C project has been generated in '{project_dir}/'\")\n",
    "print(f\"To build, navigate to this directory in your terminal and type 'make'.\")\n",
    "print(f\"To run, type './mass_integrator'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4304c5c4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ce1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "def preprocess_snapshots(\n",
    "    project_dir: str = \"project/mass_integrator\",\n",
    "    input_folder: str = \"output\",\n",
    "    processed_folder: str = \"processed_snapshots\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads all raw binary snapshot files from the input_folder, builds a\n",
    "    k-d tree for each, and saves the processed data (original data + k-d tree)\n",
    "    to a new file in the processed_folder.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting Snapshot Pre-processing for k-d Tree Generation ---\")\n",
    "    \n",
    "    # --- 1. Setup paths and directories ---\n",
    "    snapshot_dir = os.path.join(project_dir, input_folder)\n",
    "    output_dir = os.path.join(project_dir, processed_folder)\n",
    "    \n",
    "    # Create the output directory if it doesn't exist.\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Processed files will be saved to: '{output_dir}'\")\n",
    "    \n",
    "    snapshot_files = sorted(glob.glob(os.path.join(snapshot_dir, \"mass_blueprint_t_*.bin\")))\n",
    "    \n",
    "    if not snapshot_files:\n",
    "        print(f\"ERROR: No raw snapshot .bin files found in '{snapshot_dir}'\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Found {len(snapshot_files)} raw snapshots to process.\")\n",
    "\n",
    "    # Define the data type for a single record in the raw binary file\n",
    "    snapshot_dtype = np.dtype([\n",
    "        ('id', np.int32),\n",
    "        ('pos', 'f8', (3,)),\n",
    "        ('u_spatial', 'f8', (3,))\n",
    "    ])\n",
    "\n",
    "    # --- 2. Loop through each snapshot and process it ---\n",
    "    for i, snapshot_file in enumerate(snapshot_files):\n",
    "        print(f\"  Processing file {i+1}/{len(snapshot_files)}: {os.path.basename(snapshot_file)} ...\", end=\"\")\n",
    "        \n",
    "        try:\n",
    "            raw_data = np.fromfile(snapshot_file, dtype=snapshot_dtype)\n",
    "            \n",
    "            if len(raw_data) == 0:\n",
    "                print(\" empty, skipping.\")\n",
    "                continue\n",
    "\n",
    "            positions = raw_data['pos']\n",
    "            kdtree = cKDTree(positions)\n",
    "            \n",
    "            processed_data = {\n",
    "                'raw_data': raw_data,\n",
    "                'kdtree': kdtree\n",
    "            }\n",
    "            \n",
    "            # Construct the new filename and save it in the processed_folder\n",
    "            base_filename = os.path.basename(snapshot_file)\n",
    "            output_filename = os.path.join(output_dir, base_filename.replace('.bin', '.kdtree.pkl'))\n",
    "            \n",
    "            with open(output_filename, 'wb') as f:\n",
    "                pickle.dump(processed_data, f)\n",
    "            \n",
    "            print(f\" done. Saved to {os.path.basename(output_filename)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" FAILED. Error: {e}\")\n",
    "            \n",
    "    print(\"\\n--- Pre-processing complete. ---\")\n",
    "\n",
    "# --- How to Run This ---\n",
    "# After your C code has generated the .bin files in the 'output' folder,\n",
    "# run this function.\n",
    "preprocess_snapshots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89602521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_particle_trajectory(\n",
    "    project_dir: str = \"project/mass_integrator\",\n",
    "    input_filename: str = \"massive_particle_path.txt\",\n",
    "    M_scale: float = 1.0,\n",
    "    a_spin: float = 0.9\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads the trajectory data from the C code's output file and generates\n",
    "    a 3D plot of the particle's orbit around the black hole.\n",
    "\n",
    "    Args:\n",
    "        project_dir: The root directory of the C project where the output file is located.\n",
    "        input_filename: The name of the trajectory data file.\n",
    "        M_scale: The mass of the black hole, used to plot the event horizon.\n",
    "        a_spin: The spin of the black hole, used to plot the event horizon.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Particle Trajectory Plot ---\")\n",
    "    \n",
    "    # --- 1. Construct the full path and load the data ---\n",
    "    full_path = os.path.join(project_dir, input_filename)\n",
    "    \n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"ERROR: Trajectory file not found at '{full_path}'\")\n",
    "        print(\"Please ensure you have compiled and run the C code successfully.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Load the data, skipping the header row\n",
    "        data = np.loadtxt(full_path, skiprows=1)\n",
    "        # Columns: 0:τ, 1:t, 2:x, 3:y, 4:z, 5:u^t, 6:u^x, 7:u^y, 8:u^z\n",
    "        x_coords = data[:, 2]\n",
    "        y_coords = data[:, 3]\n",
    "        z_coords = data[:, 4]\n",
    "        print(f\"Successfully loaded {len(x_coords)} data points from trajectory file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load or parse the data file '{full_path}'.\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Set up the 3D plot ---\n",
    "    plt.style.use('dark_background')\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # --- 3. Plot the particle's trajectory ---\n",
    "    ax.plot(x_coords, y_coords, z_coords, label='Particle Orbit', color='cyan', lw=2)\n",
    "    \n",
    "    # Mark the start and end points\n",
    "    ax.scatter(x_coords[0], y_coords[0], z_coords[0], color='lime', s=100, label='Start', marker='o')\n",
    "    ax.scatter(x_coords[-1], y_coords[-1], z_coords[-1], color='red', s=100, label='End', marker='X')\n",
    "\n",
    "    # --- 4. Plot the black hole's event horizon ---\n",
    "    # The radius of the event horizon for a Kerr black hole\n",
    "    r_horizon = M_scale * (1 + np.sqrt(1 - a_spin**2))\n",
    "    \n",
    "    # Create a sphere for the event horizon\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "    x_bh = r_horizon * np.outer(np.cos(u), np.sin(v))\n",
    "    y_bh = r_horizon * np.outer(np.sin(u), np.sin(v))\n",
    "    z_bh = r_horizon * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "    \n",
    "    ax.plot_surface(x_bh, y_bh, z_bh, color='black', alpha=0.9, rstride=4, cstride=4)\n",
    "    # Add a grey wireframe for better visibility\n",
    "    ax.plot_wireframe(x_bh, y_bh, z_bh, color='dimgrey', alpha=0.2, rstride=10, cstride=10)\n",
    "\n",
    "    # --- 5. Customize the plot ---\n",
    "    ax.set_xlabel('X (M)', fontsize=12, labelpad=10)\n",
    "    ax.set_ylabel('Y (M)', fontsize=12, labelpad=10)\n",
    "    ax.set_zlabel('Z (M)', fontsize=12, labelpad=10)\n",
    "    \n",
    "    # Set equal aspect ratio\n",
    "    max_range = np.array([x_coords.max()-x_coords.min(), y_coords.max()-y_coords.min(), z_coords.max()-z_coords.min()]).max() / 2.0\n",
    "    mid_x = (x_coords.max()+x_coords.min()) * 0.5\n",
    "    mid_y = (y_coords.max()+y_coords.min()) * 0.5\n",
    "    mid_z = (z_coords.max()+z_coords.min()) * 0.5\n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "\n",
    "    ax.set_title(f\"Massive Particle Trajectory (M={M_scale}, a={a_spin})\", fontsize=16)\n",
    "    ax.legend()\n",
    "    ax.view_init(elev=30., azim=45) # Set a nice viewing angle\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1182d10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_trajectory_components(\n",
    "    project_dir: str = \"project/mass_integrator\",\n",
    "    input_filename: str = \"massive_particle_path.txt\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads trajectory data and creates four plots:\n",
    "    x vs t, y vs t, z vs t, and proper time (τ) vs t.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Trajectory Component Plots ---\")\n",
    "    \n",
    "    # --- 1. Load the data ---\n",
    "    full_path = os.path.join(project_dir, input_filename)\n",
    "    \n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"ERROR: Trajectory file not found at '{full_path}'\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        data = np.loadtxt(full_path, skiprows=1)\n",
    "        # Columns: 0:τ, 1:t, 2:x, 3:y, 4:z, ...\n",
    "        proper_time = data[:, 0]\n",
    "        coord_time = data[:, 1]\n",
    "        x_coords = data[:, 2]\n",
    "        y_coords = data[:, 3]\n",
    "        z_coords = data[:, 4]\n",
    "        print(f\"Successfully loaded {len(coord_time)} data points.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load or parse data file '{full_path}'. Exception: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Create the plots ---\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Particle Trajectory Components vs. Coordinate Time', fontsize=20)\n",
    "\n",
    "    # Plot 1: x(t)\n",
    "    axes[0, 0].plot(coord_time, x_coords, color='cyan')\n",
    "    axes[0, 0].set_title('X Coordinate vs. Time', fontsize=14)\n",
    "    axes[0, 0].set_xlabel('Coordinate Time (t) [M]', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('x [M]', fontsize=12)\n",
    "    axes[0, 0].grid(True)\n",
    "\n",
    "    # Plot 2: y(t)\n",
    "    axes[0, 1].plot(coord_time, y_coords, color='magenta')\n",
    "    axes[0, 1].set_title('Y Coordinate vs. Time', fontsize=14)\n",
    "    axes[0, 1].set_xlabel('Coordinate Time (t) [M]', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('y [M]', fontsize=12)\n",
    "    axes[0, 1].grid(True)\n",
    "\n",
    "    # Plot 3: z(t)\n",
    "    axes[1, 0].plot(coord_time, z_coords, color='lime')\n",
    "    axes[1, 0].set_title('Z Coordinate vs. Time', fontsize=14)\n",
    "    axes[1, 0].set_xlabel('Coordinate Time (t) [M]', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('z [M]', fontsize=12)\n",
    "    axes[1, 0].grid(True)\n",
    "\n",
    "    # Plot 4: τ(t)\n",
    "    axes[1, 1].plot(coord_time, proper_time, color='gold')\n",
    "    axes[1, 1].set_title('Proper Time vs. Coordinate Time', fontsize=14)\n",
    "    axes[1, 1].set_xlabel('Coordinate Time (t) [M]', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Proper Time (τ) [M]', fontsize=12)\n",
    "    axes[1, 1].grid(True)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99de9c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_radius_vs_time(\n",
    "    project_dir: str = \"project/mass_integrator\",\n",
    "    input_filename: str = \"massive_particle_path.txt\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads trajectory data and plots the particle's radial distance (r)\n",
    "    as a function of coordinate time (t) to validate circularity.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Radius vs. Time Validation Plot ---\")\n",
    "    \n",
    "    full_path = os.path.join(project_dir, input_filename)\n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"ERROR: Trajectory file not found at '{full_path}'\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        data = np.loadtxt(full_path, skiprows=1)\n",
    "        coord_time = data[:, 1]\n",
    "        x_coords = data[:, 2]\n",
    "        y_coords = data[:, 3]\n",
    "        z_coords = data[:, 4]\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load data. Exception: {e}\")\n",
    "        return\n",
    "\n",
    "    # Calculate the radius at each time step\n",
    "    radius = np.sqrt(x_coords**2 + y_coords**2 + z_coords**2)\n",
    "    \n",
    "    # Calculate statistics on the radius\n",
    "    mean_radius = np.mean(radius)\n",
    "    min_radius = np.min(radius)\n",
    "    max_radius = np.max(radius)\n",
    "    percent_variation = 100 * (max_radius - min_radius) / mean_radius\n",
    "\n",
    "    print(f\"Radius Statistics:\")\n",
    "    print(f\"  Mean Radius: {mean_radius:.6f} M\")\n",
    "    print(f\"  Min Radius:  {min_radius:.6f} M\")\n",
    "    print(f\"  Max Radius:  {max_radius:.6f} M\")\n",
    "    print(f\"  Total Variation: {percent_variation:.4f}%\")\n",
    "\n",
    "    # Create the plot\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.plot(coord_time, radius, label='Particle Radius r(t)', color='cyan')\n",
    "    \n",
    "    # Add lines for mean, min, and max to visualize the variation\n",
    "    plt.axhline(mean_radius, color='lime', linestyle='--', label=f'Mean r = {mean_radius:.4f}')\n",
    "    \n",
    "    plt.title('Validation: Particle Radius vs. Coordinate Time', fontsize=16)\n",
    "    plt.xlabel('Coordinate Time (t) [M]', fontsize=12)\n",
    "    plt.ylabel('Radius (r) [M]', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Use a \"tight\" y-axis to emphasize any small variations\n",
    "    plt.ylim(min_radius * 0.999, max_radius * 1.001)\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import linregress\n",
    "\n",
    "def plot_precession_validation(\n",
    "    project_dir: str = \"project/mass_integrator\",\n",
    "    input_filename: str = \"massive_particle_path.txt\",\n",
    "    M_scale: float = 1.0,\n",
    "    a_spin: float = 0.9,\n",
    "    r_initial: float = 10.0\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads trajectory data and validates the orbital precession rate against\n",
    "    the theoretical Lense-Thirring formula.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Precession Validation Plot ---\")\n",
    "    \n",
    "    full_path = os.path.join(project_dir, input_filename)\n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"ERROR: Trajectory file not found at '{full_path}'\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        data = np.loadtxt(full_path, skiprows=1)\n",
    "        coord_time = data[:, 1]\n",
    "        x_coords = data[:, 2]\n",
    "        y_coords = data[:, 3]\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load data. Exception: {e}\")\n",
    "        return\n",
    "\n",
    "    # Calculate the azimuthal angle phi at each time step\n",
    "    phi = np.arctan2(y_coords, x_coords)\n",
    "    \n",
    "    # The angle will wrap around from +pi to -pi. We need to unwrap it.\n",
    "    phi_unwrapped = np.unwrap(phi)\n",
    "\n",
    "    # --- Theoretical Calculation ---\n",
    "    r = r_initial\n",
    "    Omega_K = (M_scale**0.5) / (r**1.5 + a_spin * M_scale**0.5)\n",
    "    Omega_LT = (2 * M_scale * a_spin) / (r**3)\n",
    "    Omega_phi_theory = Omega_K + Omega_LT\n",
    "    \n",
    "    # --- Measurement from Simulation Data ---\n",
    "    # Perform a linear regression to find the slope of phi(t)\n",
    "    regression = linregress(coord_time, phi_unwrapped)\n",
    "    Omega_phi_measured = regression.slope\n",
    "    \n",
    "    percent_error = 100 * abs(Omega_phi_measured - Omega_phi_theory) / Omega_phi_theory\n",
    "\n",
    "    print(\"Precession Rate (dφ/dt) Validation:\")\n",
    "    print(f\"  Theoretical Ω_φ: {Omega_phi_theory:.6f} rad/M\")\n",
    "    print(f\"  Measured Ω_φ (from data): {Omega_phi_measured:.6f} rad/M\")\n",
    "    print(f\"  Relative Error: {percent_error:.4f}%\")\n",
    "\n",
    "    # --- Create the Plot ---\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.plot(coord_time, phi_unwrapped, label='Measured φ(t) from Simulation', color='cyan', lw=2)\n",
    "    plt.plot(coord_time, Omega_phi_theory * coord_time, label=f'Theoretical φ(t) (slope={Omega_phi_theory:.4f})', color='lime', linestyle='--', lw=2)\n",
    "    \n",
    "    plt.title('Validation: Orbital Precession (Frame-Dragging)', fontsize=16)\n",
    "    plt.xlabel('Coordinate Time (t) [M]', fontsize=12)\n",
    "    plt.ylabel('Azimuthal Angle (φ) [radians]', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216be7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def visualize_disk_snapshot(\n",
    "    project_dir: str = \"project/mass_integrator\",\n",
    "    output_folder: str = \"output\",\n",
    "    snapshot_index: int = -1, # -1 means the last available snapshot\n",
    "    M_scale: float = 1.0,\n",
    "    a_spin: float = 0.9\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads a specific mass blueprint snapshot file, performs sanity checks,\n",
    "    and generates a 3D plot of the particle disk.\n",
    "    \"\"\"\n",
    "    print(\"--- Visualizing Mass Blueprint Snapshot ---\")\n",
    "    \n",
    "    # --- 1. Find and Load the Snapshot File ---\n",
    "    snapshot_dir = os.path.join(project_dir, output_folder)\n",
    "    if not os.path.isdir(snapshot_dir):\n",
    "        print(f\"ERROR: Snapshot directory not found at '{snapshot_dir}'\")\n",
    "        return\n",
    "\n",
    "    # Find all blueprint files and sort them\n",
    "    snapshot_files = sorted(glob.glob(os.path.join(snapshot_dir, \"mass_blueprint_t_*.bin\")))\n",
    "    \n",
    "    if not snapshot_files:\n",
    "        print(f\"ERROR: No snapshot .bin files found in '{snapshot_dir}'\")\n",
    "        return\n",
    "\n",
    "    if snapshot_index == -1:\n",
    "        # Select the last file\n",
    "        snapshot_to_load = snapshot_files[-1]\n",
    "    elif snapshot_index < len(snapshot_files):\n",
    "        snapshot_to_load = snapshot_files[snapshot_index]\n",
    "    else:\n",
    "        print(f\"ERROR: Snapshot index {snapshot_index} is out of bounds. Only {len(snapshot_files)} snapshots exist.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading snapshot file: '{snapshot_to_load}'\")\n",
    "\n",
    "    # Define the data type for a single record in the binary file\n",
    "    # Format: int (id), double (x), double (y), double (z), double (ux), double (uy), double (uz)\n",
    "    snapshot_dtype = np.dtype([\n",
    "        ('id', np.int32),\n",
    "        ('pos', 'f8', (3,)), # 3 doubles for position\n",
    "        ('u_spatial', 'f8', (3,)) # 3 doubles for spatial 4-velocity\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        data = np.fromfile(snapshot_to_load, dtype=snapshot_dtype)\n",
    "        num_particles = len(data)\n",
    "        print(f\"Successfully loaded data for {num_particles} particles.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load or parse the data file '{snapshot_to_load}'.\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Perform Sanity Checks ---\n",
    "    positions = data['pos']\n",
    "    velocities = data['u_spatial']\n",
    "    \n",
    "    radii = np.sqrt(positions[:, 0]**2 + positions[:, 1]**2)\n",
    "    speeds = np.sqrt(velocities[:, 0]**2 + velocities[:, 1]**2 + velocities[:, 2]**2)\n",
    "\n",
    "    print(\"\\n--- Data Sanity Checks ---\")\n",
    "    print(f\"  Particle count: {num_particles}\")\n",
    "    print(f\"  Mean radius: {np.mean(radii):.3f} M (should be between disk_r_min and disk_r_max)\")\n",
    "    print(f\"  Mean spatial 4-velocity magnitude: {np.mean(speeds):.3f}\")\n",
    "    print(f\"  Max z-coordinate: {np.max(np.abs(positions[:, 2])):.2e} (should be close to zero)\")\n",
    "    \n",
    "    if np.any(np.isnan(positions)) or np.any(np.isnan(velocities)):\n",
    "        nan_count = np.count_nonzero(np.isnan(data['pos'][:,0]))\n",
    "        print(f\"  WARNING: Found {nan_count} terminated (NaN) particles in this snapshot.\")\n",
    "    \n",
    "    # --- 3. Create the 3D Plot ---\n",
    "    plt.style.use('dark_background')\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot a subset of particles to avoid cluttering the plot\n",
    "    num_to_plot = min(num_particles, 2000)\n",
    "    plot_indices = np.random.choice(num_particles, num_to_plot, replace=False)\n",
    "    \n",
    "    # Use color to represent the radial position of the particles\n",
    "    colors = radii[plot_indices]\n",
    "    sc = ax.scatter(positions[plot_indices, 0], positions[plot_indices, 1], positions[plot_indices, 2], \n",
    "                    c=colors, cmap='plasma', s=5, label='Disk Particles')\n",
    "    \n",
    "    # --- Plot the black hole's event horizon ---\n",
    "    r_horizon = M_scale * (1 + np.sqrt(1 - a_spin**2))\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "    x_bh = r_horizon * np.outer(np.cos(u), np.sin(v))\n",
    "    y_bh = r_horizon * np.outer(np.sin(u), np.sin(v))\n",
    "    z_bh = r_horizon * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "    ax.plot_surface(x_bh, y_bh, z_bh, color='black', alpha=0.9, rstride=4, cstride=4)\n",
    "    ax.plot_wireframe(x_bh, y_bh, z_bh, color='dimgrey', alpha=0.2, rstride=10, cstride=10)\n",
    "\n",
    "    # --- Customize the plot ---\n",
    "    ax.set_xlabel('X (M)', fontsize=12, labelpad=10)\n",
    "    ax.set_ylabel('Y (M)', fontsize=12, labelpad=10)\n",
    "    ax.set_zlabel('Z (M)', fontsize=12, labelpad=10)\n",
    "    \n",
    "    max_radius_plot = np.max(radii) * 1.1\n",
    "    ax.set_xlim(-max_radius_plot, max_radius_plot)\n",
    "    ax.set_ylim(-max_radius_plot, max_radius_plot)\n",
    "    ax.set_zlim(-max_radius_plot/2, max_radius_plot/2) # Exaggerate z-axis if needed\n",
    "\n",
    "    ax.set_title(f\"Accretion Disk Snapshot from {os.path.basename(snapshot_to_load)}\", fontsize=16)\n",
    "    fig.colorbar(sc, ax=ax, shrink=0.6, aspect=10, label='Particle Radius (M)')\n",
    "    ax.view_init(elev=45., azim=45)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad4558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def visualize_disk_and_trajectories(\n",
    "    project_dir: str = \"project/mass_integrator\",\n",
    "    output_folder: str = \"output\",\n",
    "    M_scale: float = 1.0,\n",
    "    a_spin: float = 0.9,\n",
    "    num_trajectories_to_plot: int = 3\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads ALL mass blueprint snapshots, plots the final state of the disk,\n",
    "    and overlays the full trajectories of a few sample particles.\n",
    "    \"\"\"\n",
    "    print(\"--- Visualizing Full Disk Evolution and Sample Trajectories ---\")\n",
    "    \n",
    "    # --- 1. Find and Load ALL Snapshot Files ---\n",
    "    snapshot_dir = os.path.join(project_dir, output_folder)\n",
    "    if not os.path.isdir(snapshot_dir):\n",
    "        print(f\"ERROR: Snapshot directory not found at '{snapshot_dir}'\")\n",
    "        return\n",
    "\n",
    "    snapshot_files = sorted(glob.glob(os.path.join(snapshot_dir, \"mass_blueprint_t_*.bin\")))\n",
    "    if not snapshot_files:\n",
    "        print(f\"ERROR: No snapshot .bin files found in '{snapshot_dir}'\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Found {len(snapshot_files)} snapshot files to process.\")\n",
    "\n",
    "    # Define the data type for a single record in the binary file\n",
    "    snapshot_dtype = np.dtype([\n",
    "        ('id', np.int32),\n",
    "        ('pos', 'f8', (3,)),\n",
    "        ('u_spatial', 'f8', (3,))\n",
    "    ])\n",
    "\n",
    "    # --- 2. Read all data and track specific particles ---\n",
    "    all_particle_data = {} # Dictionary to store trajectories: {id: [[x,y,z], [x,y,z], ...]}\n",
    "    \n",
    "    for snapshot_file in snapshot_files:\n",
    "        try:\n",
    "            data = np.fromfile(snapshot_file, dtype=snapshot_dtype)\n",
    "            for particle in data:\n",
    "                p_id = particle['id']\n",
    "                p_pos = particle['pos']\n",
    "                if p_id not in all_particle_data:\n",
    "                    all_particle_data[p_id] = []\n",
    "                all_particle_data[p_id].append(p_pos)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not read or parse {snapshot_file}. Skipping. Error: {e}\")\n",
    "            continue\n",
    "            \n",
    "    if not all_particle_data:\n",
    "        print(\"ERROR: No valid particle data could be loaded.\")\n",
    "        return\n",
    "\n",
    "    # --- 3. Prepare data for plotting ---\n",
    "    # Get the final positions of all particles from the last snapshot\n",
    "    final_positions = np.array([traj[-1] for traj in all_particle_data.values()])\n",
    "    final_radii = np.sqrt(final_positions[:, 0]**2 + final_positions[:, 1]**2)\n",
    "\n",
    "    # Select a few particle IDs to plot their full trajectories\n",
    "    # We'll pick particles from the inner, middle, and outer parts of the disk.\n",
    "    all_ids = sorted(list(all_particle_data.keys()))\n",
    "    num_particles = len(all_ids)\n",
    "    trajectory_indices = np.linspace(0, num_particles - 1, num_trajectories_to_plot, dtype=int)\n",
    "    trajectory_ids_to_plot = [all_ids[i] for i in trajectory_indices]\n",
    "    \n",
    "    print(f\"\\nPlotting full trajectories for particle IDs: {trajectory_ids_to_plot}\")\n",
    "\n",
    "    # --- 4. Create the 3D Plot ---\n",
    "    plt.style.use('dark_background')\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot the final state of the disk as a scatter plot\n",
    "    num_to_plot = min(len(final_positions), 4000)\n",
    "    plot_indices = np.random.choice(len(final_positions), num_to_plot, replace=False)\n",
    "    colors = final_radii[plot_indices]\n",
    "    ax.scatter(final_positions[plot_indices, 0], final_positions[plot_indices, 1], final_positions[plot_indices, 2], \n",
    "               c=colors, cmap='plasma', s=2, alpha=0.5, label='Disk Particles (Final State)')\n",
    "\n",
    "    # Plot the full trajectories for the selected particles\n",
    "    trajectory_colors = plt.cm.viridis(np.linspace(0, 1, num_trajectories_to_plot))\n",
    "    for i, p_id in enumerate(trajectory_ids_to_plot):\n",
    "        trajectory = np.array(all_particle_data[p_id])\n",
    "        ax.plot(trajectory[:, 0], trajectory[:, 1], trajectory[:, 2], \n",
    "                color=trajectory_colors[i], lw=2.5, \n",
    "                label=f'Trajectory ID {p_id}')\n",
    "\n",
    "    # --- Plot the black hole's event horizon ---\n",
    "    r_horizon = M_scale * (1 + np.sqrt(1 - a_spin**2))\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "    x_bh = r_horizon * np.outer(np.cos(u), np.sin(v))\n",
    "    y_bh = r_horizon * np.outer(np.sin(u), np.sin(v))\n",
    "    z_bh = r_horizon * np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "    ax.plot_surface(x_bh, y_bh, z_bh, color='black', alpha=0.9, rstride=4, cstride=4)\n",
    "    ax.plot_wireframe(x_bh, y_bh, z_bh, color='dimgrey', alpha=0.2, rstride=10, cstride=10)\n",
    "\n",
    "    # --- Customize the plot ---\n",
    "    ax.set_xlabel('X (M)', fontsize=12, labelpad=10)\n",
    "    ax.set_ylabel('Y (M)', fontsize=12, labelpad=10)\n",
    "    ax.set_zlabel('Z (M)', fontsize=12, labelpad=10)\n",
    "    \n",
    "    max_radius_plot = np.max(final_radii) * 1.1\n",
    "    ax.set_xlim(-max_radius_plot, max_radius_plot)\n",
    "    ax.set_ylim(-max_radius_plot, max_radius_plot)\n",
    "    ax.set_zlim(-max_radius_plot/4, max_radius_plot/4)\n",
    "\n",
    "    ax.set_title(f\"Accretion Disk Evolution and Sample Trajectories\", fontsize=16)\n",
    "    ax.legend()\n",
    "    ax.view_init(elev=60., azim=30)\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f265c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_apsidal_precession_validation(\n",
    "    project_dir: str = \"project/mass_integrator\",\n",
    "    input_filename: str = \"massive_particle_path.txt\",\n",
    "    M_scale: float = 1.0,\n",
    "    a_spin: float = 0.9\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Reads trajectory data and validates the apsidal precession rate against\n",
    "    the theoretical GR formula for nearly circular orbits.\n",
    "    \"\"\"\n",
    "    print(\"--- Generating Apsidal Precession Validation Plot ---\")\n",
    "    \n",
    "    full_path = os.path.join(project_dir, input_filename)\n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"ERROR: Trajectory file not found at '{full_path}'\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        data = np.loadtxt(full_path, skiprows=1)\n",
    "        x_coords = data[:, 2]\n",
    "        y_coords = data[:, 3]\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load data. Exception: {e}\")\n",
    "        return\n",
    "\n",
    "    radius = np.sqrt(x_coords**2 + y_coords**2)\n",
    "    phi = np.unwrap(np.arctan2(y_coords, x_coords))\n",
    "    \n",
    "    # Find the angles where the particle is at periapsis (minimum radius)\n",
    "    # We find indices where the radius is a local minimum\n",
    "    periapsis_indices = (np.r_[True, radius[1:] < radius[:-1]] & np.r_[radius[:-1] < radius[1:], True]).nonzero()[0]\n",
    "    \n",
    "    if len(periapsis_indices) < 2:\n",
    "        print(\"Could not find at least two periapsis points. Cannot calculate precession.\")\n",
    "        return\n",
    "        \n",
    "    # Calculate the measured precession angle per orbit\n",
    "    delta_phi_measured = phi[periapsis_indices[1]] - phi[periapsis_indices[0]]\n",
    "    precession_per_orbit_measured = delta_phi_measured - 2 * np.pi\n",
    "\n",
    "    # --- Theoretical Calculation at the average radius of the orbit ---\n",
    "    r_avg = np.mean(radius)\n",
    "    M = M_scale\n",
    "    a = a_spin\n",
    "    \n",
    "    Omega_phi_theory = (M**0.5) / (r_avg**1.5 + a * M**0.5)\n",
    "    Omega_r_theory_sq = Omega_phi_theory**2 * (1 - (6*M)/r_avg + (8*a*M**0.5)/r_avg**1.5 - (3*a**2)/r_avg**2)\n",
    "    \n",
    "    if Omega_r_theory_sq < 0:\n",
    "        print(\"Theoretical orbit is unstable (Ω_r^2 < 0). Cannot calculate precession.\")\n",
    "        return\n",
    "        \n",
    "    Omega_r_theory = np.sqrt(Omega_r_theory_sq)\n",
    "    \n",
    "    # Precession per unit time\n",
    "    Omega_precession_theory = Omega_phi_theory - Omega_r_theory\n",
    "    \n",
    "    # Period of one radial oscillation\n",
    "    T_r = 2 * np.pi / Omega_r_theory\n",
    "    \n",
    "    # Total precession angle over one radial period\n",
    "    precession_per_orbit_theory = Omega_precession_theory * T_r\n",
    "    \n",
    "    percent_error = 100 * abs(precession_per_orbit_measured - precession_per_orbit_theory) / precession_per_orbit_theory\n",
    "\n",
    "    print(f\"Apsidal Precession Validation (at average radius r={r_avg:.3f} M):\")\n",
    "    print(f\"  Measured precession per orbit:   {precession_per_orbit_measured:.6f} radians\")\n",
    "    print(f\"  Theoretical precession per orbit: {precession_per_orbit_theory:.6f} radians\")\n",
    "    print(f\"  Relative Error: {percent_error:.4f}%\")\n",
    "\n",
    "    # --- Create the Plot (Polar Plot) ---\n",
    "    plt.style.use('dark_background')\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, polar=True)\n",
    "    \n",
    "    ax.plot(phi, radius, color='cyan', label='Particle Orbit')\n",
    "    ax.scatter(phi[periapsis_indices], radius[periapsis_indices], color='lime', s=100, label='Periapsis Points', zorder=5)\n",
    "    \n",
    "    ax.set_title('Validation: Apsidal Precession of a Nearly Circular Orbit', fontsize=16)\n",
    "    ax.set_xlabel('Azimuthal Angle (φ)', fontsize=12)\n",
    "    ax.set_ylabel('Radius (r) [M]', fontsize=12, labelpad=-50)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca5ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_particle_trajectory(\n",
    "    project_dir=\"project/mass_integrator\",\n",
    "    input_filename=\"massive_particle_path.txt\",\n",
    "    M_scale=1.0,\n",
    "    a_spin=0.9\n",
    ")\n",
    "# After running the C code, call this function.\n",
    "plot_trajectory_components()\n",
    "# Call this function after running your C code.\n",
    "plot_radius_vs_time()\n",
    "# --- How to run ---\n",
    "plot_precession_validation()\n",
    "# --- How to run ---\n",
    "plot_apsidal_precession_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c83c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- How to Run This Test ---\n",
    "# 1. Run your C code in PRODUCTION mode (set run_in_debug_mode = false in the .par file).\n",
    "# 2. This will create an 'output' folder with several .bin files.\n",
    "# 3. Call this function. It will automatically find and plot the LAST snapshot.\n",
    "visualize_disk_snapshot()\n",
    "# --- How to Run ---\n",
    "visualize_disk_and_trajectories()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Jupyter notebook)",
   "language": "python",
   "name": "docs-project-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
