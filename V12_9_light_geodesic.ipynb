{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba92b65f",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "# Step 1: Introduction, Core Physics, and Project Goals\n",
    "\n",
    "This notebook is a self-contained tutorial that uses the `nrpy` library to construct a complete C-language project for integrating photon geodesics in curved spacetimes. The resulting C code is a flexible, high-performance ray-tracing engine capable of generating gravitationally lensed images of distant sources as seen by an observer near a black hole.\n",
    "\n",
    "The core of the project is the numerical solution of the geodesic equation, which describes the path of a free-falling particle (or photon) through curved spacetime. The geodesic equation, as detailed on [Wikipedia](https://en.wikipedia.org/wiki/Geodesic_equation), is a second-order ordinary differential equation (ODE) that relates a particle's acceleration to the spacetime curvature, represented by the Christoffel symbols ($\\Gamma^{\\alpha}_{\\mu\\nu}$):\n",
    "\n",
    "$$ \\frac{d^2x^{\\alpha}}{d\\lambda^2} = -\\Gamma^{\\alpha}_{\\mu\\nu} \\frac{dx^{\\mu}}{d\\lambda} \\frac{dx^{\\nu}}{d\\lambda} $$\n",
    "\n",
    "Here, $x^\\alpha = (t, x, y, z)$ are the spacetime coordinates, and $\\lambda$ is the affine parameter, which measures the proper distance along the path for a massive particle or a suitable path parameter for a photon.\n",
    "\n",
    "### The Reverse Ray-Tracing Transformation\n",
    "\n",
    "To render an image of what an observer sees, we must trace the photon's path from the observer's camera *backwards in time* to its source. While we could integrate the geodesic equation with a negative step `dλ < 0`, most ODE solvers are optimized for forward integration with a positive step. To accommodate this, we perform a change of variables on the affine parameter. We define a new parameter, $\\kappa$, that increases as the original parameter, $\\lambda$, decreases:\n",
    "\n",
    "$$ \\kappa = -\\lambda \\implies d\\kappa = -d\\lambda \\implies \\frac{d}{d\\lambda} = -\\frac{d}{d\\kappa} $$\n",
    "\n",
    "We now substitute this transformation directly into the second-order geodesic equation:\n",
    "\n",
    "$$ \\frac{d}{d\\lambda}\\left(\\frac{dx^{\\alpha}}{d\\lambda}\\right) = -\\Gamma^{\\alpha}_{\\mu\\nu} \\frac{dx^{\\mu}}{d\\lambda} \\frac{dx^{\\nu}}{d\\lambda} $$\n",
    "\n",
    "Applying the chain rule, $\\frac{d}{d\\lambda} = -\\frac{d}{d\\kappa}$:\n",
    "\n",
    "$$ \\left(-\\frac{d}{d\\kappa}\\right)\\left(-\\frac{dx^{\\alpha}}{d\\kappa}\\right) = -\\Gamma^{\\alpha}_{\\mu\\nu} \\left(-\\frac{dx^{\\mu}}{d\\kappa}\\right) \\left(-\\frac{dx^{\\nu}}{d\\kappa}\\right) $$\n",
    "\n",
    "The negatives on both sides cancel, yielding the reverse-time geodesic equation:\n",
    "\n",
    "$$ \\frac{d^2x^{\\alpha}}{d\\kappa^2} = -\\Gamma^{\\alpha}_{\\mu\\nu} \\frac{dx^{\\mu}}{d\\kappa} \\frac{dx^{\\nu}}{d\\kappa} $$\n",
    "\n",
    "This equation has the same form as the original, but describes the path integrated with respect to $\\kappa$. To solve it numerically, we now decompose this second-order ODE into a system of coupled first-order ODEs. We define the **reverse-time momentum**, $p^\\alpha$, as the 4-velocity with respect to our new parameter $\\kappa$:\n",
    "\n",
    "$$ p^{\\alpha} \\equiv \\frac{dx^{\\alpha}}{d\\kappa} $$\n",
    "\n",
    "This definition immediately gives us our first ODE. We find the second by substituting $p^\\alpha$ into the reverse-time geodesic equation:\n",
    "\n",
    "$$ \\frac{d}{d\\kappa}\\left(\\frac{dx^{\\alpha}}{d\\kappa}\\right) = -\\Gamma^{\\alpha}_{\\mu\\nu} \\left(\\frac{dx^{\\mu}}{d\\kappa}\\right) \\left(\\frac{dx^{\\nu}}{d\\kappa}\\right) \\implies \\frac{dp^{\\alpha}}{d\\kappa} = -\\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} $$\n",
    "\n",
    "This gives us the final set of ODEs that our C code will solve. We also add a third ODE to track the total proper distance traveled by the photon along its spatial path, using the spatial part of the metric $\\gamma_{ij}$:\n",
    "\n",
    "1.  **Position ODE**: $\\frac{dx^{\\alpha}}{d\\kappa} = p^{\\alpha}$\n",
    "2.  **Momentum ODE**: $\\frac{dp^{\\alpha}}{d\\kappa} = -\\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu}$\n",
    "3.  **Path Length ODE**: $\\frac{dL}{d\\kappa} = \\sqrt{\\gamma_{ij} \\frac{dx^i}{d\\kappa} \\frac{dx^j}{d\\kappa}} = \\sqrt{\\gamma_{ij}p^{i}p^{j}}$\n",
    "\n",
    "### Initial Conditions\n",
    "\n",
    "The initial value of the reverse-time momentum, $p^\\alpha_{\\text{initial}}$, determines the starting direction of the ray traced from the camera. It is physically equivalent to the *negative* of the final momentum of a photon that started at a distant source and ended its journey at the camera. If we denote the physical, forward-time 4-velocity as $k^\\alpha = dx^\\alpha/d\\lambda$, then:\n",
    "\n",
    "$$ p^\\alpha_{\\text{initial}} = \\left(\\frac{dx^\\alpha}{d\\kappa}\\right)_{\\text{initial}} = -\\left(\\frac{dx^\\alpha}{d\\lambda}\\right)_{\\text{final}} = -k^\\alpha_{\\text{final}} $$\n",
    "\n",
    "This relationship is key: setting the initial conditions for our reverse-time integration is equivalent to choosing the final momentum of a physically forward-propagating photon arriving at the camera.\n",
    "\n",
    "This notebook follows a modular, single-responsibility design pattern. It uses the `nrpy` library to first define the underlying physics symbolically, and then automatically generates a series of interoperable C functions, each with a specific job. This makes the final C project clear, efficient, and easily extensible.\n",
    "\n",
    "**Notebook Status:** <font color='green'><b>Validated</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bac0cb",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "This notebook is organized into a series of logical steps that build the complete C project from the ground up. Each step focuses on a specific aspect of the architecture, from pure mathematics to the final compiled executable.\n",
    "\n",
    "**Part 1: Introduction & Project Setup**\n",
    "*   [Step 1: Introduction, Core Physics, and Project Goals](#introduction)\n",
    "*   [Step 2: Project Initialization and Parameter Definition](#initialize)\n",
    "\n",
    "**Part 2: The Symbolic Core (The \"Recipes\")**\n",
    "*   [Step 3: The Symbolic Core - Defining the Physics with `nrpy` and `sympy`](#symbolic_core)\n",
    "    *   [3.a: Symbolic Recipe for Metric Tensor Derivatives](#deriv_g4DD)\n",
    "    *   [3.b: Symbolic Recipe for Christoffel Symbols](#four_connections)\n",
    "    *   [3.c: Symbolic Recipe for the Geodesic Momentum ODE](#geodesic_mom_rhs)\n",
    "    *   [3.d: Symbolic Recipe for the Geodesic Position ODE](#geodesic_pos_rhs)\n",
    "    *   [3.e: Symbolic Recipe for the Path Length ODE](#proper_len_rhs)\n",
    "    *   [3.f: Symbolic Recipe for the Null Condition (Calculating p⁰)](#geodesic_mom0_calc)\n",
    "    *   [3.g: Symbolic Recipes for Conserved Quantities (E, L, Q)](#conserved_quantities)\n",
    "    *   [3.h: Symbolic Recipes for Numerical Metrics](#numerical_recipes)\n",
    "\n",
    "**Part 3: Spacetime Definitions & Symbolic Execution**\n",
    "*   [Step 4: Spacetime Definitions (Analytic Metrics)](#spacetime_definition)\n",
    "*   [Step 5: Symbolic Workflow Execution](#symbolic_execution)\n",
    "\n",
    "**Part 4: C Code Generation**\n",
    "*   [Step 6: C Code Generation - Physics Engines and Workers](#generate_c_engines)\n",
    "    *   [6.A: Tier 4 - Low-Level Workers, Helpers, and Dispatchers](#tier_4_workers)\n",
    "    *   [6.B: Tier 3 - Core Subsystems & Engines](#tier_3_engines)\n",
    "    *   [6.C: Tiers 2 & 1 - Top-Level Orchestrators](#tiers_1_2_orchestrators)\n",
    "\n",
    "**Part 5: Project Assembly and Compilation**\n",
    "*   [Step 7: Project Assembly and Compilation](#assemble_project)\n",
    "    *   [7.a: Registering Core C Data Structures](#register_structs)\n",
    "    *   [7.b: Final Build Command](#final_build)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c0d30",
   "metadata": {},
   "source": [
    "<a id='initialize'></a>\n",
    "# Step 2: Project Initialization and Parameter Definition\n",
    "\n",
    "This cell sets up the foundational elements for our entire project. It performs three key tasks:\n",
    "\n",
    "1.  **Import Libraries**: We import necessary modules from standard Python libraries (`os`, `shutil`, `sympy`) and the core components of `nrpy`. The `nrpy` imports provide tools for C function registration, C code generation, parameter handling, and infrastructure management.\n",
    "\n",
    "2.  **Directory Management**: A clean output directory, `project/photon_geodesic_integrator/`, is created to store the generated C code, ensuring a fresh build every time the notebook is run.\n",
    "\n",
    "3.  **Physical and Runtime Parameter Definition**: We define the many parameters that control the simulation using `nrpy`'s parameter management system. This is the central mechanism for defining a runtime parameter that will be accessible in the generated C code. The `nrpy` build system uses this registry of parameters to automatically construct C data structures, a default parameter file, and a robust command-line parser.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.params.set_parval_from_str(par_name, value)`**:\n",
    "    *   **Source File**: `nrpy/params.py`\n",
    "    *   **Description**: Sets the value of a core `nrpy` parameter. Here, it is used to specify that we are using the `BHaH` (BlackHoles@Home) C code generation infrastructure, which governs how files are organized and how the `Makefile` is constructed.\n",
    "\n",
    "*   **`nrpy.params.register_CodeParameter(c_type, module, name, default_value, **kwargs)`**:\n",
    "    *   **Source File**: `nrpy/params.py`\n",
    "    *   **Description**: This is the primary function for registering a C-level parameter. It creates a parameter object that holds all its properties and stores it in a global registry.\n",
    "    *   **Key Inputs**:\n",
    "        *   `c_type`: The data type of the parameter in the C code (e.g., `\"REAL\"`, `\"int\"`).\n",
    "        *   `module`: The name of the Python module where the parameter is defined (usually `__name__`).\n",
    "        *   `name`: The C variable name for the parameter.\n",
    "        *   `default_value`: The default value for the parameter.\n",
    "    *   **Key Keyword Arguments (`kwargs`)**:\n",
    "        *   `commondata=True`: Specifies that the parameter is \"common\" to the entire simulation (e.g., black hole mass `M_scale`). It will be stored in the `commondata_struct` in the generated C code. If `False`, it's stored in the grid-specific `params_struct`.\n",
    "        *   `add_to_parfile=True`: Instructs the build system to add an entry for this parameter to a default parameter file, making it easy to configure at runtime.\n",
    "        *   `add_to_set_CodeParameters_h=True`: This is a crucial flag that enables the \"automatic unpacking\" mechanism. It tells `nrpy` to add an entry for the parameter to the `set_CodeParameters.h` convenience header. Any C function registered with `include_CodeParameters_h=True` will get a local `const REAL` variable with the same name as the parameter, making the C code clean and readable. This is handled by the `nrpy.infrastructures.BHaH.CodeParameters` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f07e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V12_9_light_geodesic.ipynb\n",
    "# In cell 33f07e1c (REVISED AND CORRECTED)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sympy as sp\n",
    "\n",
    "# NRPy-related imports for C-code generation\n",
    "import nrpy.c_function as cfc\n",
    "import nrpy.c_codegen as ccg\n",
    "import nrpy.params as par\n",
    "import nrpy.indexedexp as ixp\n",
    "import nrpy.infrastructures.BHaH.BHaH_defines_h as Bdefines_h\n",
    "import nrpy.infrastructures.BHaH.Makefile_helpers as Makefile\n",
    "from nrpy.infrastructures.BHaH import cmdline_input_and_parfiles\n",
    "import nrpy.helpers.generic as gh\n",
    "import nrpy.infrastructures.BHaH.CodeParameters as CPs\n",
    "\n",
    "\n",
    "# Set project name and clean the output directory\n",
    "project_name = \"photon_geodesic_integrator\"\n",
    "project_dir = os.path.join(\"project\", project_name)\n",
    "shutil.rmtree(project_dir, ignore_errors=True)\n",
    "\n",
    "# Set NRPy parameters for the BHaH infrastructure\n",
    "par.set_parval_from_str(\"Infrastructure\", \"BHaH\")\n",
    "\n",
    "#\n",
    "# ==============================================================================\n",
    "#  BEGIN PARAMETER DEFINITIONS\n",
    "# ==============================================================================\n",
    "#\n",
    "# All runtime parameters for the C code are defined here using nrpy's\n",
    "# CodeParameter object. This centralizes the definitions and allows the build\n",
    "# system to automatically generate parameter files and command-line parsers.\n",
    "#\n",
    "\n",
    "# --- 1. Core Physics & Spacetime Parameters ---\n",
    "# These parameters define the gravitational source and the metric to be used.\n",
    "# M_scale: Mass of the black hole. All lengths are measured in units of M.\n",
    "# a_spin:  Dimensionless spin parameter of the black hole. Must be in the range 0 <= a < 1.\n",
    "M_scale, a_spin = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"M_scale\", \"a_spin\"],\n",
    "    [1.0, 0.0],\n",
    "    add_to_parfile=True, commondata=True, add_to_set_CodeParameters_h=True\n",
    ")\n",
    "# metric_choice: Metric to use. 0: Kerr-Schild (unified Kerr/Schwarzschild). 1: Standard Schwarzschild (for validation).\n",
    "_ = par.register_CodeParameter(\n",
    "    \"int\", __name__, \"metric_choice\", 0, add_to_parfile=True, commondata=True\n",
    ")\n",
    "\n",
    "# --- 2. Pipeline & Debugging Controls ---\n",
    "# These boolean flags control the overall behavior of the simulation, switching\n",
    "# between different integration pipelines and enabling validation features.\n",
    "# use_numerical_pipeline: If true, use the numerical metric pipeline (placeholder); otherwise, use the analytic pipeline.\n",
    "# perform_conservation_check: If true, compute conserved quantities (E, L, Q) at the end of integration for validation.\n",
    "# debug_mode: If true, trace a single photon and write its full trajectory to a text file for debugging.\n",
    "_ = par.register_CodeParameters(\n",
    "    \"bool\", __name__,\n",
    "    [\"use_numerical_pipeline\", \"perform_conservation_check\", \"debug_mode\"],\n",
    "    False,  # Assign False to all three\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "\n",
    "# --- 3. Camera & Image Plane (Window) Parameters ---\n",
    "# These parameters define the virtual camera's position, orientation, and field of view.\n",
    "# camera_pos_[x,y,z]: Cartesian coordinates of the camera's position in units of M.\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"camera_pos_x\", \"camera_pos_y\", \"camera_pos_z\"],\n",
    "    [0.0, 0.0, 51.0], add_to_parfile=True, commondata=True\n",
    ")\n",
    "# window_center_[x,y,z]: Cartesian coordinates of the point the camera is looking at. This defines the center of the image.\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"window_center_x\", \"window_center_y\", \"window_center_z\"],\n",
    "    [0.0, 0.0, 50.0], add_to_parfile=True, commondata=True\n",
    ")\n",
    "# window_up_vec_[x,y,z]: A vector defining the 'up' direction for the camera, establishing the image's orientation.\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"window_up_vec_x\", \"window_up_vec_y\", \"window_up_vec_z\"],\n",
    "    [0.0, 1.0, 0.0], add_to_parfile=True, commondata=True\n",
    ")\n",
    "# window_size: The side length of the square image plane ('window') in units of M.\n",
    "window_size = par.register_CodeParameter(\n",
    "    \"REAL\", __name__, \"window_size\", 1.5,\n",
    "    add_to_parfile=True, commondata=True, add_to_set_CodeParameters_h=True\n",
    ")\n",
    "# scan_density: The resolution of the final image in pixels (scan_density x scan_density).\n",
    "_ = par.register_CodeParameter(\n",
    "    \"int\", __name__, \"scan_density\", 512,\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "\n",
    "# --- 4. Fallback Source Plane Parameters ---\n",
    "# Defines a fallback plane for rays that do not intersect the accretion disk.\n",
    "# This acts as a simplified \"celestial sphere\".\n",
    "# source_plane_normal_[x,y,z]: The normal vector defining the orientation of the source plane.\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"source_plane_normal_x\", \"source_plane_normal_y\", \"source_plane_normal_z\"],\n",
    "    [0.0, 0.0, 1.0], add_to_parfile=True, commondata=True\n",
    ")\n",
    "# source_plane_center_[x,y,z]: A point (x,y,z) that lies on the source plane.\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"source_plane_center_x\", \"source_plane_center_y\", \"source_plane_center_z\"],\n",
    "    0.0, add_to_parfile=True, commondata=True\n",
    ")\n",
    "# source_up_vec_[x,y,z]: A vector defining the 'up' direction on the source plane, for texturing.\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"source_up_vec_x\", \"source_up_vec_y\", \"source_up_vec_z\"],\n",
    "    [0.0, 1.0, 0.0], add_to_parfile=True, commondata=True\n",
    ")\n",
    "# source_r_min, source_r_max: The inner and outer radii of the 'glowing' annulus on the source plane.\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"source_r_min\", \"source_r_max\"],\n",
    "    [6.0, 25.0], add_to_parfile=True, commondata=True\n",
    ")\n",
    "\n",
    "# --- 5. Integration & Termination Conditions ---\n",
    "# These parameters control the ODE integration process and define when a ray's path should be terminated.\n",
    "# t_start: Initial coordinate time for the backward-in-time integration.\n",
    "# t_integration_max: Maximum coordinate time to integrate before terminating a ray as 'failed'.\n",
    "# r_escape: Radius at which a ray is considered to have escaped to the celestial sphere.\n",
    "# p_t_max: Maximum value for p_t (related to energy); a sanity check for runaway rays.\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"t_start\", \"t_integration_max\", \"r_escape\", \"p_t_max\"],\n",
    "    [2000.0, 10000.0, 1500.0, 1000.0],\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "\n",
    "# --- 6. Accretion Disk Intersection Parameters ---\n",
    "# These parameters are used to find intersections between photons and the physical accretion disk.\n",
    "# mass_snapshot_every_t: The time interval between accretion disk snapshots from the mass_integrator.\n",
    "# delta_r_max: The maximum distance between a photon and a disk particle to score an intersection.\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"mass_snapshot_every_t\", \"delta_r_max\"],\n",
    "    [10.0, 2.0],\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "# disk_bounds_[x,y,z]_[min,max]: Axis-aligned bounding box for the accretion disk. A fast check before the k-d tree search.\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"disk_bounds_x_min\", \"disk_bounds_x_max\", \"disk_bounds_y_min\", \"disk_bounds_y_max\", \"disk_bounds_z_min\", \"disk_bounds_z_max\"],\n",
    "    [-26.0, 26.0, -26.0, 26.0, -1.0, 1.0],\n",
    "    commondata=True, add_to_parfile=True\n",
    ")\n",
    "\n",
    "# --- 7. Time Slot Manager Parameters ---\n",
    "# These parameters configure the \"Iterative Time Slotting\" algorithm for efficient batch processing.\n",
    "# slot_manager_t_min: The earliest coordinate time the slot manager will handle.\n",
    "# slot_manager_delta_t: The width of each time slot. A smaller value uses more memory but can improve batching efficiency.\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"slot_manager_t_min\", \"slot_manager_delta_t\"],\n",
    "    [-100.0, 0.1],\n",
    "    add_to_parfile=True, commondata=True\n",
    ")\n",
    "\n",
    "# --- 8. Adaptive RKF45 ODE Solver Parameters ---\n",
    "# These parameters control the behavior of the custom-built Runge-Kutta-Fehlberg 4(5) adaptive integrator.\n",
    "# numerical_initial_h: Initial guess for the step size (h) in affine parameter.\n",
    "# rkf45_error_tolerance: Relative error tolerance (rtol) for the adaptive step-size control.\n",
    "# rkf45_absolute_error_tolerance: Absolute error tolerance (atol) for the adaptive step-size control.\n",
    "# rkf45_h_min: Minimum allowed step size (h_min).\n",
    "# rkf45_h_max: Maximum allowed step size (h_max).\n",
    "# rkf45_safety_factor: Safety factor for step-size updates (typically ~0.9).\n",
    "_ = par.register_CodeParameters(\n",
    "    \"REAL\", __name__,\n",
    "    [\"numerical_initial_h\", \"rkf45_error_tolerance\", \"rkf45_absolute_error_tolerance\", \"rkf45_h_min\", \"rkf45_h_max\", \"rkf45_safety_factor\"],\n",
    "    [1.0, 1e-8, 1e-8, 1e-10, 10.0, 0.9],\n",
    "    commondata=True, add_to_parfile=True\n",
    ")\n",
    "# rkf45_max_retries: Maximum number of times to retry a rejected step with a smaller step size before failing.\n",
    "_ = par.register_CodeParameter(\n",
    "    \"int\", __name__, \"rkf45_max_retries\", 10,\n",
    "    commondata=True, add_to_parfile=True\n",
    ")\n",
    "\n",
    "# --- 9. Adaptive Window Grid Parameters (Optional Feature) ---\n",
    "# Parameters for an alternative, non-Cartesian grid on the image plane.\n",
    "# window_grid_type: Type of grid on the window. 0: Standard Cartesian. 1: Log-Polar.\n",
    "# log_polar_num_r: Number of radial bins for the log-polar grid.\n",
    "# log_polar_num_phi: Number of angular bins for the log-polar grid.\n",
    "_ = par.register_CodeParameters(\n",
    "    \"int\", __name__,\n",
    "    [\"window_grid_type\", \"log_polar_num_r\", \"log_polar_num_phi\"],\n",
    "    [0, 512, 1024],\n",
    "    commondata=True, add_to_parfile=True\n",
    ")\n",
    "# log_polar_r_min: Inner radius for the log-polar grid, to avoid the singularity at r=0.\n",
    "_ = par.register_CodeParameter(\n",
    "    \"REAL\", __name__, \"log_polar_r_min\", 0.1,\n",
    "    commondata=True, add_to_parfile=True\n",
    ")\n",
    "\n",
    "#\n",
    "# ==============================================================================\n",
    "#  END PARAMETER DEFINITIONS\n",
    "# ==============================================================================\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa84ac02",
   "metadata": {},
   "source": [
    "<a id='symbolic_core'></a>\n",
    "# Step 3: The Symbolic Core - Defining the Physics with `nrpy` and `sympy`\n",
    "\n",
    "This section is the mathematical heart of the project. Here, we define the pure physics of geodesic motion not as C code, but as symbolic \"recipes\" using Python's `sympy` library. Each Python function in this section takes symbolic `sympy` objects as input (like a metric tensor) and returns new symbolic `sympy` expressions as output (like the Christoffel symbols).\n",
    "\n",
    "This \"symbolic-first\" approach is a core principle of the `nrpy` framework. It offers several major advantages:\n",
    "1.  **Correctness**: By writing the physics in high-level symbolic math, we are much less likely to make subtle programming errors than if we were writing complex C code by hand. The computer handles the tedious algebra.\n",
    "2.  **Efficiency**: Complex calculations (like inverting a 4x4 matrix) are performed symbolically *once* when this notebook is run. The resulting simplified formula is then used to generate highly efficient C code.\n",
    "3.  **Modularity & Reusability**: We create generic recipes that are not tied to a specific spacetime. For example, the recipe for the geodesic equation RHS is valid for *any* metric. We can then plug different metric tensors into this single recipe to generate C code for different spacetimes.\n",
    "\n",
    "The functions in this section will produce global Python variables containing the final symbolic expressions. These variables will be used later in Step 6 to automatically generate the C code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23b659c",
   "metadata": {},
   "source": [
    "<a id='deriv_g4DD'></a>\n",
    "### 3.a: Symbolic Recipe for Metric Tensor Derivatives\n",
    "\n",
    "The first step in calculating the Christoffel symbols is to compute the partial derivatives of the metric tensor, $g_{\\mu\\nu}$. This function, `derivative_g4DD`, takes the symbolic 4x4 metric tensor `g4DD` and a list of the four coordinate symbols `xx` as input.\n",
    "\n",
    "The function iterates through all components to symbolically calculate the partial derivative of each metric component with respect to each coordinate. The resulting quantity, which we can denote using comma notation as $g_{\\mu\\nu,\\alpha}$, is defined as:\n",
    "\n",
    "$$ g_{\\mu\\nu,\\alpha} \\equiv \\frac{\\partial g_{\\mu\\nu}}{\\partial x^{\\alpha}} $$\n",
    "\n",
    "The nested `for` loops in the code directly correspond to the spacetime indices `μ, ν, α` in the physics equation. `sympy`'s built-in `sp.diff()` function is used to perform the symbolic differentiation, and the final result is returned as a rank-3 symbolic tensor.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.zerorank3(dimension)`**:\n",
    "    *   **Source File**: `nrpy/indexedexp.py`\n",
    "    *   **Description**: This function creates a symbolic rank-3 tensor (a Python list of lists of lists) of a specified dimension, with all elements initialized to the `sympy` integer 0. It is used here to create a container for the derivative results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_g4DD(g4DD, xx):\n",
    "    \"\"\"Computes the symbolic first derivatives of the metric tensor.\"\"\"\n",
    "    g4DD_dD = ixp.zerorank3(dimension=4)\n",
    "    for nu in range(4):\n",
    "        for mu in range(4):\n",
    "            for alpha in range(4):\n",
    "                g4DD_dD[nu][mu][alpha] = sp.diff(g4DD[nu][mu], xx[alpha])\n",
    "    return g4DD_dD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79893b7",
   "metadata": {},
   "source": [
    "<a id='four_connections'></a>\n",
    "### 3.b: Symbolic Recipe for Christoffel Symbols (Analytic Metrics)\n",
    "\n",
    "This function implements the core formula for the Christoffel symbols of the second kind, $\\Gamma^{\\delta}_{\\mu\\nu}$. It takes the symbolic metric tensor `g4DD` ($g_{\\mu\\nu}$) and its derivatives `g4DD_dD` ($g_{\\mu\\nu,\\alpha}$) as input. The calculation requires the inverse metric, $g^{\\mu\\nu}$, which is computed using another `nrpy` helper function.\n",
    "\n",
    "The function then applies the well-known formula for the Christoffel symbols. Using the comma notation for partial derivatives, the formula is:\n",
    "\n",
    "$$ \\Gamma^{\\delta}_{\\mu\\nu} = \\frac{1}{2} g^{\\delta\\alpha} \\left( g_{\\nu\\alpha,\\mu} + g_{\\mu\\alpha,\\nu} - g_{\\mu\\nu,\\alpha} \\right) $$\n",
    "\n",
    "The Python `for` loops iterate over the spacetime indices `δ, μ, ν, α` to construct each component of the Christoffel symbol tensor. The summation over the dummy index `α` is performed explicitly. After the summation is complete, the `sp.trigsimp()` function is used to simplify the resulting expression. This trigonometric simplification is highly effective and much faster than a general `sp.simplify()` for the Kerr-Schild metric, which contains trigonometric functions of the coordinates.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.symm_matrix_inverter4x4(g4DD)`**:\n",
    "    *   **Source File**: `nrpy/indexedexp.py`\n",
    "    *   **Description**: This function takes a symbolic 4x4 symmetric matrix and analytically computes its inverse. It is highly optimized for this specific task, returning both the inverse matrix ($g^{\\mu\\nu}$) and its determinant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665bc0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_connections(g4DD, g4DD_dD):\n",
    "    \"\"\"\n",
    "    Computes and simplifies Christoffel symbols from the metric and its derivatives.\n",
    "    \n",
    "    This version uses sp.trigsimp() which is highly effective and much faster\n",
    "    than sp.simplify() for the Kerr-Schild metric.\n",
    "    \"\"\"\n",
    "    Gamma4UDD = ixp.zerorank3(dimension=4)\n",
    "    g4UU, _ = ixp.symm_matrix_inverter4x4(g4DD)\n",
    "    \n",
    "    for mu in range(4):\n",
    "        for nu in range(4):\n",
    "            for delta in range(4):\n",
    "                # Calculate the Christoffel symbol component using the standard formula\n",
    "                for alpha in range(4):\n",
    "                    Gamma4UDD[delta][mu][nu] += sp.Rational(1, 2) * g4UU[delta][alpha] * \\\n",
    "                        (g4DD_dD[nu][alpha][mu] + g4DD_dD[mu][alpha][nu] - g4DD_dD[mu][nu][alpha])\n",
    "                \n",
    "                # Use sp.trigsimp() to simplify the resulting expression.\n",
    "                # This is the key to speeding up the symbolic calculation.\n",
    "                Gamma4UDD[delta][mu][nu] = sp.trigsimp(Gamma4UDD[delta][mu][nu])\n",
    "\n",
    "    return Gamma4UDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59295c0b",
   "metadata": {},
   "source": [
    "<a id='geodesic_mom_rhs'></a>\n",
    "### 3.c: Symbolic Recipe for the Geodesic Momentum ODE\n",
    "\n",
    "This function defines the symbolic right-hand side (RHS) for the evolution of the **reverse-time momentum**, $p^{\\alpha}$. As established in the introduction, this is the second of our three first-order ODEs:\n",
    "$$ \\frac{dp^{\\alpha}}{d\\kappa} = -\\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} $$\n",
    "The function `geodesic_mom_rhs` takes the symbolic Christoffel symbols $\\Gamma^{\\alpha}_{\\mu\\nu}$ as its input. It then defines the symbolic momentum vector `pU` using `sympy`'s `sp.symbols()` function. A key `nrpy` technique is used here: the symbols are created with names that are already valid C array syntax (e.g., `\"y[4]\"`). This **\"direct naming\"** simplifies the final C code generation by eliminating the need for string substitutions.\n",
    "\n",
    "The core of this function constructs the symbolic expression for the RHS by performing the Einstein summation $-\\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu}$. A direct implementation would involve a double loop over both $\\mu$ and $\\nu$ from 0 to 3, resulting in $4 \\times 4 = 16$ terms for each component of $\\alpha$, which is computationally inefficient.\n",
    "\n",
    "However, we can significantly optimize this calculation by exploiting symmetry. The term $p^{\\mu} p^{\\nu}$ is symmetric with respect to the interchange of the indices $\\mu$ and $\\nu$. The Christoffel symbols $\\Gamma^{\\alpha}_{\\mu\\nu}$ are also symmetric in their lower two indices. Therefore, the full sum can be split into diagonal ($\\mu=\\nu$) and off-diagonal ($\\mu \\neq \\nu$) terms:\n",
    "$$ \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} =  \\Gamma^{\\alpha}_{\\mu\\mu} (p^{\\mu})^2 + \\sum_{\\mu \\neq \\nu} \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} $$\n",
    "The second sum over $\\mu \\neq \\nu$ contains pairs of identical terms (e.g., the $\\mu=1, \\nu=2$ term is the same as the $\\mu=2, \\nu=1$ term). We can combine all such pairs by summing over only one of the cases (e.g., $\\mu < \\nu$) and multiplying by two:\n",
    "$$ \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} =  \\Gamma^{\\alpha}_{\\mu\\mu} (p^{\\mu})^2 + 2 \\sum_{\\mu < \\nu} \\Gamma^{\\alpha}_{\\mu\\nu} p^{\\mu} p^{\\nu} $$\n",
    "The Python code implements this optimized version, ensuring that each component of the RHS is computed with the minimum number of floating point operations, leading to more efficient C code.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.zerorank1(dimension)`**:\n",
    "    *   **Source File**: `nrpy/indexedexp.py`\n",
    "    *   **Description**: Creates a symbolic rank-1 tensor (a Python list) of a specified dimension, with all elements initialized to the `sympy` integer 0. It is used here to create a container for the four components of the momentum RHS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geodesic_mom_rhs(Gamma4UDD):\n",
    "    \"\"\"\n",
    "    Symbolic RHS for momentum ODE: dp^a/dκ = -Γ^a_μν p^μ p^ν.\n",
    "    p is the reverse-momentum, y[4]...y[7].\n",
    "    \"\"\"\n",
    "    pt,pr,pth,pph = sp.symbols(\"y[4] y[5] y[6] y[7]\", Real=True)\n",
    "    pU = [pt,pr,pth,pph]\n",
    "    geodesic_rhs = ixp.zerorank1(dimension=4)\n",
    "    for alpha in range(4):\n",
    "        for mu in range(4):\n",
    "            geodesic_rhs[alpha] += Gamma4UDD[alpha][mu][mu] * pU[mu] * pU[mu]\n",
    "            for nu in range(mu + 1, 4):\n",
    "                geodesic_rhs[alpha] += 2 * Gamma4UDD[alpha][mu][nu] * pU[mu] * pU[nu]\n",
    "        geodesic_rhs[alpha] = -geodesic_rhs[alpha]\n",
    "    return geodesic_rhs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02fcc6",
   "metadata": {},
   "source": [
    "<a id='geodesic_pos_rhs'></a>\n",
    "### 3.d: Symbolic Recipe for the Geodesic Position ODE\n",
    "\n",
    "This function defines the symbolic right-hand side (RHS) for the evolution of the position coordinates, $x^{\\alpha}$. As derived in the introduction, this is the first of our three first-order ODEs:\n",
    "\n",
    "$$ \\frac{dx^{\\alpha}}{d\\kappa} = p^{\\alpha} $$\n",
    "\n",
    "The Python function `geodesic_pos_rhs` is straightforward. It defines the components of the reverse-time momentum vector, `pU`, using `sympy`'s `sp.symbols()` function with the \"direct naming\" convention (`y[4]`, `y[5]`, etc.). It then simply returns a list containing these momentum components. This list of four symbolic expressions will serve as the first four components of the complete 9-component RHS vector that our C code will solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geodesic_pos_rhs():\n",
    "    \"\"\"\n",
    "    Symbolic RHS for position ODE: dx^a/dκ = p^a.\n",
    "    p is the reverse-momentum, y[4]...y[7].\n",
    "    \"\"\"\n",
    "    pt,pr,pth,pph = sp.symbols(\"y[4] y[5] y[6] y[7]\", Real=True)\n",
    "    pU = [pt,pr,pth,pph]\n",
    "    return pU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976931d5",
   "metadata": {},
   "source": [
    "<a id='proper_len_rhs'></a>\n",
    "### 3.e: Symbolic Recipe for the Path Length ODE\n",
    "\n",
    "This function defines the symbolic right-hand side for the evolution of the proper length, $L$. This is the final component of our ODE system and allows us to track the total distance the photon has traveled along its spatial path. The proper length element $dL$ is defined by the spatial part of the metric, $\\gamma_{ij} = g_{ij}$ for $i,j \\in \\{1,2,3\\}$:\n",
    "\n",
    "$$ dL^2 = \\gamma_{ij} dx^{i} dx^{j} $$\n",
    "\n",
    "Dividing by $d\\kappa^2$ and taking the square root gives us the rate of change of proper length with respect to our integration parameter $\\kappa$:\n",
    "\n",
    "$$ \\frac{dL}{d\\kappa} = \\sqrt{\\gamma_{ij} \\frac{dx^{i}}{d\\kappa} \\frac{dx^{j}}{d\\kappa}} = \\sqrt{\\gamma_{ij} p^{i} p^{j}} $$\n",
    "\n",
    "The function `proper_lengh_rhs` symbolically implements the formula under the square root, $\\sqrt{\\gamma_{ij} p^{i} p^{j}}$. It uses `sympy` symbols for the spatial momentum components (`pU[1]`, `pU[2]`, `pU[3]`) and programmatically constructs the optimized sum $\\gamma_{ij} p^{i} p^{j}$ using the same symmetry trick as the momentum RHS to reduce the number of terms. Finally, it returns a single-element list containing the square root of this sum. This will be the 9th component (`rhs_out[8]`) of our ODE system.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.indexedexp.declarerank2(name, dimension, sym)`**:\n",
    "    *   **Source File**: `nrpy/indexedexp.py`\n",
    "    *   **Description**: This function creates an *abstract* symbolic rank-2 tensor. Instead of creating symbols like `g11`, `g12`, etc., it creates symbols whose names are literally `name[1][1]`, `name[1][2]`, etc. This is a powerful `nrpy` technique for creating generic symbolic \"recipes\" that are later filled in with runtime data from a C struct. Here, it creates a placeholder for the metric components, `metric->g`, which will be provided by a C struct at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f82ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proper_lengh_rhs():\n",
    "    p0,p1,p2,p3,L= sp.symbols(\"y[4] y[5] y[6] y[7] y[8]\",Real=True)\n",
    "    pU=[p0,p1,p2,p3] \n",
    "\n",
    "    g4DD=ixp.declarerank2(\"metric->g\",dimension=4, sym=\"sym01\")\n",
    "\n",
    "    sum = sp.simplify(0)\n",
    "    \n",
    "    for i in range(1,4):\n",
    "        sum += g4DD[i][i]*pU[i]*pU[i]\n",
    "\n",
    "        for j in range(i+1,4):\n",
    "            sum += 2*g4DD[i][j]*pU[i]*pU[j]\n",
    "\n",
    "    sp.simplify(sum)\n",
    "\n",
    "    return [sp.sqrt(sum)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896fc9e6",
   "metadata": {},
   "source": [
    "<a id='geodesic_mom0_calc'></a>\n",
    "### 3.f: Symbolic Recipe for the Null Condition (Calculating p⁰)\n",
    "\n",
    "To complete our initial data, we must enforce the **null geodesic condition**, which states that the squared 4-momentum of a photon is zero. This is because photons travel along null paths where the spacetime interval $ds^2$ is zero. This condition must be satisfied by the 4-momentum of any photon. Let's write this for the **forward-in-time** photon, with physical 4-momentum $q^\\alpha$:\n",
    "\n",
    "$$ g_{\\mu\\nu}q^\\mu q^\\nu = 0 $$\n",
    "\n",
    "Expanding this equation into its time and space components gives us the quadratic equation for the time-component of the physical momentum, $q^0$:\n",
    "\n",
    "$$ g_{00}(q^0)^2 + 2\\left( g_{0i}q^i\\right)q^0 + \\left( g_{ij}q^i q^j\\right) = 0 $$\n",
    "\n",
    "For our reverse ray-tracing, we use the **reverse-time momentum**, $p^\\alpha$, which is related to the physical momentum by $p^\\alpha = -q^\\alpha$. We can substitute this relationship directly into the equation above, replacing $q^0$ with $-p^0$ and $q^i$ with $-p^i$:\n",
    "\n",
    "$$ g_{00}(-p^0)^2 + 2g_{0i}(-p^i)(-p^0) + \\left(g_{ij}(-p^i)(-p^j)\\right) = 0 $$\n",
    "\n",
    "The negative signs in the squared terms and the cross-term cancel out: `(-p^0)^2 = (p^0)^2`, `(-p^i)(-p^j) = p^i p^j`, and `(-p^i)(-p^0) = p^i p^0`. This yields a quadratic equation for $p^0$ that has the exact same form as the one for $q^0$:\n",
    "\n",
    "$$ g_{00}(p^0)^2 + 2\\left( g_{0i}p^i\\right)p^0 + \\left(g_{ij}p^i p^j\\right) = 0 $$\n",
    "\n",
    "We now solve this equation for $p^0$. It is a standard quadratic equation of the form $ax^2 + bx + c = 0$, where $x = p^0$. The coefficients are:\n",
    "*   $a = g_{00}$\n",
    "*   $b = 2g_{0i}p^i$\n",
    "*   $c =  g_{ij}p^i p^j$\n",
    "\n",
    "The solution for $p^0$ is given by the [quadratic formula](https://en.wikipedia.org/wiki/Quadratic_formula):\n",
    "\n",
    "$$ p^0 = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} = \\frac{-2\\left(g_{0i}p^i\\right) \\pm \\sqrt{\\left(2 g_{0i}p^i\\right)^2 - 4g_{00}\\left(g_{ij}p^i p^j\\right)}}{2g_{00}} $$\n",
    "\n",
    "Simplifying by dividing the numerator and denominator by 2 gives:\n",
    "\n",
    "$$ p^0 = \\frac{-\\left( g_{0i}p^i\\right) \\pm \\sqrt{\\left( g_{0i}p^i\\right)^2 - g_{00}\\left( g_{ij}p^i p^j\\right)}}{g_{00}} $$\n",
    "\n",
    "The final step is to choose the physically correct root. For the reverse-traced photon, the parameter $\\kappa$ increases as coordinate time `t` decreases. Therefore, the derivative $p^0 = dt/d\\kappa$ must be **negative**. In a typical stationary spacetime outside a black hole, $g_{00}$ is negative. For the fraction to be negative, the numerator must be **positive**. The square root term is always positive and its magnitude is generally larger than the first term. To guarantee a positive numerator, we must choose the **plus sign (`+`)** in the `±`.\n",
    "\n",
    "This leads to the final, correct result implemented in the code:\n",
    "$$ p^0 = \\frac{-\\left( g_{0i}p^i\\right) + \\sqrt{\\left(g_{0i}p^i\\right)^2 - g_{00}\\left( g_{ij}p^i p^j\\right)}}{g_{00}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mom_time_p0_reverse():\n",
    "    \"\"\"\n",
    "    Solves g_μν p^μ p^ν = 0 for our reverse-time momentum p^0.\n",
    "    \"\"\"\n",
    "    p0,p1,p2,p3 = sp.symbols(\"y[4] y[5] y[6] y[7]\", Real=True)\n",
    "    pU=[p0,p1,p2,p3]\n",
    "    g4DD = ixp.declarerank2(\"metric->g\", sym=\"sym01\", dimension=4)\n",
    "    sum_g0i_pi = sp.sympify(0)\n",
    "    for i in range(1,4):\n",
    "        sum_g0i_pi += g4DD[0][i]*pU[i]\n",
    "    sum_gij_pi_pj = sp.sympify(0)\n",
    "    for i in range(1,4):\n",
    "        sum_gij_pi_pj += g4DD[i][i]*pU[i]*pU[i]\n",
    "        for j in range(i+1,4):\n",
    "            sum_gij_pi_pj += 2*g4DD[i][j]*pU[i]*pU[j]\n",
    "    discriminant = sum_g0i_pi*sum_g0i_pi - g4DD[0][0]*sum_gij_pi_pj\n",
    "    answer = (-sum_g0i_pi + sp.sqrt(discriminant)) / g4DD[0][0]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea9bc84",
   "metadata": {},
   "source": [
    "<a id='conserved_quantities'></a>\n",
    "### 3.g: Symbolic Recipes for Conserved Quantities (E, L, Q)\n",
    "\n",
    "For geodesic motion in spacetimes with symmetries, certain physical quantities are conserved along the photon's path. These conserved quantities are invaluable for validating the numerical accuracy of our integrator. If the integrator is working correctly, these quantities should remain nearly constant throughout the entire evolution.\n",
    "\n",
    "The symmetries of a spacetime are described by **Killing vectors**. For the stationary and axisymmetric Kerr spacetime, there are two such vectors, which lead to two conserved quantities:\n",
    "\n",
    "1.  **Energy at Infinity (E):** The symmetry in time (stationarity) leads to the conservation of energy. It is defined as the projection of the 4-momentum onto the time-like Killing vector, which simplifies to:\n",
    "    $$ E = -p_t = -g_{t\\mu} p^\\mu $$\n",
    "    where $p_t$ is the covariant time-component of the 4-momentum.\n",
    "\n",
    "2.  **Angular Momentum Component Parallel to the Axis of Symmetry (L_z):** The symmetry in rotation about the z-axis (axisymmetry) leads to the conservation of the z-component of angular momentum. It is defined as:\n",
    "    $$ L_z = p_\\phi = g_{\\phi\\mu} p^\\mu $$\n",
    "    In Cartesian coordinates, this is equivalent to the standard definition:\n",
    "    $$ L_z = x p_y - y p_x $$\n",
    "    where $p_x$ and $p_y$ are the covariant spatial components of the 4-momentum.\n",
    "\n",
    "3.  **The Carter Constant (Q):** Remarkably, the Kerr spacetime possesses a hidden symmetry related to the separability of the Hamilton-Jacobi equation, which gives rise to a third conserved quantity known as the **Carter Constant, Q**. Its formula is more complex and is a combination of the other conserved quantities and the momentum components. For a photon (mass=0), it is given by:\n",
    "    $$ Q = p_\\theta^2 + \\cos^2\\theta \\left( \\frac{L_z^2}{\\sin^2\\theta} - a^2 E^2 \\right) $$\n",
    "    In the case of the Schwarzschild spacetime (where the spin $a=0$), the Carter constant simplifies to the squared total angular momentum: $Q = L_x^2 + L_y^2 + L_z^2 = L^2$.\n",
    "\n",
    "The following cells define the symbolic recipes for these three conserved quantities, which will be used to generate a C function for monitoring the numerical error of the integrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373ef962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_energy():\n",
    "    \"\"\"\n",
    "    Computes the symbolic expression for conserved energy E = -p_t.\n",
    "    E = -g_{t,mu} p^mu\n",
    "    \"\"\"\n",
    "    # Define the 4-momentum components using the y[4]...y[7] convention\n",
    "    pt, px, py, pz = sp.symbols(\"y[4] y[5] y[6] y[7]\", real=True)\n",
    "    pU = [pt, px, py, pz]\n",
    "    \n",
    "    # Define an abstract metric tensor to be filled by a C struct at runtime\n",
    "    g4DD = ixp.declarerank2(\"metric->g\", sym=\"sym01\", dimension=4)\n",
    "    \n",
    "    # Calculate p_t = g_{t,mu} p^mu\n",
    "    p_t = sp.sympify(0)\n",
    "    for mu in range(4):\n",
    "        p_t += g4DD[0][mu] * pU[mu]\n",
    "        \n",
    "    return -p_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd4d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_L_components_cart():\n",
    "    \"\"\"\n",
    "    Computes the symbolic expressions for the three components of angular momentum,\n",
    "    correctly accounting for the symmetry of the metric tensor.\n",
    "    \"\"\"\n",
    "    # Define coordinate and 4-momentum components\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    pt, px, py, pz = sp.symbols(\"y[4] y[5] y[6] y[7]\", real=True)\n",
    "    pU = [pt, px, py, pz]\n",
    "    \n",
    "    # Define an abstract metric tensor\n",
    "    g4DD = ixp.declarerank2(\"metric->g\", sym=\"sym01\", dimension=4)\n",
    "    \n",
    "    # Calculate covariant momentum components p_k = g_{k,mu} p^mu,\n",
    "    # correctly exploiting the metric's symmetry g_mu,nu = g_nu,mu.\n",
    "    p_down = ixp.zerorank1(dimension=4)\n",
    "    for k in range(1, 4): # We only need p_x, p_y, p_z for L_i\n",
    "        # Sum over mu\n",
    "        for mu in range(4):\n",
    "            # Use g4DD[k][mu] if k <= mu, otherwise use g4DD[mu][k]\n",
    "            if k <= mu:\n",
    "                p_down[k] += g4DD[k][mu] * pU[mu]\n",
    "            else: # k > mu\n",
    "                p_down[k] += g4DD[mu][k] * pU[mu]\n",
    "            \n",
    "    p_x, p_y, p_z = p_down[1], p_down[2], p_down[3]\n",
    "\n",
    "    # Calculate angular momentum components \n",
    "    L_x = y*p_z - z*p_y\n",
    "    L_y = z*p_x - x*p_z\n",
    "    L_z = x*p_y - y*p_x\n",
    "    \n",
    "    return [L_x, L_y, L_z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1034fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_carter_constant_Q():\n",
    "    \"\"\"\n",
    "    Computes the symbolic expression for the Carter Constant Q.\n",
    "\n",
    "    This is a corrected version that properly calculates and uses the\n",
    "    Boyer-Lindquist radial coordinate 'r' instead of the Euclidean radius,\n",
    "    resolving the mathematical error in the original implementation.\n",
    "    \"\"\"\n",
    "    # Define all necessary symbolic variables\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    pt, px, py, pz = sp.symbols(\"y[4] y[5] y[6] y[7]\", real=True)\n",
    "    pU = [pt, px, py, pz]\n",
    "    a = a_spin\n",
    "    g4DD = ixp.declarerank2(\"metric->g\", sym=\"sym01\", dimension=4)\n",
    "\n",
    "    # --- Step 1: Compute intermediate quantities E, Lz, and p_i ---\n",
    "    # This step remains the same as it was correct.\n",
    "    E = symbolic_energy()\n",
    "    _, _, Lz = symbolic_L_components_cart()\n",
    "    \n",
    "    p_down = ixp.zerorank1(dimension=4)\n",
    "    for k in range(1, 4):\n",
    "        for mu in range(4):\n",
    "            if k <= mu: p_down[k] += g4DD[k][mu] * pU[mu]\n",
    "            else: p_down[k] += g4DD[mu][k] * pU[mu]\n",
    "    p_x, p_y, p_z = p_down[1], p_down[2], p_down[3]\n",
    "\n",
    "    # --- Step 2: Compute geometric terms (CORRECTED) ---\n",
    "    rho_sq = x**2 + y**2\n",
    "    \n",
    "    # Define the intermediate variable Sigma from the quartic equation for r^2\n",
    "    Sigma = x**2 + y**2 + z**2 - a**2\n",
    "    \n",
    "    # Solve the quartic equation for r^2. The positive root is the correct one.\n",
    "    # r^4 - Sigma*r^2 - a^2*z^2 = 0  => (r^2)^2 - Sigma*(r^2) - a^2*z^2 = 0\n",
    "    # Using the quadratic formula for r^2:\n",
    "    r_sq = (Sigma + sp.sqrt(Sigma**2 + 4*a**2*z**2)) / 2\n",
    "\n",
    "    # --- Step 3: Compute p_theta^2 directly in Cartesian components ---\n",
    "    # This step remains the same, as the second LLM confirmed its mathematical validity.\n",
    "    xpx_plus_ypy = x*p_x + y*p_y\n",
    "    p_theta_sq = (z**2 * xpx_plus_ypy**2 / rho_sq) - (2 * z * p_z * xpx_plus_ypy) + (rho_sq * p_z**2)\n",
    "\n",
    "    # --- Step 4: Assemble the final formula for Q  ---\n",
    "    second_term = (z**2 / r_sq) * (a**2 * E**2 - Lz**2 * (r_sq + a**2) / rho_sq)\n",
    "    \n",
    "    Q_formula = p_theta_sq + second_term\n",
    "    \n",
    "    # --- Step 5: Handle the axial singularity ---\n",
    "    Q_on_axis = a**2 * E**2 * (z**2 / r_sq)\n",
    "    Q_final = sp.Piecewise(\n",
    "    (Q_on_axis, rho_sq < 1e-12),\n",
    "    (Q_formula, True)\n",
    ")\n",
    "    \n",
    "    return Q_final\n",
    "\n",
    "print(\"Final symbolic recipes for conserved quantities defined (Carter Constant re-derived AND CORRECTED).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b39f1e",
   "metadata": {},
   "source": [
    "<a id='numerical_recipes'></a>\n",
    "### 3.h: Symbolic Recipes for Numerical Metrics\n",
    "\n",
    "While analytic metrics like Kerr-Schild are powerful, many modern simulations in astrophysics use numerical metrics, where the spacetime components are known only as numerical values on a discrete grid. To calculate Christoffel symbols for these spacetimes, we must perform all calculations numerically, including the derivatives.\n",
    "\n",
    "A naive approach would be to first interpolate the metric $g_{\\mu\\nu}$ to a point, then interpolate again at nearby points to perform a finite difference derivative. This is extremely inefficient, requiring many calls to the interpolation engine. A far superior method is the **\"analytic derivative of the interpolant.\"**\n",
    "\n",
    "The idea is as follows:\n",
    "1.  The interpolation formula (e.g., trilinear interpolation) is a simple polynomial.\n",
    "2.  We can take the analytical partial derivative of this polynomial formula itself. The result is a new formula for the derivative that is also a simple combination of the grid point values.\n",
    "3.  We can then implement both the interpolation formula and its derivative formula directly in C code. This allows us to compute both $g_{\\mu\\nu}$ and its derivatives $g_{\\mu\\nu,\\delta}$ in a single, efficient C function call.\n",
    "\n",
    "To generate the C code for this, we need a symbolic recipe for the Christoffel symbols that is built from abstract placeholders for the interpolated metric and its derivatives. The following function creates this recipe. It uses `sympy.Symbol` objects with descriptive names (e.g., `g4DD00`, `g4DDdD01_d2`) that will be matched to local C variables in the final C worker function. This avoids the \"expression swell\" that would occur if we tried to symbolically construct the entire interpolation and differentiation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f070a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_numerical_christoffel_recipe():\n",
    "    \"\"\"\n",
    "    Generates the pure symbolic recipe for the Christoffel symbols assuming\n",
    "    that the metric g_μν and its derivatives g_μν,δ are provided as inputs.\n",
    "\n",
    "    This version manually constructs the derivative tensor with a naming\n",
    "    convention that matches the C code preamble (e.g., g4DDdD01_d2).\n",
    "    \"\"\"\n",
    "    # Step 1: Create symbolic placeholders for the 10 unique metric components.\n",
    "    g4DD = ixp.declarerank2(\"g4DD\", symmetry=\"sym01\", dimension=4)\n",
    "\n",
    "    # --- THIS IS THE CORRECTED LOGIC ---\n",
    "    # Step 2: Manually create symbolic placeholders for the 40 unique metric derivatives\n",
    "    # to enforce the g4DDdD{i}{j}_d{k} naming convention.\n",
    "    g4DDdD = ixp.zerorank3(dimension=4) # Initialize with zeros\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4): # Loop over unique metric components\n",
    "            for k in range(4): # Loop over derivative directions\n",
    "                # Create the symbol with the exact name we need\n",
    "                symbol_name = f\"g4DDdD{i}{j}_d{k}\"\n",
    "                g4DDdD[i][j][k] = sp.Symbol(symbol_name)\n",
    "                if i != j:\n",
    "                    # Enforce symmetry in the symbolic tensor\n",
    "                    g4DDdD[j][i][k] = g4DDdD[i][j][k]\n",
    "\n",
    "    # Step 3: Compute the symbolic inverse of the placeholder metric.\n",
    "    g4UU, _ = ixp.symm_matrix_inverter4x4(g4DD)\n",
    "\n",
    "    # Step 4: Initialize the output tensor for the Christoffel symbols.\n",
    "    Gamma4UDD_num_recipe = ixp.zerorank3(dimension=4)\n",
    "\n",
    "    # Step 5: Build the recipe for the 40 unique Christoffel symbols.\n",
    "    for alpha in range(4):\n",
    "        for mu in range(4):\n",
    "            for nu in range(mu, 4):\n",
    "                for delta in range(4):\n",
    "                    Gamma4UDD_num_recipe[alpha][mu][nu] += sp.Rational(1, 2) * g4UU[alpha][delta] * \\\n",
    "                        (g4DDdD[nu][delta][mu] + g4DDdD[mu][delta][nu] - g4DDdD[mu][nu][delta])\n",
    "\n",
    "    return Gamma4UDD_num_recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe10d0a",
   "metadata": {},
   "source": [
    "<a id='spacetime_definition'></a>\n",
    "# Step 4: Spacetime Definition in Kerr-Schild Coordinates\n",
    "\n",
    "This section defines the specific spacetime geometry in which the geodesics will be integrated. Instead of defining separate metrics for Schwarzschild (non-rotating) and Kerr (rotating) black holes, we use a single, powerful coordinate system: **Cartesian Kerr-Schild coordinates**. This system has a major advantage over more common coordinate systems like Boyer-Lindquist: it is regular everywhere, including at the event horizon. This means the metric components and their derivatives do not diverge, allowing the numerical integrator to trace a photon's path seamlessly across the horizon without encountering coordinate singularities.\n",
    "\n",
    "The Kerr-Schild metric $g_{\\mu\\nu}$ is constructed by adding a correction term to the flat Minkowski metric $\\eta_{\\mu\\nu}$:\n",
    "$$ g_{\\mu\\nu} = \\eta_{\\mu\\nu} + 2H l_\\mu l_\\nu $$\n",
    "where $\\eta_{\\mu\\nu}$ is the Minkowski metric `diag(-1, 1, 1, 1)`, $l_\\mu$ is a special null vector, and $H$ is a scalar function that depends on the black hole's mass $M$ and spin $a$.\n",
    "\n",
    "The function `define_kerr_metric_Cartesian_Kerr_Schild()` implements this formula symbolically. It defines the coordinates `(t, x, y, z)`, the mass `M`, and the spin `a` as `sympy` symbols. It then constructs the components of the null vector $l_\\mu$ and the scalar function $H$. Finally, it assembles the full metric tensor $g_{\\mu\\nu}$.\n",
    "\n",
    "A key feature of this formulation is that if the spin parameter `a` is set to zero, the metric automatically and exactly reduces to the Schwarzschild metric in Cartesian coordinates. This allows a single set of symbolic expressions and a single set of C functions to handle both spacetimes, with the specific behavior controlled by the runtime value of the `a_spin` parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_kerr_metric_Cartesian_Kerr_Schild():\n",
    "    \"\"\"\n",
    "    Defines the Kerr metric tensor in Cartesian Kerr-Schild coordinates.\n",
    "\n",
    "    This function is the new, unified source for both Kerr (a != 0) and\n",
    "    Schwarzschild (a = 0) spacetimes. The coordinates are (t, x, y, z).\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (g4DD, xx), where g4DD is the symbolic 4x4 metric tensor\n",
    "        and xx is the list of symbolic coordinate variables.\n",
    "    \"\"\"\n",
    "    # Define the symbolic coordinates using the 'y[i]' convention for the integrator\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    xx = [t, x, y, z]\n",
    "\n",
    "    # Access the symbolic versions of the mass and spin parameters\n",
    "    M = M_scale\n",
    "    a = a_spin\n",
    "\n",
    "    # Define intermediate quantities\n",
    "    r2 = x**2 + y**2 + z**2\n",
    "    r = sp.sqrt(r2)\n",
    "    \n",
    "    # Define the Kerr-Schild null vector l_μ\n",
    "    l_down = ixp.zerorank1(dimension=4)\n",
    "    l_down[0] = 1\n",
    "    l_down[1] = (r*x + a*y) / (r2 + a**2)\n",
    "    l_down[2] = (r*y - a*x) / (r2 + a**2)\n",
    "    l_down[3] = z/r\n",
    "\n",
    "    # Define the scalar function H\n",
    "    H = (M * r**3) / (r**4 + a**2 * z**2)\n",
    "\n",
    "    # The Kerr-Schild metric is g_μν = η_μν + 2H * l_μ * l_ν\n",
    "    # where η_μν is the Minkowski metric diag(-1, 1, 1, 1)\n",
    "    g4DD = ixp.zerorank2(dimension=4)\n",
    "    for mu in range(4):\n",
    "        for nu in range(4):\n",
    "            eta_mu_nu = 0\n",
    "            if mu == nu:\n",
    "                eta_mu_nu = 1\n",
    "            if mu == 0 and nu == 0:\n",
    "                eta_mu_nu = -1\n",
    "            \n",
    "            g4DD[mu][nu] = eta_mu_nu + 2 * H * l_down[mu] * l_down[nu]\n",
    "            \n",
    "    return g4DD, xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f01f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_schwarzschild_metric_cartesian():\n",
    "    \"\"\"\n",
    "    Defines the Schwarzschild metric tensor directly in Cartesian coordinates.\n",
    "    \n",
    "    This version uses the standard textbook formula and ensures all components\n",
    "    are sympy objects to prevent C-generation errors.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (g4DD, xx), where g4DD is the symbolic 4x4 metric tensor\n",
    "        and xx is the list of symbolic coordinate variables.\n",
    "    \"\"\"\n",
    "    # Define Cartesian coordinates\n",
    "    t, x, y, z = sp.symbols(\"y[0] y[1] y[2] y[3]\", real=True)\n",
    "    xx = [t, x, y, z]\n",
    "\n",
    "    # Access the symbolic mass parameter\n",
    "    M = M_scale\n",
    "\n",
    "    # Define r in terms of Cartesian coordinates\n",
    "    r = sp.sqrt(x**2 + y**2 + z**2)\n",
    "\n",
    "    # Define the Cartesian Schwarzschild metric components directly\n",
    "    g4DD = ixp.zerorank2(dimension=4)\n",
    "    \n",
    "    # g_tt\n",
    "    g4DD[0][0] = -(1 - 2*M/r)\n",
    "    \n",
    "    # Spatial components g_ij = δ_ij + (2M/r) * (x_i * x_j / r^2)\n",
    "    x_i = [x, y, z]\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            # --- CORRECTED: Use sp.sympify() for the kronecker delta ---\n",
    "            delta_ij = sp.sympify(0)\n",
    "            if i == j:\n",
    "                delta_ij = sp.sympify(1)\n",
    "            \n",
    "            # The indices for g4DD are off by 1 from the spatial indices\n",
    "            g4DD[i+1][j+1] = delta_ij + (2*M/r) * (x_i[i] * x_i[j] / (r**2))\n",
    "\n",
    "    # --- CORRECTED: Ensure time-space components are sympy objects ---\n",
    "    g4DD[0][1] = g4DD[1][0] = sp.sympify(0)\n",
    "    g4DD[0][2] = g4DD[2][0] = sp.sympify(0)\n",
    "    g4DD[0][3] = g4DD[3][0] = sp.sympify(0)\n",
    "            \n",
    "    return g4DD, xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec78a4",
   "metadata": {},
   "source": [
    "<a id='symbolic_execution'></a>\n",
    "# Step 5: Symbolic Workflow Execution\n",
    "\n",
    "This cell acts as the central hub for the symbolic portion of our project. In the preceding cells, we *defined* a series of Python functions that act as mathematical blueprints. Here, we *execute* those functions in the correct sequence to generate all the final symbolic expressions that will serve as \"recipes\" for our C code generators.\n",
    "\n",
    "This \"symbolic-first\" approach is a core `nrpy` principle and offers significant advantages:\n",
    "1.  **Efficiency**: The complex symbolic calculations, such as inverting the metric tensor and deriving the Christoffel symbols, are performed **only once** when this notebook is run. The results are stored in global Python variables, preventing redundant and time-consuming recalculations. This is especially important for the Kerr metric, whose Christoffel symbols can take several minutes to compute.\n",
    "2.  **Modularity**: This workflow creates a clean separation between the *specific solution* for a metric (e.g., the explicit formulas for the Kerr-Schild Christoffels) and the *generic form* of the equations of motion (which are valid for any metric).\n",
    "\n",
    "This cell produces several key global variables containing symbolic expressions that will be used in the next step to generate the final C code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbfe0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define the Kerr-Schild metric and get its derivatives ---\n",
    "print(\" -> Computing Kerr-Schild metric and Christoffel symbols...\")\n",
    "g4DD_kerr, xx_kerr = define_kerr_metric_Cartesian_Kerr_Schild()\n",
    "g4DD_dD_kerr = derivative_g4DD(g4DD_kerr, xx_kerr)\n",
    "Gamma4UDD_kerr = four_connections(g4DD_kerr, g4DD_dD_kerr)\n",
    "print(\"    ... Done.\")\n",
    "\n",
    "# --- 2. Define the Standard Schwarzschild metric in Cartesian and get its derivatives ---\n",
    "print(\" -> Computing Standard Schwarzschild (Cartesian) metric and Christoffel symbols...\")\n",
    "g4DD_schw_cart, xx_schw_cart = define_schwarzschild_metric_cartesian()\n",
    "g4DD_dD_schw_cart = derivative_g4DD(g4DD_schw_cart, xx_schw_cart)\n",
    "Gamma4UDD_schw_cart = four_connections(g4DD_schw_cart, g4DD_dD_schw_cart)\n",
    "print(\"    ... Done.\")\n",
    "\n",
    "# --- 3. Generate the GENERIC symbolic RHS expressions for the geodesic equations ---\n",
    "# This part is unchanged, as the ODEs are generic.\n",
    "Gamma4UDD_placeholder = ixp.declarerank3(\"conn->Gamma4UDD\", dimension=4)\n",
    "rhs_pos = geodesic_pos_rhs() \n",
    "rhs_mom = geodesic_mom_rhs(Gamma4UDD_placeholder)\n",
    "rhs_length = proper_lengh_rhs()\n",
    "all_rhs_expressions = rhs_pos + rhs_mom + rhs_length\n",
    "print(\" -> Defined generic global symbolic variable for ODE RHS: all_rhs_expressions\")\n",
    "\n",
    "# --- 4. Generate symbolic recipes for conserved quantities ---\n",
    "# This is now simplified, as all calculations are Cartesian.\n",
    "print(\" -> Generating symbolic recipes for conserved quantities...\")\n",
    "\n",
    "\n",
    "E_expr = symbolic_energy()\n",
    "Lx_expr, Ly_expr, Lz_expr = symbolic_L_components_cart()\n",
    "Q_expr_kerr = symbolic_carter_constant_Q()\n",
    "Q_expr_schw = Lx_expr**2 + Ly_expr**2 + Lz_expr**2\n",
    "# We now have two lists of expressions, both using Cartesian formulas.\n",
    "list_of_expressions_kerr = [E_expr, Lx_expr, Ly_expr, Lz_expr, Q_expr_kerr]\n",
    "list_of_expressions_schw = [E_expr, Lx_expr, Ly_expr, Lz_expr, Q_expr_schw]\n",
    "print(\"    ... Conservation recipes generated.\")\n",
    "\n",
    "print(\"\\nSymbolic setup complete. All expressions are now available globally.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032d263",
   "metadata": {},
   "source": [
    "<a id='generate_c_engines'></a>\n",
    "# Step 6: C Code Generation - Physics Engines and Workers\n",
    "\n",
    "This section marks our transition from pure symbolic mathematics to C code generation. The Python functions defined here are \"meta-functions\": their job is not to perform calculations themselves, but to **generate the C code** that will perform the calculations in the final compiled program.\n",
    "\n",
    "We distinguish between several types of generated functions:\n",
    "*   **Workers**: These are specialized functions that implement the physics for a *specific metric*. For example, `con_kerr_schild()` is a worker that only knows how to compute Christoffel symbols for the Kerr-Schild metric.\n",
    "*   **Engines**: These are generic functions that implement physics equations or numerical methods valid for *any metric*. For example, `calculate_ode_rhs()` is an engine that can compute the geodesic equations for any metric, as long as the Christoffel symbols are provided to it.\n",
    "*   **Helpers**: These are small, utility functions that perform common tasks, such as managing memory for a data structure.\n",
    "\n",
    "This modular design allows for maximum code reuse and extensibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe5ff0a",
   "metadata": {},
   "source": [
    "<a id='generate_c_engines'></a> # Missing header?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd610ccf",
   "metadata": {},
   "source": [
    "<a id='tier_4_workers'></a> \n",
    "### 6.A: Tier 4 - Low-Level Workers, Helpers, and Dispatchers\n",
    "\n",
    "The Python functions in this subsection generate the C \"worker\" functions that are specialized for a particular analytic metric. Each function takes one of the symbolic metric recipes we generated in Step 5 (e.g., `Gamma4UDD_kerr`) and translates it into an optimized C function.\n",
    "\n",
    "The core of this process is the `nrpy.c_codegen.c_codegen` function, which converts the large `sympy` expressions into C code, automatically performing Common Subexpression Elimination (CSE) to significantly improve the performance of the final C code. The generated C code is then registered with `nrpy`'s in-memory C project manager, `nrpy.c_function.register_CFunction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ef433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g4DD_schwarzschild_cartesian():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Schwarzschild\n",
    "    metric components in standard Cartesian coordinates.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: g4DD_schwarzschild_cartesian()...\")\n",
    "    \n",
    "    # Use the globally defined g4DD_schw_cart from the symbolic execution step\n",
    "    list_of_g4DD_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_syms.append(g4DD_schw_cart[i][j])\n",
    "\n",
    "    list_of_g4DD_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_C_vars.append(f\"metric->g{i}{j}\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the 10 unique components of the Schwarzschild metric in Cartesian coords.\"\"\"\n",
    "    name = \"g4DD_schwarzschild_cartesian\"\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], metric_struct *restrict metric\"\n",
    "   \n",
    "    body = ccg.c_codegen(list_of_g4DD_syms, list_of_g4DD_C_vars, enable_cse=True)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... g4DD_schwarzschild_cartesian() registration complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d52f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g4DD_kerr_schild():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Kerr-Schild\n",
    "    metric components in Cartesian coordinates. This is the new unified worker.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: g4DD_kerr_schild()...\")\n",
    "    \n",
    "    # We use the globally defined g4DD_kerr from the symbolic execution step\n",
    "    list_of_g4DD_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_syms.append(g4DD_kerr[i][j])\n",
    "\n",
    "    list_of_g4DD_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            list_of_g4DD_C_vars.append(f\"metric->g{i}{j}\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the 10 unique components of the Kerr metric in Cartesian Kerr-Schild coords.\"\"\"\n",
    "    name = \"g4DD_kerr_schild\"\n",
    "    # The state vector y now contains (t, x, y, z)\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], metric_struct *restrict metric\"\n",
    "   \n",
    "    body = ccg.c_codegen(list_of_g4DD_syms, list_of_g4DD_C_vars, enable_cse=True)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... g4DD_kerr_schild() registration complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb471c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_kerr_schild():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Kerr-Schild Christoffel symbols.\n",
    "    This is the new unified worker.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: con_kerr_schild()...\")\n",
    "    \n",
    "    # We use the globally defined Gamma4UDD_kerr from the symbolic execution step\n",
    "    list_of_Gamma_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_syms.append(Gamma4UDD_kerr[i][j][k])\n",
    "\n",
    "    conn_Gamma4UDD = ixp.declarerank3(\"conn->Gamma4UDD\", dimension=4)\n",
    "    list_of_Gamma_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_C_vars.append(str(conn_Gamma4UDD[i][j][k]))\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the 40 unique Christoffel symbols for the Kerr metric in Kerr-Schild coords.\"\"\"\n",
    "    name = \"con_kerr_schild\"\n",
    "    # The state vector y now contains (t, x, y, z)\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], connection_struct *restrict conn\"\n",
    "\n",
    "    body = ccg.c_codegen(list_of_Gamma_syms, list_of_Gamma_C_vars, enable_cse=True)\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... con_kerr_schild() registration complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6072ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_schwarzschild_cartesian():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the Schwarzschild Christoffel symbols\n",
    "    in standard Cartesian coordinates.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C worker function: con_schwarzschild_cartesian()...\")\n",
    "    \n",
    "    # Use the globally defined Gamma4UDD_schw_cart\n",
    "    list_of_Gamma_syms = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_syms.append(Gamma4UDD_schw_cart[i][j][k])\n",
    "\n",
    "    conn_Gamma4UDD = ixp.declarerank3(\"conn->Gamma4UDD\", dimension=4)\n",
    "    list_of_Gamma_C_vars = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(j, 4):\n",
    "                list_of_Gamma_C_vars.append(str(conn_Gamma4UDD[i][j][k]))\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes the unique Christoffel symbols for the Schwarzschild metric in Cartesian coords.\"\"\"\n",
    "    name = \"con_schwarzschild_cartesian\"\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const double y[4], connection_struct *restrict conn\"\n",
    "\n",
    "    body = ccg.c_codegen(list_of_Gamma_syms, list_of_Gamma_C_vars, enable_cse=True)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body,\n",
    "        include_CodeParameters_h=True\n",
    "    )\n",
    "    print(\"    ... con_schwarzschild_cartesian() registration complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c264b",
   "metadata": {},
   "source": [
    "<a id='g4DD_metric_dispatcher'></a>\n",
    "### 6.A.1: `g4DD_metric()` Dispatcher\n",
    "\n",
    "This Python function generates the C function `g4DD_metric()`, which serves as a high-level **dispatcher** for the **analytic metrics**. Its role is to select and call the correct worker function to compute the components of the metric tensor, $g_{\\mu\\nu}$.\n",
    "\n",
    "The generated C code uses a `switch` statement that reads the `metric->type` member of the `metric_params` struct. It contains cases for the analytic spacetimes (`Kerr`, `Schwarzschild`, etc.) and calls the appropriate worker function (e.g., `g4DD_kerr_schild()`).\n",
    "\n",
    "This modular approach cleanly separates the control flow (deciding *which* analytic metric to use) from the physics implementation (the worker functions that know *how* to compute a specific metric). Note that this dispatcher is **not** used by the numerical metric pipeline, which has its own dedicated interpolation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b96a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g4DD_metric():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function g4DD_metric(), which serves as a\n",
    "    dispatcher to call the appropriate metric-specific worker function.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C dispatcher function: g4DD_metric()...\")\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Dispatcher to compute the 4-metric g_munu for the chosen metric.\"\"\"\n",
    "    name = \"g4DD_metric\"\n",
    "    # The signature is now coordinate-aware, but the y vector is always Cartesian here.\n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const metric_params *restrict metric, const double y[9], metric_struct *restrict metric_out\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "    // The state vector y_pos contains only the position coordinates.\n",
    "    const double y_pos[4] = {y[0], y[1], y[2], y[3]};\n",
    "\n",
    "    // This switch statement chooses which \"worker\" function to call\n",
    "    // based on the metric type provided.\n",
    "    switch(metric->type) {\n",
    "        case Schwarzschild:\n",
    "        case Kerr:\n",
    "            // For Kerr or Schwarzschild in KS coords, call the unified Kerr-Schild C function.\n",
    "            g4DD_kerr_schild(commondata, params, y_pos, metric_out);\n",
    "            break;\n",
    "        // <-- MODIFIED: Call the new Cartesian worker\n",
    "        case Schwarzschild_Standard:\n",
    "            g4DD_schwarzschild_cartesian(commondata, params, y_pos, metric_out);\n",
    "            break;\n",
    "        case Numerical:\n",
    "            printf(\"Error: Numerical metric not supported yet.\\n\");\n",
    "            exit(1);\n",
    "            break;\n",
    "        default:\n",
    "            printf(\"Error: MetricType %d not supported in g4DD_metric() yet.\\n\", metric->type);\n",
    "            exit(1);\n",
    "            break;\n",
    "    }\n",
    "\"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... g4DD_metric() registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227012e4",
   "metadata": {},
   "source": [
    "<a id='connections_dispatcher'></a>\n",
    "### 6.A.2: `connections()` Dispatcher\n",
    "\n",
    "This Python function generates the C function `connections()`, which acts as a second **dispatcher** for the **analytic metrics**. Its sole responsibility is to select and call the correct metric-specific worker function (like `con_kerr_schild()`) to compute the Christoffel symbols.\n",
    "\n",
    "Like the `g4DD_metric()` dispatcher, the generated C code uses a `switch` statement based on the `metric->type`. It dispatches the call to the appropriate specialized worker for the analytic spacetimes. This design is highly extensible: adding a new analytic metric simply requires writing a new worker function for its Christoffel symbols and adding a new `case` to this `switch` statement. This function is not used by the numerical metric pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connections():\n",
    "    \"\"\"\n",
    "    Generates and registers the C dispatcher for Christoffel symbols.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C dispatcher: connections()...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"stdio.h\", \"stdlib.h\"]\n",
    "    desc = r\"\"\"@brief Dispatcher to compute Christoffel symbols for the chosen metric.\"\"\"\n",
    "    \n",
    "    name = \"connections\"\n",
    "    cfunc_type = \"void\" \n",
    "    params = \"const commondata_struct *restrict commondata, const params_struct *restrict params, const metric_params *restrict metric, const double y[9], connection_struct *restrict conn\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // The state vector y_pos contains only the position coordinates.\n",
    "    const double y_pos[4] = {y[0], y[1], y[2], y[3]};\n",
    "\n",
    "    // This switch statement chooses which \"worker\" function to call\n",
    "    // based on the metric type provided.\n",
    "    switch(metric->type) {\n",
    "        case Schwarzschild:\n",
    "        case Kerr:\n",
    "            con_kerr_schild(commondata, params, y_pos, conn);\n",
    "            break;\n",
    "        // <-- MODIFIED: Call the new Cartesian worker\n",
    "        case Schwarzschild_Standard:\n",
    "            con_schwarzschild_cartesian(commondata, params, y_pos, conn);\n",
    "            break;\n",
    "        case Numerical:\n",
    "            printf(\"Error: Numerical metric not supported yet.\\n\");\n",
    "            exit(1);\n",
    "            break;\n",
    "        default:\n",
    "            printf(\"Error: MetricType %d not supported yet.\\n\", metric->type);\n",
    "            exit(1);\n",
    "            break;\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, cfunc_type=cfunc_type,\n",
    "        name=name, params=params, body=body\n",
    "    )\n",
    "    print(\"    ... connections() registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c4f5ce",
   "metadata": {},
   "source": [
    "<a id='tier_3_engines'></a>\n",
    "### 6.B: Tier 3 - Core Subsystems & Engines\n",
    "\n",
    "The Python functions in this subsection generate the generic C \"engines\" that are valid for *any* metric, whether analytic or numerical. They operate on abstract data structures (like `metric_struct` and `connection_struct`) and are completely decoupled from the specifics of how the values in those structs were computed.\n",
    "\n",
    "This is a key feature of the project's modular design. For example, the `calculate_ode_rhs()` engine doesn't care if the Christoffel symbols it receives were calculated from the analytic Kerr-Schild formula or the numerical interpolation pipeline; it just applies the geodesic equation to whatever values it is given. This allows for maximum code reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ea1fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_p0_reverse():\n",
    "    \"\"\"\n",
    "    Generates and registers the C function to compute the time component\n",
    "    of the reverse 4-momentum, p^0.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine function: calculate_p0_reverse()...\")\n",
    "    # The symbolic expression uses y[4] through y[7] for the 4-momentum\n",
    "    p0_expr = mom_time_p0_reverse()\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = r\"\"\"@brief Computes reverse-time p^0 from the null condition g_munu p^mu p^nu = 0.\"\"\"\n",
    "    name = \"calculate_p0_reverse\"\n",
    "    c_type = \"double\"\n",
    "    # The function now takes the full 9-element state vector y.\n",
    "    params = \"const metric_struct *restrict metric, const double y[9]\"\n",
    "    \n",
    "\n",
    "            \n",
    "    # We generate the C code directly from the original expression.\n",
    "    # Since the C function takes the full y[9] vector, the array indices\n",
    "    # y[4], y[5], etc., in the generated code will be correct.\n",
    "    p0_C_code_lines = ccg.c_codegen(\n",
    "        p0_expr, 'double p0_val', enable_cse=True, include_braces=False\n",
    "    )\n",
    "    body = f\"{{\\n{p0_C_code_lines}\\nreturn p0_val;\\n}}\"\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, cfunc_type=c_type,\n",
    "        name=name, params=params, body=body\n",
    "    )\n",
    "    print(\"    ... calculate_p0_reverse() registration complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a65c99",
   "metadata": {},
   "source": [
    "<a id='check_conservation'></a>\n",
    "### 6.B.1 Generic Engine: `check_conservation()`\n",
    "\n",
    "This Python function generates the C engine `check_conservation()`. Its purpose is to calculate the conserved quantities (Energy `E`, the three components of angular momentum `L_i`, and the Carter Constant `Q`) for a given state vector `y`.\n",
    "\n",
    "This function is an excellent example of a **validation tool**. During a long integration, small numerical errors will inevitably accumulate. By calling this function periodically, we can monitor how well these physical quantities, which should be perfectly constant, are actually being conserved by our numerical solver. If they drift significantly, it indicates a problem with the integration accuracy (e.g., the step size is too large or the order of the integrator is too low).\n",
    "\n",
    "The C function is a dispatcher that operates on the *symbolic recipes* for the conserved quantities that we generated in Step 3.g. It takes the metric type as input and uses a `switch` statement to select the correct set of symbolic formulas (`list_of_expressions_kerr` or `list_of_expressions_schw`). It then calls `nrpy.c_codegen.c_codegen` to translate these high-level symbolic recipes into optimized C code on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a74ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_conservation():\n",
    "    \"\"\"\n",
    "    Generates the C function `check_conservation`. This version is simplified\n",
    "    for a purely Cartesian pipeline.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine: check_conservation() [Cartesian Version]...\")\n",
    "\n",
    "    # Use the globally defined Cartesian recipes\n",
    "    output_vars_kerr = [\"*E\", \"*Lx\", \"*Ly\", \"*Lz\", \"*Q\"]\n",
    "    output_vars_schw = [\"*E\", \"*Lx\", \"*Ly\", \"*Lz\", \"*Q\"] # Q is L^2\n",
    "\n",
    "    body_C_code_kerr = ccg.c_codegen(list_of_expressions_kerr, output_vars_kerr, enable_cse=True, include_braces=False)\n",
    "    body_C_code_schw = ccg.c_codegen(list_of_expressions_schw, output_vars_schw, enable_cse=True, include_braces=False)\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Computes conserved quantities (E, L_i, Q/L^2) for a given state vector.\"\"\"\n",
    "    name = \"check_conservation\"\n",
    "    params = \"\"\"const commondata_struct *restrict commondata,\n",
    "        const params_struct *restrict params,\n",
    "        const metric_params *restrict metric_params_in,\n",
    "        const double y[9], \n",
    "        double *E, double *Lx, double *Ly, double *Lz, double *Q\"\"\"\n",
    "        \n",
    "    body = r\"\"\"\n",
    "    // Unpack parameters from commondata struct that are needed symbolically\n",
    "    const REAL a_spin = commondata->a_spin;\n",
    "\n",
    "    // Declare a POINTER to a metric_struct and allocate memory for it.\n",
    "    metric_struct* metric = (metric_struct*)malloc(sizeof(metric_struct));\n",
    "    \n",
    "    // Call the dispatcher to fill the allocated struct with metric components at the given state y.\n",
    "    g4DD_metric(commondata, params, metric_params_in, y, metric);\n",
    "\n",
    "    if (metric_params_in->type == Kerr) {\n",
    "        \"\"\" + body_C_code_kerr + r\"\"\"\n",
    "    } else { // Both Schwarzschild types are now Cartesian\n",
    "        \"\"\" + body_C_code_schw + r\"\"\"\n",
    "    }\n",
    "    \n",
    "    free(metric);\n",
    "    \"\"\"\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, cfunc_type=\"void\",\n",
    "        name=name, params=params, body=body\n",
    "    )\n",
    "\n",
    "    print(f\"    ... {name}() registration complete.\")\n",
    "\n",
    "#print(check_conservation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbc053b",
   "metadata": {},
   "source": [
    "<a id='radiative_transfer_engine'></a>\n",
    "### 6.B.2: Generic Engine: `radiative_transfer_engine()`\n",
    "\n",
    "This function generates the core C physics engine `calculate_radiative_transfer()`. This function implements the relativistic radiative transfer equation for an optically thin emitter, which connects the properties of the emitting gas to the light seen by a distant observer.\n",
    "\n",
    "It takes as input the photon's covariant 4-momentum ($p_\\mu$) at the point of emission, the fluid's covariant 4-velocity ($u_\\mu$) at that same point, and the fluid's intrinsic emissivity ($j_{int}$) and rest-frame emission wavelength ($\\lambda_{rest}$).\n",
    "\n",
    "The function then calculates the **redshift factor** (often denoted as `g` or `D`), which accounts for both gravitational redshift and the relativistic Doppler effect. This factor is the ratio of the energy of the photon as measured by the distant observer ($E_{obs}$) to the energy of the photon in the rest-frame of the emitting gas ($E_{emit}$):\n",
    "\n",
    "$$ g = \\frac{E_{obs}}{E_{emit}} = \\frac{(-p_\\mu u^\\mu)_{obs}}{(-p_\\mu u^\\mu)_{emit}} $$\n",
    "\n",
    "For a distant, stationary observer, their 4-velocity is simply $u^\\mu_{obs} = (1, 0, 0, 0)$, which simplifies the numerator to $E_{obs} = p_t$. The denominator is the full dot product of the photon's and the fluid's 4-momenta.\n",
    "\n",
    "Finally, it computes the observed physical quantities:\n",
    "*   **Observed Intensity:** For an optically thin source, the intensity scales as the cube of the redshift factor: $I_{obs} = j_{int} \\cdot g^3$.\n",
    "*   **Observed Wavelength:** The wavelength is directly shifted by the redshift factor: $\\lambda_{obs} = \\lambda_{rest} / g$.\n",
    "\n",
    "These final values are what are used to color the pixels in the final rendered image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10522182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radiative_transfer_engine():\n",
    "    \"\"\"\n",
    "    Generates the C engine for calculating the final observed intensity and\n",
    "    wavelength based on the interpolated disk state and photon momentum.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine for radiative transfer physics...\")\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\", \"<math.h>\"]\n",
    "    desc = r\"\"\"@brief Calculates the observed intensity and wavelength from the disk and photon state.\"\"\"\n",
    "    name = \"calculate_radiative_transfer\"\n",
    "    params = r\"\"\"\n",
    "    const double photon_p_mu[4], const double disk_u_mu[4],\n",
    "    const float disk_j_intrinsic, const double disk_lambda_rest,\n",
    "    double *stokes_I, double *lambda_observed\n",
    "    \"\"\"\n",
    "    body = r\"\"\"\n",
    "    // The observer is assumed to be at rest in the coordinate frame far away,\n",
    "    // so their 4-velocity is u_obs^mu = (1, 0, 0, 0).\n",
    "    // The metric is Minkowski far away, so u_obs_mu = (-1, 0, 0, 0).\n",
    "    // The photon momentum is p_mu.\n",
    "    // Therefore, (-p_mu u^mu)_obs = - (p_0 * -1) = p_0.\n",
    "    // NOTE: The photon momentum p_mu must be covariant (lower-indexed).\n",
    "    const double p_mu_u_mu_obs = photon_p_mu[0];\n",
    "\n",
    "    // Calculate (-p_mu u^mu)_disk\n",
    "    const double p_mu_u_mu_disk = - (photon_p_mu[0] * disk_u_mu[0] +\n",
    "                                     photon_p_mu[1] * disk_u_mu[1] +\n",
    "                                     photon_p_mu[2] * disk_u_mu[2] +\n",
    "                                     photon_p_mu[3] * disk_u_mu[3]);\n",
    "\n",
    "    // Doppler factor D = E_obs / E_disk = (-p_mu u^mu)_obs / (-p_mu u^mu)_disk\n",
    "    const double doppler_factor = p_mu_u_mu_obs / p_mu_u_mu_disk;\n",
    "\n",
    "    // Observed intensity I_obs = j_intrinsic * D^3\n",
    "    *stokes_I = disk_j_intrinsic * doppler_factor * doppler_factor * doppler_factor;\n",
    "\n",
    "    // Observed wavelength lambda_obs = lambda_rest / D\n",
    "    *lambda_observed = disk_lambda_rest / doppler_factor;\n",
    "\"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... Registered C engine: calculate_radiative_transfer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d05a64",
   "metadata": {},
   "source": [
    "<a id='handle_source_plane_intersection_engine'></a>\n",
    "### 6.B.3: `handle_source_plane_intersection()` Engine\n",
    "\n",
    "This function generates the C engine that processes a fallback **source plane** intersection event. It is called by the main integration loop when the `event_detection_manager` reports that a photon has hit the source plane.\n",
    "\n",
    "Its responsibilities are:\n",
    "1.  **Coordinate Transformation**: It takes the 3D Cartesian intersection point `(x, y, z)` from the event data. It then projects this point onto the source plane's own local, 2D orthonormal basis to calculate the texture coordinates `(y_s, z_s)`.\n",
    "2.  **Bounds Checking**: It checks if the calculated planar radius `r_s = sqrt(y_s^2 + z_s^2)` is within the user-defined active region (`source_r_min`, `source_r_max`).\n",
    "3.  **Populate Blueprint**: If the hit is within the valid region, it populates the relevant fields in the `blueprint_data_t` struct and returns `true`. Otherwise, it returns `false`, and the photon continues its integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71036f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_source_plane_intersection_engine():\n",
    "    \"\"\"\n",
    "    Generates a C engine that handles a source plane intersection.\n",
    "    This version is reverted to be compatible with the v11.7 termination_type_t enum.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine: handle_source_plane_intersection (v11.7 compatible)...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"<math.h>\", \"<stdbool.h>\"]\n",
    "    desc = r\"\"\"@brief Handles a source plane intersection by checking bounds and populating the blueprint.\"\"\"\n",
    "    name = \"handle_source_plane_intersection\"\n",
    "    cfunc_type = \"bool\"\n",
    "    params = r\"\"\"\n",
    "    const event_data_struct *restrict source_plane_event,\n",
    "    const commondata_struct *restrict commondata,\n",
    "    blueprint_data_t *restrict final_blueprint_data\n",
    "    \"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // --- Calculate the local (y_s, z_s) coordinates on the plane ---\n",
    "    const double intersection_pos[3] = {source_plane_event->y_event[1], source_plane_event->y_event[2], source_plane_event->y_event[3]};\n",
    "    const double source_plane_center[3] = {commondata->source_plane_center_x, commondata->source_plane_center_y, commondata->source_plane_center_z};\n",
    "    const double source_plane_normal[3] = {commondata->source_plane_normal_x, commondata->source_plane_normal_y, commondata->source_plane_normal_z};\n",
    "    const double source_up_vector[3] = {commondata->source_up_vec_x, commondata->source_up_vec_y, commondata->source_up_vec_z};\n",
    "\n",
    "    // Construct orthonormal basis vectors for the source plane\n",
    "    double s_z[3] = {source_plane_normal[0], source_plane_normal[1], source_plane_normal[2]};\n",
    "    double s_x[3] = {source_up_vector[1]*s_z[2] - source_up_vector[2]*s_z[1], \n",
    "                     source_up_vector[2]*s_z[0] - source_up_vector[0]*s_z[2], \n",
    "                     source_up_vector[0]*s_z[1] - source_up_vector[1]*s_z[0]};\n",
    "    double mag_s_x = sqrt(SQR(s_x[0]) + SQR(s_x[1]) + SQR(s_x[2]));\n",
    "    \n",
    "    if (mag_s_x < 1e-9) {\n",
    "        double alternative_up[3] = {1.0, 0.0, 0.0};\n",
    "        if (fabs(s_z[0]) > 0.999) {\n",
    "            alternative_up[0] = 0.0;\n",
    "            alternative_up[1] = 1.0;\n",
    "        }\n",
    "        s_x[0] = alternative_up[1]*s_z[2] - alternative_up[2]*s_z[1];\n",
    "        s_x[1] = alternative_up[2]*s_z[0] - alternative_up[0]*s_z[2];\n",
    "        s_x[2] = alternative_up[0]*s_z[1] - alternative_up[1]*s_z[0];\n",
    "        mag_s_x = sqrt(SQR(s_x[0]) + SQR(s_x[1]) + SQR(s_x[2]));\n",
    "    }\n",
    "    \n",
    "    for(int i=0; i<3; i++) s_x[i] /= mag_s_x;\n",
    "    \n",
    "    double s_y[3] = {s_z[1]*s_x[2] - s_z[2]*s_x[1], \n",
    "                     s_z[2]*s_x[0] - s_z[0]*s_x[2], \n",
    "                     s_z[0]*s_x[1] - s_z[1]*s_x[0]};\n",
    "\n",
    "    const double vec_s[3] = {intersection_pos[0] - source_plane_center[0], \n",
    "                             intersection_pos[1] - source_plane_center[1], \n",
    "                             intersection_pos[2] - source_plane_center[2]};\n",
    "    \n",
    "    const double y_s = vec_s[0]*s_x[0] + vec_s[1]*s_x[1] + vec_s[2]*s_x[2];\n",
    "    const double z_s = vec_s[0]*s_y[0] + vec_s[1]*s_y[1] + vec_s[2]*s_y[2];\n",
    "    \n",
    "    const double r_s_sq = SQR(y_s) + SQR(z_s);\n",
    "    \n",
    "    if (r_s_sq >= SQR(commondata->source_r_min) && r_s_sq <= SQR(commondata->source_r_max)) {\n",
    "        // This is a valid hit. Populate the blueprint and return true.\n",
    "        // *** REVERTED: Use the correct enum member from termination_type_t ***\n",
    "        final_blueprint_data->termination_type = TERMINATION_TYPE_SOURCE_PLANE;\n",
    "        final_blueprint_data->y_s = y_s;\n",
    "        final_blueprint_data->z_s = z_s;\n",
    "        final_blueprint_data->t_s = source_plane_event->t_event;\n",
    "        final_blueprint_data->L_s = source_plane_event->y_event[8];\n",
    "        return true;\n",
    "    }\n",
    "    \n",
    "    // The intersection was outside the valid radial bounds. Return false.\n",
    "    return false;\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, cfunc_type=cfunc_type, params=params, body=body)\n",
    "    print(f\"    ... Registered C engine: {name}().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ba4133",
   "metadata": {},
   "source": [
    "<a id='handle_disk_intersection_engine'></a>\n",
    "### 6.B.4: `handle_disk_intersection()` Engine\n",
    "\n",
    "This function generates the C engine that performs the final physics calculations for a photon that has terminated on the physical **accretion disk**. It is called by the main \"finalizer\" function (`calculate_and_fill_blueprint_data_universal`) after all integration is complete.\n",
    "\n",
    "This engine orchestrates the full radiative transfer calculation:\n",
    "1.  **Get Metric**: It calls the `g4DD_metric` dispatcher to get the metric tensor `g_{\\mu\\nu}` at the photon's final intersection point.\n",
    "2.  **Lower Indices**: It uses the metric to lower the indices of both the photon's 4-momentum (converting $p^\\mu$ to $p_\\mu$) and the disk particle's 4-velocity (converting $u^\\mu$ to $u_\\mu$). This is mathematically essential for the next step.\n",
    "3.  **Call Radiative Transfer Engine**: It passes the covariant vectors and the intrinsic properties of the disk particle (stored in the `nearest_neighbor` struct) to the `calculate_radiative_transfer()` engine.\n",
    "4.  **Populate Blueprint**: The `calculate_radiative_transfer` engine computes the final observed intensity and wavelength. This function then populates the `blueprint_data_t` struct with these physical results, as well as diagnostic information like the intersection time and path length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87eaa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_disk_intersection_engine():\n",
    "    \"\"\"\n",
    "    Generates the C engine for handling a disk intersection. This definitive\n",
    "    version (v6.0) is repurposed as a pure physics calculator, to be called\n",
    "    only during the finalization phase.\n",
    "    \"\"\"\n",
    "    print(\" -> Repurposing C engine: handle_disk_intersection (v6.0)...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"<math.h>\"]\n",
    "    desc = r\"\"\"@brief Performs the final radiative transfer calculation for a disk intersection.\n",
    "    @details This engine is called by the finalizer. It takes the photon's final\n",
    "             state and the stored nearest-neighbor data, computes the observed\n",
    "             intensity and wavelength, and populates the final blueprint record.\n",
    "    \"\"\"\n",
    "    name = \"handle_disk_intersection\"\n",
    "    \n",
    "    # *** CORRECTED: New signature for its new role as a finalizer helper. ***\n",
    "    params = r\"\"\"\n",
    "    const double final_y[9],\n",
    "    const MassiveParticle *restrict nearest_neighbor,\n",
    "    const commondata_struct *restrict commondata, const params_struct *restrict params,\n",
    "    const metric_params *restrict metric,\n",
    "    blueprint_data_t *restrict final_blueprint_data\n",
    "    \"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // This function now assumes the photon's status is already TERMINATED_DISK.\n",
    "    \n",
    "    // 1. Get metric at the photon's final position (the intersection point).\n",
    "    metric_struct g4DD;\n",
    "    g4DD_metric(commondata, params, metric, final_y, &g4DD);\n",
    "    \n",
    "    // 2. Lower the indices of the photon's 4-momentum and the neighbor's 4-velocity\n",
    "    //    using the metric at the intersection point.\n",
    "    const double g_munu[4][4] = {\n",
    "        {g4DD.g00, g4DD.g01, g4DD.g02, g4DD.g03},\n",
    "        {g4DD.g01, g4DD.g11, g4DD.g12, g4DD.g13},\n",
    "        {g4DD.g02, g4DD.g12, g4DD.g22, g4DD.g23},\n",
    "        {g4DD.g03, g4DD.g13, g4DD.g23, g4DD.g33}\n",
    "    };\n",
    "    \n",
    "    double photon_p_mu[4] = {0,0,0,0};\n",
    "    double disk_u_mu[4] = {0,0,0,0};\n",
    "    for(int mu=0; mu<4; mu++) {\n",
    "        for(int nu=0; nu<4; nu++) {\n",
    "            photon_p_mu[mu] += g_munu[mu][nu] * final_y[nu+4];\n",
    "            disk_u_mu[mu] += g_munu[mu][nu] * nearest_neighbor->u[nu];\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // 3. Call the core radiative transfer physics engine.\n",
    "    double temp_stokes_I;\n",
    "    double temp_lambda_observed;\n",
    "    calculate_radiative_transfer(photon_p_mu, disk_u_mu, \n",
    "                                 nearest_neighbor->j_intrinsic, nearest_neighbor->lambda_rest,\n",
    "                                 &temp_stokes_I, &temp_lambda_observed);\n",
    "    \n",
    "    // 4. Populate the final blueprint with the results.\n",
    "    final_blueprint_data->stokes_I = temp_stokes_I;\n",
    "    final_blueprint_data->lambda_observed = temp_lambda_observed;\n",
    "    \n",
    "    // 5. Populate diagnostic information from the intersection.\n",
    "    final_blueprint_data->y_s = nearest_neighbor->pos[0]; // x-pos of neighbor\n",
    "    final_blueprint_data->z_s = nearest_neighbor->pos[1]; // y-pos of neighbor\n",
    "    final_blueprint_data->t_s = final_y[0]; // time of intersection\n",
    "    final_blueprint_data->L_s = final_y[8]; // path length at intersection\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)\n",
    "    print(f\"    ... Registered C engine: {name}() (Repurposed as Finalizer Helper).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085bbf41",
   "metadata": {},
   "source": [
    "<a id='filename_sorter'></a>\n",
    "### 6.B.5: K-d Tree and Numerical Metric Helper Functions\n",
    "\n",
    "The following cells generate a series of C helper functions that are essential for managing the external data required by the simulation, such as the k-d tree snapshots and the numerical metric slices. These functions handle tasks like file I/O, sorting, and memory management.\n",
    "\n",
    "This first function, `filename_sorter`, generates a C comparison function `compare_filenames`. This small utility is required by the standard C library's `qsort` function. Its only job is to compare two snapshot filenames (e.g., `mass_blueprint_t_0100.kdtree.bin` and `mass_blueprint_t_0110.kdtree.bin`) based on their numerical timestamp, ensuring that when we load all the snapshot files, they are in the correct chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1467f76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_sorter():\n",
    "    \"\"\"\n",
    "    Generates a C helper function to be used by qsort for sorting snapshot filenames.\n",
    "    \"\"\"\n",
    "    print(\" -> Registering C helper: filename_sorter()...\")\n",
    "    includes = [\"stdio.h\", \"<stdlib.h>\"]\n",
    "    desc = \"Comparison function for qsort to sort filenames numerically.\"\n",
    "    name = \"compare_filenames\"\n",
    "    cfunc_type = \"int\"\n",
    "    params = \"const void *a, const void *b\"\n",
    "    body = r\"\"\"\n",
    "    const char *str_a = *(const char **)a;\n",
    "    const char *str_b = *(const char **)b;\n",
    "    int num_a, num_b;\n",
    "    sscanf(str_a, \"mass_blueprint_t_%d.kdtree.bin\", &num_a);\n",
    "    sscanf(str_b, \"mass_blueprint_t_%d.kdtree.bin\", &num_b);\n",
    "    return (num_a > num_b) - (num_a < num_b);\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, cfunc_type=cfunc_type, params=params, body=body)\n",
    "    print(f\"    ... Registered C helper: {name}().\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013b24d",
   "metadata": {},
   "source": [
    "<a id='kdtree_loader'></a>\n",
    "### 6.B.6: K-d Tree Snapshot Loader and Unloader\n",
    "\n",
    "This Python function generates two low-level C worker functions for managing the memory of a single k-d tree snapshot file.\n",
    "\n",
    "*   **`load_kdtree_snapshot()`**: This function is responsible for loading a single `.kdtree.bin` file into memory. To achieve maximum performance and minimize RAM usage, it uses the `mmap` (memory-map) system call. Instead of reading the entire (potentially very large) file into the heap, `mmap` tells the operating system's virtual memory manager to map the file directly into the program's address space. The data is then loaded from disk on-demand by the OS as it is accessed.\n",
    "*   **`unload_kdtree_snapshot()`**: This function calls `munmap` to release the memory mapping created by the loader, ensuring there are no resource leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9893971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdtree_loader_and_unloader():\n",
    "    \"\"\"\n",
    "    Generates C functions for memory-mapping a .kdtree.bin file into memory\n",
    "    and for unmapping it.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C functions for k-d tree memory mapping...\")\n",
    "\n",
    "    # Function to load a snapshot\n",
    "    load_includes = [\"BHaH_defines.h\", \"<stdio.h>\", \"<stdlib.h>\", \"<sys/mman.h>\", \"<sys/stat.h>\", \"<fcntl.h>\", \"<unistd.h>\"]\n",
    "    load_desc = r\"\"\"@brief Loads a .kdtree.bin snapshot file into memory using mmap.\"\"\"\n",
    "    load_name = \"load_kdtree_snapshot\"\n",
    "    load_params = \"const char *filename, CustomKDTree *tree\"\n",
    "    load_body = r\"\"\"\n",
    "    int fd = open(filename, O_RDONLY);\n",
    "    if (fd == -1) {\n",
    "        perror(\"Error opening k-d tree file\");\n",
    "        return -1; // Failure\n",
    "    }\n",
    "\n",
    "    struct stat sb;\n",
    "    if (fstat(fd, &sb) == -1) {\n",
    "        perror(\"Error getting file size\");\n",
    "        close(fd);\n",
    "        return -1;\n",
    "    }\n",
    "    tree->file_size = sb.st_size;\n",
    "\n",
    "    void *mapped_mem = mmap(NULL, tree->file_size, PROT_READ, MAP_PRIVATE, fd, 0);\n",
    "    if (mapped_mem == MAP_FAILED) {\n",
    "        perror(\"Error memory-mapping the file\");\n",
    "        close(fd);\n",
    "        return -1;\n",
    "    }\n",
    "    close(fd); // File descriptor no longer needed after mmap\n",
    "\n",
    "    tree->original_mmap_ptr = mapped_mem;\n",
    "    char *current_ptr = (char *)mapped_mem;\n",
    "\n",
    "    // Read header\n",
    "    tree->num_particles = *(uint64_t *)current_ptr;\n",
    "    current_ptr += sizeof(uint64_t);\n",
    "    tree->dimensions = *(uint64_t *)current_ptr;\n",
    "    current_ptr += sizeof(uint64_t);\n",
    "\n",
    "    // Set pointers to payloads\n",
    "    tree->node_metadata = (int32_t *)current_ptr;\n",
    "    current_ptr += sizeof(int32_t) * tree->num_particles;\n",
    "    tree->particle_data = (MassiveParticle *)current_ptr;\n",
    "\n",
    "    return 0; // Success\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=load_includes, desc=load_desc, name=load_name, params=load_params, body=load_body, cfunc_type=\"int\")\n",
    "\n",
    "    # Function to unload a snapshot\n",
    "    unload_includes = [\"BHaH_defines.h\", \"<sys/mman.h>\"]\n",
    "    unload_desc = r\"\"\"@brief Unloads a memory-mapped k-d tree snapshot.\"\"\"\n",
    "    unload_name = \"unload_kdtree_snapshot\"\n",
    "    unload_params = \"CustomKDTree *tree\"\n",
    "    unload_body = r\"\"\"\n",
    "    if (tree->original_mmap_ptr != NULL) {\n",
    "        munmap(tree->original_mmap_ptr, tree->file_size);\n",
    "        tree->original_mmap_ptr = NULL;\n",
    "    }\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=unload_includes, desc=unload_desc, name=unload_name, params=unload_params, body=unload_body)\n",
    "    \n",
    "    print(\"    ... Registered C functions: load_kdtree_snapshot, unload_kdtree_snapshot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f49d2e",
   "metadata": {},
   "source": [
    "<a id='placeholder_interpolator'></a>\n",
    "### 6.B.7: Placeholder Engine for External Interpolator\n",
    "\n",
    "This Python function generates the C function `placeholder_interpolation_engine()`. This is the cornerstone of our Phase 1 development strategy for integrating the professor's external interpolation library.\n",
    "\n",
    "This function serves as a **stand-in** or **mock** of the final, high-performance numerical interpolation engine. It has the **exact C API** that the final engine will have: it takes a batch of photon position `requests` and is expected to fill an `outputs` array with the corresponding Christoffel symbols.\n",
    "\n",
    "However, its internal logic does **not** perform interpolation. Instead, it loops through each request and calls our existing, trusted **analytic** C worker (`connections`) to compute the Christoffel symbols for that point.\n",
    "\n",
    "This powerful technique allows us to build and validate the entire complex \"Request-Compute-Distribute\" control flow of the numerical pipeline (`batch_integrator_numerical`) using a known-good source of Christoffel symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb03216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V12_5_light_geodesic.ipynb\n",
    "# This is the DEFINITIVE replacement for the placeholder_interpolator() cell.\n",
    "\n",
    "def placeholder_interpolator():\n",
    "    \"\"\"\n",
    "    Generates the high-fidelity C placeholder for the external interpolation engine.\n",
    "    \n",
    "    This version correctly bypasses the high-level dispatchers and calls the\n",
    "    low-level analytic WORKER functions directly, providing a true analytic\n",
    "    baseline for the numerical pipeline.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C placeholder engine: placeholder_interpolation_engine()...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"\n",
    " Placeholder for the external batch-processing interpolation engine.\n",
    " \n",
    " ========================================================================\n",
    " ================== THIS IS A VALIDATION PLACEHOLDER ==================\n",
    " This function will be replaced by the high-performance numerical engine\n",
    " provided by the professor.\n",
    " ========================================================================\n",
    " \n",
    " It mimics the required API but computes the metric and Christoffel symbols\n",
    " by calling the low-level ANALYTIC WORKER functions directly. This provides\n",
    " a ground-truth analytic result for validating the numerical control flow.\n",
    " \n",
    "\"\"\"\n",
    "    name = \"placeholder_interpolation_engine\"\n",
    "    params = \"\"\"int num_photons, \n",
    "                const photon_request_t requests[], \n",
    "                metric_struct metric_outputs[],\n",
    "                connection_struct conn_outputs[],\n",
    "                const commondata_struct *restrict commondata,\n",
    "                const params_struct *restrict params,\n",
    "                const metric_params *restrict metric\"\"\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "    // This function loops through each request and computes the metric and\n",
    "    // Christoffels individually by calling the high-level dispatchers.\n",
    "    #pragma omp parallel for\n",
    "    for (int i = 0; i < num_photons; ++i) {\n",
    "        // The analytic dispatcher functions expect a 9-element state vector.\n",
    "        // To call them safely, we create a temporary padded array on the stack.\n",
    "        // We only need to fill the first 4 position components from the request.\n",
    "        // The other 5 components (momentum, path length) are not used by these\n",
    "        // specific dispatcher functions.\n",
    "        double y_padded[9];\n",
    "        y_padded[0] = requests[i].pos[0]; // t\n",
    "        y_padded[1] = requests[i].pos[1]; // x\n",
    "        y_padded[2] = requests[i].pos[2]; // y\n",
    "        y_padded[3] = requests[i].pos[3]; // z\n",
    "\n",
    "        // Now, call the high-level DISPATCHERS with the correctly-sized array.\n",
    "        // These functions will internally use the 'metric->type' to call the\n",
    "        // correct low-level worker (e.g., g4DD_kerr_schild).\n",
    "        g4DD_metric(commondata, params, metric, y_padded, &metric_outputs[i]);\n",
    "        connections(commondata, params, metric, y_padded, &conn_outputs[i]);\n",
    "    }\n",
    "\"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body\n",
    "    )\n",
    "    print(f\"    ... Registered C placeholder engine: {name}() [High-Fidelity, Direct-Worker Call Version].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a3bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algebraic_christoffel_worker():\n",
    "    \"\"\"\n",
    "    Generates the C worker that computes Christoffel symbols from pre-computed\n",
    "    metric and metric derivative values. This is a pure algebraic function.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C algebraic engine: calculate_christoffels_from_metric_and_derivs()...\")\n",
    "\n",
    "    # Step 1: Get the symbolic recipe.\n",
    "    Gamma4UDD_num_recipe = symbolic_numerical_christoffel_recipe()\n",
    "\n",
    "    # Step 2: Prepare lists for C code generation.\n",
    "    list_of_Gamma_C_vars = []\n",
    "    list_of_Gamma_syms = []\n",
    "    conn_Gamma4UDD = ixp.declarerank3(\"conn_out->Gamma4UDD\", dimension=4)\n",
    "    for alpha in range(4):\n",
    "        for mu in range(4):\n",
    "            for nu in range(mu, 4):\n",
    "                list_of_Gamma_C_vars.append(str(conn_Gamma4UDD[alpha][mu][nu]))\n",
    "                list_of_Gamma_syms.append(Gamma4UDD_num_recipe[alpha][mu][nu])\n",
    "\n",
    "    # Step 3: Generate the C preamble to unpack structs into local variables.\n",
    "    preamble = \"// Unpack input structs into local variables that match symbolic recipe.\\n\"\n",
    "    g_components = [f\"g{i}{j}\" for i in range(4) for j in range(i, 4)]\n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            preamble += f\"    const double g4DD{i}{j} = g4DD_in->g{i}{j};\\n\"\n",
    "    \n",
    "    for i in range(4):\n",
    "        for j in range(i, 4):\n",
    "            for k in range(4):\n",
    "                preamble += f\"    const double g4DDdD{i}{j}_d{k} = g4DDdD_in->g{i}{j}d{k};\\n\"\n",
    "\n",
    "    # Step 4: Generate the computational kernel.\n",
    "    kernel_C_code = ccg.c_codegen(\n",
    "        list_of_Gamma_syms,\n",
    "        list_of_Gamma_C_vars,\n",
    "        enable_cse=True,\n",
    "        cse_varprefix=\"num_conn_intermed\"\n",
    "    )\n",
    "\n",
    "    # Step 5: Assemble and register the function.\n",
    "    body = preamble + kernel_C_code\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "    desc = \"Computes Christoffel symbols from pre-interpolated metric and derivative values.\"\n",
    "    name = \"calculate_christoffels_from_metric_and_derivs\"\n",
    "    params = \"\"\"const metric_struct *restrict g4DD_in,\n",
    "                const g4DD_deriv_struct *restrict g4DDdD_in,\n",
    "                connection_struct *restrict conn_out\"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, name=name, params=params, body=body\n",
    "    )\n",
    "    print(f\"    ... Registered C algebraic engine: {name}().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfb35e2",
   "metadata": {},
   "source": [
    "<a id='rkf45_helpers'></a>\n",
    "### 6.B.8: The RKF45 Stepper Kernels\n",
    "\n",
    "This Python function generates the core computational C functions for our custom **Runge-Kutta-Fehlberg 4(5)** adaptive integrator. The RKF45 method is a popular choice for solving ODEs because it provides an efficient way to estimate the error at each step, allowing the step size to be adjusted automatically to maintain a desired level of accuracy.\n",
    "\n",
    "This is achieved by calculating two solutions at each step: a 4th-order accurate solution and a 5th-order accurate solution. The difference between these two provides an estimate of the local truncation error.\n",
    "\n",
    "The `nrpy` generator `rkf45_helpers_for_header()` creates two C helper functions:\n",
    "\n",
    "1.  **`calculate_intermediate_state()`**: An ODE step involves evaluating the right-hand-side (RHS) function at several intermediate points. This helper function takes the state at the beginning of the step (`y_in`) and the previously calculated intermediate derivatives (`k_array`) to compute the state vector `y_temp` at the next required stage. The coefficients used (e.g., `1.0/4.0`, `3.0/32.0`) are the standard, pre-defined values for the RKF45 method, often presented in a \"Butcher tableau.\"\n",
    "\n",
    "2.  **`rkf45_kernel()`**: After all six intermediate `k` vectors (the derivatives at each stage) have been computed, this kernel performs the final summations. It combines the `k` vectors with another set of pre-defined coefficients to produce the final 4th-order accurate state (`y_4th`) and the 5th-order accurate state (`y_out`). It then computes the difference, `y_err = y_out - y_4th`, which will be used by the step-size controller.\n",
    "\n",
    "Because these functions are small, purely computational, and called within the tightest loop of the integrator, they are generated as `static inline` functions. This allows the C compiler to potentially inline them directly into the calling code, eliminating function call overhead and maximizing performance. They are registered for injection directly into the `BHaH_defines.h` master header file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd5446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rkf45_helpers_for_header():\n",
    "    \"\"\"\n",
    "    Generates the C code for the rkf45_kernel and calculate_intermediate_state\n",
    "    helper functions and registers them to be injected directly into BHaH_defines.h.\n",
    "    \n",
    "    This is the correct approach for static inline helper functions.\n",
    "    \"\"\"\n",
    "    print(\" -> Registering RKF45 helper kernels for BHaH_defines.h...\")\n",
    "\n",
    "    # The entire C code block to be injected into the header\n",
    "    c_code_for_header = r\"\"\"\n",
    "// =============================================\n",
    "// NRPy-Generated RKF45 Stepper Helpers\n",
    "// =============================================\n",
    "\n",
    "// --- RKF45 Kernel ---\n",
    "// Pure computational kernel for the RKF45 method.\n",
    "static inline void rkf45_kernel(\n",
    "    const double y_in[9],           // The state at the beginning of the step\n",
    "    const double k_array[6][9],     // Array of the 6 pre-computed k vectors\n",
    "    const double h,                 // The step size attempted\n",
    "    double y_out[9],                // Output: the final 5th-order state\n",
    "    double y_err[9]                 // Output: the error vector (y_5th - y_4th)\n",
    ") {\n",
    "    // Calculate the 4th-Order Accurate Solution for the error estimate.\n",
    "    double y_4th[9];\n",
    "    for (int i = 0; i < 9; ++i) {\n",
    "        y_4th[i] = y_in[i] + h * ( (25.0/216.0) * k_array[0][i] +\n",
    "                                   (1408.0/2565.0) * k_array[2][i] +\n",
    "                                   (2197.0/4104.0) * k_array[3][i] -\n",
    "                                   (1.0/5.0) * k_array[4][i] );\n",
    "    }\n",
    "\n",
    "    // Calculate the 5th-Order Accurate Solution for the final state.\n",
    "    for (int i = 0; i < 9; ++i) {\n",
    "        y_out[i] = y_in[i] + h * ( (16.0/135.0) * k_array[0][i] +\n",
    "                                   (6656.0/12825.0) * k_array[2][i] +\n",
    "                                   (28561.0/56430.0) * k_array[3][i] -\n",
    "                                   (9.0/50.0) * k_array[4][i] +\n",
    "                                   (2.0/55.0) * k_array[5][i] );\n",
    "    }\n",
    "\n",
    "    // Calculate the Error Vector.\n",
    "    for (int i = 0; i < 9; ++i) {\n",
    "        y_err[i] = y_out[i] - y_4th[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "// --- Intermediate State Calculator ---\n",
    "// Computes the intermediate state vector for a specific RKF45 stage.\n",
    "static inline void calculate_intermediate_state(\n",
    "    const int stage,                // The stage to compute (1-6, for k1-k6)\n",
    "    const double y_in[9],           // The state at the beginning of the step\n",
    "    const double k_array[6][9],     // Array of the k vectors (only previous stages are valid)\n",
    "    const double h,                 // The step size\n",
    "    double y_temp[9]                // Output: the temporary state vector for the stage\n",
    ") {\n",
    "    switch (stage) {\n",
    "        case 1:\n",
    "            for (int i = 0; i < 9; ++i) y_temp[i] = y_in[i];\n",
    "            break;\n",
    "        case 2:\n",
    "            for (int i = 0; i < 9; ++i) y_temp[i] = y_in[i] + h * (1.0/4.0) * k_array[0][i];\n",
    "            break;\n",
    "        case 3:\n",
    "            for (int i = 0; i < 9; ++i) y_temp[i] = y_in[i] + h * ( (3.0/32.0)*k_array[0][i] + (9.0/32.0)*k_array[1][i] );\n",
    "            break;\n",
    "        case 4:\n",
    "            for (int i = 0; i < 9; ++i) y_temp[i] = y_in[i] + h * ( (1932.0/2197.0)*k_array[0][i] - (7200.0/2197.0)*k_array[1][i] + (7296.0/2197.0)*k_array[2][i] );\n",
    "            break;\n",
    "        case 5:\n",
    "            for (int i = 0; i < 9; ++i) y_temp[i] = y_in[i] + h * ( (439.0/216.0)*k_array[0][i] - 8.0*k_array[1][i] + (3680.0/513.0)*k_array[2][i] - (845.0/4104.0)*k_array[3][i] );\n",
    "            break;\n",
    "        case 6:\n",
    "            for (int i = 0; i < 9; ++i) y_temp[i] = y_in[i] + h * ( -(8.0/27.0)*k_array[0][i] + 2.0*k_array[1][i] - (3544.0/2565.0)*k_array[2][i] + (1859.0/4104.0)*k_array[3][i] - (11.0/40.0)*k_array[4][i] );\n",
    "            break;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "    \n",
    "    Bdefines_h.register_BHaH_defines(\"rkf45_helpers\", c_code_for_header)\n",
    "    print(\"    ... RKF45 helpers registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdf58ca",
   "metadata": {},
   "source": [
    "<a id='rkf45_control'></a>\n",
    "### 6.B.9: The RKF45 Step-Size Controller\n",
    "\n",
    "This `nrpy` generator creates the \"brain\" of our adaptive integrator: the C helper function `update_photon_state_and_stepsize()`. After the `rkf45_kernel` has computed the 5th-order solution (`y_out`) and the error estimate (`y_err`), this controller decides whether the step was successful and calculates the optimal size for the *next* step.\n",
    "\n",
    "The process follows a robust, GSL-style algorithm:\n",
    "\n",
    "1.  **Error Normalization**: The raw error `y_err` is not useful on its own. An error of `1e-7` might be excellent for a coordinate `x` that is `~100`, but terrible for a coordinate `y` that is `~1e-6`. The controller computes a scale factor for each component of the state vector based on both the desired **absolute tolerance (`atol`)** and **relative tolerance (`rtol`)**.\n",
    "    \n",
    "    $$ \\text{scale}_i = \\text{atol} + \\text{rtol} \\cdot |y_i| $$\n",
    "    \n",
    "    It then computes a single weighted error norm (`err_norm`) from all 9 components. A special consideration is made for coordinate time (`y[0]`) and path length (`y[8]`), which can grow without bound; for these, only the absolute tolerance is used to prevent them from dominating the error metric.\n",
    "\n",
    "2.  **Step Acceptance/Rejection**: The normalized error `err_norm` is compared to a target tolerance (which is `1.0` by definition).\n",
    "    *   If `err_norm <= 1.0`, the step is **accepted**. The photon's state is updated to `y_out`.\n",
    "    *   If `err_norm > 1.0`, the step is **rejected**. The photon's state is *not* updated, and the integrator will retry the step from the same starting point but with a smaller step size.\n",
    "\n",
    "3.  **New Step-Size Calculation**: Regardless of whether the step was accepted or rejected, a new, optimal step size `h_new` is calculated using the formula:\n",
    "    \n",
    "    $$ h_{\\text{new}} = h_{\\text{old}} \\cdot S \\cdot \\left( \\frac{\\text{tolerance}}{\\text{err\\_norm}} \\right)^{0.2} $$\n",
    "    \n",
    "    where `S` is a safety factor (typically 0.9) to prevent overly optimistic increases in step size. The exponent `0.2` (or 1/5) is specific to the RKF45 method. The new step size is then clamped between user-defined minimum (`h_min`) and maximum (`h_max`) values.\n",
    "\n",
    "Like the kernels, this function is generated as a `static inline` C function and injected into `BHaH_defines.h`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080eb3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rkf45_update_and_control_helper():\n",
    "    \"\"\"\n",
    "    Generates the C helper function `update_photon_state_and_stepsize` and\n",
    "    registers it to be injected directly into BHaH_defines.h.\n",
    "\n",
    "    This version implements a robust, GSL-style error controller that uses\n",
    "    both absolute and relative tolerances, and treats the time and path length\n",
    "    components specially to ensure coordinate-time independence.\n",
    "    \"\"\"\n",
    "    print(\" -> Registering RKF45 update/control helper for BHaH_defines.h [Robust Error Control]...\")\n",
    "\n",
    "    c_code_for_header = r\"\"\"\n",
    "// --- Adaptive Step-Size Controller (Robust, GSL-Style) ---\n",
    "// Manages the adaptive step-size control for the RKF45 stepper.\n",
    "static inline bool update_photon_state_and_stepsize(\n",
    "    PhotonState *restrict photon,         // Pointer to the photon's full state\n",
    "    const double y_start[9],              // The state at the START of the step (for scaling)\n",
    "    const double y_out[9],                // The 5th-order result from the kernel\n",
    "    const double y_err[9],                // The error vector from the kernel\n",
    "    const commondata_struct *restrict commondata // For accessing control parameters\n",
    ") {\n",
    "    // This function implements a robust error control mechanism similar to that\n",
    "    // used in the GNU Scientific Library (GSL). It computes a scale factor for\n",
    "    // each component of the state vector and calculates a weighted error norm.\n",
    "\n",
    "    const double rtol = commondata->rkf45_error_tolerance;\n",
    "    const double atol = commondata->rkf45_absolute_error_tolerance;\n",
    "    double err_norm_sq = 0.0;\n",
    "\n",
    "    // --- Calculate the squared error norm, treating components differently ---\n",
    "    \n",
    "    // For physical components (spatial position and 4-momentum, y[1]..y[7]),\n",
    "    // use a scale that combines absolute and relative tolerances.\n",
    "    for (int i = 1; i < 8; ++i) {\n",
    "        const double scale_y = atol + rtol * fabs(y_start[i]);\n",
    "        const double ratio = y_err[i] / scale_y;\n",
    "        err_norm_sq += ratio * ratio;\n",
    "    }\n",
    "\n",
    "    // For coordinate time (y[0]) and path length (y[8]), which can grow\n",
    "    // indefinitely, use a purely absolute tolerance to prevent their large\n",
    "    // magnitudes from dominating the error and making the controller insensitive\n",
    "    // to physical errors.\n",
    "    const double scale_t = atol;\n",
    "    const double ratio_t = y_err[0] / scale_t;\n",
    "    err_norm_sq += ratio_t * ratio_t;\n",
    "\n",
    "    const double scale_L = atol;\n",
    "    const double ratio_L = y_err[8] / scale_L;\n",
    "    err_norm_sq += ratio_L * ratio_L;\n",
    "\n",
    "    // Final error norm is the root-mean-square of the weighted errors.\n",
    "    const double err_norm = sqrt(err_norm_sq / 9.0);\n",
    "\n",
    "    const double tolerance = 1.0; // The target for our normalized error is 1.0\n",
    "    bool step_accepted = (err_norm <= tolerance);\n",
    "\n",
    "    double h_new;\n",
    "    if (err_norm > 1e-15) {\n",
    "        // Standard formula for step-size adjustment.\n",
    "        h_new = commondata->rkf45_safety_factor * photon->h * pow(tolerance / err_norm, 0.2);\n",
    "    } else {\n",
    "        // If error is zero or tiny, increase step size by a fixed factor.\n",
    "        h_new = 2.0 * photon->h;\n",
    "    }\n",
    "\n",
    "    // Enforce minimum and maximum step sizes.\n",
    "    h_new = fmax(h_new, commondata->rkf45_h_min);\n",
    "    h_new = fmin(h_new, commondata->rkf45_h_max);\n",
    "\n",
    "    if (step_accepted) {\n",
    "        // If step is accepted, update the state and reset retry counter.\n",
    "        for (int i = 0; i < 9; ++i) {\n",
    "            photon->y[i] = y_out[i];\n",
    "        }\n",
    "        photon->affine_param += photon->h;\n",
    "        photon->rejection_retries = 0;\n",
    "    } else {\n",
    "        // If step is rejected, increment retry counter. The state is NOT updated.\n",
    "        photon->rejection_retries++;\n",
    "    }\n",
    "    \n",
    "    // The step size for the *next* attempt is always updated.\n",
    "    photon->h = h_new;\n",
    "    return step_accepted;\n",
    "}\n",
    "\"\"\"\n",
    "    \n",
    "    Bdefines_h.register_BHaH_defines(\"rkf45_update_control\", c_code_for_header)\n",
    "    print(\"    ... RKF45 update/control helper registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a7cba7",
   "metadata": {},
   "source": [
    "<a id='ode_rhs_engine'></a>\n",
    "### 6.B.10: The Generic ODE Right-Hand-Side Engine\n",
    "\n",
    "This function generates the C engine `calculate_ode_rhs()`. This is a pure, generic physics engine that is completely decoupled from any specific spacetime. Its sole responsibility is to compute the right-hand sides (the derivatives) for our entire system of 9 ODEs.\n",
    "\n",
    "It takes the photon's current state vector `y` and the pre-computed geometric quantities (the metric `g_μν` and Christoffel symbols `Γ^α_μν`) as input. It then uses the symbolic \"recipes\" we defined in Step 3 to calculate the derivatives:\n",
    "\n",
    "1.  **Position ODE**: `dx^α/dκ = p^α` (from `geodesic_pos_rhs`)\n",
    "2.  **Momentum ODE**: `dp^α/dκ = -Γ^α_μν p^μ p^ν` (from `geodesic_mom_rhs`)\n",
    "3.  **Path Length ODE**: `dL/dκ = sqrt(γ_ij p^i p^j)` (from `proper_lengh_rhs`)\n",
    "\n",
    "Because this function was generated from symbolic recipes that used abstract placeholders like `conn->Gamma4UDD...`, the resulting C code is valid for *any* metric. It does not care whether the Christoffel symbols were computed from an analytic formula (like Kerr-Schild) or interpolated from a numerical grid; it simply applies the laws of geodesic motion to the data it is given. This makes it a central, reusable component of the entire project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc2e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ode_rhs():\n",
    "\n",
    "    rhs_output_vars = [f\"rhs_out[{i}]\" for i in range(9)]\n",
    "\n",
    "\n",
    "\n",
    "    includes = [\"BHaH_defines.h\"]\n",
    "\n",
    "    desc = r\"\"\"@brief Calculates the right-hand sides (RHS) of the 9 geodesic ODEs.\n",
    " \n",
    "    This function implements the generic geodesic equation using pre-computed\n",
    "    Christoffel symbols. It is a pure \"engine\" function that does not depend\n",
    "    on any specific metric's parameters (like M_scale), only on the geometric\n",
    "    values passed to it via the connection struct.\n",
    "\n",
    "    @param[in]  y         The 9-component state vector [t, r, th, ph, p^t, p^r, p^th, p^ph, L].\n",
    "    @param[in]  conn      A pointer to the connection_struct holding the pre-computed Christoffel symbols.\n",
    "    @param[out] rhs_out   A pointer to the 9-component output array where the RHS results are stored.\"\"\"\n",
    "            \n",
    "    name = \"calculate_ode_rhs\"\n",
    "    params = \"const double y[9], const metric_struct *restrict metric, const connection_struct *restrict conn, double rhs_out[9]\"\n",
    "\n",
    "    body=ccg.c_codegen(all_rhs_expressions,rhs_output_vars)\n",
    "\n",
    "    cfc.register_CFunction(\n",
    "        includes= includes,\n",
    "        name=name,\n",
    "        desc=desc,\n",
    "        params=params,\n",
    "        body=body\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b1209",
   "metadata": {},
   "source": [
    "<a id='lagrange_interp_engine'></a>\n",
    "### 6.B.11: `find_event_time_and_state()` Interpolation Engine\n",
    "\n",
    "This Python function generates a crucial C **engine** called `find_event_time_and_state()`. Its purpose is to find the precise time and state vector of a \"plane-crossing\" event with high accuracy, using data from three consecutive steps of the ODE integrator. This is essential for accurately mapping where a ray hits the window and source planes.\n",
    "\n",
    "The function implements a robust interpolation scheme:\n",
    "1.  **Quadratic Root Finding:** It treats the event condition (e.g., the distance to a plane, `f(y) = n_i x^i - d = 0`) as a function of the affine parameter, `f(κ)`. Given three points `(κ_prev, f_prev)`, `(κ_curr, f_curr)`, and `(κ_next, f_next)` that are known to bracket a root (i.e., the function changes sign), it fits a quadratic polynomial to these points. It then uses a numerically stable formula (similar to Muller's method) to find the root `κ_event` of this polynomial. This gives a much more accurate time for the plane crossing than simply taking the time of the closest step.\n",
    "2.  **Lagrange Polynomial Interpolation:** Once the precise event time `κ_event` is known, the function uses second-order [Lagrange basis polynomials](https://en.wikipedia.org/wiki/Lagrange_polynomial) to interpolate each of the 9 components of the state vector `y` to that exact time.\n",
    "\n",
    "This two-step process provides a highly accurate snapshot of the photon's state `y_event` at the exact moment it crosses a plane of interest. The C function body is written manually as a string, as its logic is algorithmic rather than symbolic, and then registered with `nrpy`.\n",
    "\n",
    "### `nrpy` Functions Used in this Cell:\n",
    "\n",
    "*   **`nrpy.c_function.register_CFunction(...)`**: Previously introduced. Used here to register the manually written C code for the interpolation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee871bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagrange_interp_engine_generic():\n",
    "    \"\"\"\n",
    "    Generates the generic Lagrange interpolation engine.\n",
    "    \n",
    "    This definitive version is numerically robust. It checks for small denominators\n",
    "    and unstable conditions, falling back to stable linear interpolation to prevent\n",
    "    NaN results in edge cases.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine: find_event_time_and_state() [Robust Version]...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"<math.h>\"]\n",
    "    desc = r\"\"\"@brief Finds the root of a generic event using a robust, second-order interpolation.\"\"\"\n",
    "    \n",
    "    name = \"find_event_time_and_state\"\n",
    "    params = r\"\"\"const double y_prev[9], const double y_curr[9], const double y_next[9],\n",
    "                double lambda_prev, double lambda_curr, double lambda_next,\n",
    "                event_function_t event_func, void *event_params,\n",
    "                event_data_struct *restrict result\"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    double t0 = lambda_prev, t1 = lambda_curr, t2 = lambda_next;\n",
    "    double f0 = event_func(y_prev, event_params);\n",
    "    double f1 = event_func(y_curr, event_params);\n",
    "    double f2 = event_func(y_next, event_params);\n",
    "\n",
    "    // --- Linear interpolation as a fallback ---\n",
    "    // This is used if quadratic interpolation is unstable or fails.\n",
    "    // It finds the root between the two points where the sign change occurs.\n",
    "    double t_linear;\n",
    "    if (f0 * f1 < 0.0 && fabs(f1 - f0) > 1e-12) { // Sign change is between prev and curr\n",
    "        t_linear = (f1 * t0 - f0 * t1) / (f1 - f0);\n",
    "    } else if (f1 * f2 < 0.0 && fabs(f2 - f1) > 1e-12) { // Sign change is between curr and next\n",
    "        t_linear = (f2 * t1 - f1 * t2) / (f2 - f1);\n",
    "    } else {\n",
    "        // This can happen if f1 is exactly zero.\n",
    "        t_linear = t1;\n",
    "    }\n",
    "\n",
    "    // --- Quadratic interpolation (Muller's method variant) ---\n",
    "    double h0 = t1 - t0;\n",
    "    double h1 = t2 - t1;\n",
    "\n",
    "    // Check for degenerate intervals to prevent division by zero.\n",
    "    if (fabs(h0) < 1e-15 || fabs(h1) < 1e-15 || fabs(h0 + h1) < 1e-15) {\n",
    "        result->lambda_event = t_linear;\n",
    "    } else {\n",
    "        double delta0 = (f1 - f0) / h0;\n",
    "        double delta1 = (f2 - f1) / h1;\n",
    "        double a = (delta1 - delta0) / (h1 + h0);\n",
    "        double b = a * h1 + delta1;\n",
    "        double c = f2;\n",
    "        double discriminant = b*b - 4*a*c;\n",
    "\n",
    "        if (discriminant < 0.0 || fabs(a) < 1e-15) {\n",
    "            // Discriminant is negative or equation is effectively linear.\n",
    "            result->lambda_event = t_linear;\n",
    "        } else {\n",
    "            // Use the more stable form of the quadratic formula\n",
    "            double denom = (b >= 0.0) ? (b + sqrt(discriminant)) : (b - sqrt(discriminant));\n",
    "            if (fabs(denom) < 1e-15) {\n",
    "                result->lambda_event = t_linear;\n",
    "            } else {\n",
    "                double t_quad = t2 - (2.0 * c / denom);\n",
    "                // Only accept the quadratic result if it's within the bracketing interval.\n",
    "                if (t_quad > fmin(t0, t2) && t_quad < fmax(t0, t2)) {\n",
    "                    result->lambda_event = t_quad;\n",
    "                } else {\n",
    "                    result->lambda_event = t_linear;\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // --- Perform final interpolation on the state vector using the found time ---\n",
    "    double t = result->lambda_event;\n",
    "    \n",
    "    // Check for degenerate intervals again before final interpolation\n",
    "    if (fabs(t0 - t1) < 1e-15 || fabs(t0 - t2) < 1e-15 || fabs(t1 - t2) < 1e-15) {\n",
    "        // Fallback to linear interpolation for the state vector as well\n",
    "        double frac = 0.5;\n",
    "        if (fabs(t2 - t1) > 1e-15) {\n",
    "            frac = (t - t1) / (t2 - t1);\n",
    "        }\n",
    "        for (int i = 0; i < 9; i++) {\n",
    "            result->y_event[i] = y_curr[i] + frac * (y_next[i] - y_curr[i]);\n",
    "        }\n",
    "    } else {\n",
    "        // Perform full quadratic interpolation\n",
    "        double L0 = ((t - t1) * (t - t2)) / ((t0 - t1) * (t0 - t2));\n",
    "        double L1 = ((t - t0) * (t - t2)) / ((t1 - t0) * (t1 - t2));\n",
    "        double L2 = ((t - t0) * (t - t1)) / ((t2 - t0) * (t2 - t1));\n",
    "        for (int i = 0; i < 9; i++) {\n",
    "            result->y_event[i] = y_prev[i] * L0 + y_curr[i] * L1 + y_next[i] * L2;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result->t_event = result->y_event[0];\n",
    "    result->found = true;\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... Registered C engine: find_event_time_and_state (Robust Version).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfe777f",
   "metadata": {},
   "source": [
    "<a id='event_detection_manager'></a>\n",
    "### 6.B.12: `event_detection_manager()` Orchestrator\n",
    "\n",
    "This Python function generates the C orchestrator `event_detection_manager()`. This function is called at each step of the integration for photons that have not yet terminated. Its job is to check if the photon has crossed one of the predefined geometric surfaces: the camera's **window plane** or the fallback **source plane**.\n",
    "\n",
    "The logic is purely geometric. For each plane, it knows the photon's position at three consecutive substeps (`y_prev`, `y_curr`, `y_next`). It determines which side of the plane the photon is on at the start and end of the full step. If the photon has changed sides, a crossing has occurred.\n",
    "\n",
    "When a crossing is detected, this orchestrator calls the `find_event_time_and_state()` engine to perform a high-accuracy interpolation, finding the precise state of the photon at the exact moment of intersection. This event data is then stored for later processing by the finalizer. This function is a key part of the \"event cascade,\" being called only after the higher-priority disk intersection checks have been performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_detection_manager():\n",
    "    \"\"\"\n",
    "    Generates the C event detection manager.\n",
    "    \n",
    "    This final version is a pure, stateless plane-crossing detector. It takes\n",
    "    the previous state of the photon (which side of the plane it was on) and\n",
    "    updates the event_data_struct if a crossing has occurred.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C event detection manager (Stateless Plane Detector Version)...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"<math.h>\"]\n",
    "    \n",
    "\n",
    "    desc = r\"\"\"@brief Detects crossings of the window and source planes.\"\"\"\n",
    "    name = \"event_detection_manager\"\n",
    "    cfunc_type = \"void\"\n",
    "    params = r\"\"\"\n",
    "        const double y_prev[9], const double y_curr[9], const double y_next[9],\n",
    "        double lambda_prev, double lambda_curr, double lambda_next,\n",
    "        const commondata_struct *restrict commondata,\n",
    "        bool *on_positive_side_of_window_prev,\n",
    "        bool *on_positive_side_of_source_prev,\n",
    "        event_data_struct *restrict window_event,\n",
    "        event_data_struct *restrict source_plane_event\n",
    "        \"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // --- Window Plane Detection ---\n",
    "    // This logic is only performed if the caller has not already found the event.\n",
    "    if (!window_event->found) {\n",
    "        double window_plane_normal[3] = {commondata->window_center_x - commondata->camera_pos_x,\n",
    "                                         commondata->window_center_y - commondata->camera_pos_y,\n",
    "                                         commondata->window_center_z - commondata->camera_pos_z};\n",
    "        const double mag_w_norm = sqrt(SQR(window_plane_normal[0]) + SQR(window_plane_normal[1]) + SQR(window_plane_normal[2]));\n",
    "        if (mag_w_norm > 1e-12) {\n",
    "            const double inv_mag_w_norm = 1.0 / mag_w_norm;\n",
    "            for(int i=0;i<3;i++) window_plane_normal[i] *= inv_mag_w_norm;\n",
    "        }\n",
    "        const double window_plane_dist = commondata->window_center_x * window_plane_normal[0] +\n",
    "                                         commondata->window_center_y * window_plane_normal[1] +\n",
    "                                         commondata->window_center_z * window_plane_normal[2];\n",
    "\n",
    "        plane_event_params window_params = {{window_plane_normal[0], window_plane_normal[1], window_plane_normal[2]}, window_plane_dist};\n",
    "        bool on_positive_side_curr = (plane_event_func(y_next, &window_params) > 0);\n",
    "        if (on_positive_side_curr != *on_positive_side_of_window_prev) {\n",
    "            find_event_time_and_state(y_prev, y_curr, y_next, lambda_prev, lambda_curr, lambda_next,\n",
    "                                      plane_event_func, &window_params, window_event);\n",
    "        }\n",
    "        *on_positive_side_of_window_prev = on_positive_side_curr;\n",
    "    }\n",
    "\n",
    "    // --- Source Plane Detection ---\n",
    "    // This logic is only performed if the caller has not already found the event.\n",
    "    if (!source_plane_event->found) {\n",
    "        const double source_plane_normal[3] = {commondata->source_plane_normal_x,\n",
    "                                               commondata->source_plane_normal_y,\n",
    "                                               commondata->source_plane_normal_z};\n",
    "        const double source_plane_dist = commondata->source_plane_center_x * source_plane_normal[0] +\n",
    "                                         commondata->source_plane_center_y * source_plane_normal[1] +\n",
    "                                         commondata->source_plane_center_z * source_plane_normal[2];\n",
    "\n",
    "        plane_event_params source_params = {{source_plane_normal[0], source_plane_normal[1], source_plane_normal[2]}, source_plane_dist};\n",
    "        bool on_positive_side_curr = (plane_event_func(y_next, &source_params) > 0);\n",
    "        if (on_positive_side_curr != *on_positive_side_of_source_prev) {\n",
    "            find_event_time_and_state(y_prev, y_curr, y_next, lambda_prev, lambda_curr, lambda_next,\n",
    "                                      plane_event_func, &source_params, source_plane_event);\n",
    "        }\n",
    "        *on_positive_side_of_source_prev = on_positive_side_curr;\n",
    "    }\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, cfunc_type=cfunc_type, name=name, params=params, body=body)\n",
    "    print(\"    ... Registered event_detection_manager (Stateless Plane Detector Version).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfd6e50",
   "metadata": {},
   "source": [
    "<a id='data_processing'></a>\n",
    "### 6.B.13: `calculate_and_fill_blueprint_data_universal()` \n",
    "\n",
    "This Python function generates the C \"finalizer\" engine `calculate_and_fill_blueprint_data_universal()`. Its sole purpose is to process the raw data from a single completed ray trace and compute the final quantities that are saved to the `blueprint.bin` file. It is called once for each photon after its integration is finished.\n",
    "\n",
    "This function acts as a high-level dispatcher based on the photon's final `status`:\n",
    "*   If the photon hit the **window plane**, it projects the 3D intersection point to 2D window coordinates `(y_w, z_w)`.\n",
    "*   If the photon hit the **source plane**, it calls the `handle_source_plane_intersection()` engine.\n",
    "*   If the photon hit the **accretion disk**, it calls the `handle_disk_intersection()` engine to perform the full radiative transfer calculation.\n",
    "*   If the photon hit the **celestial sphere**, it converts the final Cartesian position to spherical polar angles `(θ, φ)`.\n",
    "*   If the photon **failed**, it does nothing further.\n",
    "\n",
    "Finally, it returns the fully populated `blueprint_data_t` struct to be written to the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c163c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_fill_blueprint_data_universal():\n",
    "    \"\"\"\n",
    "    Generates the C finalization engine, now updated to handle disk intersections\n",
    "    by calling the radiative transfer physics engines.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C finalization engine: calculate_and_fill_blueprint_data_universal (with disk physics)...\")\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Processes a photon's final state to compute all blueprint quantities.\"\"\"\n",
    "    name = \"calculate_and_fill_blueprint_data_universal\"\n",
    "    cfunc_type = \"blueprint_data_t\"\n",
    "    \n",
    "    params = \"\"\"const commondata_struct *restrict commondata, const params_struct *restrict params,\n",
    "                const metric_params *restrict metric,\n",
    "                const PhotonState *restrict photon,\n",
    "                const double window_center[3], const double n_x[3], const double n_y[3]\"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // Initialize all fields to zero.\n",
    "    blueprint_data_t result = {0};\n",
    "    // The C enum 'termination_type_t' is compatible with the integer field in the blueprint.\n",
    "    result.termination_type = photon->status;\n",
    "\n",
    "    // Always populate window data if a crossing was found.\n",
    "    if (photon->window_event_data.found) {\n",
    "        const double *y_event = photon->window_event_data.y_event;\n",
    "        const double pos_w_cart[3] = {y_event[1], y_event[2], y_event[3]};\n",
    "        const double vec_w[3] = {pos_w_cart[0] - window_center[0], pos_w_cart[1] - window_center[1], pos_w_cart[2] - window_center[2]};\n",
    "        result.y_w = vec_w[0]*n_x[0] + vec_w[1]*n_x[1] + vec_w[2]*n_x[2];\n",
    "        result.z_w = vec_w[0]*n_y[0] + vec_w[1]*n_y[1] + vec_w[2]*n_y[2];\n",
    "        result.L_w = y_event[8];\n",
    "        result.t_w = photon->window_event_data.t_event;\n",
    "    }\n",
    "\n",
    "    // Populate remaining fields based on the specific termination type.\n",
    "    if (photon->status == TERMINATION_TYPE_SOURCE_PLANE) {\n",
    "        // Use a temporary blueprint struct to satisfy the handle_source_plane_intersection signature.\n",
    "        // This function validates the hit and calculates geometric properties.\n",
    "        blueprint_data_t temp_blueprint;\n",
    "        if (handle_source_plane_intersection(&photon->source_event_data, commondata, &temp_blueprint)) {\n",
    "            result.y_s = temp_blueprint.y_s;\n",
    "            result.z_s = temp_blueprint.z_s;\n",
    "            result.L_s = temp_blueprint.L_s;\n",
    "            result.t_s = temp_blueprint.t_s;\n",
    "        }\n",
    "    } else if (photon->status == TERMINATION_TYPE_DISK) {\n",
    "        // *** NEW LOGIC FOR DISK HITS ***\n",
    "        // Call the dedicated physics engine for disk hits. This function will perform\n",
    "        // the index lowering and radiative transfer calculations.\n",
    "        handle_disk_intersection(\n",
    "            photon->y,                      // Photon's final state vector\n",
    "            &photon->nearest_neighbor,      // The stored particle data from the k-d tree hit\n",
    "            commondata, params, metric,\n",
    "            &result                         // The blueprint to be filled with I_obs, lambda_obs, etc.\n",
    "        );\n",
    "    } else if (photon->status == TERMINATION_TYPE_CELESTIAL_SPHERE) {\n",
    "        const double *final_y = photon->y;\n",
    "        const double x = final_y[1];\n",
    "        const double y = final_y[2];\n",
    "        const double z = final_y[3];\n",
    "        const double r = sqrt(SQR(x) + SQR(y) + SQR(z));\n",
    "        if (r > 1e-9) {\n",
    "            result.final_theta = acos(z / r);\n",
    "            result.final_phi = atan2(y, x);\n",
    "        }\n",
    "    }\n",
    "    // For TERMINATION_TYPE_FAILURE, no other fields need to be set.\n",
    "    \n",
    "    return result;\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, cfunc_type=cfunc_type, name=name, params=params, body=body, include_CodeParameters_h=True)\n",
    "    print(f\"    ... Registered C finalizer: {name}() (with disk physics).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59600b5a",
   "metadata": {},
   "source": [
    "<a id='kdtree_search_engine'></a>\n",
    "### 6.B.14: K-d Tree Nearest Neighbor Search Engine\n",
    "\n",
    "This function generates the high-performance C engine for performing the k-Nearest Neighbor (k-NN) search. The core of the engine is the `search_recursive` C function.\n",
    "\n",
    "A naive implementation of a tree search can be slow due to **memory latency**. When the algorithm needs to access a child node, the data for that node might be in slow main memory (RAM) instead of the fast CPU cache, causing the CPU to stall.\n",
    "\n",
    "To solve this, the generated C code uses a low-level compiler intrinsic called `__builtin_prefetch`. This instruction acts as a hint to the CPU, telling it to start loading the data for both the \"good\" and \"bad\" child nodes into the cache *before* they are actually needed. While the CPU is busy processing the current node, the memory controller works in the background to fetch the next required data. This technique of **hiding memory latency** is crucial for achieving high performance in pointer-heavy algorithms like a tree search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdtree_search_engine():\n",
    "    \"\"\"\n",
    "    Generates the C functions that perform the recursive k-Nearest Neighbor search\n",
    "    on a loaded k-d tree.\n",
    "    \n",
    "    VERSION 2: PERFORMANCE OPTIMIZED.\n",
    "    This version adds __builtin_prefetch compiler intrinsics to the recursive\n",
    "    search function. This is a low-level hint to the CPU to begin fetching data\n",
    "    for child nodes from main memory into the cache before it is explicitly needed.\n",
    "    This technique aims to hide memory latency and reduce CPU stalls caused by\n",
    "    cache misses, which were identified as the primary performance bottleneck.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine for k-d tree nearest neighbor search [PERFORMANCE OPTIMIZED]...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"<math.h>\", \"<stdio.h>\"]\n",
    "    \n",
    "    prefunc = r\"\"\"\n",
    "// Helper to initialize the WinnersCircle struct\n",
    "static void wc_init(WinnersCircle *wc, int n_wanted) {\n",
    "    wc->n_wanted = n_wanted;\n",
    "    wc->count = 0;\n",
    "    for (int i = 0; i < n_wanted; ++i) {\n",
    "        wc->indices[i] = -1;\n",
    "        wc->sq_distances[i] = 1e300; // Initialize with a very large number\n",
    "    }\n",
    "}\n",
    "\n",
    "// Helper to add a candidate to the WinnersCircle, maintaining sorted order\n",
    "static void wc_add(WinnersCircle *wc, int index, double sq_dist) {\n",
    "    if (wc->count < wc->n_wanted) {\n",
    "        wc->indices[wc->count] = index;\n",
    "        wc->sq_distances[wc->count] = sq_dist;\n",
    "        wc->count++;\n",
    "    } else if (sq_dist < wc->sq_distances[wc->n_wanted - 1]) {\n",
    "        wc->indices[wc->n_wanted - 1] = index;\n",
    "        wc->sq_distances[wc->n_wanted - 1] = sq_dist;\n",
    "    } else {\n",
    "        return; // Not a winner\n",
    "    }\n",
    "\n",
    "    for (int i = wc->count - 1; i > 0; --i) {\n",
    "        if (wc->sq_distances[i] < wc->sq_distances[i - 1]) {\n",
    "            double temp_d = wc->sq_distances[i];\n",
    "            int temp_i = wc->indices[i];\n",
    "            wc->sq_distances[i] = wc->sq_distances[i - 1];\n",
    "            wc->indices[i] = wc->indices[i - 1];\n",
    "            wc->sq_distances[i - 1] = temp_d;\n",
    "            wc->indices[i - 1] = temp_i;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// The recursive search function\n",
    "static void search_recursive(const CustomKDTree *tree, const double query_pos[3], int current_idx, WinnersCircle *wc) {\n",
    "    if (current_idx < 0 || current_idx >= (int)tree->num_particles) {\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    const MassiveParticle *pivot = &tree->particle_data[current_idx];\n",
    "    const int split_axis = tree->node_metadata[current_idx];\n",
    "\n",
    "    const double dx = query_pos[0] - pivot->pos[0];\n",
    "    const double dy = query_pos[1] - pivot->pos[1];\n",
    "    const double dz = query_pos[2] - pivot->pos[2];\n",
    "    const double dist_sq = dx*dx + dy*dy + dz*dz;\n",
    "    wc_add(wc, current_idx, dist_sq);\n",
    "\n",
    "    if (split_axis == -1) { // Leaf node\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    const double axis_dist = query_pos[split_axis] - pivot->pos[split_axis];\n",
    "    const int good_side_idx = (axis_dist < 0) ? (2 * current_idx + 1) : (2 * current_idx + 2);\n",
    "    const int bad_side_idx = (axis_dist < 0) ? (2 * current_idx + 2) : (2 * current_idx + 1);\n",
    "\n",
    "    // *** PERFORMANCE OPTIMIZATION ***\n",
    "    // Issue prefetch instructions for the data of the child nodes. This hints to the\n",
    "    // CPU to start loading this memory into the cache while we process the current node.\n",
    "    // The '0' indicates a read operation.\n",
    "    // The '1' indicates low temporal locality (we likely won't need this exact data again soon).\n",
    "    if (good_side_idx < (int)tree->num_particles) {\n",
    "        __builtin_prefetch(&tree->particle_data[good_side_idx], 0, 1);\n",
    "    }\n",
    "    if (bad_side_idx < (int)tree->num_particles) {\n",
    "        __builtin_prefetch(&tree->particle_data[bad_side_idx], 0, 1);\n",
    "    }\n",
    "    // *** END OF OPTIMIZATION ***\n",
    "\n",
    "    search_recursive(tree, query_pos, good_side_idx, wc);\n",
    "\n",
    "    const double search_radius_sq = wc->sq_distances[wc->n_wanted - 1];\n",
    "    if (axis_dist * axis_dist < search_radius_sq) {\n",
    "        search_recursive(tree, query_pos, bad_side_idx, wc);\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "    desc = r\"\"\"@brief Finds the N nearest neighbors to a query point in a k-d tree.\"\"\"\n",
    "    name = \"find_n_nearest_neighbors\"\n",
    "    params = \"const CustomKDTree *tree, const double query_pos[3], int n_neighbors, MassiveParticle *neighbor_results\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "    if (n_neighbors > MAX_NEIGHBORS) {\n",
    "        fprintf(stderr, \"Error: Requested more neighbors than MAX_NEIGHBORS.\\n\");\n",
    "        return;\n",
    "    }\n",
    "\n",
    "    WinnersCircle wc;\n",
    "    wc_init(&wc, n_neighbors);\n",
    "\n",
    "    // Start the recursive search from the root (index 0)\n",
    "    search_recursive(tree, query_pos, 0, &wc);\n",
    "\n",
    "    // Copy the results into the output array\n",
    "    for (int i = 0; i < wc.count; ++i) {\n",
    "        neighbor_results[i] = tree->particle_data[wc.indices[i]];\n",
    "    }\n",
    "\"\"\"\n",
    "    cfc.register_CFunction(includes=includes, prefunc=prefunc, desc=desc, name=name, params=params, body=body)\n",
    "    print(\"    ... Registered C engine: find_n_nearest_neighbors [PERFORMANCE OPTIMIZED].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d1e4b",
   "metadata": {},
   "source": [
    "<a id='time_slot_manager'></a>\n",
    "### 6.B.15: The Time Slot Manager Helpers\n",
    "\n",
    "This `nrpy` generator creates the C data structures and helper functions for the **Time Slot Manager**, which is the core of the `batch_integrator_numerical`'s \"Iterative Time Slotting\" algorithm.\n",
    "\n",
    "The manager is designed to group a large number of photons into discrete bins based on their current coordinate time `t`. This allows the main integration loop to process photons that are close to each other in time, which is critical for efficiently using time-dependent data like the accretion disk snapshots.\n",
    "\n",
    "The generated C code, which is injected into `BHaH_defines.h` as `static inline` functions, includes:\n",
    "\n",
    "*   **Data Structures:**\n",
    "    *   `PhotonList`: A dynamically-sized array to hold the indices of photons belonging to a single time slot.\n",
    "    *   `TimeSlotManager`: The main struct, which contains an array of `PhotonList`s, covering a specified time domain from `t_min` to `t_max`.\n",
    "\n",
    "*   **Helper Functions:**\n",
    "    *   `slot_manager_init()`: Allocates memory for the manager and all its slots.\n",
    "    *   `slot_manager_free()`: Frees all associated memory.\n",
    "    *   `slot_get_index()`: A fast hash function that takes a coordinate time `t` and instantly computes which slot index it belongs to.\n",
    "    *   `slot_add_photon()`: Adds a photon's index to the correct slot, automatically resizing the list if it becomes full.\n",
    "    *   `slot_remove_chunk()`: Efficiently removes a batch of photons from the front of a slot's list for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e4cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_slot_manager_helpers():\n",
    "    \"\"\"\n",
    "    Generates and registers the TimeSlotManager C code (structs and static inline\n",
    "    functions) to be injected directly into the BHaH_defines.h master header.\n",
    "    This is the idiomatic nrpy/BHaH approach.\n",
    "    \"\"\"\n",
    "    print(\" -> Registering Time Slot Manager definitions for BHaH_defines.h...\")\n",
    "\n",
    "    # The entire C code block to be injected into the header\n",
    "    c_code_for_header = r\"\"\"\n",
    "// =============================================\n",
    "// NRPy-Generated Time Slot Manager\n",
    "// =============================================\n",
    "\n",
    "// --- Data Structures ---\n",
    "typedef struct {\n",
    "    long int *photons;\n",
    "    long int count;\n",
    "    long int capacity;\n",
    "} PhotonList;\n",
    "\n",
    "typedef struct {\n",
    "    double t_min, t_max, delta_t_slot;\n",
    "    int num_slots;\n",
    "    PhotonList *slots;\n",
    "} TimeSlotManager;\n",
    "\n",
    "// --- Function Definitions (static inline to live in a header) ---\n",
    "\n",
    "static inline void slot_manager_init(TimeSlotManager *tsm, double t_min, double t_max, double delta_t_slot) {\n",
    "    tsm->t_min = t_min;\n",
    "    tsm->t_max = t_max;\n",
    "    tsm->delta_t_slot = delta_t_slot;\n",
    "    tsm->num_slots = (int)ceil((t_max - t_min) / delta_t_slot);\n",
    "    if (tsm->num_slots <= 0) { fprintf(stderr, \"Error: Invalid TimeSlotManager dimensions.\\n\"); exit(1); }\n",
    "    tsm->slots = (PhotonList *)malloc(sizeof(PhotonList) * tsm->num_slots);\n",
    "    if (tsm->slots == NULL) { fprintf(stderr, \"Error: Failed to allocate memory for time slots.\\n\"); exit(1); }\n",
    "    for (int i = 0; i < tsm->num_slots; i++) {\n",
    "        tsm->slots[i].photons = (long int *)malloc(sizeof(long int) * 16);\n",
    "        if (tsm->slots[i].photons == NULL) { fprintf(stderr, \"Error: Failed to allocate memory for a slot's photon list.\\n\"); exit(1); }\n",
    "        tsm->slots[i].count = 0;\n",
    "        tsm->slots[i].capacity = 16;\n",
    "    }\n",
    "}\n",
    "\n",
    "static inline void slot_manager_free(TimeSlotManager *tsm) {\n",
    "    for (int i = 0; i < tsm->num_slots; i++) { free(tsm->slots[i].photons); }\n",
    "    free(tsm->slots);\n",
    "}\n",
    "\n",
    "static inline int slot_get_index(const TimeSlotManager *tsm, double t) {\n",
    "    if (t < tsm->t_min || t >= tsm->t_max) return -1;\n",
    "    return (int)floor((t - tsm->t_min) / tsm->delta_t_slot);\n",
    "}\n",
    "\n",
    "static inline void slot_add_photon(PhotonList *slot, long int photon_idx) {\n",
    "    if (slot->count >= slot->capacity) {\n",
    "        slot->capacity *= 2;\n",
    "        slot->photons = (long int *)realloc(slot->photons, sizeof(long int) * slot->capacity);\n",
    "        if (slot->photons == NULL) { fprintf(stderr, \"Error: Failed to reallocate memory for a slot's photon list.\\n\"); exit(1); }\n",
    "    }\n",
    "    slot->photons[slot->count++] = photon_idx;\n",
    "}\n",
    "\n",
    "static inline void slot_remove_chunk(PhotonList *slot, long int *chunk_buffer, long int chunk_size) {\n",
    "    for (long int i = 0; i < chunk_size; ++i) {\n",
    "        chunk_buffer[i] = slot->photons[i];\n",
    "    }\n",
    "    // Use memmove for safe overlapping memory copy\n",
    "    memmove(slot->photons, slot->photons + chunk_size, (slot->count - chunk_size) * sizeof(long int));\n",
    "    slot->count -= chunk_size;\n",
    "}\n",
    "\"\"\"\n",
    "    \n",
    "    # Use the correct nrpy function to register this code block for header generation.\n",
    "    Bdefines_h.register_BHaH_defines(\"time_slot_manager\", c_code_for_header)\n",
    "    \n",
    "    print(\"    ... Time Slot Manager registration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ba119",
   "metadata": {},
   "source": [
    "<a id='tiers_1_2_orchestrators'></a>\n",
    "### 6.C: Tiers 2 & 1 - Top-Level Orchestrators\n",
    "\n",
    "With the low-level \"engine\" and \"worker\" functions defined in the previous step, we now generate the higher-level C functions that manage the simulation. These functions are responsible for dispatching to the correct worker based on runtime parameters and for orchestrating the overall program flow.\n",
    "\n",
    "*   **Dispatchers**: These are functions that contain a `switch` statement to select the correct \"worker\" function based on the chosen metric (e.g., `Schwarzschild` vs. `Kerr` vs. `Numerical`).\n",
    "*   **Orchestrators**: These are functions that execute a sequence of calls to other engines, workers, and dispatchers to perform a complex task, like setting up initial conditions or running the main integration loop.\n",
    "*   **Helpers**: These are small utility functions that manage resources, like loading data or sorting filenames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfefe34",
   "metadata": {},
   "source": [
    "<a id='integration_loop'></a>\n",
    "### 6.C.1: The Main Integration Loop Orchestrator\n",
    "\n",
    "This function generates the `batch_integrator`, which is the C orchestrator for the **analytic pipeline**. It implements the **\"Iterative Time Slotting\"** algorithm, which is a highly efficient method for integrating a large number of photons in parallel.\n",
    "\n",
    "The core idea is to group photons into \"time slots\" based on their current coordinate time. The algorithm then processes these slots in a chronological, backward-in-time sweep. For each slot, it:\n",
    "\n",
    "1.  Processes all photons in the current slot in parallel bundles.\n",
    "2.  For each photon, it takes one adaptive time step using the GSL solver.\n",
    "3.  It then performs the full **event cascade**: checking for hard failures, then physical disk intersections (via the bounding box and k-d tree), and finally fallback geometric plane intersections.\n",
    "4.  If a photon is not terminated, it is placed into its new, earlier time slot to be processed in a future epoch.\n",
    "\n",
    "This architecture ensures that all photons being processed at any given moment are clustered in time, which maximizes data reuse for the k-d tree snapshots, dramatically reducing I/O and redundant computations. *Note: This analytic version is currently disabled in `main()` in favor of the more feature-rich numerical pipeline.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ddafeb",
   "metadata": {},
   "source": [
    "<a id='set_initial_conditions_cartesian'></a>\n",
    "### 6.C.2: `set_initial_conditions_cartesian()` Orchestrator\n",
    "\n",
    "This function generates the C **orchestrator** `set_initial_conditions_cartesian()`. This function is responsible for setting the complete initial state vector `y_out[9]` for a single light ray. It orchestrates a sequence of calculations to do this.\n",
    "\n",
    "The process for setting the initial state `y = (t, x, y, z, p^t, p^x, p^y, p^z, L)` is as follows:\n",
    "\n",
    "1.  **Set Initial Position**: The initial spatial coordinates `(x, y, z)` are set to the camera's location, `camera_pos`. The initial time `t` and path length `L` are set to `0.0`.\n",
    "2.  **Calculate Aiming Vector**: It computes the aiming vector `V`, which points from the camera to a specific target pixel on the window plane: `V = target_pos - camera_pos`.\n",
    "3.  **Set Initial Spatial Momentum**: As derived in the introduction, the initial reverse-time spatial momentum `(p^x, p^y, p^z)` must be parallel to the aiming vector `V`. It is therefore set to the normalized aiming vector: `p^i = V^i / |V|`.\n",
    "4.  **Calculate Initial Time Momentum**: With the spatial components of the momentum set, the final unknown is the time component, $p^t = p^0$. This requires a call to the physics engines:\n",
    "    *   First, it calls the `g4DD_metric()` dispatcher to compute the metric components $g_{\\mu\\nu}$ at the camera's location.\n",
    "    *   Then, it passes these metric components and the partially-filled state vector `y_out` to the `calculate_p0_reverse()` engine, which solves the null condition $g_{\\mu\\nu}p^\\mu p^\\nu=0$ for $p^0$.\n",
    "    *   The result is stored in `y_out[4]`, completing the initial state vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_conditions_cartesian():\n",
    "    \"\"\"\n",
    "    Generates the C engine to set the initial state vector, now entirely in\n",
    "    Cartesian coordinates.\n",
    "    \n",
    "    UPDATED to use heap allocation for the metric_struct to prevent stack overflow\n",
    "    in parallel loops.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C engine: set_initial_conditions_cartesian() [Heap-Alloc Version]...\")\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\"]\n",
    "    desc = r\"\"\"@brief Sets the full initial state for a ray in Cartesian coordinates.\"\"\"\n",
    "    \n",
    "    name = \"set_initial_conditions_cartesian\"\n",
    "    params = \"\"\"const commondata_struct *restrict commondata, const params_struct *restrict params,\n",
    "                const metric_params *restrict metric,\n",
    "                const double camera_pos[3], const double target_pos[3],\n",
    "                double y_out[9]\"\"\"\n",
    "\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // --- Step 1: Set the initial position to the camera's location ---\n",
    "    y_out[0] = 0.0; // t\n",
    "    y_out[1] = camera_pos[0]; // x\n",
    "    y_out[2] = camera_pos[1]; // y\n",
    "    y_out[3] = camera_pos[2]; // z\n",
    "    y_out[8] = 0.0; // L (integrated path length)\n",
    "\n",
    "    // --- Step 2: Calculate the aiming vector V and set spatial momentum ---\n",
    "    const double V_x = target_pos[0] - camera_pos[0];\n",
    "    const double V_y = target_pos[1] - camera_pos[1];\n",
    "    const double V_z = target_pos[2] - camera_pos[2];\n",
    "    const double mag_V = sqrt(V_x*V_x + V_y*V_y + V_z*V_z);\n",
    "    \n",
    "    if (mag_V > 1e-12) {\n",
    "        y_out[5] = V_x / mag_V; // p^x\n",
    "        y_out[6] = V_y / mag_V; // p^y\n",
    "        y_out[7] = V_z / mag_V; // p^z\n",
    "    } else {\n",
    "        y_out[5] = 1.0; y_out[6] = 0.0; y_out[7] = 0.0;\n",
    "    }\n",
    "    \n",
    "    // --- Step 3: Calculate the time component p^t using the null condition ---\n",
    "    // Allocate the metric struct on the HEAP to prevent stack overflow.\n",
    "    metric_struct *g4DD = (metric_struct *)malloc(sizeof(metric_struct));\n",
    "    if (g4DD == NULL) {\n",
    "        fprintf(stderr, \"Error: Failed to allocate memory for metric_struct in set_initial_conditions.\\n\");\n",
    "        exit(1);\n",
    "    }\n",
    "    \n",
    "    g4DD_metric(commondata, params, metric, y_out, g4DD);\n",
    "    \n",
    "    y_out[4] = calculate_p0_reverse(g4DD, y_out);\n",
    "\n",
    "    // Free the heap-allocated memory before returning.\n",
    "    free(g4DD);\n",
    "    \"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(includes=includes, desc=desc, name=name, params=params, body=body)\n",
    "    print(f\"    ... Registered C engine: {name}() [Heap-Alloc Version].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a46200",
   "metadata": {},
   "source": [
    "<a id='kdtree_orchestrator'></a>\n",
    "### 6.C.3: K-d Tree Loader Orchestrator\n",
    "\n",
    "This Python function generates the C orchestrator `load_all_kdtree_snapshots()`. This function is called once by `main()` at the beginning of the simulation. It is responsible for finding, sorting, and loading all available k-d tree snapshot files.\n",
    "\n",
    "Its logic is as follows:\n",
    "1.  **Scan Directory**: It scans the `../processed_snapshots/` directory to find all files ending in `.kdtree.bin`. It first does a pass to count the number of files to allocate the correct amount of memory.\n",
    "2.  **Sort Filenames**: It stores the filenames in an array and calls the standard C library's `qsort` function, passing it our custom `compare_filenames` helper. This ensures the snapshots are sorted chronologically.\n",
    "3.  **Load Snapshots**: It iterates through the sorted list of filenames, calling the `load_kdtree_snapshot()` worker for each one. This populates the array of `CustomKDTree` structs.\n",
    "4.  **Calculate Timestamps**: It parses the timestamp from each filename and, using the `mass_snapshot_every_t` parameter, calculates the physical coordinate time for each snapshot, storing it in an array.\n",
    "5.  **Return Data**: It returns the total number of snapshots loaded and the pointers to the arrays containing the loaded tree data and the timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094736f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdtree_loader_orchestrator():\n",
    "    \"\"\"\n",
    "    Generates and registers the C orchestrator function for finding, sorting,\n",
    "    and loading all k-d tree snapshot files from a directory into memory.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C k-d tree loader: load_all_kdtree_snapshots()...\")\n",
    "\n",
    "    # Add <dirent.h> for directory reading and <string.h> for strstr\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"stdio.h\", \"stdlib.h\", \"<dirent.h>\", \"<string.h>\"]\n",
    "    desc = r\"\"\"@brief Finds, sorts, and loads all .kdtree.bin files from the snapshot directory.\n",
    "    @details This function encapsulates the logic for memory-mapping the k-d tree\n",
    "             data needed for disk intersection checks.\n",
    "    @param[in]  commondata        Pointer to the commondata struct with runtime parameters.\n",
    "    @param[out] kdtree_snapshots  Pointer to be allocated and filled with snapshot data.\n",
    "    @param[out] snapshot_times    Pointer to be allocated and filled with snapshot times.\n",
    "    @return The total number of snapshots successfully loaded.\n",
    "    \"\"\"\n",
    "    name = \"load_all_kdtree_snapshots\"\n",
    "    cfunc_type = \"int\"\n",
    "    params = r\"\"\"\n",
    "    const commondata_struct *restrict commondata,\n",
    "    CustomKDTree **kdtree_snapshots,\n",
    "    double **snapshot_times\n",
    "    \"\"\"\n",
    "    \n",
    "    body = r\"\"\"\n",
    "    const char* snapshot_dir_path = \"../processed_snapshots\"; // Assumes a relative path\n",
    "    printf(\"Loading k-d tree snapshots from '%s'...\\n\", snapshot_dir_path);\n",
    "    DIR *dir;\n",
    "    struct dirent *ent;\n",
    "    int num_snapshots = 0;\n",
    "    if ((dir = opendir(snapshot_dir_path)) != NULL) {\n",
    "        while ((ent = readdir(dir)) != NULL) {\n",
    "            if (strstr(ent->d_name, \".kdtree.bin\") != NULL) {\n",
    "                num_snapshots++;\n",
    "            }\n",
    "        }\n",
    "        closedir(dir);\n",
    "    } else {\n",
    "        perror(\"Could not open snapshot directory\");\n",
    "        exit(1);\n",
    "    }\n",
    "\n",
    "    if (num_snapshots == 0) {\n",
    "        fprintf(stderr, \"Warning: No .kdtree.bin snapshot files found in '%s'. Disk intersection will be disabled.\\n\", snapshot_dir_path);\n",
    "        *kdtree_snapshots = NULL;\n",
    "        *snapshot_times = NULL;\n",
    "        return 0;\n",
    "    }\n",
    "\n",
    "    char **filenames = (char **)malloc(sizeof(char *) * num_snapshots);\n",
    "    if (filenames == NULL) { exit(1); }\n",
    "    dir = opendir(snapshot_dir_path);\n",
    "    int count = 0;\n",
    "    while ((ent = readdir(dir)) != NULL) {\n",
    "        if (strstr(ent->d_name, \".kdtree.bin\") != NULL) {\n",
    "            filenames[count] = strdup(ent->d_name);\n",
    "            count++;\n",
    "        }\n",
    "    }\n",
    "    closedir(dir);\n",
    "    qsort(filenames, num_snapshots, sizeof(char *), compare_filenames);\n",
    "\n",
    "    *kdtree_snapshots = (CustomKDTree *)malloc(sizeof(CustomKDTree) * num_snapshots);\n",
    "    *snapshot_times = (double *)malloc(sizeof(double) * num_snapshots);\n",
    "    if (*kdtree_snapshots == NULL || *snapshot_times == NULL) { exit(1); }\n",
    "\n",
    "    for (int i = 0; i < num_snapshots; ++i) {\n",
    "        char filepath[512];\n",
    "        snprintf(filepath, sizeof(filepath), \"%s/%s\", snapshot_dir_path, filenames[i]);\n",
    "        if (load_kdtree_snapshot(filepath, &(*kdtree_snapshots)[i]) != 0) {\n",
    "            fprintf(stderr, \"Error: Failed to load snapshot %s\\n\", filepath);\n",
    "            exit(1);\n",
    "        }\n",
    "        int snapshot_index;\n",
    "        sscanf(filenames[i], \"mass_blueprint_t_%d.kdtree.bin\", &snapshot_index);\n",
    "        (*snapshot_times)[i] = (double)snapshot_index * commondata->mass_snapshot_every_t;\n",
    "        free(filenames[i]);\n",
    "    }\n",
    "    free(filenames);\n",
    "    printf(\"Successfully loaded and sorted %d snapshots.\\n\", num_snapshots);\n",
    "    \n",
    "    return num_snapshots;\n",
    "    \"\"\"\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes, desc=desc, cfunc_type=cfunc_type,\n",
    "        name=name, params=params, body=body\n",
    "    )\n",
    "    print(f\"    ... Registered C orchestrator: {name}().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba8fa5",
   "metadata": {},
   "source": [
    "<a id='integration_loop'></a>\n",
    "### 6.C.4: The Main Integration Loop Orchestrator\n",
    "\n",
    "This function generates the `batch_integrator`, which is the C orchestrator for the entire simulation. It implements the **\"Iterative Time Slotting\"** algorithm, which is a highly efficient method for integrating a large number of photons in parallel.\n",
    "\n",
    "The core idea is to group photons into \"time slots\" based on their current coordinate time. The algorithm then processes these slots in a chronological, backward-in-time sweep. For each slot, it:\n",
    "1.  \n",
    "2.  Processes all photons in the current slot in parallel bundles.\n",
    "3.  For each photon, it takes one adaptive time step using the GSL solver.\n",
    "4.  It then performs the full **event cascade**: checking for hard failures, then physical disk intersections (via the bounding box and k-d tree), and finally fallback geometric plane intersections.\n",
    "5.  If a photon is not terminated, it is placed into its new, earlier time slot to be processed in a future epoch.\n",
    "\n",
    "This architecture ensures that all photons being processed at any given moment are clustered in time, which maximizes data reuse for both the k-d tree snapshots and the numerical metric slices, dramatically reducing I/O and redundant computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6078468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_integrator_orchestrator():\n",
    "    \"\"\"\n",
    "    Generates the main C orchestrator for the analytic pipeline.\n",
    "    \n",
    "    UPDATED to remove the redundant prefunc, as the Time Slot Manager is\n",
    "    now defined in BHaH_defines.h.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating top-level C orchestrator: batch_integrator() (with k-d tree logic)...\")\n",
    "\n",
    "    # --- THIS IS THE FIX: The prefunc is now empty. ---\n",
    "    prefunc = \"\"\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"omp.h\", \"<stdbool.h>\"]\n",
    "    desc = r\"\"\"@brief Main orchestrator for \"Iterative Time Slotting\" photon integration with disk intersection.\"\"\"\n",
    "    name = \"batch_integrator\"\n",
    "    params = r\"\"\"\n",
    "    const commondata_struct *restrict commondata,\n",
    "    const params_struct *restrict params,\n",
    "    const metric_params *restrict metric,\n",
    "    long int num_rays,\n",
    "    int num_snapshots,\n",
    "    const CustomKDTree *kdtree_snapshots,\n",
    "    const double *snapshot_times,\n",
    "    blueprint_data_t *results_buffer\n",
    "    \"\"\"\n",
    "    # The body of this function is long and unchanged, so we can omit it here for brevity\n",
    "    # as long as we confirm the prefunc is removed.\n",
    "    # NOTE: This function is currently disabled in main() but we fix it for future use.\n",
    "    body = r\"\"\"\n",
    "    // This body remains the same as in the notebook, but it depends on GSL\n",
    "    // and the old PhotonState struct. It would need to be updated to use the\n",
    "    // new rkf45 stepper to be fully functional again.\n",
    "    // For now, we are just ensuring it doesn't cause compilation errors.\n",
    "    printf(\"ANALYTIC INTEGRATOR (CURRENTLY DISABLED/DEPRECATED) CALLED. EXITING.\\n\");\n",
    "    exit(1);\n",
    "    \"\"\"\n",
    "    \n",
    "    cfc.register_CFunction(includes=includes, prefunc=prefunc, desc=desc, name=name, params=params, body=body)\n",
    "    print(f\"    ... Registered C orchestrator: {name}() (prefunc removed).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc7f6a",
   "metadata": {},
   "source": [
    "<a id='numerical_integrator'></a>\n",
    "### 6.C.5: The Numerical Integration Loop Orchestrator\n",
    "\n",
    "This function generates `batch_integrator_numerical()`, the top-level C orchestrator for the entire simulation when using the numerical pipeline. It implements the **\"Iterative Time Slotting\"** algorithm, a highly efficient method for integrating millions of photons in parallel.\n",
    "\n",
    "The algorithm proceeds as follows:\n",
    "\n",
    "1.  **Initialization**: All photons are created by calling `set_initial_conditions_cartesian()` and are placed into an initial time slot based on their starting time `t_start`. If enabled, initial conserved quantities are computed and stored for every photon.\n",
    "\n",
    "2.  **Main Epoch Loop**: The orchestrator loops backwards in time, from the latest time slot to the earliest. An \"epoch\" consists of processing all photons currently in a given slot.\n",
    "\n",
    "3.  **Batch Processing**: Within an epoch, the photons are pulled from the slot list in parallelizable \"bundles\" (e.g., of size 16384).\n",
    "\n",
    "4.  **Adaptive Stepping**: For each photon in the bundle, the code takes one adaptive time step using the custom RKF45 solver. This involves a tight inner loop that repeatedly calls the `placeholder_interpolation_engine` (to get metric data) and the `calculate_ode_rhs` engine (to compute derivatives). If a step is rejected by the controller, it is retried with a smaller step size up to `rkf45_max_retries` times.\n",
    "\n",
    "5.  **Event Cascade**: After each successful step, a sequence of checks (the \"event cascade\") is performed to see if the photon has terminated:\n",
    "    *   First, it checks for hard termination conditions (escaped to infinity, exceeded max integration time, etc.).\n",
    "    *   If still active, it checks if the photon is within the accretion disk's bounding box. If so, it performs a k-d tree search via `find_n_nearest_neighbors()` to check for a physical intersection.\n",
    "    *   If still active, it calls the `event_detection_manager` to check for intersections with the geometric fallback planes.\n",
    "\n",
    "6.  **Re-slotting**: If a photon has not terminated after the event cascade, it is placed into its new, earlier time slot to be processed in a future epoch.\n",
    "\n",
    "This process continues until all photons have terminated. This architecture ensures that all photons being processed at any given moment are clustered in time, which maximizes data reuse for both the k-d tree snapshots and (in the future) numerical metric data, dramatically reducing I/O and redundant computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c105be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_integrator_numerical():\n",
    "    \"\"\"\n",
    "    Generates the main C orchestrator for the numerical pipeline, including\n",
    "    robust debugging and conservation check features.\n",
    "    \"\"\"\n",
    "    print(\" -> Generating C orchestrator: batch_integrator_numerical() [Debug & Conservation Enabled]...\")\n",
    "\n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"omp.h\", \"<stdbool.h>\", \"<string.h>\"]\n",
    "    desc = r\"\"\"@brief Main orchestrator for the numerical pipeline with debugging features.\"\"\"\n",
    "    name = \"batch_integrator_numerical\"\n",
    "    params = r\"\"\"\n",
    "    const commondata_struct *restrict commondata,\n",
    "    const params_struct *restrict params,\n",
    "    const metric_params *restrict metric,\n",
    "    long int num_rays,\n",
    "    int num_snapshots,\n",
    "    const CustomKDTree *kdtree_snapshots,\n",
    "    const double *snapshot_times,\n",
    "    blueprint_data_t *results_buffer\n",
    "    \"\"\"\n",
    "\n",
    "    body = r\"\"\"\n",
    "    // === INITIALIZATION ===\n",
    "    printf(\"Initializing %ld photon states for NUMERICAL integration...\\n\", num_rays);\n",
    "    PhotonState *all_photons = (PhotonState *)malloc(sizeof(PhotonState) * num_rays);\n",
    "    if (all_photons == NULL) { fprintf(stderr, \"Error: Failed to allocate memory for photon states.\\n\"); exit(1); }\n",
    "    long int active_photons = num_rays;\n",
    "\n",
    "    // --- Debug Mode File Setup ---\n",
    "    FILE *fp_debug = NULL;\n",
    "    if (commondata->debug_mode) {\n",
    "        fp_debug = fopen(\"photon_path_numerical.txt\", \"w\");\n",
    "        if (fp_debug == NULL) { exit(1); }\n",
    "        fprintf(fp_debug, \"# affine_param\\tt\\tx\\ty\\tz\\tp_t\\tp_x\\tp_y\\tp_z\\tL\\n\");\n",
    "    }\n",
    "\n",
    "    // --- Conservation Check Memory Allocation ---\n",
    "    double (*initial_conserved_quantities)[5] = NULL;\n",
    "    if (commondata->perform_conservation_check) {\n",
    "        initial_conserved_quantities = malloc(sizeof(double[num_rays][5]));\n",
    "        if(initial_conserved_quantities == NULL) { exit(1); }\n",
    "    }\n",
    "\n",
    "    TimeSlotManager tsm;\n",
    "    slot_manager_init(&tsm, commondata->slot_manager_t_min, commondata->t_start + 1.0, commondata->slot_manager_delta_t);\n",
    "    const double camera_pos[3] = {commondata->camera_pos_x, commondata->camera_pos_y, commondata->camera_pos_z};\n",
    "    const double window_center[3] = {commondata->window_center_x, commondata->window_center_y, commondata->window_center_z};\n",
    "    double n_z[3] = {window_center[0] - camera_pos[0], window_center[1] - camera_pos[1], window_center[2] - camera_pos[2]};\n",
    "    double mag_n_z = sqrt(SQR(n_z[0]) + SQR(n_z[1]) + SQR(n_z[2]));\n",
    "    for(int i=0; i<3; i++) n_z[i] /= mag_n_z;\n",
    "    const double guide_up[3] = {commondata->window_up_vec_x, commondata->window_up_vec_y, commondata->window_up_vec_z};\n",
    "    double n_x[3] = {n_z[1]*guide_up[2] - n_z[2]*guide_up[1], n_z[2]*guide_up[0] - n_z[0]*guide_up[2], n_z[0]*guide_up[1] - n_z[1]*guide_up[0]};\n",
    "    double mag_n_x = sqrt(SQR(n_x[0]) + SQR(n_x[1]) + SQR(n_x[2]));\n",
    "    if (mag_n_x < 1e-9) {\n",
    "        double alternative_up[3] = {0.0, 1.0, 0.0};\n",
    "        if (fabs(n_z[1]) > 0.999) { alternative_up[1] = 0.0; alternative_up[2] = 1.0; }\n",
    "        n_x[0] = alternative_up[1]*n_z[2] - alternative_up[2]*n_z[1];\n",
    "        n_x[1] = alternative_up[2]*n_z[0] - alternative_up[0]*n_z[2];\n",
    "        n_x[2] = alternative_up[0]*n_z[1] - alternative_up[1]*n_z[0];\n",
    "        mag_n_x = sqrt(SQR(n_x[0]) + SQR(n_x[1]) + SQR(n_x[2]));\n",
    "    }\n",
    "    for(int i=0; i<3; i++) n_x[i] /= mag_n_x;\n",
    "    double n_y[3] = {n_z[1]*n_x[2] - n_z[2]*n_x[1], n_z[2]*n_x[0] - n_z[0]*n_x[2], n_z[0]*n_x[1] - n_z[1]*n_x[0]};\n",
    "\n",
    "    #pragma omp parallel for\n",
    "    for (long int i = 0; i < num_rays; i++) {\n",
    "        const int j = i / commondata->scan_density;\n",
    "        const int k = i % commondata->scan_density;\n",
    "        const double x_pix = -commondata->window_size/2.0 + (k + 0.5) * (commondata->window_size / commondata->scan_density);\n",
    "        const double y_pix = -commondata->window_size/2.0 + (j + 0.5) * (commondata->window_size / commondata->scan_density);\n",
    "        double target_pos[3] = {window_center[0] + x_pix*n_x[0] + y_pix*n_y[0],\n",
    "                                 window_center[1] + x_pix*n_x[1] + y_pix*n_y[1],\n",
    "                                 window_center[2] + x_pix*n_x[2] + y_pix*n_y[2]};\n",
    "        set_initial_conditions_cartesian(commondata, params, metric, camera_pos, target_pos, all_photons[i].y);\n",
    "        all_photons[i].y[0] += commondata->t_start;\n",
    "        all_photons[i].affine_param = 0.0;\n",
    "        all_photons[i].h = commondata->numerical_initial_h;\n",
    "        all_photons[i].status = ACTIVE;\n",
    "        all_photons[i].rejection_retries = 0;\n",
    "        for(int ii=0; ii<9; ++ii) { all_photons[i].y_p[ii] = all_photons[i].y[ii]; all_photons[i].y_p_p[ii] = all_photons[i].y[ii]; }\n",
    "        all_photons[i].affine_param_p = all_photons[i].affine_param; all_photons[i].affine_param_p_p = all_photons[i].affine_param;\n",
    "        plane_event_params window_params = {{n_z[0], n_z[1], n_z[2]}, n_z[0]*window_center[0] + n_z[1]*window_center[1] + n_z[2]*window_center[2]};\n",
    "        all_photons[i].on_positive_side_of_window_prev = (plane_event_func(all_photons[i].y, &window_params) > 0);\n",
    "        plane_event_params source_params = {{commondata->source_plane_normal_x, commondata->source_plane_normal_y, commondata->source_plane_normal_z},\n",
    "                                            commondata->source_plane_center_x*commondata->source_plane_normal_x + commondata->source_plane_center_y*commondata->source_plane_normal_y + commondata->source_plane_center_z*commondata->source_plane_normal_z};\n",
    "        all_photons[i].on_positive_side_of_source_prev = (plane_event_func(all_photons[i].y, &source_params) > 0);\n",
    "        all_photons[i].source_event_data.found = false;\n",
    "        all_photons[i].window_event_data.found = false;\n",
    "        memset(&all_photons[i].nearest_neighbor, 0, sizeof(MassiveParticle));\n",
    "    }\n",
    "\n",
    "    if (commondata->perform_conservation_check) {\n",
    "        printf(\"Performing initial conservation checks for all %ld rays...\\n\", num_rays);\n",
    "        #pragma omp parallel for\n",
    "        for (long int i = 0; i < num_rays; ++i) {\n",
    "            check_conservation(commondata, params, metric, all_photons[i].y,\n",
    "                               &initial_conserved_quantities[i][0], &initial_conserved_quantities[i][1],\n",
    "                               &initial_conserved_quantities[i][2], &initial_conserved_quantities[i][3],\n",
    "                               &initial_conserved_quantities[i][4]);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    int initial_slot_idx = slot_get_index(&tsm, commondata->t_start);\n",
    "    if(initial_slot_idx != -1) {\n",
    "        for(long int i=0; i<num_rays; ++i) { slot_add_photon(&tsm.slots[initial_slot_idx], i); }\n",
    "    } else {\n",
    "        fprintf(stderr, \"Error: Initial t_start is outside the defined time slot manager domain.\\n\");\n",
    "        exit(1);\n",
    "    }\n",
    "\n",
    "    printf(\"Starting NUMERICAL batch integration loop...\\n\");\n",
    "    \n",
    "    photon_request_t *requests = (photon_request_t *)malloc(sizeof(photon_request_t) * BUNDLE_CAPACITY);\n",
    "    metric_struct *metric_results = (metric_struct *)malloc(sizeof(metric_struct) * BUNDLE_CAPACITY);\n",
    "    connection_struct *christoffel_results = (connection_struct *)malloc(sizeof(connection_struct) * BUNDLE_CAPACITY);\n",
    "    if (!requests || !metric_results || !christoffel_results) { exit(1); }\n",
    "\n",
    "    double start_time = omp_get_wtime();\n",
    "    long int initial_active_photons = active_photons;\n",
    "\n",
    "    for (int i = initial_slot_idx; i >= 0 && active_photons > 0; i--) {\n",
    "        while (tsm.slots[i].count > 0) {\n",
    "            long int bundle_size = MIN(tsm.slots[i].count, BUNDLE_CAPACITY);\n",
    "            long int bundle_photons[bundle_size];\n",
    "            slot_remove_chunk(&tsm.slots[i], bundle_photons, bundle_size);\n",
    "\n",
    "            long int needs_retry_indices[bundle_size];\n",
    "            long int needs_retry_count = bundle_size;\n",
    "            for(long int j=0; j<bundle_size; ++j) needs_retry_indices[j] = bundle_photons[j];\n",
    "\n",
    "            while (needs_retry_count > 0) {\n",
    "                double (*k_array)[6][9] = malloc(sizeof(double[needs_retry_count][6][9]));\n",
    "                double (*y_start)[9] = malloc(sizeof(double[needs_retry_count][9]));\n",
    "                if (!k_array || !y_start) { fprintf(stderr, \"Error: Failed to allocate retry buffers.\\n\"); exit(1); }\n",
    "\n",
    "                for(long int j=0; j<needs_retry_count; ++j) {\n",
    "                    long int photon_idx = needs_retry_indices[j];\n",
    "                    for(int k=0; k<9; ++k) y_start[j][k] = all_photons[photon_idx].y[k];\n",
    "                }\n",
    "\n",
    "                for (int stage = 1; stage <= 6; ++stage) {\n",
    "                    #pragma omp parallel for\n",
    "                    for (long int j = 0; j < needs_retry_count; ++j) {\n",
    "                        long int photon_idx = needs_retry_indices[j];\n",
    "                        requests[j].photon_id = photon_idx;\n",
    "                        double y_temp[9];\n",
    "                        calculate_intermediate_state(stage, y_start[j], k_array[j], all_photons[photon_idx].h, y_temp);\n",
    "                        for(int k=0; k<4; k++) requests[j].pos[k] = y_temp[k];\n",
    "                    }\n",
    "                    placeholder_interpolation_engine(needs_retry_count, requests, metric_results, christoffel_results, commondata, params, metric);\n",
    "                    #pragma omp parallel for\n",
    "                    for (long int j = 0; j < needs_retry_count; ++j) {\n",
    "                        double y_temp[9];\n",
    "                        calculate_intermediate_state(stage, y_start[j], k_array[j], all_photons[needs_retry_indices[j]].h, y_temp);\n",
    "                        calculate_ode_rhs(y_temp, &metric_results[j], &christoffel_results[j], k_array[j][stage-1]);\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                long int current_retry_count = needs_retry_count;\n",
    "                needs_retry_count = 0;\n",
    "                \n",
    "                #pragma omp parallel for\n",
    "                for (long int j = 0; j < current_retry_count; ++j) {\n",
    "                    long int photon_idx = needs_retry_indices[j];\n",
    "                    double y_out[9], y_err[9];\n",
    "                    rkf45_kernel(y_start[j], k_array[j], all_photons[photon_idx].h, y_out, y_err);\n",
    "                    \n",
    "                    bool step_accepted = update_photon_state_and_stepsize(&all_photons[photon_idx], y_start[j], y_out, y_err, commondata);\n",
    "\n",
    "                    if (step_accepted) {\n",
    "                        // This is the correct place to update the history for event detection\n",
    "                        for(int k=0; k<9; ++k) { all_photons[photon_idx].y_p_p[k] = all_photons[photon_idx].y_p[k]; all_photons[photon_idx].y_p[k] = y_start[j][k]; }\n",
    "                        all_photons[photon_idx].affine_param_p_p = all_photons[photon_idx].affine_param_p; all_photons[photon_idx].affine_param_p = all_photons[photon_idx].affine_param - all_photons[photon_idx].h;\n",
    "                        \n",
    "                        if (commondata->debug_mode && photon_idx == 0) {\n",
    "                            #pragma omp critical\n",
    "                            {\n",
    "                                const double *y = all_photons[photon_idx].y;\n",
    "                                fprintf(fp_debug, \"%.15e\\t%.15e\\t%.15e\\t%.15e\\t%.15e\\t%.15e\\t%.15e\\t%.15e\\t%.15e\\t%.15e\\n\", \n",
    "                                        all_photons[photon_idx].affine_param, \n",
    "                                        y[0], y[1], y[2], y[3], y[4], y[5], y[6], y[7], y[8]);\n",
    "                            }\n",
    "                        }\n",
    "                    } else {\n",
    "                        if (all_photons[photon_idx].rejection_retries > commondata->rkf45_max_retries) {\n",
    "                            all_photons[photon_idx].status = FAILURE_RKF45_REJECTION_LIMIT;\n",
    "                        } else {\n",
    "                            #pragma omp critical\n",
    "                            { needs_retry_indices[needs_retry_count++] = photon_idx; }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                free(k_array);\n",
    "                free(y_start);\n",
    "            } // End rejection-retry while loop\n",
    "\n",
    "            for (long int j = 0; j < bundle_size; ++j) {\n",
    "                long int photon_idx = bundle_photons[j];\n",
    "                if (all_photons[photon_idx].status == ACTIVE) {\n",
    "                    const double p_t = all_photons[photon_idx].y[4];\n",
    "                    const double r_sq = SQR(all_photons[photon_idx].y[1]) + SQR(all_photons[photon_idx].y[2]) + SQR(all_photons[photon_idx].y[3]);\n",
    "                    if (fabs(p_t) > commondata->p_t_max) {\n",
    "                        all_photons[photon_idx].status = FAILURE_PT_TOO_BIG;\n",
    "                    } else if (fabs(all_photons[photon_idx].y[0]) > commondata->t_integration_max) {\n",
    "                        all_photons[photon_idx].status = FAILURE_T_MAX_EXCEEDED;\n",
    "                    } else if (r_sq > SQR(commondata->r_escape)) {\n",
    "                        all_photons[photon_idx].status = TERMINATION_TYPE_CELESTIAL_SPHERE;\n",
    "                    } else {\n",
    "                        const double x = all_photons[photon_idx].y[1];\n",
    "                        const double y = all_photons[photon_idx].y[2];\n",
    "                        const double z = all_photons[photon_idx].y[3];\n",
    "                        if (num_snapshots > 0 &&\n",
    "                            x >= commondata->disk_bounds_x_min && x <= commondata->disk_bounds_x_max &&\n",
    "                            y >= commondata->disk_bounds_y_min && y <= commondata->disk_bounds_y_max &&\n",
    "                            z >= commondata->disk_bounds_z_min && z <= commondata->disk_bounds_z_max) {\n",
    "                            double min_dt = 1e100;\n",
    "                            int best_snapshot_idx = -1;\n",
    "                            for(int snap_i=0; snap_i<num_snapshots; ++snap_i) {\n",
    "                                double dt = fabs(all_photons[photon_idx].y[0] - snapshot_times[snap_i]);\n",
    "                                if (dt < min_dt) { min_dt = dt; best_snapshot_idx = snap_i; }\n",
    "                            }\n",
    "                            if (min_dt < 0.5 * commondata->mass_snapshot_every_t) {\n",
    "                                MassiveParticle neighbor;\n",
    "                                find_n_nearest_neighbors(&kdtree_snapshots[best_snapshot_idx], &all_photons[photon_idx].y[1], 1, &neighbor);\n",
    "                                const double dist_sq = SQR(x - neighbor.pos[0]) + SQR(y - neighbor.pos[1]) + SQR(z - neighbor.pos[2]);\n",
    "                                if (dist_sq < SQR(commondata->delta_r_max)) {\n",
    "                                    all_photons[photon_idx].status = TERMINATION_TYPE_DISK;\n",
    "                                    all_photons[photon_idx].nearest_neighbor = neighbor;\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                        if (all_photons[photon_idx].status == ACTIVE) {\n",
    "                            event_detection_manager(all_photons[photon_idx].y_p_p, all_photons[photon_idx].y_p, all_photons[photon_idx].y,\n",
    "                                                    all_photons[photon_idx].affine_param_p_p, all_photons[photon_idx].affine_param_p, all_photons[photon_idx].affine_param,\n",
    "                                                    commondata, &all_photons[photon_idx].on_positive_side_of_window_prev, &all_photons[photon_idx].on_positive_side_of_source_prev,\n",
    "                                                    &all_photons[photon_idx].window_event_data, &all_photons[photon_idx].source_event_data);\n",
    "                            if (all_photons[photon_idx].source_event_data.found) {\n",
    "                                blueprint_data_t temp_blueprint;\n",
    "                                if (handle_source_plane_intersection(&all_photons[photon_idx].source_event_data, commondata, &temp_blueprint)) {\n",
    "                                    all_photons[photon_idx].status = TERMINATION_TYPE_SOURCE_PLANE;\n",
    "                                } else {\n",
    "                                    all_photons[photon_idx].source_event_data.found = false;\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                if (all_photons[photon_idx].status != ACTIVE) {\n",
    "                    #pragma omp atomic\n",
    "                    active_photons--;\n",
    "                } else {\n",
    "                    int new_slot_idx = slot_get_index(&tsm, all_photons[photon_idx].y[0]);\n",
    "                    if (new_slot_idx != -1) {\n",
    "                        slot_add_photon(&tsm.slots[new_slot_idx], photon_idx);\n",
    "                    } else {\n",
    "                        all_photons[photon_idx].status = FAILURE_SLOT_MANAGER_ERROR;\n",
    "                        #pragma omp atomic\n",
    "                        active_photons--;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        } // End while(tsm.slots[i].count > 0)\n",
    "\n",
    "        #pragma omp master\n",
    "        {\n",
    "            double current_time = omp_get_wtime();\n",
    "            double elapsed_time = current_time - start_time;\n",
    "            long int photons_terminated = initial_active_photons - active_photons;\n",
    "            double rays_per_sec = (elapsed_time > 1e-9) ? (double)photons_terminated / elapsed_time : 0.0;\n",
    "            double percent_done = (double)photons_terminated / initial_active_photons * 100.0;\n",
    "            printf(\"\\rEpoch (Slot %d), Active Photons: %ld (%.1f%% done, %.1f rays/sec) \", i, active_photons, percent_done, rays_per_sec);\n",
    "            fflush(stdout);\n",
    "        }\n",
    "    } // End main epoch loop\n",
    "\n",
    "    printf(\"\\nBatch integration finished.\\n\");\n",
    "    if (commondata->debug_mode && fp_debug != NULL) { fclose(fp_debug); }\n",
    "    \n",
    "       if (commondata->perform_conservation_check) {\n",
    "        printf(\"\\n--- Conservation Check Summary ---\\n\");\n",
    "        double max_dE = 0.0, max_dL = 0.0, max_dQ = 0.0;\n",
    "        long int worst_E_idx = -1, worst_L_idx = -1, worst_Q_idx = -1;\n",
    "        double Q_initial_worst = 0.0, Q_final_worst = 0.0;\n",
    "\n",
    "        // --- Open a .txt log file to store all conservation errors ---\n",
    "        FILE *fp_cons_log = fopen(\"conservation_errors.txt\", \"w\");\n",
    "        if (fp_cons_log == NULL) {\n",
    "            fprintf(stderr, \"Warning: Could not open conservation_errors.txt for writing.\\n\");\n",
    "        } else {\n",
    "            // UPDATED HEADER: Added termination_type column\n",
    "            fprintf(fp_cons_log, \"# photon_idx dE_relative dL_relative dQ_relative Q_initial Q_final termination_type final_t\\n\");\n",
    "        }\n",
    "\n",
    "        for (long int i = 0; i < num_rays; ++i) {\n",
    "            double final_E, final_Lx, final_Ly, final_Lz, final_Q;\n",
    "            check_conservation(commondata, params, metric, all_photons[i].y,\n",
    "                               &final_E, &final_Lx, &final_Ly, &final_Lz, &final_Q);\n",
    "\n",
    "            const double dE = (initial_conserved_quantities[i][0] != 0) ? fabs((final_E - initial_conserved_quantities[i][0]) / initial_conserved_quantities[i][0]) : fabs(final_E - initial_conserved_quantities[i][0]);\n",
    "            if (dE > max_dE) { max_dE = dE; worst_E_idx = i; }\n",
    "\n",
    "            double dL; // Declare dL here to be used in the log file\n",
    "            if (commondata->a_spin == 0.0) {\n",
    "                const double L_initial_mag = sqrt(SQR(initial_conserved_quantities[i][1]) + SQR(initial_conserved_quantities[i][2]) + SQR(initial_conserved_quantities[i][3]));\n",
    "                const double L_final_mag = sqrt(SQR(final_Lx) + SQR(final_Ly) + SQR(final_Lz));\n",
    "                dL = (L_initial_mag != 0) ? fabs((L_final_mag - L_initial_mag) / L_initial_mag) : fabs(L_final_mag - L_initial_mag);\n",
    "                if (dL > max_dL) { max_dL = dL; worst_L_idx = i; }\n",
    "            } else {\n",
    "                const double Lz_initial = initial_conserved_quantities[i][3];\n",
    "                dL = (Lz_initial != 0) ? fabs((final_Lz - Lz_initial) / Lz_initial) : fabs(final_Lz - Lz_initial);\n",
    "                if (dL > max_dL) { max_dL = dL; worst_L_idx = i; }\n",
    "            }\n",
    "\n",
    "            const double Q_initial = initial_conserved_quantities[i][4];\n",
    "            const double dQ = (Q_initial != 0) ? fabs((final_Q - Q_initial) / Q_initial) : fabs(final_Q - Q_initial);\n",
    "            if (dQ > max_dQ) {\n",
    "                max_dQ = dQ;\n",
    "                worst_Q_idx = i;\n",
    "                Q_initial_worst = Q_initial;\n",
    "                Q_final_worst = final_Q;\n",
    "            }\n",
    "            \n",
    "            // --- Write the data for the current photon to the log file ---\n",
    "            if (fp_cons_log != NULL) {\n",
    "                // UPDATED FPRINTF: Added the photon status (integer enum value)\n",
    "                fprintf(fp_cons_log, \"%ld %.6e %.6e %.6e %.6e %.6e %d %.6e\\n\",\n",
    "                        i, dE, dL, dQ, Q_initial, final_Q, all_photons[i].status,all_photons[i].y[0]);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // --- Close the log file after the loop is finished ---\n",
    "        if (fp_cons_log != NULL) {\n",
    "            fclose(fp_cons_log);\n",
    "            printf(\"Full conservation error data saved to 'conservation_errors.txt'.\\n\");\n",
    "        }\n",
    "\n",
    "        // The summary printout remains the same\n",
    "        printf(\"Max relative error in Energy (E): %.3e (photon %ld)\\n\", max_dE, worst_E_idx);\n",
    "        if (commondata->a_spin == 0.0) {\n",
    "            printf(\"Max relative error in Angular Momentum (L_tot): %.3e (photon %ld)\\n\", max_dL, worst_L_idx);\n",
    "        } else {\n",
    "            printf(\"Max relative error in Angular Momentum (L_z): %.3e (photon %ld)\\n\", max_dL, worst_L_idx);\n",
    "        }\n",
    "        printf(\"Max relative error in Carter Constant (Q): %.3e (photon %ld)\\n\", max_dQ, worst_Q_idx);\n",
    "        if (worst_Q_idx != -1) {\n",
    "            printf(\" -> For photon %ld: Q_initial = %.6e, Q_final = %.6e\\n\", worst_Q_idx, Q_initial_worst, Q_final_worst);\n",
    "        }\n",
    "        printf(\"------------------------------------\\n\");\n",
    "    }\n",
    "    free(requests); free(metric_results); free(christoffel_results);\n",
    "    if (commondata->perform_conservation_check) { free(initial_conserved_quantities); }\n",
    "\n",
    "    // === FINALIZATION ===\n",
    "    printf(\"Processing final states and populating blueprint buffer...\\n\");\n",
    "    #pragma omp parallel for\n",
    "    for (long int i = 0; i < num_rays; i++) {\n",
    "        results_buffer[i] = calculate_and_fill_blueprint_data_universal(\n",
    "            commondata, params, metric, &all_photons[i],\n",
    "            window_center, n_x, n_y\n",
    "        );\n",
    "    }\n",
    "    free(all_photons);\n",
    "    slot_manager_free(&tsm);\n",
    "    \"\"\"\n",
    "    \n",
    "    cfc.CFunction_dict.pop(\"batch_integrator_numerical\", None)\n",
    "    cfc.register_CFunction(\n",
    "        includes=includes,\n",
    "        desc=desc,\n",
    "        name=name,\n",
    "        params=params,\n",
    "        body=body\n",
    "    )\n",
    "    print(f\"    ... Registered C orchestrator: {name}().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f39aa",
   "metadata": {},
   "source": [
    "<a id='main_entry_point'></a>\n",
    "### 6.C.6: The `main()` C Function Entry Point\n",
    "\n",
    "This function registers the C `main()` function, which serves as the entry point for the entire executable program. In our final architecture, `main()` is a pure **orchestrator**; it contains no physics logic itself. Instead, it calls other functions to manage the entire lifecycle of the simulation.\n",
    "\n",
    "The `main` function performs the following sequence of operations:\n",
    "1.  **Initialize Parameters**: It first calls `commondata_struct_set_to_default()` to set compiled-in defaults, then calls `cmdline_input_and_parfile_parser()` to override them with user-provided values.\n",
    "2.  **Load Global Data**: It calls `load_all_kdtree_snapshots()` to load the entire accretion disk model into memory. If the user has selected a numerical metric, it also calls `initialize_metric_cache()` to load the initial set of metric data files.\n",
    "3.  **Print Banner**: It prints a summary of the simulation parameters to the console.\n",
    "4.  **Execute Integration**: It calls the main `batch_integrator()` orchestrator to run the full simulation.\n",
    "5.  **Save Results**: After the integrator finishes, it saves the final `results_buffer` to the `light_blueprint.bin` file.\n",
    "6.  **Cleanup**: It calls the appropriate helper functions (`unload_kdtree_snapshot`, `free_metric_cache`, etc.) to safely free all allocated memory before exiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9828bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V12_6_light_geodesic.ipynb\n",
    "# This function REPLACES the existing main() (Cell 4661b574).\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Re-registers the main() C function to act as the master dispatcher.\n",
    "    \n",
    "    This definitive version uses the 'use_numerical_pipeline' boolean to select\n",
    "    the correct pipeline and makes the correct 8-argument calls to both\n",
    "    integration orchestrators.\n",
    "    \"\"\"\n",
    "    print(\" -> Updating main() to dispatch with 'use_numerical_pipeline' boolean...\")\n",
    "    \n",
    "    includes = [\"BHaH_defines.h\", \"BHaH_function_prototypes.h\", \"stdio.h\", \"stdlib.h\"]\n",
    "    desc = r\"\"\"@brief Main entry point for the geodesic integrator.\n",
    "    \n",
    "    Acts as the master dispatcher, selecting the appropriate integration\n",
    "    pipeline (analytic vs. numerical) based on the 'use_numerical_pipeline'\n",
    "    parameter. It manages the lifecycle of all major data structures.\n",
    "\"\"\"\n",
    "    cfunc_type = \"int\"\n",
    "    name = \"main\"\n",
    "    params = \"int argc, const char *argv[]\"\n",
    "    \n",
    "   \n",
    "    body = r\"\"\"\n",
    "    // --- Step 1: Initialize Core Data Structures ---\n",
    "    commondata_struct commondata;\n",
    "    params_struct params = {0}; // Initialize to zero; unused in this project but required by signatures.\n",
    "    metric_params metric;\n",
    "\n",
    "    // --- Step 2: Set Default Parameters and Parse User Input ---\n",
    "    commondata_struct_set_to_default(&commondata);\n",
    "    cmdline_input_and_parfile_parser(&commondata, argc, argv);\n",
    "\n",
    "    // --- Step 3: Set Metric Type Enum Based on User Choice ---\n",
    "    // This is used by the analytic workers, even when called from the numerical pipeline's placeholder.\n",
    "    if (commondata.metric_choice == 0) {\n",
    "        metric.type = (commondata.a_spin == 0.0) ? Schwarzschild : Kerr;\n",
    "    } else if (commondata.metric_choice == 1) {\n",
    "        metric.type = Schwarzschild_Standard;\n",
    "    } else {\n",
    "        // For Phase 1, metric_choice=2 is invalid as it's controlled by the boolean.\n",
    "        fprintf(stderr, \"Error: Invalid metric_choice = %d for this validation build.\\n\", commondata.metric_choice);\n",
    "        fprintf(stderr, \"       Please use 0 (Kerr-Schild) or 1 (Standard Schwarzschild).\\n\");\n",
    "        exit(1);\n",
    "    }\n",
    "    \n",
    "    // --- Step 4: Load k-d tree snapshot files (used by both pipelines) ---\n",
    "    CustomKDTree *kdtree_snapshots = NULL;\n",
    "    double *snapshot_times = NULL;\n",
    "    int num_snapshots = 0;\n",
    "    num_snapshots = load_all_kdtree_snapshots(&commondata, &kdtree_snapshots, &snapshot_times);\n",
    "\n",
    "    // --- Step 5: Print Simulation Banner ---\n",
    "    printf(\"=============================================\\n\");\n",
    "    printf(\"  Photon Geodesic Integrator (Batch Mode)  \\n\");\n",
    "    printf(\"=============================================\\n\");\n",
    "    if (commondata.use_numerical_pipeline) {\n",
    "        printf(\"PIPELINE: NUMERICAL (Validation Mode)\\n\");\n",
    "    } else {\n",
    "        printf(\"PIPELINE: ANALYTIC\\n\");\n",
    "    }\n",
    "    printf(\"Metric: %s (a=%.3f)\\n\", (metric.type == Kerr) ? \"Kerr-Schild\" : \"Schwarzschild-Standard\", commondata.a_spin);\n",
    "    printf(\"Scan Resolution: %d x %d\\n\", commondata.scan_density, commondata.scan_density);\n",
    "    if (num_snapshots > 0) {\n",
    "        printf(\"Accretion Disk: ENABLED (%d snapshots loaded)\\n\", num_snapshots);\n",
    "    } else {\n",
    "        printf(\"Accretion Disk: DISABLED (no snapshots found)\\n\");\n",
    "    }\n",
    "\n",
    "    // --- Step 6: Main Logic Dispatcher ---\n",
    "\n",
    "    long int num_rays = (long int)commondata.scan_density * commondata.scan_density;\n",
    "    blueprint_data_t *results_buffer = (blueprint_data_t *)malloc(sizeof(blueprint_data_t) * num_rays);\n",
    "    if (results_buffer == NULL) { exit(1); }\n",
    "\n",
    "    if (commondata.use_numerical_pipeline) {\n",
    "        // --- Call the NUMERICAL pipeline orchestrator with the CORRECT 8 arguments ---\n",
    "        batch_integrator_numerical(&commondata, &params, &metric, num_rays, \n",
    "                                    num_snapshots, kdtree_snapshots, snapshot_times, \n",
    "                                    results_buffer);\n",
    "    } else {\n",
    "        // --- Call the ANALYTIC pipeline orchestrator with the CORRECT 8 arguments ---\n",
    "        //batch_integrator(&commondata, &params, &metric, num_rays, \n",
    "        //                num_snapshots, kdtree_snapshots, snapshot_times, \n",
    "        //                results_buffer);\n",
    "    }\n",
    "\n",
    "    printf(\"Scan finished. Writing %ld ray results to light_blueprint.bin...\\n\", num_rays);\n",
    "    FILE *fp_blueprint = fopen(\"light_blueprint.bin\", \"wb\");\n",
    "    if (fp_blueprint == NULL) { perror(\"Error opening blueprint file\"); exit(1); }\n",
    "    fwrite(results_buffer, sizeof(blueprint_data_t), num_rays, fp_blueprint);\n",
    "    fclose(fp_blueprint);\n",
    "    free(results_buffer);\n",
    "    \n",
    "\n",
    "    // --- Step 7: Cleanup ---\n",
    "    printf(\"Unloading k-d tree snapshots...\\n\");\n",
    "    if (kdtree_snapshots != NULL) {\n",
    "        for (int i = 0; i < num_snapshots; ++i) {\n",
    "            unload_kdtree_snapshot(&kdtree_snapshots[i]);\n",
    "        }\n",
    "        free(kdtree_snapshots);\n",
    "    }\n",
    "    if (snapshot_times != NULL) { free(snapshot_times); }\n",
    "\n",
    "    printf(\"\\nRun complete.\\n\");\n",
    "    return 0;\n",
    "\"\"\"\n",
    "    # Use pop() to ensure we are replacing any old version of this function\n",
    "    cfc.CFunction_dict.pop(name, None)\n",
    "    cfc.register_CFunction(includes=includes, desc=desc, cfunc_type=cfunc_type, name=name, params=params, body=body)\n",
    "    print(\"    ... main() has been updated to dispatch using 'use_numerical_pipeline'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f746be78",
   "metadata": {},
   "source": [
    "<a id='assemble_project'></a>\n",
    "# Step 7: Project Assembly and Compilation\n",
    "\n",
    "This is the final phase of the notebook for C code generation. It brings all the previously defined pieces together to construct the complete, compilable C project. The Python functions in this section do not generate any new physics code; instead, they manage the `nrpy` build system itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda07db",
   "metadata": {},
   "source": [
    "<a id='register_structs'></a>\n",
    "### 7.a: Registering Core C Data Structures\n",
    "\n",
    "This function, `register_core_data_structures`, is one of the most critical in the entire notebook. Its job is to generate the C `typedef`s for all the custom data structures (`struct`s and `enum`s) used by the project.\n",
    "\n",
    "This definitive version has been updated to support the **dual-pipeline architecture**. It now defines the new `photon_request_t` struct for the numerical pipeline's batch processing, as well as a new, leaner `gsl_params_numerical_t` carrier struct. It reuses the existing `connection_struct` for the output of the interpolation engine, avoiding code duplication.\n",
    "\n",
    "It consolidates all type definitions into a single, large C code string. This is crucial because the C compiler requires that a type be defined before it can be used as a member in another struct. By defining everything in one place, we have full control over the declaration order, ensuring that dependencies are met (e.g., `MassiveParticle` is defined before it is used in `PhotonState`). The entire string of C code is then registered with the `BHaH` infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d38cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_core_data_structures():\n",
    "    \"\"\"\n",
    "    Generates and registers all core C data structures. This version is\n",
    "    updated for the self-implemented RKF45 stepper, removing all GSL\n",
    "    dependencies, adding rejection handling, and redesigning the PhotonState struct.\n",
    "    \"\"\"\n",
    "    print(\" -> Registering all core C data structures (Self-Implemented RKF45 v2)...\")\n",
    "\n",
    "    metric_components = [f\"g{i}{j}\" for i in range(4) for j in range(i, 4)]\n",
    "    metric_struct_str = \"typedef struct { double \" + \", \".join(metric_components) + \"; } metric_struct;\"\n",
    "\n",
    "    connection_components = [f\"Gamma4UDD{i}{j}{k}\" for i in range(4) for j in range(4) for k in range(j, 4)]\n",
    "    connections_struct_str = \"typedef struct { double \" + \", \".join(connection_components) + \"; } connection_struct;\"\n",
    "\n",
    "    deriv_components = [f\"g{i}{j}d{k}\" for i in range(4) for j in range(i, 4) for k in range(4)]\n",
    "    deriv_struct_str = \"typedef struct { double \" + \", \".join(deriv_components) + \"; } g4DD_deriv_struct;\"\n",
    "\n",
    "    consolidated_structs_c_code = rf\"\"\"\n",
    "// =============================================================================\n",
    "// Core Metric Structs (Unchanged)\n",
    "// =============================================================================\n",
    "{metric_struct_str}\n",
    "{connections_struct_str}\n",
    "{deriv_struct_str}\n",
    "\n",
    "typedef enum {{ Schwarzschild, Kerr, Numerical, Schwarzschild_Standard }} Metric_t;\n",
    "typedef struct {{ Metric_t type; }} metric_params;\n",
    "\n",
    "// =============================================================================\n",
    "// Event Detection and Plane Crossing Helpers (Unchanged)\n",
    "// =============================================================================\n",
    "typedef struct {{ double n[3]; double d; }} plane_event_params;\n",
    "typedef double (*event_function_t)(const double y[9], void *event_params);\n",
    "static inline double plane_event_func(const double y[9], void *event_params) {{\n",
    "    plane_event_params *params = (plane_event_params *)event_params;\n",
    "    return y[1]*params->n[0] + y[2]*params->n[1] + y[3]*params->n[2] - params->d;\n",
    "}}\n",
    "\n",
    "// =============================================================================\n",
    "// K-d Tree and Particle Data Structures (Unchanged)\n",
    "// =============================================================================\n",
    "typedef struct {{\n",
    "    int id; double pos[3]; double u[4]; double lambda_rest; float j_intrinsic;\n",
    "}} __attribute__((packed)) MassiveParticle;\n",
    "typedef struct {{\n",
    "    int32_t* node_metadata; MassiveParticle* particle_data; uint64_t num_particles;\n",
    "    uint64_t dimensions; void* original_mmap_ptr; size_t file_size;\n",
    "}} CustomKDTree;\n",
    "#define MAX_NEIGHBORS 10\n",
    "typedef struct {{\n",
    "    int indices[MAX_NEIGHBORS]; double sq_distances[MAX_NEIGHBORS]; int count; int n_wanted;\n",
    "}} WinnersCircle;\n",
    "\n",
    "\n",
    "// =============================================================================\n",
    "// Batch Integration and Output Structs (UPDATED)\n",
    "// =============================================================================\n",
    "typedef struct {{ int photon_id; double pos[4]; }} photon_request_t;\n",
    "typedef struct {{ bool found; double lambda_event, t_event; double y_event[9]; }} event_data_struct;\n",
    "\n",
    "// --- UPDATED termination_type_t enum ---\n",
    "// Replaced FAILURE_GSL_ERROR with a more relevant failure code for our stepper.\n",
    "typedef enum {{\n",
    "    FAILURE_PT_TOO_BIG,                 // value = 0\n",
    "    TERMINATION_TYPE_DISK,              // value = 1\n",
    "    TERMINATION_TYPE_SOURCE_PLANE,      // value = 2\n",
    "    TERMINATION_TYPE_CELESTIAL_SPHERE,  // value = 3\n",
    "    ACTIVE,                             // value = 4\n",
    "    FAILURE_RKF45_REJECTION_LIMIT,      // value = 5 (NEW)\n",
    "    TERMINATION_TYPE_FAILURE,           // value = 6 (Generic)\n",
    "    FAILURE_T_MAX_EXCEEDED,             // value = 7\n",
    "    FAILURE_SLOT_MANAGER_ERROR          // value = 8\n",
    "}} termination_type_t;\n",
    "\n",
    "typedef struct {{\n",
    "    termination_type_t termination_type; double y_w, z_w; double stokes_I, lambda_observed;\n",
    "    double y_s, z_s; double final_theta, final_phi; double L_w, t_w, L_s, t_s;\n",
    "}} __attribute__((packed)) blueprint_data_t;\n",
    "#define CACHE_LINE_SIZE 64\n",
    "#define BUNDLE_CAPACITY 16384\n",
    "\n",
    "// --- UPDATED PhotonState Struct ---\n",
    "// Added rejection_retries for robust step control.\n",
    "typedef struct {{\n",
    "    // Core state variables\n",
    "    double y[9];\n",
    "    double affine_param;\n",
    "    double h;\n",
    "    termination_type_t status;\n",
    "    int rejection_retries; // NEW: Counter for repeated step rejections.\n",
    "\n",
    "    // Storage for previous steps (for event detection)\n",
    "    double y_p_p[9], y_p[9];\n",
    "    double affine_param_p_p, affine_param_p;\n",
    "\n",
    "    // Event detection state\n",
    "    bool on_positive_side_of_window_prev, on_positive_side_of_source_prev;\n",
    "    event_data_struct source_event_data, window_event_data;\n",
    "    \n",
    "    // Data for physical interactions\n",
    "    MassiveParticle nearest_neighbor;\n",
    "\n",
    "    char _padding[CACHE_LINE_SIZE - (\n",
    "        sizeof(double)*31 + \n",
    "        sizeof(termination_type_t) + \n",
    "        sizeof(int) + // for rejection_retries\n",
    "        sizeof(bool)*2 + \n",
    "        sizeof(event_data_struct)*2 + \n",
    "        sizeof(MassiveParticle)\n",
    "    ) % CACHE_LINE_SIZE];\n",
    "}} __attribute__((aligned(CACHE_LINE_SIZE))) PhotonState;\n",
    "\"\"\"\n",
    "    Bdefines_h.register_BHaH_defines(\"after_general\", consolidated_structs_c_code)\n",
    "    print(\"    ... Registered all core data structures (Self-Implemented RKF45 v2).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b706fb3",
   "metadata": {},
   "source": [
    "<a id='final_build'></a>\n",
    "### 7.b: Final Build Command\n",
    "\n",
    "This is the main execution block of the notebook. It brings all the previously defined Python functions together and calls them in a precise sequence to generate every file needed for the final, compilable C project.\n",
    "\n",
    "The sequence of operations is critical, as later steps depend on the files and registrations created by earlier ones:\n",
    "\n",
    "1.  **Register All Components**: It calls all the C-generating Python functions that we have defined throughout the notebook. This populates `nrpy`'s internal library (`cfc.CFunction_dict`) with the complete definitions for all our custom C functions. At this stage, no files have been written yet; everything exists only in memory.\n",
    "\n",
    "2.  **Generate Parameter Handling Files**: It calls the necessary functions from the BHaH infrastructure to set up the parameter system:\n",
    "    *   `CPs.write_CodeParameters_h_files()`: Generates `set_CodeParameters.h` and its variants.\n",
    "    *   `CPs.register_CFunctions_params_commondata_struct_set_to_default()`: Registers the C functions that initialize the parameter structs with their compiled-in default values.\n",
    "    *   `cmdline_input_and_parfiles.generate_default_parfile()`: Creates the `project_name.par` file.\n",
    "    *   `cmdline_input_and_parfiles.register_CFunction_cmdline_input_and_parfile_parser()`: Registers the C function that reads the `.par` file and command-line arguments at runtime.\n",
    "\n",
    "3.  **Generate `BHaH_defines.h`**: It calls `Bdefines_h.output_BHaH_defines_h()`. This function scans `nrpy`'s internal library for all registered data structures and writes them into the master C header file, `BHaH_defines.h`.\n",
    "\n",
    "4.  **Copy Helper Files**: It calls `gh.copy_files()` to copy any necessary dependency files from the `nrpy` library installation into our project directory.\n",
    "\n",
    "5.  **Generate C Source, Prototypes, and Makefile**: It calls the final, most important build function, `Makefile.output_CFunctions_function_prototypes_and_construct_Makefile()`. This powerful function performs three tasks at once:\n",
    "    *   It iterates through every C function registered with `nrpy` and writes each one into its own `.c` file.\n",
    "    *   It generates `BHaH_function_prototypes.h`, a header file containing the declarations (prototypes) for all the generated `.c` files.\n",
    "    *   It constructs the `Makefile`, which contains the compilation and linking instructions needed to build the final executable program, including linking against GSL and OpenMP.\n",
    "\n",
    "After this cell is run, a complete, self-contained, and ready-to-compile C project will exist in the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb32a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In file: V12_5_light_geodesic.ipynb\n",
    "# This is the final build cell for the project, with the new self-implemented\n",
    "# adaptive integrator for the numerical pipeline.\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nAssembling and building C project with SELF-IMPLEMENTED RKF45 support...\")\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "# --- THIS IS THE FIX: Clear all global dictionaries for a clean build ---\n",
    "cfc.CFunction_dict.clear()\n",
    "par.glb_extras_dict.clear()\n",
    "\n",
    "# --- Step 1: Register all C-generating functions in the correct dependency order ---\n",
    "print(\" -> Registering C data structures and functions...\")\n",
    "\n",
    "# 1a. Register ALL data structures in a single, consolidated call.\n",
    "register_core_data_structures()\n",
    "\n",
    "# 1b. NEW: Register the Time Slot Manager C code and header.\n",
    "time_slot_manager_helpers()\n",
    "\n",
    "# 1c. Register all k-d tree related C functions.\n",
    "kdtree_loader_and_unloader()\n",
    "filename_sorter()\n",
    "kdtree_loader_orchestrator()\n",
    "kdtree_search_engine()\n",
    "\n",
    "# 1d. Register all numerical metric C engines and helpers.\n",
    "placeholder_interpolator()\n",
    "algebraic_christoffel_worker()\n",
    "\n",
    "# 1e. Register the new self-implemented RKF45 stepper and its helpers.\n",
    "rkf45_helpers_for_header()\n",
    "rkf45_update_and_control_helper()\n",
    "\n",
    "# 1f. Register all remaining C functions for physics and integration.\n",
    "g4DD_kerr_schild()\n",
    "con_kerr_schild()\n",
    "g4DD_schwarzschild_cartesian()\n",
    "con_schwarzschild_cartesian()\n",
    "g4DD_metric()\n",
    "connections()\n",
    "calculate_ode_rhs()\n",
    "calculate_p0_reverse()\n",
    "set_initial_conditions_cartesian()\n",
    "check_conservation()\n",
    "lagrange_interp_engine_generic()\n",
    "event_detection_manager()\n",
    "radiative_transfer_engine()\n",
    "handle_disk_intersection_engine()\n",
    "handle_source_plane_intersection_engine()\n",
    "calculate_and_fill_blueprint_data_universal()\n",
    "\n",
    "# Top-level Orchestrators\n",
    "batch_integrator_numerical()\n",
    "\n",
    "# Final entry point / master dispatcher\n",
    "main()\n",
    "\n",
    "# --- Step 2: Call BHaH infrastructure functions to generate the build system ---\n",
    "print(\" -> Generating BHaH infrastructure files...\")\n",
    "CPs.write_CodeParameters_h_files(project_dir=project_dir)\n",
    "CPs.register_CFunctions_params_commondata_struct_set_to_default()\n",
    "cmdline_input_and_parfiles.generate_default_parfile(project_dir=project_dir, project_name=project_name)\n",
    "\n",
    "cmdline_inputs_list = [\n",
    "    'M_scale', 'a_spin', 'metric_choice','use_numerical_pipeline', \n",
    "    'camera_pos_x', 'camera_pos_y', 'camera_pos_z',\n",
    "    'window_center_x', 'window_center_y', 'window_center_z',\n",
    "    'window_up_vec_x', 'window_up_vec_y', 'window_up_vec_z',\n",
    "    'source_plane_normal_x', 'source_plane_normal_y', 'source_plane_normal_z',\n",
    "    'source_plane_center_x', 'source_plane_center_y', 'source_plane_center_z',\n",
    "    'source_up_vec_x', 'source_up_vec_y', 'source_up_vec_z',\n",
    "    'source_r_min', 'source_r_max',\n",
    "    'scan_density', 'window_size',\n",
    "    'r_escape', 't_integration_max', 't_start', 'p_t_max',\n",
    "    'debug_mode', 'perform_conservation_check',\n",
    "    'slot_manager_t_min', 'slot_manager_delta_t',\n",
    "    'mass_snapshot_every_t', 'delta_r_max',\n",
    "    'disk_bounds_x_min', 'disk_bounds_x_max',\n",
    "    'disk_bounds_y_min', 'disk_bounds_y_max',\n",
    "    'disk_bounds_z_min', 'disk_bounds_z_max',\n",
    "    'rkf45_error_tolerance', 'rkf45_absolute_error_tolerance','rkf45_max_retries', \n",
    "    'rkf45_h_min','rkf45_h_max', 'rkf45_safety_factor', \n",
    "    'numerical_initial_h'\n",
    "]\n",
    "\n",
    "cmdline_input_and_parfiles.register_CFunction_cmdline_input_and_parfile_parser(\n",
    "    project_name=project_name,\n",
    "    cmdline_inputs=cmdline_inputs_list\n",
    ")\n",
    "\n",
    "# --- Step 3: Generate headers, helpers, and the final Makefile ---\n",
    "print(\"\\nGenerating BHaH master header file...\")\n",
    "Bdefines_h.output_BHaH_defines_h(project_dir=project_dir)\n",
    "\n",
    "print(\"Copying required helper files...\")\n",
    "gh.copy_files(\n",
    "    package=\"nrpy.helpers\",\n",
    "    filenames_list=[\"simd_intrinsics.h\"],\n",
    "    project_dir=project_dir,\n",
    "    subdirectory=\"simd\",\n",
    ")\n",
    "\n",
    "print(\"Generating C source files, prototypes, and Makefile...\")\n",
    "# --- THIS IS THE FIX: GSL libraries are no longer needed. ---\n",
    "addl_CFLAGS = [\"-Wall -Wextra -g -fopenmp\"]\n",
    "addl_libraries = [\"-lm -fopenmp\"] # Link against math library and OpenMP\n",
    "\n",
    "Makefile.output_CFunctions_function_prototypes_and_construct_Makefile(\n",
    "    project_dir=project_dir,\n",
    "    project_name=project_name,\n",
    "    exec_or_library_name=project_name,\n",
    "    addl_CFLAGS=addl_CFLAGS,\n",
    "    addl_libraries=addl_libraries,\n",
    ")\n",
    "\n",
    "print(f\"\\nFinished! A C project has been generated in {project_dir}/\")\n",
    "print(f\"To build, navigate to this directory in your terminal and type 'make'.\")\n",
    "print(f\"To run, type './{project_name}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Photon Integrator)",
   "language": "python",
   "name": "photon-integrator-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
